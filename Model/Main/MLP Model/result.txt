MLP with 1 layer: 16 nodes - Result:
Epoch [1/50], Loss: 0.5720, Val Loss: 1.2210
Epoch [2/50], Loss: 0.5499, Val Loss: 1.2172
Epoch [3/50], Loss: 0.3632, Val Loss: 1.1937
Epoch [4/50], Loss: 0.3631, Val Loss: 1.1509
Epoch [5/50], Loss: 0.6957, Val Loss: 1.0685
Epoch [6/50], Loss: 0.4792, Val Loss: 0.9875
Epoch [7/50], Loss: 0.2065, Val Loss: 0.9726
Epoch [8/50], Loss: 0.1782, Val Loss: 0.9551
Epoch [9/50], Loss: 0.4390, Val Loss: 0.9289
Epoch [10/50], Loss: 0.3921, Val Loss: 0.8653
Epoch [11/50], Loss: 0.1666, Val Loss: 0.8460
Epoch [12/50], Loss: 0.2702, Val Loss: 0.8408
Epoch [13/50], Loss: 0.2269, Val Loss: 0.8392
Epoch [14/50], Loss: 0.1540, Val Loss: 0.8200
Epoch [15/50], Loss: 0.2248, Val Loss: 0.8247
Epoch [16/50], Loss: 0.1640, Val Loss: 0.7960
Epoch [17/50], Loss: 0.3455, Val Loss: 0.7996
Epoch [18/50], Loss: 0.4787, Val Loss: 0.7784
Epoch [19/50], Loss: 0.7273, Val Loss: 0.8906
Epoch [20/50], Loss: 0.4956, Val Loss: 0.8926
Epoch [21/50], Loss: 0.7336, Val Loss: 0.9266
Epoch [22/50], Loss: 0.5292, Val Loss: 0.9095
Epoch [23/50], Loss: 0.2231, Val Loss: 1.0226
Epoch [24/50], Loss: 0.8289, Val Loss: 1.0614
Epoch [25/50], Loss: 0.3800, Val Loss: 1.0167
Epoch [26/50], Loss: 0.1139, Val Loss: 1.0512
Epoch [27/50], Loss: 0.1732, Val Loss: 1.0377
Epoch [28/50], Loss: 0.1805, Val Loss: 1.0601
Epoch [29/50], Loss: 0.4479, Val Loss: 1.0389
Epoch [30/50], Loss: 0.2201, Val Loss: 1.0441
Epoch [31/50], Loss: 0.1560, Val Loss: 1.0253
Epoch [32/50], Loss: 0.3021, Val Loss: 1.0166
Epoch [33/50], Loss: 0.1575, Val Loss: 0.9936
Epoch [34/50], Loss: 0.2408, Val Loss: 1.0000
Epoch [35/50], Loss: 0.2276, Val Loss: 0.9813
Epoch [36/50], Loss: 0.2282, Val Loss: 1.0072
Epoch [37/50], Loss: 0.2152, Val Loss: 0.9767
Epoch [38/50], Loss: 0.1694, Val Loss: 0.9586
Epoch [39/50], Loss: 0.1796, Val Loss: 0.9567
Epoch [40/50], Loss: 0.1934, Val Loss: 0.9428
Epoch [41/50], Loss: 0.1353, Val Loss: 0.9613
Epoch [42/50], Loss: 0.3049, Val Loss: 0.9247
Epoch [43/50], Loss: 0.2470, Val Loss: 0.9448
Epoch [44/50], Loss: 0.1675, Val Loss: 0.9422
Epoch [45/50], Loss: 0.1286, Val Loss: 0.9433
Epoch [46/50], Loss: 0.0995, Val Loss: 0.9513
Epoch [47/50], Loss: 0.1478, Val Loss: 0.9356
Epoch [48/50], Loss: 0.1808, Val Loss: 0.9386
Epoch [49/50], Loss: 0.2385, Val Loss: 0.9420
Epoch [50/50], Loss: 0.1014, Val Loss: 0.9435
========================================
Test Loss: 0.9870
MLP with 1 layer: 10 nodes - Result:
Epoch [1/50], Loss: 1.2749, Val Loss: 1.2078
Epoch [2/50], Loss: 1.1547, Val Loss: 1.2304
Epoch [3/50], Loss: 0.3022, Val Loss: 1.0534
Epoch [4/50], Loss: 0.7735, Val Loss: 1.0171
Epoch [5/50], Loss: 0.2299, Val Loss: 0.9997
Epoch [6/50], Loss: 0.3491, Val Loss: 1.0079
Epoch [7/50], Loss: 0.2456, Val Loss: 0.9944
Epoch [8/50], Loss: 0.6283, Val Loss: 0.9896
Epoch [9/50], Loss: 1.7326, Val Loss: 1.0047
Epoch [10/50], Loss: 0.4818, Val Loss: 0.9329
Epoch [11/50], Loss: 0.7515, Val Loss: 1.1229
Epoch [12/50], Loss: 0.7476, Val Loss: 0.9048
Epoch [13/50], Loss: 0.3718, Val Loss: 0.9637
Epoch [14/50], Loss: 0.3701, Val Loss: 1.0442
Epoch [15/50], Loss: 0.2507, Val Loss: 1.0775
Epoch [16/50], Loss: 0.1284, Val Loss: 1.1015
Epoch [17/50], Loss: 0.1702, Val Loss: 1.0933
Epoch [18/50], Loss: 0.0996, Val Loss: 1.0980
Epoch [19/50], Loss: 0.3040, Val Loss: 1.1348
Epoch [20/50], Loss: 0.1667, Val Loss: 1.0730
Epoch [21/50], Loss: 0.1979, Val Loss: 1.0645
Epoch [22/50], Loss: 0.1943, Val Loss: 1.0580
Epoch [23/50], Loss: 0.1834, Val Loss: 1.0610
Epoch [24/50], Loss: 0.1755, Val Loss: 1.0441
Epoch [25/50], Loss: 0.2139, Val Loss: 1.0413
Epoch [26/50], Loss: 0.1650, Val Loss: 1.0670
Epoch [27/50], Loss: 0.1832, Val Loss: 1.0422
Epoch [28/50], Loss: 0.1961, Val Loss: 1.0452
Epoch [29/50], Loss: 0.1650, Val Loss: 1.0183
Epoch [30/50], Loss: 0.2257, Val Loss: 1.0437
Epoch [31/50], Loss: 0.1369, Val Loss: 1.0119
Epoch [32/50], Loss: 0.1289, Val Loss: 1.0639
Epoch [33/50], Loss: 0.3978, Val Loss: 1.0030
Epoch [34/50], Loss: 0.1423, Val Loss: 0.9963
Epoch [35/50], Loss: 0.1688, Val Loss: 0.9805
Epoch [36/50], Loss: 0.0702, Val Loss: 0.9786
Epoch [37/50], Loss: 0.1295, Val Loss: 0.9588
Epoch [38/50], Loss: 0.1437, Val Loss: 0.9775
Epoch [39/50], Loss: 0.3074, Val Loss: 0.9521
Epoch [40/50], Loss: 0.1807, Val Loss: 0.9949
Epoch [41/50], Loss: 0.5066, Val Loss: 0.9584
Epoch [42/50], Loss: 0.1082, Val Loss: 0.9671
Epoch [43/50], Loss: 0.1936, Val Loss: 0.9329
Epoch [44/50], Loss: 0.2123, Val Loss: 0.9267
Epoch [45/50], Loss: 0.1482, Val Loss: 0.9309
Epoch [46/50], Loss: 0.2421, Val Loss: 0.9520
Epoch [47/50], Loss: 0.2123, Val Loss: 0.9313
Epoch [48/50], Loss: 0.1663, Val Loss: 0.9490
Epoch [49/50], Loss: 0.5607, Val Loss: 0.9099
Epoch [50/50], Loss: 0.1598, Val Loss: 0.9314
========================================
Test Loss: 0.9842
MLP with 1 layer: 13 nodes - Result:
Epoch [1/50], Loss: 0.5208, Val Loss: 1.2382
Epoch [2/50], Loss: 0.4050, Val Loss: 1.2471
Epoch [3/50], Loss: 0.3753, Val Loss: 1.1745
Epoch [4/50], Loss: 0.5299, Val Loss: 1.0516
Epoch [5/50], Loss: 0.2519, Val Loss: 1.0037
Epoch [6/50], Loss: 0.6077, Val Loss: 1.0327
Epoch [7/50], Loss: 0.2479, Val Loss: 0.9312
Epoch [8/50], Loss: 0.1432, Val Loss: 0.9390
Epoch [9/50], Loss: 0.2716, Val Loss: 0.9180
Epoch [10/50], Loss: 0.2305, Val Loss: 0.9223
Epoch [11/50], Loss: 0.1739, Val Loss: 0.8904
Epoch [12/50], Loss: 0.2267, Val Loss: 0.8912
Epoch [13/50], Loss: 0.2728, Val Loss: 0.8478
Epoch [14/50], Loss: 0.2510, Val Loss: 0.8456
Epoch [15/50], Loss: 0.1574, Val Loss: 0.8288
Epoch [16/50], Loss: 0.1753, Val Loss: 0.8323
Epoch [17/50], Loss: 0.2993, Val Loss: 0.8097
Epoch [18/50], Loss: 0.0912, Val Loss: 0.8156
Epoch [19/50], Loss: 0.1662, Val Loss: 0.8089
Epoch [20/50], Loss: 0.1300, Val Loss: 0.7931
Epoch [21/50], Loss: 0.2085, Val Loss: 0.7923
Epoch [22/50], Loss: 0.1396, Val Loss: 0.7845
Epoch [23/50], Loss: 0.1537, Val Loss: 0.7827
Epoch [24/50], Loss: 0.1223, Val Loss: 0.7848
Epoch [25/50], Loss: 0.1721, Val Loss: 0.7946
Epoch [26/50], Loss: 0.1377, Val Loss: 0.7779
Epoch [27/50], Loss: 0.1479, Val Loss: 0.7926
Epoch [28/50], Loss: 0.5176, Val Loss: 0.8350
Epoch [29/50], Loss: 0.5496, Val Loss: 0.8386
Epoch [30/50], Loss: 0.4607, Val Loss: 0.8640
Epoch [31/50], Loss: 0.3599, Val Loss: 0.8442
Epoch [32/50], Loss: 0.2641, Val Loss: 0.8532
Epoch [33/50], Loss: 0.0895, Val Loss: 0.8328
Epoch [34/50], Loss: 0.1455, Val Loss: 0.8326
Epoch [35/50], Loss: 0.1318, Val Loss: 0.8343
Epoch [36/50], Loss: 0.2841, Val Loss: 0.8283
Epoch [37/50], Loss: 0.1015, Val Loss: 0.8253
Epoch [38/50], Loss: 0.1502, Val Loss: 0.8579
Epoch [39/50], Loss: 0.1671, Val Loss: 0.8282
Epoch [40/50], Loss: 0.5104, Val Loss: 0.8153
Epoch [41/50], Loss: 0.0897, Val Loss: 0.8129
Epoch [42/50], Loss: 0.0961, Val Loss: 0.8373
Epoch [43/50], Loss: 0.2391, Val Loss: 0.8144
Epoch [44/50], Loss: 0.1556, Val Loss: 0.8195
Epoch [45/50], Loss: 0.1049, Val Loss: 0.7957
Epoch [46/50], Loss: 0.1737, Val Loss: 0.7896
Epoch [47/50], Loss: 0.0784, Val Loss: 0.8010
Epoch [48/50], Loss: 0.1520, Val Loss: 0.8013
Epoch [49/50], Loss: 0.0756, Val Loss: 0.7867
Epoch [50/50], Loss: 0.0988, Val Loss: 0.7898
========================================
Test Loss: 0.8307
MLP with 1 layer: 70 nodes - Result:
Epoch [1/50], Loss: 0.4005, Val Loss: 1.1117
Epoch [2/50], Loss: 0.4314, Val Loss: 0.9937
Epoch [3/50], Loss: 0.7663, Val Loss: 1.0130
Epoch [4/50], Loss: 0.6508, Val Loss: 1.0400
Epoch [5/50], Loss: 0.1869, Val Loss: 0.9402
Epoch [6/50], Loss: 0.6990, Val Loss: 0.9469
Epoch [7/50], Loss: 0.3013, Val Loss: 0.8493
Epoch [8/50], Loss: 0.4552, Val Loss: 0.7848
Epoch [9/50], Loss: 0.3627, Val Loss: 0.8519
Epoch [10/50], Loss: 0.2951, Val Loss: 0.8109
Epoch [11/50], Loss: 0.3594, Val Loss: 0.7837
Epoch [12/50], Loss: 0.2250, Val Loss: 0.7737
Epoch [13/50], Loss: 0.3273, Val Loss: 0.7766
Epoch [14/50], Loss: 0.1655, Val Loss: 0.7705
Epoch [15/50], Loss: 0.1903, Val Loss: 0.7748
Epoch [16/50], Loss: 0.1577, Val Loss: 0.7717
Epoch [17/50], Loss: 0.1447, Val Loss: 0.7548
Epoch [18/50], Loss: 0.2527, Val Loss: 0.7616
Epoch [19/50], Loss: 0.1962, Val Loss: 0.8460
Epoch [20/50], Loss: 0.4338, Val Loss: 0.7659
Epoch [21/50], Loss: 0.0926, Val Loss: 0.7553
Epoch [22/50], Loss: 0.1888, Val Loss: 0.7668
Epoch [23/50], Loss: 0.1038, Val Loss: 0.7849
Epoch [24/50], Loss: 0.3389, Val Loss: 0.7825
Epoch [25/50], Loss: 0.2056, Val Loss: 0.7980
Epoch [26/50], Loss: 0.2920, Val Loss: 0.8077
Epoch [27/50], Loss: 0.1888, Val Loss: 0.8370
Epoch [28/50], Loss: 0.1814, Val Loss: 0.7355
Epoch [29/50], Loss: 0.2639, Val Loss: 0.7665
Epoch [30/50], Loss: 0.3025, Val Loss: 0.7938
Epoch [31/50], Loss: 0.5290, Val Loss: 0.8408
Epoch [32/50], Loss: 0.2725, Val Loss: 0.7858
Epoch [33/50], Loss: 0.1437, Val Loss: 0.7894
Epoch [34/50], Loss: 0.2467, Val Loss: 0.8597
Epoch [35/50], Loss: 0.1237, Val Loss: 0.8192
Epoch [36/50], Loss: 0.2465, Val Loss: 0.8619
Epoch [37/50], Loss: 0.2125, Val Loss: 0.8967
Epoch [38/50], Loss: 0.0876, Val Loss: 0.9382
Epoch [39/50], Loss: 0.3218, Val Loss: 0.8277
Epoch [40/50], Loss: 0.0651, Val Loss: 0.9762
Epoch [41/50], Loss: 0.1861, Val Loss: 0.9782
Epoch [42/50], Loss: 0.1204, Val Loss: 1.0441
Epoch [43/50], Loss: 0.1725, Val Loss: 0.9065
Epoch [44/50], Loss: 0.1778, Val Loss: 0.9674
Epoch [45/50], Loss: 0.1180, Val Loss: 0.8822
Epoch [46/50], Loss: 0.1321, Val Loss: 0.9752
Epoch [47/50], Loss: 0.2402, Val Loss: 0.9181
Epoch [48/50], Loss: 0.1806, Val Loss: 0.9697
Epoch [49/50], Loss: 0.1253, Val Loss: 0.9894
Epoch [50/50], Loss: 0.1401, Val Loss: 0.7595
========================================
Test Loss: 0.8305
MLP with 1 layer: 12 nodes - Result:
Epoch [1/200], Loss: 1.0573, Val Loss: 1.3043
Epoch [2/200], Loss: 1.2810, Val Loss: 1.2409
Epoch [3/200], Loss: 0.2611, Val Loss: 1.2539
Epoch [4/200], Loss: 0.6577, Val Loss: 1.2183
Epoch [5/200], Loss: 0.3010, Val Loss: 1.0635
Epoch [6/200], Loss: 0.2234, Val Loss: 1.0517
Epoch [7/200], Loss: 0.4942, Val Loss: 1.0470
Epoch [8/200], Loss: 0.4692, Val Loss: 0.9630
Epoch [9/200], Loss: 0.2786, Val Loss: 0.9632
Epoch [10/200], Loss: 0.2313, Val Loss: 0.9386
Epoch [11/200], Loss: 0.1561, Val Loss: 0.9162
Epoch [12/200], Loss: 0.2285, Val Loss: 0.8852
Epoch [13/200], Loss: 0.4803, Val Loss: 0.9024
Epoch [14/200], Loss: 0.5232, Val Loss: 0.8605
Epoch [15/200], Loss: 0.4473, Val Loss: 0.8580
Epoch [16/200], Loss: 0.1776, Val Loss: 0.8558
Epoch [17/200], Loss: 0.1569, Val Loss: 0.8445
Epoch [18/200], Loss: 0.1922, Val Loss: 0.8285
Epoch [19/200], Loss: 0.2282, Val Loss: 0.8141
Epoch [20/200], Loss: 0.1707, Val Loss: 0.8145
Epoch [21/200], Loss: 0.2416, Val Loss: 0.7928
Epoch [22/200], Loss: 0.7195, Val Loss: 1.0125
Epoch [23/200], Loss: 0.2738, Val Loss: 1.0519
Epoch [24/200], Loss: 0.2642, Val Loss: 1.0064
Epoch [25/200], Loss: 0.2228, Val Loss: 1.0161
Epoch [26/200], Loss: 0.4578, Val Loss: 1.1349
Epoch [27/200], Loss: 0.6692, Val Loss: 1.0749
Epoch [28/200], Loss: 0.2320, Val Loss: 1.1520
Epoch [29/200], Loss: 0.3284, Val Loss: 1.1790
Epoch [30/200], Loss: 0.1850, Val Loss: 1.1794
Epoch [31/200], Loss: 0.2050, Val Loss: 1.1781
Epoch [32/200], Loss: 0.3012, Val Loss: 1.1277
Epoch [33/200], Loss: 0.3554, Val Loss: 1.1401
Epoch [34/200], Loss: 0.2228, Val Loss: 1.1262
Epoch [35/200], Loss: 0.1690, Val Loss: 1.1260
Epoch [36/200], Loss: 0.2629, Val Loss: 1.1125
Epoch [37/200], Loss: 0.3168, Val Loss: 1.1472
Epoch [38/200], Loss: 0.1440, Val Loss: 1.0989
Epoch [39/200], Loss: 0.1455, Val Loss: 1.1301
Epoch [40/200], Loss: 0.2197, Val Loss: 1.1060
Epoch [41/200], Loss: 0.1891, Val Loss: 1.0536
Epoch [42/200], Loss: 0.2155, Val Loss: 1.1197
Epoch [43/200], Loss: 0.2026, Val Loss: 1.0510
Epoch [44/200], Loss: 0.2186, Val Loss: 1.0874
Epoch [45/200], Loss: 0.1928, Val Loss: 1.0882
Epoch [46/200], Loss: 0.1214, Val Loss: 1.0751
Epoch [47/200], Loss: 0.2606, Val Loss: 1.0774
Epoch [48/200], Loss: 0.1078, Val Loss: 1.0985
Epoch [49/200], Loss: 0.1041, Val Loss: 1.0730
Epoch [50/200], Loss: 0.1409, Val Loss: 1.1589
Epoch [51/200], Loss: 0.1178, Val Loss: 1.0608
Epoch [52/200], Loss: 0.5907, Val Loss: 1.0364
Epoch [53/200], Loss: 0.2022, Val Loss: 1.1232
Epoch [54/200], Loss: 0.2154, Val Loss: 1.1002
Epoch [55/200], Loss: 0.2536, Val Loss: 1.1198
Epoch [56/200], Loss: 0.1526, Val Loss: 1.0765
Epoch [57/200], Loss: 0.2060, Val Loss: 1.0892
Epoch [58/200], Loss: 0.3483, Val Loss: 1.1443
Epoch [59/200], Loss: 0.1854, Val Loss: 1.1253
Epoch [60/200], Loss: 0.1036, Val Loss: 1.1632
Epoch [61/200], Loss: 0.0929, Val Loss: 1.1430
Epoch [62/200], Loss: 0.1536, Val Loss: 1.1967
Epoch [63/200], Loss: 0.1002, Val Loss: 1.1795
Epoch [64/200], Loss: 0.2031, Val Loss: 1.2051
Epoch [65/200], Loss: 0.2124, Val Loss: 1.1973
Epoch [66/200], Loss: 0.2038, Val Loss: 1.2181
Epoch [67/200], Loss: 0.1231, Val Loss: 1.2604
Epoch [68/200], Loss: 0.1849, Val Loss: 1.1729
Epoch [69/200], Loss: 0.1402, Val Loss: 1.1825
Epoch [70/200], Loss: 0.1448, Val Loss: 1.2546
Epoch [71/200], Loss: 0.1630, Val Loss: 1.1967
Epoch [72/200], Loss: 0.1091, Val Loss: 1.2135
Epoch [73/200], Loss: 0.1796, Val Loss: 1.1944
Epoch [74/200], Loss: 0.1077, Val Loss: 1.2006
Epoch [75/200], Loss: 0.1194, Val Loss: 1.2381
Epoch [76/200], Loss: 0.1566, Val Loss: 1.2162
Epoch [77/200], Loss: 0.1580, Val Loss: 1.1793
Epoch [78/200], Loss: 0.2382, Val Loss: 1.1971
Epoch [79/200], Loss: 0.0943, Val Loss: 1.1562
Epoch [80/200], Loss: 0.2236, Val Loss: 1.2625
Epoch [81/200], Loss: 0.4407, Val Loss: 1.2876
Epoch [82/200], Loss: 0.0815, Val Loss: 1.2413
Epoch [83/200], Loss: 1.7577, Val Loss: 1.1882
Epoch [84/200], Loss: 0.1190, Val Loss: 1.2223
Epoch [85/200], Loss: 0.2065, Val Loss: 1.2432
Epoch [86/200], Loss: 0.2149, Val Loss: 1.1807
Epoch [87/200], Loss: 0.3824, Val Loss: 1.2119
Epoch [88/200], Loss: 0.0873, Val Loss: 1.1503
Epoch [89/200], Loss: 0.2134, Val Loss: 1.2475
Epoch [90/200], Loss: 0.1380, Val Loss: 1.2430
Epoch [91/200], Loss: 0.1944, Val Loss: 1.2661
Epoch [92/200], Loss: 0.5273, Val Loss: 1.2413
Epoch [93/200], Loss: 0.1571, Val Loss: 1.2533
Epoch [94/200], Loss: 0.2012, Val Loss: 1.2636
Epoch [95/200], Loss: 0.2071, Val Loss: 1.3113
Epoch [96/200], Loss: 0.1783, Val Loss: 1.3710
Epoch [97/200], Loss: 0.1256, Val Loss: 1.3583
Epoch [98/200], Loss: 0.1025, Val Loss: 1.4355
Epoch [99/200], Loss: 0.0732, Val Loss: 1.3685
Epoch [100/200], Loss: 0.2370, Val Loss: 1.3999
Epoch [101/200], Loss: 0.4445, Val Loss: 1.3297
Epoch [102/200], Loss: 0.3428, Val Loss: 1.3580
Epoch [103/200], Loss: 0.1321, Val Loss: 1.3048
Epoch [104/200], Loss: 0.1026, Val Loss: 1.3328
Epoch [105/200], Loss: 0.1305, Val Loss: 1.3677
Epoch [106/200], Loss: 0.1320, Val Loss: 1.4574
Epoch [107/200], Loss: 0.1046, Val Loss: 1.3694
Epoch [108/200], Loss: 0.3144, Val Loss: 1.4788
Epoch [109/200], Loss: 0.1385, Val Loss: 1.3869
Epoch [110/200], Loss: 0.0625, Val Loss: 1.4542
Epoch [111/200], Loss: 0.1924, Val Loss: 1.3791
Epoch [112/200], Loss: 0.1474, Val Loss: 1.4191
Epoch [113/200], Loss: 0.2850, Val Loss: 1.3648
Epoch [114/200], Loss: 0.1119, Val Loss: 1.4386
Epoch [115/200], Loss: 0.1804, Val Loss: 1.3707
Epoch [116/200], Loss: 0.1249, Val Loss: 1.4180
Epoch [117/200], Loss: 0.1893, Val Loss: 1.3840
Epoch [118/200], Loss: 0.0889, Val Loss: 1.4781
Epoch [119/200], Loss: 0.2789, Val Loss: 1.4347
Epoch [120/200], Loss: 0.6117, Val Loss: 1.4817
Epoch [121/200], Loss: 0.0979, Val Loss: 1.6036
Epoch [122/200], Loss: 0.1821, Val Loss: 1.4481
Epoch [123/200], Loss: 0.0657, Val Loss: 1.4950
Epoch [124/200], Loss: 0.4538, Val Loss: 1.5648
Epoch [125/200], Loss: 0.1211, Val Loss: 1.5001
Epoch [126/200], Loss: 0.1249, Val Loss: 1.4118
Epoch [127/200], Loss: 0.2143, Val Loss: 1.5726
Epoch [128/200], Loss: 0.1621, Val Loss: 1.5749
Epoch [129/200], Loss: 0.1197, Val Loss: 1.5148
Epoch [130/200], Loss: 0.1116, Val Loss: 1.4939
Epoch [131/200], Loss: 0.1275, Val Loss: 1.4750
Epoch [132/200], Loss: 0.1619, Val Loss: 1.5781
Epoch [133/200], Loss: 0.2377, Val Loss: 1.4914
Epoch [134/200], Loss: 0.1104, Val Loss: 1.5218
Epoch [135/200], Loss: 0.1541, Val Loss: 1.5513
Epoch [136/200], Loss: 0.1231, Val Loss: 1.4772
Epoch [137/200], Loss: 0.1368, Val Loss: 1.5887
Epoch [138/200], Loss: 0.1385, Val Loss: 1.5493
Epoch [139/200], Loss: 0.2200, Val Loss: 1.5055
Epoch [140/200], Loss: 0.0712, Val Loss: 1.5538
Epoch [141/200], Loss: 0.0656, Val Loss: 1.5504
Epoch [142/200], Loss: 0.1330, Val Loss: 1.4984
Epoch [143/200], Loss: 0.2291, Val Loss: 1.5504
Epoch [144/200], Loss: 0.1423, Val Loss: 1.4252
Epoch [145/200], Loss: 0.1120, Val Loss: 1.5260
Epoch [146/200], Loss: 0.2140, Val Loss: 1.5837
Epoch [147/200], Loss: 0.0878, Val Loss: 1.6481
Epoch [148/200], Loss: 0.2596, Val Loss: 1.5856
Epoch [149/200], Loss: 0.8103, Val Loss: 3.0788
Epoch [150/200], Loss: 0.3463, Val Loss: 2.7796
Epoch [151/200], Loss: 0.2538, Val Loss: 3.1425
Epoch [152/200], Loss: 0.2168, Val Loss: 2.9601
Epoch [153/200], Loss: 0.1019, Val Loss: 2.9147
Epoch [154/200], Loss: 0.1360, Val Loss: 2.9539
Epoch [155/200], Loss: 0.0782, Val Loss: 2.9348
Epoch [156/200], Loss: 0.1742, Val Loss: 2.8385
Epoch [157/200], Loss: 0.1728, Val Loss: 2.8163
Epoch [158/200], Loss: 0.1383, Val Loss: 2.7081
Epoch [159/200], Loss: 0.1295, Val Loss: 2.8457
Epoch [160/200], Loss: 0.1973, Val Loss: 2.7817
Epoch [161/200], Loss: 0.1111, Val Loss: 2.8272
Epoch [162/200], Loss: 0.1158, Val Loss: 2.8653
Epoch [163/200], Loss: 0.2250, Val Loss: 2.8579
Epoch [164/200], Loss: 0.0948, Val Loss: 2.7348
Epoch [165/200], Loss: 0.2529, Val Loss: 2.8660
Epoch [166/200], Loss: 0.1831, Val Loss: 2.8881
Epoch [167/200], Loss: 0.1107, Val Loss: 2.9648
Epoch [168/200], Loss: 0.1880, Val Loss: 2.8142
Epoch [169/200], Loss: 0.1207, Val Loss: 2.7296
Epoch [170/200], Loss: 0.1392, Val Loss: 2.7248
Epoch [171/200], Loss: 0.1533, Val Loss: 2.6209
Epoch [172/200], Loss: 0.0962, Val Loss: 2.8054
Epoch [173/200], Loss: 0.0915, Val Loss: 2.5076
Epoch [174/200], Loss: 0.0811, Val Loss: 2.3637
Epoch [175/200], Loss: 0.1669, Val Loss: 2.5569
Epoch [176/200], Loss: 0.3043, Val Loss: 2.7155
Epoch [177/200], Loss: 0.2068, Val Loss: 2.6646
Epoch [178/200], Loss: 0.1081, Val Loss: 2.6939
Epoch [179/200], Loss: 0.2041, Val Loss: 2.5064
Epoch [180/200], Loss: 0.0896, Val Loss: 2.6469
Epoch [181/200], Loss: 0.1379, Val Loss: 2.6030
Epoch [182/200], Loss: 0.3156, Val Loss: 2.5795
Epoch [183/200], Loss: 0.2080, Val Loss: 2.4702
Epoch [184/200], Loss: 0.0885, Val Loss: 2.6451
Epoch [185/200], Loss: 0.1304, Val Loss: 2.8425
Epoch [186/200], Loss: 0.1023, Val Loss: 2.7342
Epoch [187/200], Loss: 0.1495, Val Loss: 2.4240
Epoch [188/200], Loss: 0.4355, Val Loss: 2.9174
Epoch [189/200], Loss: 0.1945, Val Loss: 2.6048
Epoch [190/200], Loss: 0.1330, Val Loss: 2.5963
Epoch [191/200], Loss: 0.1352, Val Loss: 2.5060
Epoch [192/200], Loss: 0.1392, Val Loss: 2.4700
Epoch [193/200], Loss: 0.3229, Val Loss: 2.6831
Epoch [194/200], Loss: 0.2350, Val Loss: 3.1281
Epoch [195/200], Loss: 0.0837, Val Loss: 2.5892
Epoch [196/200], Loss: 0.0893, Val Loss: 2.5443
Epoch [197/200], Loss: 0.1289, Val Loss: 3.1392
Epoch [198/200], Loss: 0.1227, Val Loss: 2.5972
Epoch [199/200], Loss: 0.0804, Val Loss: 2.5766
Epoch [200/200], Loss: 0.2385, Val Loss: 2.7391
========================================
Test Loss: 2.6176
MLP with 1 layer: 100 nodes - Result:
Epoch [1/50], Loss: 0.6778, Val Loss: 1.1397
Epoch [2/50], Loss: 0.8272, Val Loss: 1.0280
Epoch [3/50], Loss: 0.4766, Val Loss: 1.0002
Epoch [4/50], Loss: 0.5517, Val Loss: 1.0419
Epoch [5/50], Loss: 0.3731, Val Loss: 0.8955
Epoch [6/50], Loss: 0.3953, Val Loss: 0.8831
Epoch [7/50], Loss: 0.2657, Val Loss: 0.8421
Epoch [8/50], Loss: 0.5222, Val Loss: 0.8822
Epoch [9/50], Loss: 0.8592, Val Loss: 0.8176
Epoch [10/50], Loss: 0.4523, Val Loss: 0.7915
Epoch [11/50], Loss: 0.1397, Val Loss: 0.7855
Epoch [12/50], Loss: 0.2575, Val Loss: 0.7698
Epoch [13/50], Loss: 0.2808, Val Loss: 0.8028
Epoch [14/50], Loss: 0.4092, Val Loss: 0.7486
Epoch [15/50], Loss: 0.2499, Val Loss: 0.7459
Epoch [16/50], Loss: 0.1608, Val Loss: 0.7625
Epoch [17/50], Loss: 0.4337, Val Loss: 0.7438
Epoch [18/50], Loss: 0.1712, Val Loss: 0.7272
Epoch [19/50], Loss: 0.2460, Val Loss: 0.7342
Epoch [20/50], Loss: 0.1727, Val Loss: 0.7252
Epoch [21/50], Loss: 0.1466, Val Loss: 0.7372
Epoch [22/50], Loss: 0.2976, Val Loss: 0.7208
Epoch [23/50], Loss: 0.1126, Val Loss: 0.7308
Epoch [24/50], Loss: 0.2531, Val Loss: 0.7138
Epoch [25/50], Loss: 0.4963, Val Loss: 0.7006
Epoch [26/50], Loss: 0.1858, Val Loss: 0.6908
Epoch [27/50], Loss: 0.1823, Val Loss: 0.7028
Epoch [28/50], Loss: 0.1486, Val Loss: 0.7173
Epoch [29/50], Loss: 0.4301, Val Loss: 0.7133
Epoch [30/50], Loss: 0.1346, Val Loss: 0.7217
Epoch [31/50], Loss: 0.5551, Val Loss: 0.7394
Epoch [32/50], Loss: 0.2608, Val Loss: 0.7219
Epoch [33/50], Loss: 0.1870, Val Loss: 0.7041
Epoch [34/50], Loss: 0.3946, Val Loss: 0.7237
Epoch [35/50], Loss: 0.1524, Val Loss: 0.6837
Epoch [36/50], Loss: 0.3041, Val Loss: 0.7002
Epoch [37/50], Loss: 0.0905, Val Loss: 0.6933
Epoch [38/50], Loss: 0.2166, Val Loss: 0.6766
Epoch [39/50], Loss: 0.1321, Val Loss: 0.7267
Epoch [40/50], Loss: 0.1688, Val Loss: 0.6754
Epoch [41/50], Loss: 0.1547, Val Loss: 0.6796
Epoch [42/50], Loss: 0.4721, Val Loss: 0.7083
Epoch [43/50], Loss: 0.2532, Val Loss: 0.7273
Epoch [44/50], Loss: 0.3015, Val Loss: 0.7175
Epoch [45/50], Loss: 0.8018, Val Loss: 1.6384
Epoch [46/50], Loss: 0.5208, Val Loss: 1.4487
Epoch [47/50], Loss: 0.4792, Val Loss: 1.7586
Epoch [48/50], Loss: 0.2741, Val Loss: 1.1115
Epoch [49/50], Loss: 0.3196, Val Loss: 0.9873
Epoch [50/50], Loss: 0.0906, Val Loss: 1.0452
========================================
Test Loss: 1.0764
MLP with layer size: 1 - Result:
MLP with layer size: 16 - Result:
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [2/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [3/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [4/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [5/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [6/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [7/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [8/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [9/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [10/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [11/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [12/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [13/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [14/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [15/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [16/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [17/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [18/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [19/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [20/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [21/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [22/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [23/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [24/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [25/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [26/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [27/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [28/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [29/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [30/50], Loss: 0.0000, Val Loss: 0.0000
Epoch [31/50], Loss: 0.0000, Val Loss: 0.0000
Early stopping at epoch 31========================================
Test Loss: 0.2882
========================================
Test Loss: 0.0000
========================================
Test Loss: 1.3339
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 1.1862, Val Loss: 1.3261
Epoch [2/50], Loss: 1.2280, Val Loss: 1.3267
Epoch [3/50], Loss: 1.1720, Val Loss: 1.3212
Epoch [4/50], Loss: 1.0920, Val Loss: 1.3423
Epoch [5/50], Loss: 1.1544, Val Loss: 1.3289
Epoch [6/50], Loss: 1.1702, Val Loss: 1.3261
Epoch [7/50], Loss: 1.2081, Val Loss: 1.3318
Epoch [8/50], Loss: 1.1058, Val Loss: 1.3305
Epoch [9/50], Loss: 1.2275, Val Loss: 1.3302
Epoch [10/50], Loss: 1.1917, Val Loss: 1.3089
Epoch [11/50], Loss: 1.1996, Val Loss: 1.3129
Epoch [12/50], Loss: 1.0809, Val Loss: 1.3146
Epoch [13/50], Loss: 1.1046, Val Loss: 1.3160
Epoch [14/50], Loss: 1.1106, Val Loss: 1.3216
Epoch [15/50], Loss: 1.4710, Val Loss: 1.3346
Epoch [16/50], Loss: 1.0922, Val Loss: 1.3045
Epoch [17/50], Loss: 1.0640, Val Loss: 1.3179
Epoch [18/50], Loss: 1.2183, Val Loss: 1.3258
Epoch [19/50], Loss: 1.1045, Val Loss: 1.3200
Epoch [20/50], Loss: 1.1081, Val Loss: 1.3221
Epoch [21/50], Loss: 1.1946, Val Loss: 1.3010
Epoch [22/50], Loss: 1.0550, Val Loss: 1.3254
Epoch [23/50], Loss: 1.1409, Val Loss: 1.3127
Epoch [24/50], Loss: 1.1148, Val Loss: 1.3213
Epoch [25/50], Loss: 1.1169, Val Loss: 1.3176
Epoch [26/50], Loss: 1.1139, Val Loss: 1.3278
Epoch [27/50], Loss: 1.1243, Val Loss: 1.3194
Epoch [28/50], Loss: 1.3607, Val Loss: 1.3015
Epoch [29/50], Loss: 1.1359, Val Loss: 1.3208
Epoch [30/50], Loss: 1.1822, Val Loss: 1.3070
Early stopping at epoch 30========================================
Test Loss: 1.3162
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 1.9917, Val Loss: 1.0179
Epoch [2/50], Loss: 4.5653, Val Loss: 0.9169
Epoch [3/50], Loss: 0.2869, Val Loss: 0.7936
Epoch [4/50], Loss: 0.3408, Val Loss: 0.7299
Epoch [5/50], Loss: 0.4320, Val Loss: 0.6588
Epoch [6/50], Loss: 0.4361, Val Loss: 0.6601
Epoch [7/50], Loss: 0.3347, Val Loss: 0.7421
Epoch [8/50], Loss: 0.2641, Val Loss: 0.6772
Epoch [9/50], Loss: 0.4471, Val Loss: 0.6997
Epoch [10/50], Loss: 0.5103, Val Loss: 0.6524
Epoch [11/50], Loss: 0.3172, Val Loss: 0.6559
Epoch [12/50], Loss: 0.0840, Val Loss: 0.6892
Epoch [13/50], Loss: 0.2168, Val Loss: 0.8277
Epoch [14/50], Loss: 0.2506, Val Loss: 0.6944
Epoch [15/50], Loss: 0.1312, Val Loss: 0.7092
Epoch [16/50], Loss: 0.0906, Val Loss: 0.6988
Epoch [17/50], Loss: 0.1299, Val Loss: 0.6811
Epoch [18/50], Loss: 0.2078, Val Loss: 0.6776
Epoch [19/50], Loss: 0.3241, Val Loss: 0.6934
Early stopping at epoch 19========================================
Test Loss: 2.6948
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 1.6739, Val Loss: 1.7830
Epoch [2/50], Loss: 1.8685, Val Loss: 1.1901
Epoch [3/50], Loss: 1.3424, Val Loss: 1.2033
Epoch [4/50], Loss: 0.6829, Val Loss: 0.7095
Epoch [5/50], Loss: 0.6723, Val Loss: 0.5085
Epoch [6/50], Loss: 0.6800, Val Loss: 0.4023
Epoch [7/50], Loss: 0.1738, Val Loss: 0.3424
Epoch [8/50], Loss: 0.3121, Val Loss: 0.4485
Epoch [9/50], Loss: 0.3424, Val Loss: 0.3894
Epoch [10/50], Loss: 0.3021, Val Loss: 0.3448
Epoch [11/50], Loss: 0.3566, Val Loss: 0.3204
Epoch [12/50], Loss: 0.4777, Val Loss: 0.3272
Epoch [13/50], Loss: 0.0888, Val Loss: 0.3020
Epoch [14/50], Loss: 0.2055, Val Loss: 0.2971
Epoch [15/50], Loss: 0.2347, Val Loss: 0.2894
Epoch [16/50], Loss: 0.0875, Val Loss: 0.2843
Epoch [17/50], Loss: 0.1338, Val Loss: 0.2973
Epoch [18/50], Loss: 0.2209, Val Loss: 0.2993
Epoch [19/50], Loss: 0.1749, Val Loss: 0.2904
Epoch [20/50], Loss: 0.3834, Val Loss: 0.2881
Epoch [21/50], Loss: 0.2522, Val Loss: 0.2875
Epoch [22/50], Loss: 0.1893, Val Loss: 0.3007
Epoch [23/50], Loss: 0.0828, Val Loss: 0.2999
Epoch [24/50], Loss: 0.3317, Val Loss: 0.2778
Epoch [25/50], Loss: 0.3695, Val Loss: 0.2813
Epoch [26/50], Loss: 0.2151, Val Loss: 0.2736
Epoch [27/50], Loss: 0.2437, Val Loss: 0.2947
Epoch [28/50], Loss: 0.1655, Val Loss: 0.2818
Epoch [29/50], Loss: 0.0674, Val Loss: 0.2781
Epoch [30/50], Loss: 0.1013, Val Loss: 0.2779
Epoch [31/50], Loss: 0.0662, Val Loss: 0.2791
Epoch [32/50], Loss: 0.1840, Val Loss: 0.3104
Epoch [33/50], Loss: 0.4097, Val Loss: 0.2818
Epoch [34/50], Loss: 0.0999, Val Loss: 0.2692
Epoch [35/50], Loss: 0.1609, Val Loss: 0.2755
Epoch [36/50], Loss: 0.1659, Val Loss: 0.2874
Epoch [37/50], Loss: 0.2602, Val Loss: 0.2698
Epoch [38/50], Loss: 0.1299, Val Loss: 0.2750
Epoch [39/50], Loss: 0.4074, Val Loss: 0.2775
Epoch [40/50], Loss: 0.1472, Val Loss: 0.2885
Epoch [41/50], Loss: 0.1155, Val Loss: 0.2725
Epoch [42/50], Loss: 0.2525, Val Loss: 0.2782
Epoch [43/50], Loss: 0.1813, Val Loss: 0.2856
Early stopping at epoch 43========================================
Test Loss: 1.3200
MLP with 1 layer: 128 nodes - Result:
MLP with 1 layer: 128 nodes - Result:
Epoch [1/50], Loss: 2.4263, Val Loss: 1.5601
Epoch [2/50], Loss: 0.5256, Val Loss: 1.4689
Epoch [3/50], Loss: 1.3249, Val Loss: 1.5815
Epoch [4/50], Loss: 0.4350, Val Loss: 1.6383
Epoch [5/50], Loss: 0.5317, Val Loss: 1.6419
Epoch [6/50], Loss: 0.5032, Val Loss: 1.7856
Epoch [7/50], Loss: 0.3151, Val Loss: 1.8662
Epoch [8/50], Loss: 0.6031, Val Loss: 1.9014
Epoch [9/50], Loss: 0.4775, Val Loss: 2.0740
Epoch [10/50], Loss: 0.1704, Val Loss: 2.1474
Epoch [11/50], Loss: 0.1429, Val Loss: 2.2135
Epoch [12/50], Loss: 0.3429, Val Loss: 2.3117
Epoch [13/50], Loss: 0.2915, Val Loss: 2.3763
Epoch [14/50], Loss: 0.2430, Val Loss: 2.5419
Epoch [15/50], Loss: 0.2620, Val Loss: 2.6310
Epoch [16/50], Loss: 0.2178, Val Loss: 2.6812
MLP with 1 layer: 128 nodes - Result:
Epoch [1/50], Loss: 2.0769, Val Loss: 2.1919
Epoch [2/50], Loss: 2.0538, Val Loss: 2.1927
Epoch [3/50], Loss: 1.3499, Val Loss: 2.1927
Epoch [4/50], Loss: 2.5444, Val Loss: 2.2082
Epoch [5/50], Loss: 1.4341, Val Loss: 2.2001
Epoch [6/50], Loss: 2.0997, Val Loss: 2.2664
Epoch [7/50], Loss: 2.7903, Val Loss: 2.1940
Epoch [8/50], Loss: 3.1740, Val Loss: 2.1998
Epoch [9/50], Loss: 3.0726, Val Loss: 2.1927
Epoch [10/50], Loss: 3.3005, Val Loss: 2.1927
Epoch [11/50], Loss: 1.5761, Val Loss: 2.1935
Epoch [12/50], Loss: 4.5494, Val Loss: 2.1921
Epoch [13/50], Loss: 1.7722, Val Loss: 2.1927
Epoch [14/50], Loss: 1.6122, Val Loss: 2.1995
Epoch [15/50], Loss: 1.8264, Val Loss: 2.1930
Epoch [16/50], Loss: 1.5447, Val Loss: 2.1933
Epoch [17/50], Loss: 0.9930, Val Loss: 2.1926
Epoch [18/50], Loss: 1.0335, Val Loss: 2.1940
Epoch [19/50], Loss: 2.0908, Val Loss: 2.2179
Epoch [20/50], Loss: 1.5284, Val Loss: 2.1943
Epoch [21/50], Loss: 1.6679, Val Loss: 2.1947
Epoch [22/50], Loss: 2.4931, Val Loss: 2.1923
Epoch [23/50], Loss: 1.4911, Val Loss: 2.1933
MLP with 1 layer: 128 nodes - Result:
Epoch [1/50], Loss: 1782570256.2411, Val Loss: 2217752279.5912
Epoch [2/50], Loss: 1950724104.4242, Val Loss: 2195913626.8365
Epoch [3/50], Loss: 2183113323.6019, Val Loss: 2192408925.6491
Epoch [4/50], Loss: 781909727.6218, Val Loss: 2193105096.1930
Epoch [5/50], Loss: 824902399.9793, Val Loss: 2195228617.9160
Epoch [6/50], Loss: 1735166364.0890, Val Loss: 2196825078.9239
Epoch [7/50], Loss: 1047349070.8627, Val Loss: 2205304112.2686
Epoch [8/50], Loss: 1161400879.4449, Val Loss: 2193445561.1723
Epoch [9/50], Loss: 1337295750.0812, Val Loss: 2933915117.0912
Epoch [10/50], Loss: 3309265487.5713, Val Loss: 2192457405.2690
MLP with layer size: [64, 32, 16] - Result:
MLP with layer size: [64, 32, 16] - Result:
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 1.4343, Val Loss: 1.1516
Epoch [2/50], Loss: 0.3677, Val Loss: 1.1124
Epoch [3/50], Loss: 0.4568, Val Loss: 0.8202
Epoch [4/50], Loss: 0.8340, Val Loss: 0.4480
Epoch [5/50], Loss: 0.4849, Val Loss: 0.3828
Epoch [6/50], Loss: 0.4127, Val Loss: 0.4681
Epoch [7/50], Loss: 0.0928, Val Loss: 0.3754
Epoch [8/50], Loss: 0.3513, Val Loss: 0.3364
Epoch [9/50], Loss: 0.1482, Val Loss: 0.3491
Epoch [10/50], Loss: 0.0892, Val Loss: 0.3158
Epoch [11/50], Loss: 0.1525, Val Loss: 0.3155
Epoch [12/50], Loss: 0.6083, Val Loss: 0.3484
Epoch [13/50], Loss: 0.1294, Val Loss: 0.3132
Epoch [14/50], Loss: 0.1106, Val Loss: 0.3224
Epoch [15/50], Loss: 0.2971, Val Loss: 0.3048
Epoch [16/50], Loss: 0.1986, Val Loss: 0.2918
Epoch [17/50], Loss: 0.1043, Val Loss: 0.2999
Epoch [18/50], Loss: 0.1339, Val Loss: 0.3038
Epoch [19/50], Loss: 0.2199, Val Loss: 0.2950
Epoch [20/50], Loss: 0.1191, Val Loss: 0.2735
Epoch [21/50], Loss: 0.2015, Val Loss: 0.2676
Epoch [22/50], Loss: 0.0891, Val Loss: 0.2764
Epoch [23/50], Loss: 0.1372, Val Loss: 0.2999
Epoch [24/50], Loss: 0.1789, Val Loss: 0.2828
Epoch [25/50], Loss: 0.1494, Val Loss: 0.2961
Epoch [26/50], Loss: 0.1017, Val Loss: 0.2624
Epoch [27/50], Loss: 0.1296, Val Loss: 0.2854
Epoch [28/50], Loss: 0.1972, Val Loss: 0.2984
Epoch [29/50], Loss: 0.1550, Val Loss: 0.2811
Epoch [30/50], Loss: 0.2893, Val Loss: 0.3048
Epoch [31/50], Loss: 0.1765, Val Loss: 0.2730
Epoch [32/50], Loss: 0.1615, Val Loss: 0.2861
Epoch [33/50], Loss: 0.2241, Val Loss: 0.2941
Epoch [34/50], Loss: 0.4519, Val Loss: 0.2684
Epoch [35/50], Loss: 0.0810, Val Loss: 0.2736
Early stopping at epoch 35========================================
Test Loss: 1259834567.0925
========================================
Test Loss: nan
========================================
Test Loss: 1259842138.0528
========================================
Test Loss: 1259828929.3958
R^2 Score: 0.6903
========================================
Test Loss: 1259943654.6165
R^2 Score: 0.6903
MLP with 1 layer: 16 nodes - Result:
Epoch [1/50], Loss: 1673760269.2976, Val Loss: 2194453424.2551
Epoch [2/50], Loss: 1973054431.2221, Val Loss: 2192380087.3164
Epoch [3/50], Loss: 1691546556.4340, Val Loss: 2201226571.2434
Epoch [4/50], Loss: 4216803764.2021, Val Loss: 2207757290.7581
Epoch [5/50], Loss: 3801009030.5595, Val Loss: 2196680071.2850
Epoch [6/50], Loss: 2744764503.1015, Val Loss: 2194412455.0541
Epoch [7/50], Loss: 2474538499.1513, Val Loss: 2197497529.7767
Epoch [8/50], Loss: 1127176768.4516, Val Loss: 2195540674.0560
Epoch [9/50], Loss: 1691672571.2197, Val Loss: 2192157035.2515
Epoch [10/50], Loss: 843089053.2468, Val Loss: 2219121239.6899
Epoch [11/50], Loss: 2006138551.8383, Val Loss: 2199856994.5636
Epoch [12/50], Loss: 2498487409.1232, Val Loss: 2193125148.6659
Epoch [13/50], Loss: 1250328503.4341, Val Loss: 2193114376.8258
Epoch [14/50], Loss: 1812060686.8988, Val Loss: 2193621601.6038
Epoch [15/50], Loss: 2226188956.6164, Val Loss: 2198067455.9823
Epoch [16/50], Loss: 1463090740.5874, Val Loss: 2194258746.1831
Epoch [17/50], Loss: 1478109956.7035, Val Loss: 2195983565.1687
Epoch [18/50], Loss: 3360233084.2679, Val Loss: 2205609680.6794
Epoch [19/50], Loss: 1844197702.8648, Val Loss: 2192311911.8210
Epoch [20/50], Loss: 2446184652.7372, Val Loss: 2198417816.8667
Epoch [21/50], Loss: 2076839111.6273, Val Loss: 2192524033.7547
Epoch [22/50], Loss: 1539488665.5048, Val Loss: 2192797940.8796
Epoch [23/50], Loss: 1190248889.9239, Val Loss: 2192301613.4060
Epoch [24/50], Loss: 2708224469.9826, Val Loss: 2193201690.9060
Epoch [25/50], Loss: 1944330017.9812, Val Loss: 2191945848.0391
Epoch [26/50], Loss: 2431293784.2735, Val Loss: 2192614463.6243
Epoch [27/50], Loss: 1747484701.1864, Val Loss: 2203160403.5843
Epoch [28/50], Loss: 1087710924.8225, Val Loss: 2193168141.6307
Epoch [29/50], Loss: 1885797032.3412, Val Loss: 2206541939.6680
Epoch [30/50], Loss: 1566614742.6499, Val Loss: 2192184841.3820
Epoch [31/50], Loss: 2188580457.2135, Val Loss: 2194541945.9753
Epoch [32/50], Loss: 1543679010.5854, Val Loss: 2192177996.5011
Epoch [33/50], Loss: 842651398.5049, Val Loss: 2192183803.4987
Epoch [34/50], Loss: 3520714117.7063, Val Loss: 2196290048.9912
Epoch [35/50], Loss: 1318893123.8687, Val Loss: 2200678535.0986
Epoch [36/50], Loss: 1219898701.4298, Val Loss: 2192291790.8921
Epoch [37/50], Loss: 1762723779.0089, Val Loss: 2192317798.1675
Epoch [38/50], Loss: 3199513129.0796, Val Loss: 2198886257.0555
Epoch [39/50], Loss: 2603248151.9618, Val Loss: 2368851821.1670
Epoch [40/50], Loss: 1278509478.8589, Val Loss: 2204786887.3144
Epoch [41/50], Loss: 1700742513.2826, Val Loss: 2227499299.3961
Epoch [42/50], Loss: 2817742725.9217, Val Loss: 2209373634.2080
Epoch [43/50], Loss: 865657241.9061, Val Loss: 2192409206.2741
Epoch [44/50], Loss: 1055807537.3377, Val Loss: 2193773232.9975
Epoch [45/50], Loss: 2577278011.6121, Val Loss: 2194864898.3690
Epoch [46/50], Loss: 1542536556.7174, Val Loss: 2200375612.5802
Epoch [47/50], Loss: 2407767852.4947, Val Loss: 2191820873.2043
Epoch [48/50], Loss: 1656784506.7816, Val Loss: 2198756513.9085
Epoch [49/50], Loss: 2710247877.9641, Val Loss: 2192436903.9230
Epoch [50/50], Loss: 1891653627.3249, Val Loss: 2192566128.3153
MLP with 1 layer: 128 nodes - Result:
Epoch [1/50], Loss: 1.1440, Val Loss: 1.0678
Epoch [2/50], Loss: 0.7804, Val Loss: 0.8626
Epoch [3/50], Loss: 0.4043, Val Loss: 0.8243
Epoch [4/50], Loss: 0.6004, Val Loss: 0.7596
Epoch [5/50], Loss: 0.1815, Val Loss: 0.7339
Epoch [6/50], Loss: 0.1749, Val Loss: 0.7342
Epoch [7/50], Loss: 0.4197, Val Loss: 0.6887
Epoch [8/50], Loss: 0.4366, Val Loss: 0.6737
Epoch [9/50], Loss: 0.1517, Val Loss: 0.7469
Epoch [10/50], Loss: 0.3955, Val Loss: 0.6754
Epoch [11/50], Loss: 0.1797, Val Loss: 0.7210
Epoch [12/50], Loss: 0.6036, Val Loss: 0.7170
Epoch [13/50], Loss: 0.1612, Val Loss: 0.7066
Epoch [14/50], Loss: 0.2948, Val Loss: 0.6949
Epoch [15/50], Loss: 0.3036, Val Loss: 0.7307
Epoch [16/50], Loss: 0.4242, Val Loss: 0.7297
Epoch [17/50], Loss: 0.1608, Val Loss: 0.6968
Epoch [18/50], Loss: 0.2217, Val Loss: 0.7480
Epoch [19/50], Loss: 0.1470, Val Loss: 0.7108
Epoch [20/50], Loss: 0.3445, Val Loss: 0.7109
Epoch [21/50], Loss: 0.1359, Val Loss: 0.6777
Epoch [22/50], Loss: 0.1921, Val Loss: 0.7012
Epoch [23/50], Loss: 0.2135, Val Loss: 0.6910
Epoch [24/50], Loss: 0.4548, Val Loss: 0.6918
Epoch [25/50], Loss: 0.2789, Val Loss: 0.7101
Epoch [26/50], Loss: 0.0973, Val Loss: 0.6945
Epoch [27/50], Loss: 0.4593, Val Loss: 0.6889
Epoch [28/50], Loss: 0.2036, Val Loss: 0.6735
Epoch [29/50], Loss: 0.3867, Val Loss: 0.7005
Epoch [30/50], Loss: 0.2377, Val Loss: 0.6985
Epoch [31/50], Loss: 0.6247, Val Loss: 0.6959
Epoch [32/50], Loss: 0.2652, Val Loss: 0.7258
Epoch [33/50], Loss: 0.5286, Val Loss: 0.6800
Epoch [34/50], Loss: 0.2520, Val Loss: 0.7090
Epoch [35/50], Loss: 0.6159, Val Loss: 0.6933
Epoch [36/50], Loss: 0.3797, Val Loss: 0.6965
Epoch [37/50], Loss: 0.2305, Val Loss: 0.6955
Epoch [38/50], Loss: 0.2273, Val Loss: 0.6631
Epoch [39/50], Loss: 0.1093, Val Loss: 0.7027
Epoch [40/50], Loss: 0.2067, Val Loss: 0.6925
Epoch [41/50], Loss: 0.4947, Val Loss: 0.7063
Epoch [42/50], Loss: 0.1255, Val Loss: 0.7086
Epoch [43/50], Loss: 0.3446, Val Loss: 0.6924
Epoch [44/50], Loss: 0.1550, Val Loss: 0.6844
Epoch [45/50], Loss: 0.1729, Val Loss: 0.7230
Epoch [46/50], Loss: 0.0823, Val Loss: 0.7028
Epoch [47/50], Loss: 0.1993, Val Loss: 0.6950
Epoch [48/50], Loss: 0.2515, Val Loss: 0.6961
Epoch [49/50], Loss: 0.1853, Val Loss: 0.7166
Epoch [50/50], Loss: 0.1298, Val Loss: 0.6859
========================================
Test Loss: 0.7925
========================================
Test Loss: 0.7952
R^2 Score: 0.8407
========================================
Test Loss: 0.7928
R^2 Score: 0.8407
R Score: 0.9169
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 0.3844, Val Loss: 0.8824
Epoch [2/50], Loss: 0.3040, Val Loss: 0.9138
Epoch [3/50], Loss: 0.0632, Val Loss: 0.6517
Epoch [4/50], Loss: 0.1103, Val Loss: 0.5908
Epoch [5/50], Loss: 0.2346, Val Loss: 0.6388
Epoch [6/50], Loss: 0.6743, Val Loss: 0.6110
Epoch [7/50], Loss: 0.1559, Val Loss: 0.6105
Epoch [8/50], Loss: 0.0678, Val Loss: 0.6031
Epoch [9/50], Loss: 0.1184, Val Loss: 0.6329
Epoch [10/50], Loss: 0.4772, Val Loss: 0.6455
Epoch [11/50], Loss: 0.1125, Val Loss: 0.5821
Epoch [12/50], Loss: 0.0438, Val Loss: 0.5921
Epoch [13/50], Loss: 0.0890, Val Loss: 0.6311
Epoch [14/50], Loss: 0.1159, Val Loss: 0.5946
Epoch [15/50], Loss: 0.1817, Val Loss: 0.5758
Epoch [16/50], Loss: 0.0650, Val Loss: 0.5759
Epoch [17/50], Loss: 0.1718, Val Loss: 0.5789
Epoch [18/50], Loss: 0.0783, Val Loss: 0.6010
Epoch [19/50], Loss: 0.2686, Val Loss: 0.6365
Epoch [20/50], Loss: 0.0413, Val Loss: 0.5991
Epoch [21/50], Loss: 0.4963, Val Loss: 0.5974
Epoch [22/50], Loss: 0.2292, Val Loss: 0.6497
Epoch [23/50], Loss: 0.5288, Val Loss: 0.5992
Epoch [24/50], Loss: 0.1906, Val Loss: 0.6033
Epoch [25/50], Loss: 0.2714, Val Loss: 0.6268
Epoch [26/50], Loss: 0.8525, Val Loss: 0.5917
Early stopping at epoch 26
R^2 Score: 0.7701
RMSE: 1.0858
MAE: 0.2003
MAPE: 18.36%
MLP with layer size: [128, 64, 32, 16] - Result:
MLP with layer size: [128, 64, 32, 16] - Result:
Epoch [1/50], Loss: 1.0698, Val Loss: 0.9249
Epoch [2/50], Loss: 0.1236, Val Loss: 0.8958
Epoch [3/50], Loss: 0.8918, Val Loss: 0.6873
Epoch [4/50], Loss: 0.2565, Val Loss: 0.6380
Epoch [5/50], Loss: 0.0911, Val Loss: 0.6356
Epoch [6/50], Loss: 0.1582, Val Loss: 0.6523
Epoch [7/50], Loss: 0.6999, Val Loss: 0.6317
Epoch [8/50], Loss: 0.3169, Val Loss: 0.7037
Epoch [9/50], Loss: 0.3504, Val Loss: 0.6161
Epoch [10/50], Loss: 1.4536, Val Loss: 0.6073
Epoch [11/50], Loss: 2.3536, Val Loss: 0.7928
Epoch [12/50], Loss: 0.1148, Val Loss: 0.6084
Epoch [13/50], Loss: 0.2335, Val Loss: 0.7428
Epoch [14/50], Loss: 0.2185, Val Loss: 0.6042
Epoch [15/50], Loss: 0.4041, Val Loss: 0.6708
Epoch [16/50], Loss: 0.1457, Val Loss: 0.6082
Epoch [17/50], Loss: 0.0946, Val Loss: 0.6166
Epoch [18/50], Loss: 0.1203, Val Loss: 0.6358
Epoch [19/50], Loss: 0.1672, Val Loss: 0.7053
Epoch [20/50], Loss: 0.1814, Val Loss: 0.6386
Epoch [21/50], Loss: 0.2334, Val Loss: 0.6306
Epoch [22/50], Loss: 0.7735, Val Loss: 0.6244
Epoch [23/50], Loss: 0.3219, Val Loss: 0.6398
Epoch [24/50], Loss: 0.3530, Val Loss: 0.6103
Epoch [25/50], Loss: 0.2637, Val Loss: 0.5978
Epoch [26/50], Loss: 0.1578, Val Loss: 0.6147
Epoch [27/50], Loss: 0.1028, Val Loss: 0.6061
Epoch [28/50], Loss: 1.0040, Val Loss: 0.7422
Epoch [29/50], Loss: 0.1494, Val Loss: 0.6044
Epoch [30/50], Loss: 0.1304, Val Loss: 0.6359
Epoch [31/50], Loss: 0.3153, Val Loss: 0.6058
Epoch [32/50], Loss: 0.1119, Val Loss: 0.6279
Epoch [33/50], Loss: 0.2095, Val Loss: 0.6483
Epoch [34/50], Loss: 0.1635, Val Loss: 0.6112
Epoch [35/50], Loss: 0.2441, Val Loss: 0.6179
Epoch [36/50], Loss: 0.1233, Val Loss: 0.6207
Early stopping at epoch 36
R^2 Score: 0.7337
RMSE: 1.1686
MAE: 0.2160
MAPE: 20.39%
MLP with layer size: [128] - Result:
Epoch [1/50], Loss: 1.4067, Val Loss: 1.0389
Epoch [2/50], Loss: 0.4447, Val Loss: 0.7353
Epoch [3/50], Loss: 0.3773, Val Loss: 0.6459
Epoch [4/50], Loss: 0.0455, Val Loss: 0.6001
Epoch [5/50], Loss: 0.6170, Val Loss: 0.6084
Epoch [6/50], Loss: 0.1340, Val Loss: 0.6212
Epoch [7/50], Loss: 0.1174, Val Loss: 0.6367
Epoch [8/50], Loss: 0.3306, Val Loss: 0.6712
Epoch [9/50], Loss: 0.1653, Val Loss: 0.6165
Epoch [10/50], Loss: 0.1842, Val Loss: 0.7069
Epoch [11/50], Loss: 6.1977, Val Loss: 0.6350
Epoch [12/50], Loss: 0.0840, Val Loss: 0.6061
Epoch [13/50], Loss: 0.1201, Val Loss: 0.5907
Epoch [14/50], Loss: 0.0744, Val Loss: 0.5950
Epoch [15/50], Loss: 0.3060, Val Loss: 0.5913
Epoch [16/50], Loss: 1.4357, Val Loss: 0.6486
Epoch [17/50], Loss: 0.6205, Val Loss: 0.8108
Epoch [18/50], Loss: 0.1586, Val Loss: 0.5884
Epoch [19/50], Loss: 0.1578, Val Loss: 0.5938
Epoch [20/50], Loss: 0.0590, Val Loss: 0.5852
Epoch [21/50], Loss: 0.1858, Val Loss: 0.5783
Epoch [22/50], Loss: 0.1862, Val Loss: 0.5765
Epoch [23/50], Loss: 0.1360, Val Loss: 0.5673
Epoch [24/50], Loss: 0.7131, Val Loss: 0.5804
Epoch [25/50], Loss: 0.3696, Val Loss: 0.5791
Epoch [26/50], Loss: 0.0664, Val Loss: 0.6035
Epoch [27/50], Loss: 0.0963, Val Loss: 0.5839
Epoch [28/50], Loss: 0.1159, Val Loss: 0.6227
Epoch [29/50], Loss: 0.0378, Val Loss: 0.5867
Epoch [30/50], Loss: 0.1570, Val Loss: 0.5847
Epoch [31/50], Loss: 0.2431, Val Loss: 0.5805
Epoch [32/50], Loss: 0.4094, Val Loss: 0.5969
Epoch [33/50], Loss: 0.1609, Val Loss: 0.5724
Epoch [34/50], Loss: 0.1393, Val Loss: 0.6006
Early stopping at epoch 34
R^2 Score: 0.7553
RMSE: 1.1201
MAE: 0.2096
MAPE: 19.15%
MLP with layer size: [128, 64, 32] - Result:
MLP with layer size: [128, 64, 32] - Result:
Epoch [1/50], Loss: 0.6838, Val Loss: 0.8884
Epoch [2/50], Loss: 1.1653, Val Loss: 0.6888
Epoch [3/50], Loss: 0.0565, Val Loss: 0.6470
Epoch [4/50], Loss: 0.1253, Val Loss: 0.6422
Epoch [5/50], Loss: 0.0887, Val Loss: 0.6287
Epoch [6/50], Loss: 0.4246, Val Loss: 0.6484
Epoch [7/50], Loss: 5.4235, Val Loss: 0.7477
Epoch [8/50], Loss: 0.5401, Val Loss: 0.6179
Epoch [9/50], Loss: 0.1628, Val Loss: 0.6192
Epoch [10/50], Loss: 0.2323, Val Loss: 0.6262
Epoch [11/50], Loss: 0.2738, Val Loss: 0.5838
Epoch [12/50], Loss: 0.7815, Val Loss: 0.5988
Epoch [13/50], Loss: 0.5090, Val Loss: 0.6048
Epoch [14/50], Loss: 0.1315, Val Loss: 0.5829
Epoch [15/50], Loss: 0.1889, Val Loss: 0.6011
Epoch [16/50], Loss: 0.5915, Val Loss: 0.5832
Epoch [17/50], Loss: 0.1666, Val Loss: 0.5922
Epoch [18/50], Loss: 0.1179, Val Loss: 0.5992
Epoch [19/50], Loss: 0.0887, Val Loss: 0.6460
Epoch [20/50], Loss: 0.5095, Val Loss: 0.6197
Epoch [21/50], Loss: 0.1904, Val Loss: 0.5950
Epoch [22/50], Loss: 0.0950, Val Loss: 0.6910
Epoch [23/50], Loss: 0.1039, Val Loss: 0.6275
Epoch [24/50], Loss: 0.0428, Val Loss: 0.5839
Epoch [25/50], Loss: 0.0231, Val Loss: 0.5997
Early stopping at epoch 25
Runtime: 0:00:47.809065
R^2 Score: 0.7072
RMSE: 1.2253
MAE: 0.2544
MAPE: 26.57%
MLP with layer size: [32] - Result:
Epoch [1/50], Loss: 0.1717, Val Loss: 1.0043
Epoch [2/50], Loss: 0.2470, Val Loss: 0.9061
Epoch [3/50], Loss: 0.5618, Val Loss: 0.7258
Epoch [4/50], Loss: 0.5892, Val Loss: 1.2518
Epoch [5/50], Loss: 0.3362, Val Loss: 0.6063
Epoch [6/50], Loss: 0.9696, Val Loss: 0.6117
Epoch [7/50], Loss: 0.0794, Val Loss: 0.5751
Epoch [8/50], Loss: 0.1430, Val Loss: 0.5880
Epoch [9/50], Loss: 0.1884, Val Loss: 0.5737
Epoch [10/50], Loss: 0.4827, Val Loss: 0.5868
Epoch [11/50], Loss: 0.5669, Val Loss: 0.5824
Epoch [12/50], Loss: 0.1400, Val Loss: 0.5995
Epoch [13/50], Loss: 0.4149, Val Loss: 0.5745
Epoch [14/50], Loss: 0.1181, Val Loss: 0.5904
Epoch [15/50], Loss: 0.1351, Val Loss: 0.6077
Epoch [16/50], Loss: 0.1662, Val Loss: 0.5723
Epoch [17/50], Loss: 0.7108, Val Loss: 0.6351
Epoch [18/50], Loss: 0.1000, Val Loss: 0.6269
Epoch [19/50], Loss: 0.1009, Val Loss: 0.6465
Epoch [20/50], Loss: 0.0812, Val Loss: 0.5792
Epoch [21/50], Loss: 0.1178, Val Loss: 0.5854
Epoch [22/50], Loss: 0.6655, Val Loss: 0.5947
Epoch [23/50], Loss: 0.0497, Val Loss: 0.5741
Epoch [24/50], Loss: 0.1223, Val Loss: 0.5882
Epoch [25/50], Loss: 0.1648, Val Loss: 0.5773
Epoch [26/50], Loss: 0.2632, Val Loss: 0.5989
Epoch [27/50], Loss: 0.0717, Val Loss: 0.6120
Early stopping at epoch 27
Runtime: 0:01:37.166204
R^2 Score: 0.7468
RMSE: 1.1394
MAE: 0.2148
MAPE: 20.45%
MLP with layer size: [128, 32, 16, 8] - Result:
Epoch [1/50], Loss: 0.9692, Val Loss: 1.2247
Epoch [2/50], Loss: 0.0930, Val Loss: 0.7266
Epoch [3/50], Loss: 0.0911, Val Loss: 0.6901
Epoch [4/50], Loss: 0.1266, Val Loss: 0.6710
Epoch [5/50], Loss: 0.1620, Val Loss: 0.6400
Epoch [6/50], Loss: 0.1065, Val Loss: 0.6389
Epoch [7/50], Loss: 0.3625, Val Loss: 0.6315
Epoch [8/50], Loss: 0.1012, Val Loss: 0.6087
Epoch [9/50], Loss: 0.8520, Val Loss: 0.6455
Epoch [10/50], Loss: 0.0486, Val Loss: 0.6404
Epoch [11/50], Loss: 0.0934, Val Loss: 0.6697
Epoch [12/50], Loss: 0.1971, Val Loss: 0.6280
Epoch [13/50], Loss: 1.3962, Val Loss: 0.6251
Epoch [14/50], Loss: 0.1696, Val Loss: 0.6073
Epoch [15/50], Loss: 0.1152, Val Loss: 0.6848
Epoch [16/50], Loss: 0.3936, Val Loss: 0.5989
Epoch [17/50], Loss: 0.0375, Val Loss: 0.5924
Epoch [18/50], Loss: 0.8375, Val Loss: 0.6262
Epoch [19/50], Loss: 0.0742, Val Loss: 0.5972
Epoch [20/50], Loss: 0.1031, Val Loss: 0.6527
Epoch [21/50], Loss: 0.3497, Val Loss: 0.6183
Epoch [22/50], Loss: 0.0822, Val Loss: 0.6143
Epoch [23/50], Loss: 0.0304, Val Loss: 0.6112
Epoch [24/50], Loss: 0.1856, Val Loss: 0.5985
Epoch [25/50], Loss: 0.0566, Val Loss: 0.6061
Epoch [26/50], Loss: 0.0345, Val Loss: 0.5925
Epoch [27/50], Loss: 0.0554, Val Loss: 0.6588
Epoch [28/50], Loss: 0.0798, Val Loss: 0.6490
Early stopping at epoch 28
Runtime: 0:01:40.228355
TruncatedSVD_100
MLP with layer size: [16, 8] - Result:
Epoch [1/50], Loss: 0.4855, Val Loss: 1.0313
Epoch [2/50], Loss: 0.7046, Val Loss: 0.8946
Epoch [3/50], Loss: 0.3934, Val Loss: 0.8789
Epoch [4/50], Loss: 0.3771, Val Loss: 0.8419
Epoch [5/50], Loss: 0.1868, Val Loss: 0.8067
Epoch [6/50], Loss: 2.3861, Val Loss: 0.8241
Epoch [7/50], Loss: 2.4930, Val Loss: 0.8113
Epoch [8/50], Loss: 0.2283, Val Loss: 0.8690
Epoch [9/50], Loss: 0.5170, Val Loss: 0.7696
Epoch [10/50], Loss: 0.3821, Val Loss: 0.8007
Epoch [11/50], Loss: 0.9485, Val Loss: 0.7850
Epoch [12/50], Loss: 0.6006, Val Loss: 0.8020
Epoch [13/50], Loss: 0.1841, Val Loss: 0.8009
Epoch [14/50], Loss: 0.6990, Val Loss: 0.8148
Epoch [15/50], Loss: 0.4021, Val Loss: 0.7678
Epoch [16/50], Loss: 0.1557, Val Loss: 0.7768
Epoch [17/50], Loss: 1.3452, Val Loss: 0.7746
Epoch [18/50], Loss: 0.1006, Val Loss: 0.7675
Epoch [19/50], Loss: 0.3244, Val Loss: 0.8065
Epoch [20/50], Loss: 0.3255, Val Loss: 0.7930
Epoch [21/50], Loss: 0.2327, Val Loss: 0.8203
Epoch [22/50], Loss: 0.0977, Val Loss: 0.7784
Epoch [23/50], Loss: 0.9270, Val Loss: 0.7744
Epoch [24/50], Loss: 0.0906, Val Loss: 0.7886
Epoch [25/50], Loss: 0.1296, Val Loss: 0.7619
Epoch [26/50], Loss: 0.2524, Val Loss: 0.7874
Epoch [27/50], Loss: 0.3645, Val Loss: 0.8173
Epoch [28/50], Loss: 0.1922, Val Loss: 0.7792
Epoch [29/50], Loss: 0.2182, Val Loss: 0.7898
Epoch [30/50], Loss: 0.3348, Val Loss: 0.7570
Epoch [31/50], Loss: 1.3205, Val Loss: 0.7963
Epoch [32/50], Loss: 0.2180, Val Loss: 0.7639
Epoch [33/50], Loss: 0.8565, Val Loss: 0.7801
Epoch [34/50], Loss: 1.2785, Val Loss: 0.8873
Epoch [35/50], Loss: 1.1384, Val Loss: 0.7739
Epoch [36/50], Loss: 0.0961, Val Loss: 0.7808
Epoch [37/50], Loss: 0.1085, Val Loss: 0.7611
Epoch [38/50], Loss: 0.1731, Val Loss: 0.8036
Epoch [39/50], Loss: 0.3203, Val Loss: 0.7868
Epoch [40/50], Loss: 0.0785, Val Loss: 0.7792
Epoch [41/50], Loss: 0.2522, Val Loss: 0.7351
Epoch [42/50], Loss: 0.4901, Val Loss: 0.7730
Epoch [43/50], Loss: 0.1600, Val Loss: 0.8078
Epoch [44/50], Loss: 0.1371, Val Loss: 0.7540
Epoch [45/50], Loss: 0.9385, Val Loss: 0.8120
Epoch [46/50], Loss: 0.1092, Val Loss: 0.7735
Epoch [47/50], Loss: 0.2854, Val Loss: 0.7489
Epoch [48/50], Loss: 0.2532, Val Loss: 0.7850
Epoch [49/50], Loss: 0.8666, Val Loss: 0.7779
Epoch [50/50], Loss: 0.1021, Val Loss: 0.7588
Runtime: 0:02:58.522760
R^2 Score: 0.8431
RMSE: 0.8969
MAE: 0.2621
MAPE: 21.68%
TruncatedSVD_100MLP with layer size: [32, 16] - Result:
Epoch [1/50], Loss: 0.4815, Val Loss: 0.9957
Epoch [2/50], Loss: 0.6255, Val Loss: 0.9081
Epoch [3/50], Loss: 0.1500, Val Loss: 0.9185
Epoch [4/50], Loss: 0.6608, Val Loss: 0.8415
Epoch [5/50], Loss: 0.2711, Val Loss: 0.8584
Epoch [6/50], Loss: 0.0999, Val Loss: 0.8526
Epoch [7/50], Loss: 0.4316, Val Loss: 0.8580
Epoch [8/50], Loss: 0.0832, Val Loss: 0.8858
Epoch [9/50], Loss: 0.1965, Val Loss: 0.8660
Epoch [10/50], Loss: 0.4963, Val Loss: 0.8067
Epoch [11/50], Loss: 0.3735, Val Loss: 0.7989
Epoch [12/50], Loss: 0.7021, Val Loss: 0.7974
Epoch [13/50], Loss: 0.2885, Val Loss: 0.9174
Epoch [14/50], Loss: 0.6378, Val Loss: 0.8210
Epoch [15/50], Loss: 0.2384, Val Loss: 0.8826
Epoch [16/50], Loss: 0.3612, Val Loss: 0.7994
Epoch [17/50], Loss: 0.1936, Val Loss: 0.7955
Epoch [18/50], Loss: 0.3144, Val Loss: 0.8210
Epoch [19/50], Loss: 0.9538, Val Loss: 0.8573
Epoch [20/50], Loss: 0.5524, Val Loss: 0.8361
Epoch [21/50], Loss: 0.0734, Val Loss: 0.7885
Epoch [22/50], Loss: 0.2204, Val Loss: 0.8061
Epoch [23/50], Loss: 0.2299, Val Loss: 0.8134
Epoch [24/50], Loss: 0.7583, Val Loss: 0.7956
Epoch [25/50], Loss: 0.2310, Val Loss: 0.8429
Epoch [26/50], Loss: 0.4263, Val Loss: 0.9173
Epoch [27/50], Loss: 0.1190, Val Loss: 0.7984
Epoch [28/50], Loss: 0.7030, Val Loss: 0.8198
Epoch [29/50], Loss: 0.6278, Val Loss: 0.8120
Epoch [30/50], Loss: 1.6200, Val Loss: 0.8976
Epoch [31/50], Loss: 0.3266, Val Loss: 0.8354
Epoch [32/50], Loss: 0.3472, Val Loss: 0.8274
Epoch [33/50], Loss: 0.3895, Val Loss: 0.7746
Epoch [34/50], Loss: 1.0360, Val Loss: 0.8558
Epoch [35/50], Loss: 0.2852, Val Loss: 0.8377
Epoch [36/50], Loss: 0.0753, Val Loss: 0.8680
Epoch [37/50], Loss: 2.3853, Val Loss: 0.7773
Epoch [38/50], Loss: 0.1640, Val Loss: 0.7905
Epoch [39/50], Loss: 0.0963, Val Loss: 0.8290
Epoch [40/50], Loss: 0.1003, Val Loss: 0.8234
Epoch [41/50], Loss: 0.5911, Val Loss: 0.9427
Epoch [42/50], Loss: 0.2221, Val Loss: 0.7816
Epoch [43/50], Loss: 0.2032, Val Loss: 0.8205
Epoch [44/50], Loss: 0.1244, Val Loss: 0.8746
Early stopping at epoch 44
Runtime: 0:02:46.296959
R^2 Score: 0.8090
RMSE: 0.9895
MAE: 0.3039
MAPE: 25.95%
TruncatedSVD_100MLP with layer size: [20] - Result:
Epoch [1/50], Loss: 0.8318, Val Loss: 1.1102
Epoch [2/50], Loss: 0.3556, Val Loss: 1.0123
Epoch [3/50], Loss: 0.1989, Val Loss: 0.9804
Epoch [4/50], Loss: 0.3945, Val Loss: 0.9605
Epoch [5/50], Loss: 0.6437, Val Loss: 0.9571
Epoch [6/50], Loss: 0.1957, Val Loss: 1.0208
Epoch [7/50], Loss: 0.0853, Val Loss: 0.9891
Epoch [8/50], Loss: 0.1031, Val Loss: 0.9456
Epoch [9/50], Loss: 0.0744, Val Loss: 0.9453
Epoch [10/50], Loss: 0.1125, Val Loss: 0.9512
Epoch [11/50], Loss: 1.3381, Val Loss: 0.9146
Epoch [12/50], Loss: 0.4425, Val Loss: 0.9231
Epoch [13/50], Loss: 1.7784, Val Loss: 0.9283
Epoch [14/50], Loss: 0.1460, Val Loss: 0.9444
Epoch [15/50], Loss: 0.2444, Val Loss: 0.9541
Epoch [16/50], Loss: 0.4388, Val Loss: 0.8952
Epoch [17/50], Loss: 0.4852, Val Loss: 0.9455
Epoch [18/50], Loss: 0.2067, Val Loss: 0.9192
Epoch [19/50], Loss: 0.4184, Val Loss: 0.9884
Epoch [20/50], Loss: 0.4491, Val Loss: 0.9169
Epoch [21/50], Loss: 0.4162, Val Loss: 0.9252
Epoch [22/50], Loss: 0.1272, Val Loss: 0.9168
Epoch [23/50], Loss: 0.3859, Val Loss: 0.9125
Epoch [24/50], Loss: 0.2633, Val Loss: 0.9005
Epoch [25/50], Loss: 0.9490, Val Loss: 0.9107
Epoch [26/50], Loss: 4.7961, Val Loss: 0.9182
Epoch [27/50], Loss: 0.1555, Val Loss: 0.9428
Early stopping at epoch 27
Runtime: 0:01:21.346802
TruncatedSVD_100MLP with layer size: [20] - Result:
TruncatedSVD_100MLP with layer size: [20] - Result:
Epoch [1/50], Loss: 0.3860, Val Loss: 1.0944
Epoch [2/50], Loss: 1.1805, Val Loss: 1.0106
Epoch [3/50], Loss: 0.4838, Val Loss: 1.0064
Epoch [4/50], Loss: 0.3460, Val Loss: 0.9389
Epoch [5/50], Loss: 0.7495, Val Loss: 0.9339
Epoch [6/50], Loss: 0.5852, Val Loss: 0.8894
Epoch [7/50], Loss: 0.4842, Val Loss: 0.8747
Epoch [8/50], Loss: 0.4214, Val Loss: 0.8794
Epoch [9/50], Loss: 0.1073, Val Loss: 0.8836
Epoch [10/50], Loss: 1.1078, Val Loss: 0.8920
Epoch [11/50], Loss: 0.1166, Val Loss: 0.8846
Epoch [12/50], Loss: 0.1208, Val Loss: 0.8880
Epoch [13/50], Loss: 0.1903, Val Loss: 0.8612
Epoch [14/50], Loss: 0.8075, Val Loss: 0.8554
Epoch [15/50], Loss: 0.4988, Val Loss: 0.8621
Epoch [16/50], Loss: 1.8921, Val Loss: 0.8680
Epoch [17/50], Loss: 0.8018, Val Loss: 0.8702
Epoch [18/50], Loss: 0.7675, Val Loss: 0.8813
Epoch [19/50], Loss: 0.0859, Val Loss: 0.8978
Epoch [20/50], Loss: 0.4761, Val Loss: 0.8707
Epoch [21/50], Loss: 0.1188, Val Loss: 0.8794
Epoch [22/50], Loss: 0.3187, Val Loss: 0.8730
Epoch [23/50], Loss: 0.4169, Val Loss: 0.8414
Epoch [24/50], Loss: 0.0606, Val Loss: 0.8524
Epoch [25/50], Loss: 1.3731, Val Loss: 0.8848
Epoch [26/50], Loss: 0.7841, Val Loss: 0.8953
Epoch [27/50], Loss: 0.1175, Val Loss: 0.9103
Epoch [28/50], Loss: 0.3678, Val Loss: 0.8726
Epoch [29/50], Loss: 0.3950, Val Loss: 0.8591
Epoch [30/50], Loss: 0.6285, Val Loss: 0.8703
Epoch [31/50], Loss: 0.0720, Val Loss: 0.8472
Epoch [32/50], Loss: 0.1039, Val Loss: 0.8545
Epoch [33/50], Loss: 0.4857, Val Loss: 0.8612
Epoch [34/50], Loss: 0.5189, Val Loss: 0.8487
Early stopping at epoch 34
Runtime: 0:01:41.255865
R^2 Score: 0.7399
RMSE: 1.1549
MAE: 0.3355
MAPE: 27.16%
TruncatedSVD_100MLP with layer size: [16, 8, 4] - Result:
Epoch [1/50], Loss: 0.2765, Val Loss: 1.0720
Epoch [2/50], Loss: 0.6944, Val Loss: 0.9911
Epoch [3/50], Loss: 0.5307, Val Loss: 0.9360
Epoch [4/50], Loss: 0.2474, Val Loss: 0.9720
Epoch [5/50], Loss: 0.2326, Val Loss: 0.9156
Epoch [6/50], Loss: 0.2072, Val Loss: 0.9350
Epoch [7/50], Loss: 0.3956, Val Loss: 0.8581
Epoch [8/50], Loss: 0.8324, Val Loss: 0.8684
Epoch [9/50], Loss: 0.7613, Val Loss: 0.8263
Epoch [10/50], Loss: 1.2069, Val Loss: 0.8116
Epoch [11/50], Loss: 0.2136, Val Loss: 0.8355
Epoch [12/50], Loss: 1.3209, Val Loss: 0.8257
Epoch [13/50], Loss: 0.2025, Val Loss: 1.0029
Epoch [14/50], Loss: 0.0763, Val Loss: 0.8124
Epoch [15/50], Loss: 0.7538, Val Loss: 0.8731
Epoch [16/50], Loss: 0.1620, Val Loss: 0.8281
Epoch [17/50], Loss: 0.0937, Val Loss: 0.8779
Epoch [18/50], Loss: 0.1576, Val Loss: 0.8475
Epoch [19/50], Loss: 0.1982, Val Loss: 0.9017
Epoch [20/50], Loss: 0.2030, Val Loss: 0.7961
Epoch [21/50], Loss: 0.3236, Val Loss: 0.7975
Epoch [22/50], Loss: 0.3480, Val Loss: 0.8395
Epoch [23/50], Loss: 0.9695, Val Loss: 0.8095
Epoch [24/50], Loss: 0.3312, Val Loss: 0.8323
Epoch [25/50], Loss: 0.2988, Val Loss: 0.8155
Epoch [26/50], Loss: 0.1441, Val Loss: 0.8037
Epoch [27/50], Loss: 3.0519, Val Loss: 0.7918
Epoch [28/50], Loss: 0.2193, Val Loss: 0.7946
Epoch [29/50], Loss: 0.2429, Val Loss: 0.8199
Epoch [30/50], Loss: 0.4028, Val Loss: 0.8130
Epoch [31/50], Loss: 0.1874, Val Loss: 0.8302
Epoch [32/50], Loss: 1.0251, Val Loss: 0.8208
Epoch [33/50], Loss: 0.1757, Val Loss: 0.7942
Epoch [34/50], Loss: 3.1833, Val Loss: 0.8517
Epoch [35/50], Loss: 0.5183, Val Loss: 0.8060
Epoch [36/50], Loss: 0.3215, Val Loss: 0.8420
Epoch [37/50], Loss: 0.2212, Val Loss: 0.8231
Epoch [38/50], Loss: 0.1810, Val Loss: 0.8152
Early stopping at epoch 38
Runtime: 0:02:39.502129
R^2 Score: 0.8075
RMSE: 0.9934
MAE: 0.2987
MAPE: 27.33%
TruncatedSVD_100MLP with layer size: [16, 8] - Result:
Epoch [1/50], Loss: 0.4411, Val Loss: 1.0270
Epoch [2/50], Loss: 0.2630, Val Loss: 0.9356
Epoch [3/50], Loss: 0.3681, Val Loss: 0.9220
Epoch [4/50], Loss: 0.5396, Val Loss: 0.9756
Epoch [5/50], Loss: 0.1899, Val Loss: 0.8587
Epoch [6/50], Loss: 0.2553, Val Loss: 0.8261
Epoch [7/50], Loss: 0.3401, Val Loss: 0.8618
Epoch [8/50], Loss: 0.6952, Val Loss: 0.8719
Epoch [9/50], Loss: 0.1565, Val Loss: 0.8439
Epoch [10/50], Loss: 0.7465, Val Loss: 0.8813
Epoch [11/50], Loss: 0.1050, Val Loss: 0.8215
Epoch [12/50], Loss: 0.9846, Val Loss: 0.8514
Epoch [13/50], Loss: 0.1846, Val Loss: 0.7988
Epoch [14/50], Loss: 1.0875, Val Loss: 0.8423
Epoch [15/50], Loss: 2.9011, Val Loss: 0.8436
Epoch [16/50], Loss: 0.1980, Val Loss: 0.8701
Epoch [17/50], Loss: 1.0828, Val Loss: 0.8287
Epoch [18/50], Loss: 0.1294, Val Loss: 0.7960
Epoch [19/50], Loss: 0.5352, Val Loss: 0.8501
Epoch [20/50], Loss: 0.8371, Val Loss: 0.8067
Epoch [21/50], Loss: 0.2269, Val Loss: 0.8650
Epoch [22/50], Loss: 0.1477, Val Loss: 0.9317
Epoch [23/50], Loss: 0.1337, Val Loss: 0.8117
Epoch [24/50], Loss: 0.2292, Val Loss: 0.8287
Epoch [25/50], Loss: 0.1849, Val Loss: 0.8547
Epoch [26/50], Loss: 0.2807, Val Loss: 0.8306
Epoch [27/50], Loss: 0.1459, Val Loss: 0.8401
Epoch [28/50], Loss: 0.1041, Val Loss: 0.7846
Epoch [29/50], Loss: 0.3871, Val Loss: 0.7999
Epoch [30/50], Loss: 0.4399, Val Loss: 0.8067
Epoch [31/50], Loss: 0.1586, Val Loss: 0.8079
Epoch [32/50], Loss: 0.1486, Val Loss: 0.8066
Epoch [33/50], Loss: 0.1573, Val Loss: 0.8004
Epoch [34/50], Loss: 0.1429, Val Loss: 0.8214
Epoch [35/50], Loss: 0.1176, Val Loss: 0.7980
Epoch [36/50], Loss: 1.1119, Val Loss: 0.7975
Epoch [37/50], Loss: 0.8530, Val Loss: 0.8395
Epoch [38/50], Loss: 0.4244, Val Loss: 0.8105
Epoch [39/50], Loss: 0.2475, Val Loss: 0.8465
Early stopping at epoch 39
Runtime: 0:02:21.185601
R^2 Score: 0.8030
RMSE: 1.0051
MAE: 0.3214
MAPE: 29.79%
TruncatedSVD_100MLP with layer size: [20, 10] - Result:
Epoch [1/50], Loss: 0.1994, Val Loss: 1.0202
Epoch [2/50], Loss: 0.6601, Val Loss: 0.9354
Epoch [3/50], Loss: 1.0619, Val Loss: 0.8690
Epoch [4/50], Loss: 0.3629, Val Loss: 0.9684
Epoch [5/50], Loss: 6.5896, Val Loss: 0.8284
Epoch [6/50], Loss: 0.4486, Val Loss: 0.8046
Epoch [7/50], Loss: 0.1640, Val Loss: 0.7790
Epoch [8/50], Loss: 0.6228, Val Loss: 0.8467
Epoch [9/50], Loss: 0.3625, Val Loss: 0.7800
Epoch [10/50], Loss: 0.2688, Val Loss: 0.7609
Epoch [11/50], Loss: 0.1226, Val Loss: 0.7659
Epoch [12/50], Loss: 0.5824, Val Loss: 0.7973
Epoch [13/50], Loss: 2.9552, Val Loss: 0.7771
Epoch [14/50], Loss: 0.2394, Val Loss: 0.7685
Epoch [15/50], Loss: 0.3028, Val Loss: 0.7572
Epoch [16/50], Loss: 0.1162, Val Loss: 0.7791
Epoch [17/50], Loss: 0.3093, Val Loss: 0.7705
Epoch [18/50], Loss: 0.2658, Val Loss: 0.7512
Epoch [19/50], Loss: 0.3756, Val Loss: 0.7968
Epoch [20/50], Loss: 0.5436, Val Loss: 0.7645
Epoch [21/50], Loss: 0.2233, Val Loss: 0.8322
Epoch [22/50], Loss: 0.1180, Val Loss: 0.7549
Epoch [23/50], Loss: 0.4107, Val Loss: 0.7771
Epoch [24/50], Loss: 0.8091, Val Loss: 0.7749
Epoch [25/50], Loss: 0.1485, Val Loss: 0.8365
Epoch [26/50], Loss: 2.6485, Val Loss: 0.7618
Epoch [27/50], Loss: 0.4996, Val Loss: 0.7708
Epoch [28/50], Loss: 0.3232, Val Loss: 0.7060
Epoch [29/50], Loss: 0.2497, Val Loss: 0.7440
Epoch [30/50], Loss: 0.1432, Val Loss: 0.7769
Epoch [31/50], Loss: 0.1744, Val Loss: 0.7544
Epoch [32/50], Loss: 0.1391, Val Loss: 0.7679
Epoch [33/50], Loss: 0.2446, Val Loss: 0.7426
Epoch [34/50], Loss: 0.2030, Val Loss: 0.7601
Epoch [35/50], Loss: 0.3241, Val Loss: 0.7491
Epoch [36/50], Loss: 0.2414, Val Loss: 0.7138
Epoch [37/50], Loss: 0.4165, Val Loss: 0.7064
Epoch [38/50], Loss: 0.2621, Val Loss: 0.7218
Epoch [39/50], Loss: 0.2418, Val Loss: 0.7374
Early stopping at epoch 39
Runtime: 0:02:21.545596
R^2 Score: 0.8384
RMSE: 0.9102
MAE: 0.2844
MAPE: 28.71%
TruncatedSVD_100MLP with layer size: [20, 10] - Result:
Epoch [1/50], Loss: 0.3613, Val Loss: 1.0409
Epoch [2/50], Loss: 0.1512, Val Loss: 0.9158
Epoch [3/50], Loss: 1.0514, Val Loss: 0.9003
Epoch [4/50], Loss: 0.1563, Val Loss: 0.8381
Epoch [5/50], Loss: 0.5446, Val Loss: 0.8212
Epoch [6/50], Loss: 0.2195, Val Loss: 0.8714
Epoch [7/50], Loss: 0.3459, Val Loss: 0.7807
Epoch [8/50], Loss: 0.2445, Val Loss: 0.7995
Epoch [9/50], Loss: 0.2965, Val Loss: 0.8206
Epoch [10/50], Loss: 0.3522, Val Loss: 0.7927
Epoch [11/50], Loss: 0.6123, Val Loss: 0.7508
Epoch [12/50], Loss: 0.4952, Val Loss: 0.7541
Epoch [13/50], Loss: 0.1355, Val Loss: 0.7317
Epoch [14/50], Loss: 0.1274, Val Loss: 0.7283
Epoch [15/50], Loss: 0.3272, Val Loss: 0.8596
Epoch [16/50], Loss: 0.3178, Val Loss: 0.7341
Epoch [17/50], Loss: 0.1052, Val Loss: 0.7206
Epoch [18/50], Loss: 0.1134, Val Loss: 0.7581
Epoch [19/50], Loss: 0.4079, Val Loss: 0.7420
Epoch [20/50], Loss: 0.5447, Val Loss: 0.7511
Epoch [21/50], Loss: 0.1331, Val Loss: 0.7986
Epoch [22/50], Loss: 0.0873, Val Loss: 0.7029
Epoch [23/50], Loss: 0.7366, Val Loss: 0.7078
Epoch [24/50], Loss: 0.4885, Val Loss: 0.7332
Epoch [25/50], Loss: 0.2719, Val Loss: 0.7267
Epoch [26/50], Loss: 0.5682, Val Loss: 0.6885
Epoch [27/50], Loss: 0.2391, Val Loss: 0.6848
Epoch [28/50], Loss: 0.2820, Val Loss: 0.8347
Epoch [29/50], Loss: 0.1371, Val Loss: 0.7185
Epoch [30/50], Loss: 0.1850, Val Loss: 0.7656
Epoch [31/50], Loss: 0.0949, Val Loss: 0.7046
Epoch [32/50], Loss: 0.2214, Val Loss: 0.6952
Epoch [33/50], Loss: 0.3075, Val Loss: 0.7494
Epoch [34/50], Loss: 0.0758, Val Loss: 0.7418
Epoch [35/50], Loss: 0.2643, Val Loss: 0.6985
Epoch [36/50], Loss: 3.1389, Val Loss: 0.6989
Epoch [37/50], Loss: 0.2018, Val Loss: 0.7219
Epoch [38/50], Loss: 0.6342, Val Loss: 0.6867
Epoch [39/50], Loss: 0.1867, Val Loss: 0.6699
Epoch [40/50], Loss: 0.2446, Val Loss: 0.7187
Epoch [41/50], Loss: 0.0820, Val Loss: 0.6993
Epoch [42/50], Loss: 0.1967, Val Loss: 0.7014
Epoch [43/50], Loss: 0.1485, Val Loss: 0.7890
Epoch [44/50], Loss: 0.0794, Val Loss: 0.6596
Epoch [45/50], Loss: 0.2246, Val Loss: 0.6768
Epoch [46/50], Loss: 0.4533, Val Loss: 0.7611
Epoch [47/50], Loss: 0.1505, Val Loss: 0.6914
Epoch [48/50], Loss: 0.1868, Val Loss: 0.6745
Epoch [49/50], Loss: 0.2471, Val Loss: 0.6885
Epoch [50/50], Loss: 1.3083, Val Loss: 0.6475
Runtime: 0:02:55.748689
R^2 Score: 0.8533
RMSE: 0.8674
MAE: 0.2636
MAPE: 24.76%
R^2 Score: 0.8533
RMSE: 0.8674
MAE: 0.2636
MAPE: 24.76%
TruncatedSVD_100MLP with layer size: [20, 10] - Result:
Epoch [1/50], Loss: 0.5905, Val Loss: 1.0215
Epoch [2/50], Loss: 0.1748, Val Loss: 0.9202
Epoch [3/50], Loss: 0.2750, Val Loss: 0.8882
Epoch [4/50], Loss: 0.1356, Val Loss: 0.8172
Epoch [5/50], Loss: 0.5212, Val Loss: 0.8053
Epoch [6/50], Loss: 0.1564, Val Loss: 0.8342
Epoch [7/50], Loss: 0.2753, Val Loss: 0.7858
Epoch [8/50], Loss: 0.8588, Val Loss: 0.7638
Epoch [9/50], Loss: 0.4909, Val Loss: 0.7930
Epoch [10/50], Loss: 0.7848, Val Loss: 0.7999
Epoch [11/50], Loss: 0.2289, Val Loss: 0.7810
Epoch [12/50], Loss: 0.1462, Val Loss: 0.7450
Epoch [13/50], Loss: 0.1019, Val Loss: 0.8066
Epoch [14/50], Loss: 0.1374, Val Loss: 0.7369
Epoch [15/50], Loss: 0.2919, Val Loss: 0.7586
Epoch [16/50], Loss: 0.1428, Val Loss: 0.7275
Epoch [17/50], Loss: 0.3142, Val Loss: 0.7751
Epoch [18/50], Loss: 0.3173, Val Loss: 0.7379
Epoch [19/50], Loss: 0.3844, Val Loss: 0.7135
Epoch [20/50], Loss: 0.1432, Val Loss: 0.7153
Epoch [21/50], Loss: 1.1212, Val Loss: 0.7417
Epoch [22/50], Loss: 0.2623, Val Loss: 0.7455
Epoch [23/50], Loss: 0.1395, Val Loss: 0.8772
Epoch [24/50], Loss: 0.2313, Val Loss: 0.7598
Epoch [25/50], Loss: 0.2172, Val Loss: 0.7298
Epoch [26/50], Loss: 0.3148, Val Loss: 0.7157
Epoch [27/50], Loss: 0.3161, Val Loss: 0.6977
Epoch [28/50], Loss: 0.1719, Val Loss: 0.6999
Epoch [29/50], Loss: 1.0199, Val Loss: 0.7569
Epoch [30/50], Loss: 0.1066, Val Loss: 0.7204
Epoch [31/50], Loss: 0.1094, Val Loss: 0.7354
Epoch [32/50], Loss: 0.2667, Val Loss: 0.7839
Epoch [33/50], Loss: 0.3260, Val Loss: 0.7253
Epoch [34/50], Loss: 0.3853, Val Loss: 0.6927
Epoch [35/50], Loss: 0.3813, Val Loss: 0.7203
Epoch [36/50], Loss: 0.1880, Val Loss: 0.7216
Epoch [37/50], Loss: 0.1349, Val Loss: 0.7158
Epoch [38/50], Loss: 0.3591, Val Loss: 0.7267
Epoch [39/50], Loss: 0.4637, Val Loss: 0.7642
Epoch [40/50], Loss: 0.2174, Val Loss: 0.6891
Epoch [41/50], Loss: 0.2433, Val Loss: 0.7883
Epoch [42/50], Loss: 0.1114, Val Loss: 0.6895
Epoch [43/50], Loss: 0.3095, Val Loss: 0.7504
Epoch [44/50], Loss: 1.5610, Val Loss: 0.7440
Epoch [45/50], Loss: 0.2605, Val Loss: 0.6674
Epoch [46/50], Loss: 0.2457, Val Loss: 0.6905
Epoch [47/50], Loss: 0.0829, Val Loss: 0.6837
Epoch [48/50], Loss: 0.5164, Val Loss: 0.8069
Epoch [49/50], Loss: 0.1733, Val Loss: 0.7154
Epoch [50/50], Loss: 0.2015, Val Loss: 0.7372
Runtime: 0:02:55.477771
TruncatedSVD_100MLP with layer size: [32, 16] - Result:
Epoch [1/50], Loss: 0.8932, Val Loss: 1.0015
Epoch [2/50], Loss: 0.2088, Val Loss: 0.8584
Epoch [3/50], Loss: 0.1756, Val Loss: 0.8526
Epoch [4/50], Loss: 0.5945, Val Loss: 0.8037
Epoch [5/50], Loss: 3.9566, Val Loss: 0.8314
Epoch [6/50], Loss: 0.2813, Val Loss: 0.7969
Epoch [7/50], Loss: 0.1504, Val Loss: 0.7736
Epoch [8/50], Loss: 0.2663, Val Loss: 0.7596
Epoch [9/50], Loss: 0.2120, Val Loss: 0.7625
Epoch [10/50], Loss: 0.1019, Val Loss: 0.7603
Epoch [11/50], Loss: 0.3948, Val Loss: 0.7949
Epoch [12/50], Loss: 0.1967, Val Loss: 0.7457
Epoch [13/50], Loss: 0.4696, Val Loss: 0.8406
Epoch [14/50], Loss: 0.3516, Val Loss: 0.7330
Epoch [15/50], Loss: 0.0786, Val Loss: 0.7376
Epoch [16/50], Loss: 1.7645, Val Loss: 0.7274
Epoch [17/50], Loss: 0.2511, Val Loss: 0.7709
Epoch [18/50], Loss: 0.1183, Val Loss: 0.7559
Epoch [19/50], Loss: 0.1529, Val Loss: 0.7101
Epoch [20/50], Loss: 0.1340, Val Loss: 0.7223
Epoch [21/50], Loss: 0.1074, Val Loss: 0.7306
Epoch [22/50], Loss: 0.1325, Val Loss: 0.8007
Epoch [23/50], Loss: 0.0687, Val Loss: 0.7017
Epoch [24/50], Loss: 0.7892, Val Loss: 0.6894
Epoch [25/50], Loss: 0.5597, Val Loss: 0.6823
Epoch [26/50], Loss: 0.7250, Val Loss: 0.6953
Epoch [27/50], Loss: 0.1622, Val Loss: 0.7025
Epoch [28/50], Loss: 0.4577, Val Loss: 0.6970
Epoch [29/50], Loss: 0.5298, Val Loss: 0.6792
Epoch [30/50], Loss: 0.1903, Val Loss: 0.6835
Epoch [31/50], Loss: 2.4563, Val Loss: 0.6726
Epoch [32/50], Loss: 0.3325, Val Loss: 0.7110
Epoch [33/50], Loss: 0.1324, Val Loss: 0.7725
Epoch [34/50], Loss: 0.4229, Val Loss: 0.6537
Epoch [35/50], Loss: 0.7234, Val Loss: 0.8095
Epoch [36/50], Loss: 0.1301, Val Loss: 0.6491
Epoch [37/50], Loss: 0.1899, Val Loss: 0.6256
Epoch [38/50], Loss: 0.2888, Val Loss: 0.6346
Epoch [39/50], Loss: 0.2320, Val Loss: 0.6357
Epoch [40/50], Loss: 0.7823, Val Loss: 0.6304
Epoch [41/50], Loss: 0.9512, Val Loss: 0.6162
Epoch [42/50], Loss: 0.1796, Val Loss: 0.6314
Epoch [43/50], Loss: 0.4924, Val Loss: 0.6171
Epoch [44/50], Loss: 0.0986, Val Loss: 0.6213
Epoch [45/50], Loss: 0.1582, Val Loss: 0.6232
Epoch [46/50], Loss: 0.3554, Val Loss: 0.6491
Epoch [47/50], Loss: 0.1115, Val Loss: 0.6116
Epoch [48/50], Loss: 0.3765, Val Loss: 0.6257
Epoch [49/50], Loss: 0.6108, Val Loss: 0.5952
Epoch [50/50], Loss: 0.3730, Val Loss: 0.6027
Runtime: 0:02:55.548804
R^2 Score: 0.8536
RMSE: 0.8665
MAE: 0.2614
MAPE: 24.03%
R^2 Score: 0.8536
RMSE: 0.8665
MAE: 0.2614
MAPE: 24.03%
TruncatedSVD_100MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 0.1262, Val Loss: 1.0605
Epoch [2/50], Loss: 0.4430, Val Loss: 0.8653
Epoch [3/50], Loss: 2.7976, Val Loss: 0.9505
Epoch [4/50], Loss: 0.8582, Val Loss: 0.7899
Epoch [5/50], Loss: 0.5093, Val Loss: 0.7581
Epoch [6/50], Loss: 0.4695, Val Loss: 0.8279
Epoch [7/50], Loss: 0.2081, Val Loss: 0.7554
Epoch [8/50], Loss: 0.1197, Val Loss: 0.7579
Epoch [9/50], Loss: 0.3714, Val Loss: 0.7268
Epoch [10/50], Loss: 0.1447, Val Loss: 0.7661
Epoch [11/50], Loss: 0.7292, Val Loss: 0.7958
Epoch [12/50], Loss: 0.1667, Val Loss: 0.7124
Epoch [13/50], Loss: 0.2827, Val Loss: 0.7561
Epoch [14/50], Loss: 0.4069, Val Loss: 0.6872
Epoch [15/50], Loss: 0.7722, Val Loss: 0.8068
Epoch [16/50], Loss: 0.3649, Val Loss: 0.7047
Epoch [17/50], Loss: 0.2947, Val Loss: 0.6639
Epoch [18/50], Loss: 0.3785, Val Loss: 0.7243
Epoch [19/50], Loss: 0.2002, Val Loss: 0.7166
Epoch [20/50], Loss: 0.1366, Val Loss: 0.6641
Epoch [21/50], Loss: 0.1801, Val Loss: 0.6299
Epoch [22/50], Loss: 0.0891, Val Loss: 0.6267
Epoch [23/50], Loss: 0.1397, Val Loss: 0.7094
Epoch [24/50], Loss: 0.2722, Val Loss: 0.6245
Epoch [25/50], Loss: 0.1362, Val Loss: 0.6345
Epoch [26/50], Loss: 0.3424, Val Loss: 0.6838
Epoch [27/50], Loss: 0.2211, Val Loss: 0.5935
Epoch [28/50], Loss: 0.3819, Val Loss: 0.6160
Epoch [29/50], Loss: 0.6741, Val Loss: 0.6945
Epoch [30/50], Loss: 0.7308, Val Loss: 0.6731
Epoch [31/50], Loss: 0.4126, Val Loss: 0.5854
Epoch [32/50], Loss: 0.4338, Val Loss: 0.6279
Epoch [33/50], Loss: 0.1575, Val Loss: 0.6073
Epoch [34/50], Loss: 0.2140, Val Loss: 0.6068
Epoch [35/50], Loss: 0.0715, Val Loss: 0.6199
Epoch [36/50], Loss: 0.5385, Val Loss: 0.5915
Epoch [37/50], Loss: 0.5092, Val Loss: 0.5954
Epoch [38/50], Loss: 0.1541, Val Loss: 0.5899
Epoch [39/50], Loss: 0.2149, Val Loss: 0.6181
Epoch [40/50], Loss: 0.3118, Val Loss: 0.6673
Epoch [41/50], Loss: 0.7013, Val Loss: 0.5817
Epoch [42/50], Loss: 0.1168, Val Loss: 0.5805
Epoch [43/50], Loss: 0.1325, Val Loss: 0.6013
Epoch [44/50], Loss: 0.3802, Val Loss: 0.5997
Epoch [45/50], Loss: 0.1135, Val Loss: 0.5968
Epoch [46/50], Loss: 0.1155, Val Loss: 0.6260
Epoch [47/50], Loss: 0.7948, Val Loss: 0.5757
Epoch [48/50], Loss: 0.1923, Val Loss: 0.5934
Epoch [49/50], Loss: 0.0598, Val Loss: 0.5801
Epoch [50/50], Loss: 0.0670, Val Loss: 0.5898
Runtime: 0:01:19.036092
R^2 Score: 0.8455
RMSE: 0.8901
MAE: 0.2308
MAPE: 20.28%
TruncatedSVD_100MLP with layer size: [64, 32, 16] - Result:
Epoch [1/50], Loss: 9.1428, Val Loss: 0.9678
Epoch [2/50], Loss: 0.3706, Val Loss: 0.8826
Epoch [3/50], Loss: 0.3429, Val Loss: 0.8152
Epoch [4/50], Loss: 0.6687, Val Loss: 0.7953
Epoch [5/50], Loss: 0.3180, Val Loss: 0.8129
Epoch [6/50], Loss: 0.3618, Val Loss: 0.7724
Epoch [7/50], Loss: 0.2643, Val Loss: 0.7894
Epoch [8/50], Loss: 0.1087, Val Loss: 0.7834
Epoch [9/50], Loss: 0.9101, Val Loss: 0.8140
Epoch [10/50], Loss: 0.2678, Val Loss: 0.7609
Epoch [11/50], Loss: 3.8568, Val Loss: 0.7492
Epoch [12/50], Loss: 0.2716, Val Loss: 0.7675
Epoch [13/50], Loss: 0.0868, Val Loss: 0.7867
Epoch [14/50], Loss: 0.2768, Val Loss: 0.7662
Epoch [15/50], Loss: 0.2209, Val Loss: 0.7282
Epoch [16/50], Loss: 0.1438, Val Loss: 0.7566
Epoch [17/50], Loss: 0.3324, Val Loss: 0.7542
Epoch [18/50], Loss: 0.2076, Val Loss: 0.7180
Epoch [19/50], Loss: 1.6050, Val Loss: 0.7611
Epoch [20/50], Loss: 0.2006, Val Loss: 0.8581
Epoch [21/50], Loss: 0.3489, Val Loss: 0.7324
Epoch [22/50], Loss: 0.3874, Val Loss: 0.7199
Epoch [23/50], Loss: 0.1897, Val Loss: 0.6648
Epoch [24/50], Loss: 0.1330, Val Loss: 0.7851
Epoch [25/50], Loss: 0.0795, Val Loss: 0.7004
Epoch [26/50], Loss: 0.1665, Val Loss: 0.6696
Epoch [27/50], Loss: 0.1999, Val Loss: 0.6578
Epoch [28/50], Loss: 0.2857, Val Loss: 0.6340
Epoch [29/50], Loss: 0.2242, Val Loss: 0.6644
Epoch [30/50], Loss: 0.3466, Val Loss: 0.7049
Epoch [31/50], Loss: 0.3044, Val Loss: 0.6976
Epoch [32/50], Loss: 0.4217, Val Loss: 0.7044
Epoch [33/50], Loss: 0.2765, Val Loss: 0.6804
Epoch [34/50], Loss: 0.6563, Val Loss: 0.6112
Epoch [35/50], Loss: 0.7747, Val Loss: 0.6195
Epoch [36/50], Loss: 0.7546, Val Loss: 0.6158
Epoch [37/50], Loss: 0.2747, Val Loss: 0.6235
Epoch [38/50], Loss: 0.2004, Val Loss: 0.6264
Epoch [39/50], Loss: 0.1208, Val Loss: 0.6302
Epoch [40/50], Loss: 0.4524, Val Loss: 0.6721
Epoch [41/50], Loss: 0.1134, Val Loss: 0.8204
Epoch [42/50], Loss: 0.1941, Val Loss: 0.6087
Epoch [43/50], Loss: 0.3945, Val Loss: 0.8593
Epoch [44/50], Loss: 0.0870, Val Loss: 0.6231
Epoch [45/50], Loss: 0.4843, Val Loss: 0.6343
Epoch [46/50], Loss: 1.7708, Val Loss: 0.6871
Epoch [47/50], Loss: 0.3693, Val Loss: 0.6087
Epoch [48/50], Loss: 0.2387, Val Loss: 0.5917
Epoch [49/50], Loss: 0.1148, Val Loss: 0.5913
Epoch [50/50], Loss: 0.1384, Val Loss: 0.6104
Runtime: 0:01:14.830612
R^2 Score: 0.8205
RMSE: 0.9594
MAE: 0.2393
MAPE: 22.11%
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/50], Loss: 0.6340, Val Loss: 0.9009
Epoch [2/50], Loss: 0.2459, Val Loss: 1.0090
Epoch [3/50], Loss: 0.5568, Val Loss: 0.8258
Epoch [4/50], Loss: 1.9262, Val Loss: 0.8078
Epoch [5/50], Loss: 3.3370, Val Loss: 0.7449
Epoch [6/50], Loss: 0.5723, Val Loss: 0.7863
Epoch [7/50], Loss: 0.2059, Val Loss: 0.8251
Epoch [8/50], Loss: 0.2260, Val Loss: 0.7752
Epoch [9/50], Loss: 0.2231, Val Loss: 0.7088
Epoch [10/50], Loss: 0.1624, Val Loss: 0.7483
Epoch [11/50], Loss: 0.1413, Val Loss: 0.7893
Epoch [12/50], Loss: 1.3713, Val Loss: 0.6875
Epoch [13/50], Loss: 1.6671, Val Loss: 0.7895
Epoch [14/50], Loss: 0.3868, Val Loss: 0.7327
Epoch [15/50], Loss: 0.2483, Val Loss: 0.6967
Epoch [16/50], Loss: 0.0852, Val Loss: 0.7010
Epoch [17/50], Loss: 0.1812, Val Loss: 0.6988
Epoch [18/50], Loss: 0.5603, Val Loss: 0.7932
Epoch [19/50], Loss: 0.0727, Val Loss: 0.6864
Epoch [20/50], Loss: 0.0761, Val Loss: 0.6756
Epoch [21/50], Loss: 0.4540, Val Loss: 0.7288
Epoch [22/50], Loss: 0.3323, Val Loss: 0.7035
Epoch [23/50], Loss: 0.0961, Val Loss: 0.6380
Epoch [24/50], Loss: 0.1215, Val Loss: 0.6933
Epoch [25/50], Loss: 0.4059, Val Loss: 0.6644
Epoch [26/50], Loss: 0.1581, Val Loss: 0.6243
Epoch [27/50], Loss: 0.1734, Val Loss: 0.8747
Epoch [28/50], Loss: 0.1280, Val Loss: 0.6296
Epoch [29/50], Loss: 0.4503, Val Loss: 0.6318
Epoch [30/50], Loss: 0.0723, Val Loss: 0.6621
Epoch [31/50], Loss: 0.1088, Val Loss: 0.6153
Epoch [32/50], Loss: 0.3904, Val Loss: 0.6968
Epoch [33/50], Loss: 0.5736, Val Loss: 0.6468
Epoch [34/50], Loss: 0.1737, Val Loss: 0.6215
Epoch [35/50], Loss: 0.1725, Val Loss: 0.6598
Epoch [36/50], Loss: 0.1027, Val Loss: 0.5835
Epoch [37/50], Loss: 1.1220, Val Loss: 0.5901
Epoch [38/50], Loss: 0.3761, Val Loss: 0.6269
Epoch [39/50], Loss: 0.4100, Val Loss: 0.6302
Epoch [40/50], Loss: 0.5718, Val Loss: 0.6785
Epoch [41/50], Loss: 0.1166, Val Loss: 0.6126
Epoch [42/50], Loss: 0.2926, Val Loss: 0.7920
Epoch [43/50], Loss: 0.1257, Val Loss: 0.5622
Epoch [44/50], Loss: 0.1172, Val Loss: 0.5687
Epoch [45/50], Loss: 0.4031, Val Loss: 0.5712
Epoch [46/50], Loss: 0.1313, Val Loss: 0.5552
Epoch [47/50], Loss: 0.8544, Val Loss: 0.5500
Epoch [48/50], Loss: 0.2670, Val Loss: 0.5880
Epoch [49/50], Loss: 0.1273, Val Loss: 0.5988
Epoch [50/50], Loss: 0.0729, Val Loss: 0.5591
Runtime: 0:01:14.482153
R^2 Score: 0.8916
RMSE: 0.7454
MAE: 0.2092
MAPE: 19.27%
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/100], Loss: 0.0943, Val Loss: 0.5473
Epoch [2/100], Loss: 0.1220, Val Loss: 0.6199
Epoch [3/100], Loss: 0.4841, Val Loss: 0.5449
Epoch [4/100], Loss: 0.2449, Val Loss: 0.6038
Epoch [5/100], Loss: 0.4642, Val Loss: 0.5736
Epoch [6/100], Loss: 0.0796, Val Loss: 0.5481
Epoch [7/100], Loss: 0.1863, Val Loss: 0.6202
Epoch [8/100], Loss: 0.1213, Val Loss: 0.5642
Epoch [9/100], Loss: 0.1353, Val Loss: 0.5427
Epoch [10/100], Loss: 0.0797, Val Loss: 0.5587
Epoch [11/100], Loss: 0.4003, Val Loss: 0.7275
Epoch [12/100], Loss: 0.2424, Val Loss: 0.6247
Epoch [13/100], Loss: 0.1165, Val Loss: 0.5570
Epoch [14/100], Loss: 0.2715, Val Loss: 0.5545
Epoch [15/100], Loss: 0.2419, Val Loss: 0.6218
Epoch [16/100], Loss: 0.0587, Val Loss: 0.5422
Epoch [17/100], Loss: 0.1901, Val Loss: 0.5356
Epoch [18/100], Loss: 0.6964, Val Loss: 0.5444
Epoch [19/100], Loss: 0.1419, Val Loss: 0.5287
Epoch [20/100], Loss: 0.1099, Val Loss: 0.5478
Epoch [21/100], Loss: 0.0866, Val Loss: 0.5435
Epoch [22/100], Loss: 0.8212, Val Loss: 0.5661
Epoch [23/100], Loss: 0.1345, Val Loss: 0.5228
Epoch [24/100], Loss: 0.9385, Val Loss: 0.7361
Epoch [25/100], Loss: 0.1153, Val Loss: 0.5684
Epoch [26/100], Loss: 1.0470, Val Loss: 0.6011
Epoch [27/100], Loss: 0.1403, Val Loss: 0.5403
Epoch [28/100], Loss: 0.1566, Val Loss: 0.5404
Epoch [29/100], Loss: 0.0754, Val Loss: 0.5604
Epoch [30/100], Loss: 0.0621, Val Loss: 0.5565
Epoch [31/100], Loss: 0.0516, Val Loss: 0.5603
Epoch [32/100], Loss: 0.1484, Val Loss: 0.5253
Epoch [33/100], Loss: 0.1285, Val Loss: 0.5575
Epoch [34/100], Loss: 0.1051, Val Loss: 0.5246
Early stopping at epoch 34
Runtime: 0:00:51.462616
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/100], Loss: 1.7881, Val Loss: 0.8993
Epoch [2/100], Loss: 0.4979, Val Loss: 0.8050
Epoch [3/100], Loss: 0.9112, Val Loss: 1.0549
Epoch [4/100], Loss: 0.5798, Val Loss: 0.8110
Epoch [5/100], Loss: 0.2377, Val Loss: 0.7844
Epoch [6/100], Loss: 0.0848, Val Loss: 0.7617
Epoch [7/100], Loss: 0.5813, Val Loss: 0.7126
Epoch [8/100], Loss: 0.4666, Val Loss: 0.7292
Epoch [9/100], Loss: 0.4358, Val Loss: 0.7947
Epoch [10/100], Loss: 0.0518, Val Loss: 0.7483
Epoch [11/100], Loss: 0.9071, Val Loss: 0.6626
Early stopping at epoch 11
Runtime: 0:00:18.140535
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/100], Loss: 0.0939, Val Loss: 0.7210
Epoch [2/100], Loss: 0.4849, Val Loss: 0.6691
Epoch [3/100], Loss: 0.0877, Val Loss: 0.6305
Epoch [4/100], Loss: 0.4048, Val Loss: 0.5959
Epoch [5/100], Loss: 0.2336, Val Loss: 0.8489
Epoch [6/100], Loss: 0.2543, Val Loss: 0.6435
Epoch [7/100], Loss: 0.4740, Val Loss: 0.6272
Epoch [8/100], Loss: 0.6348, Val Loss: 0.6313
Epoch [9/100], Loss: 0.1520, Val Loss: 0.6499
Epoch [10/100], Loss: 0.5161, Val Loss: 0.6838
Epoch [11/100], Loss: 0.2502, Val Loss: 0.5974
Epoch [12/100], Loss: 2.0178, Val Loss: 0.5931
Epoch [13/100], Loss: 0.2306, Val Loss: 0.6776
Epoch [14/100], Loss: 0.2168, Val Loss: 0.6184
Epoch [15/100], Loss: 0.3900, Val Loss: 0.6146
Epoch [16/100], Loss: 0.4611, Val Loss: 0.5974
Epoch [17/100], Loss: 0.0970, Val Loss: 0.6233
Epoch [18/100], Loss: 0.5721, Val Loss: 0.5777
Epoch [19/100], Loss: 1.5288, Val Loss: 0.5932
Epoch [20/100], Loss: 0.1852, Val Loss: 0.6528
Epoch [21/100], Loss: 0.2171, Val Loss: 0.6611
Epoch [22/100], Loss: 0.3873, Val Loss: 0.5921
Epoch [23/100], Loss: 0.1430, Val Loss: 0.6594
Epoch [24/100], Loss: 0.1005, Val Loss: 0.6574
Epoch [25/100], Loss: 0.2045, Val Loss: 0.7071
Epoch [26/100], Loss: 0.1785, Val Loss: 0.5942
Epoch [27/100], Loss: 0.1688, Val Loss: 0.6057
Epoch [28/100], Loss: 0.7180, Val Loss: 0.5748
Epoch [29/100], Loss: 0.3193, Val Loss: 0.5766
Epoch [30/100], Loss: 0.1607, Val Loss: 0.6200
Epoch [31/100], Loss: 0.0747, Val Loss: 0.5859
Epoch [32/100], Loss: 0.7580, Val Loss: 0.5573
Epoch [33/100], Loss: 0.2473, Val Loss: 0.5664
Epoch [34/100], Loss: 0.0908, Val Loss: 0.5609
Epoch [35/100], Loss: 1.7674, Val Loss: 0.5944
Epoch [36/100], Loss: 0.2143, Val Loss: 0.6035
Epoch [37/100], Loss: 0.5000, Val Loss: 0.6400
Epoch [38/100], Loss: 0.1479, Val Loss: 0.7346
Epoch [39/100], Loss: 0.0765, Val Loss: 0.5786
Epoch [40/100], Loss: 0.0484, Val Loss: 0.5623
Epoch [41/100], Loss: 0.5259, Val Loss: 0.6057
Epoch [42/100], Loss: 0.0947, Val Loss: 0.6178
Epoch [43/100], Loss: 0.2620, Val Loss: 0.5865
Epoch [44/100], Loss: 0.0656, Val Loss: 0.5768
Epoch [45/100], Loss: 0.1143, Val Loss: 0.6157
Early stopping at epoch 45
Runtime: 0:01:07.276384
R^2 Score: 0.8679
RMSE: 0.8229
MAE: 0.2267
MAPE: 20.26%
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/100], Loss: 0.1523, Val Loss: 0.9582
Epoch [2/100], Loss: 0.1748, Val Loss: 0.8588
Epoch [3/100], Loss: 0.4105, Val Loss: 0.7841
Epoch [4/100], Loss: 0.2008, Val Loss: 0.7429
Epoch [5/100], Loss: 0.1316, Val Loss: 0.9032
Epoch [6/100], Loss: 0.2090, Val Loss: 0.7261
Epoch [7/100], Loss: 0.1325, Val Loss: 0.7976
Epoch [8/100], Loss: 0.2553, Val Loss: 0.7806
Epoch [9/100], Loss: 0.6807, Val Loss: 0.7119
Epoch [10/100], Loss: 0.4270, Val Loss: 0.6861
Epoch [11/100], Loss: 0.1507, Val Loss: 0.7785
Epoch [12/100], Loss: 0.8826, Val Loss: 0.7406
Epoch [13/100], Loss: 0.1347, Val Loss: 0.8249
Epoch [14/100], Loss: 0.0930, Val Loss: 0.6819
Epoch [15/100], Loss: 0.7925, Val Loss: 0.7472
Epoch [16/100], Loss: 0.6724, Val Loss: 0.6985
Epoch [17/100], Loss: 1.2652, Val Loss: 0.6885
Epoch [18/100], Loss: 0.1193, Val Loss: 0.6787
Epoch [19/100], Loss: 0.7663, Val Loss: 0.6782
Epoch [20/100], Loss: 0.2052, Val Loss: 0.6520
Epoch [21/100], Loss: 0.1594, Val Loss: 0.7386
Epoch [22/100], Loss: 0.2578, Val Loss: 0.7650
Epoch [23/100], Loss: 0.9616, Val Loss: 0.8020
Epoch [24/100], Loss: 1.0342, Val Loss: 0.6675
Epoch [25/100], Loss: 0.0876, Val Loss: 0.7437
Epoch [26/100], Loss: 0.1976, Val Loss: 0.7192
Epoch [27/100], Loss: 0.1517, Val Loss: 0.6970
Epoch [28/100], Loss: 0.2102, Val Loss: 0.7025
Epoch [29/100], Loss: 0.1079, Val Loss: 0.7137
Epoch [30/100], Loss: 0.1893, Val Loss: 0.6769
Epoch [31/100], Loss: 0.0743, Val Loss: 0.6581
Epoch [32/100], Loss: 0.4442, Val Loss: 0.6457
Epoch [33/100], Loss: 1.1385, Val Loss: 0.6028
Epoch [34/100], Loss: 0.5649, Val Loss: 0.6963
Epoch [35/100], Loss: 0.3599, Val Loss: 0.7582
Epoch [36/100], Loss: 0.5189, Val Loss: 0.6416
Epoch [37/100], Loss: 0.1298, Val Loss: 0.5730
Epoch [38/100], Loss: 0.2658, Val Loss: 0.6152
Epoch [39/100], Loss: 0.2793, Val Loss: 0.5870
Epoch [40/100], Loss: 0.1529, Val Loss: 0.5780
Epoch [41/100], Loss: 0.1251, Val Loss: 0.5866
Epoch [42/100], Loss: 0.7054, Val Loss: 0.5971
Epoch [43/100], Loss: 0.0666, Val Loss: 0.6409
Epoch [44/100], Loss: 0.1566, Val Loss: 0.5733
Epoch [45/100], Loss: 0.0741, Val Loss: 0.5891
Epoch [46/100], Loss: 0.0580, Val Loss: 0.5878
Epoch [47/100], Loss: 0.1700, Val Loss: 0.5508
Epoch [48/100], Loss: 0.1939, Val Loss: 0.5764
Epoch [49/100], Loss: 0.1986, Val Loss: 0.6407
Epoch [50/100], Loss: 0.2634, Val Loss: 0.5824
Epoch [51/100], Loss: 0.0635, Val Loss: 0.5901
Epoch [52/100], Loss: 0.0402, Val Loss: 0.6016
Epoch [53/100], Loss: 0.2293, Val Loss: 0.5851
Epoch [54/100], Loss: 1.0011, Val Loss: 0.6316
Epoch [55/100], Loss: 0.1735, Val Loss: 0.5855
Epoch [56/100], Loss: 0.1029, Val Loss: 0.6046
Epoch [57/100], Loss: 0.0988, Val Loss: 0.5948
Epoch [58/100], Loss: 0.0660, Val Loss: 0.5913
Early stopping at epoch 58
Runtime: 0:01:25.670344
R^2 Score: 0.8154
RMSE: 0.9729
MAE: 0.2498
MAPE: 17.75%
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/100], Loss: 0.3871, Val Loss: 0.8735
Epoch [2/100], Loss: 0.2892, Val Loss: 0.8347
Epoch [3/100], Loss: 0.2348, Val Loss: 0.9349
Epoch [4/100], Loss: 0.1782, Val Loss: 0.8453
Epoch [5/100], Loss: 0.5140, Val Loss: 0.7807
Epoch [6/100], Loss: 0.3095, Val Loss: 0.7937
Epoch [7/100], Loss: 0.2464, Val Loss: 0.8989
Epoch [8/100], Loss: 0.2300, Val Loss: 0.7598
Epoch [9/100], Loss: 0.3146, Val Loss: 0.7005
Epoch [10/100], Loss: 0.5795, Val Loss: 0.7236
Epoch [11/100], Loss: 0.5611, Val Loss: 0.8923
Epoch [12/100], Loss: 0.2122, Val Loss: 0.6839
Epoch [13/100], Loss: 0.0984, Val Loss: 0.7400
Epoch [14/100], Loss: 0.6573, Val Loss: 0.7400
Epoch [15/100], Loss: 0.1713, Val Loss: 0.6953
Epoch [16/100], Loss: 0.7548, Val Loss: 0.6994
Epoch [17/100], Loss: 0.1326, Val Loss: 0.6356
Epoch [18/100], Loss: 0.3536, Val Loss: 0.6511
Epoch [19/100], Loss: 0.3383, Val Loss: 0.6555
Epoch [20/100], Loss: 0.4260, Val Loss: 0.6430
Epoch [21/100], Loss: 1.2269, Val Loss: 0.7197
Epoch [22/100], Loss: 0.7998, Val Loss: 0.7129
Epoch [23/100], Loss: 0.9210, Val Loss: 0.6625
Epoch [24/100], Loss: 0.1281, Val Loss: 0.6441
Epoch [25/100], Loss: 0.1896, Val Loss: 0.6778
Epoch [26/100], Loss: 0.1023, Val Loss: 0.5976
Epoch [27/100], Loss: 1.8344, Val Loss: 0.6615
Epoch [28/100], Loss: 0.1708, Val Loss: 0.6334
Epoch [29/100], Loss: 0.2580, Val Loss: 0.7461
Epoch [30/100], Loss: 0.3886, Val Loss: 0.6060
Epoch [31/100], Loss: 0.0886, Val Loss: 0.5873
Epoch [32/100], Loss: 0.2643, Val Loss: 0.5642
Epoch [33/100], Loss: 0.1041, Val Loss: 0.6313
Epoch [34/100], Loss: 0.0591, Val Loss: 0.6009
Epoch [35/100], Loss: 0.1983, Val Loss: 0.6405
Epoch [36/100], Loss: 1.0611, Val Loss: 0.5905
Epoch [37/100], Loss: 0.2326, Val Loss: 0.6047
Epoch [38/100], Loss: 0.1775, Val Loss: 0.6543
Epoch [39/100], Loss: 0.1167, Val Loss: 0.6368
Epoch [40/100], Loss: 0.1898, Val Loss: 0.6127
Epoch [41/100], Loss: 0.1434, Val Loss: 0.5792
Epoch [42/100], Loss: 0.1094, Val Loss: 0.6480
Epoch [43/100], Loss: 0.1010, Val Loss: 0.6102
Epoch [44/100], Loss: 0.4097, Val Loss: 0.5964
Epoch [45/100], Loss: 0.2424, Val Loss: 0.5936
Epoch [46/100], Loss: 0.1531, Val Loss: 0.6021
Epoch [47/100], Loss: 0.3088, Val Loss: 0.5938
Epoch [48/100], Loss: 0.1762, Val Loss: 0.5820
Epoch [49/100], Loss: 0.0692, Val Loss: 0.5907
Epoch [50/100], Loss: 0.7900, Val Loss: 0.6437
Epoch [51/100], Loss: 0.3412, Val Loss: 0.6867
Early stopping at epoch 51
Runtime: 0:01:17.286680
R^2 Score: 0.8567
RMSE: 0.8572
MAE: 0.2374
MAPE: 21.42%
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/100], Loss: 0.4894, Val Loss: 0.8927
Epoch [2/100], Loss: 0.4011, Val Loss: 0.8490
Epoch [3/100], Loss: 0.5955, Val Loss: 0.9768
Epoch [4/100], Loss: 0.0621, Val Loss: 0.7900
Epoch [5/100], Loss: 0.8132, Val Loss: 0.7593
Epoch [6/100], Loss: 0.1267, Val Loss: 0.7574
Epoch [7/100], Loss: 0.3233, Val Loss: 0.7795
Epoch [8/100], Loss: 0.5355, Val Loss: 0.7843
Epoch [9/100], Loss: 0.1992, Val Loss: 0.8072
Epoch [10/100], Loss: 0.2971, Val Loss: 0.6861
Epoch [11/100], Loss: 1.0516, Val Loss: 0.8045
Epoch [12/100], Loss: 0.7865, Val Loss: 0.6785
Epoch [13/100], Loss: 0.8355, Val Loss: 0.6504
Epoch [14/100], Loss: 0.6012, Val Loss: 0.7070
Epoch [15/100], Loss: 0.1968, Val Loss: 0.6639
Epoch [16/100], Loss: 0.0722, Val Loss: 0.7471
Epoch [17/100], Loss: 0.5083, Val Loss: 0.6946
Epoch [18/100], Loss: 0.1751, Val Loss: 0.6431
Epoch [19/100], Loss: 0.5108, Val Loss: 0.6751
Epoch [20/100], Loss: 0.2720, Val Loss: 0.6801
Epoch [21/100], Loss: 0.1186, Val Loss: 0.6730
Epoch [22/100], Loss: 0.1447, Val Loss: 0.7032
Epoch [23/100], Loss: 0.2106, Val Loss: 0.6281
Epoch [24/100], Loss: 0.1955, Val Loss: 0.6649
Epoch [25/100], Loss: 0.3829, Val Loss: 0.6656
Epoch [26/100], Loss: 0.2393, Val Loss: 0.6332
Epoch [27/100], Loss: 0.1936, Val Loss: 0.6251
Epoch [28/100], Loss: 0.0769, Val Loss: 0.6073
Epoch [29/100], Loss: 0.0737, Val Loss: 0.5943
Epoch [30/100], Loss: 0.1080, Val Loss: 0.6027
Epoch [31/100], Loss: 0.2555, Val Loss: 0.6382
Epoch [32/100], Loss: 0.9247, Val Loss: 0.5811
Epoch [33/100], Loss: 0.0698, Val Loss: 0.6205
Epoch [34/100], Loss: 0.2010, Val Loss: 0.6175
Epoch [35/100], Loss: 0.2720, Val Loss: 0.5656
Epoch [36/100], Loss: 0.4342, Val Loss: 0.5771
Epoch [37/100], Loss: 0.0888, Val Loss: 0.5751
Epoch [38/100], Loss: 0.0888, Val Loss: 0.6174
Epoch [39/100], Loss: 0.0825, Val Loss: 0.6234
Epoch [40/100], Loss: 0.1585, Val Loss: 0.6325
Epoch [41/100], Loss: 0.2115, Val Loss: 0.5682
Epoch [42/100], Loss: 0.0791, Val Loss: 0.6286
Epoch [43/100], Loss: 0.0414, Val Loss: 0.5671
Epoch [44/100], Loss: 0.1196, Val Loss: 0.5686
Epoch [45/100], Loss: 0.0393, Val Loss: 0.5806
Epoch [46/100], Loss: 0.6691, Val Loss: 0.5539
Epoch [47/100], Loss: 0.1579, Val Loss: 0.5529
Epoch [48/100], Loss: 0.0960, Val Loss: 0.5686
Epoch [49/100], Loss: 1.0369, Val Loss: 0.6844
Epoch [50/100], Loss: 0.1625, Val Loss: 0.5642
Epoch [51/100], Loss: 0.0998, Val Loss: 0.5783
Epoch [52/100], Loss: 0.1273, Val Loss: 0.6192
Epoch [53/100], Loss: 0.9534, Val Loss: 0.5854
Epoch [54/100], Loss: 0.1874, Val Loss: 0.5705
Epoch [55/100], Loss: 0.7073, Val Loss: 0.5755
Epoch [56/100], Loss: 0.2471, Val Loss: 0.5542
Epoch [57/100], Loss: 0.8261, Val Loss: 0.5796
Epoch [58/100], Loss: 0.4199, Val Loss: 0.5378
Epoch [59/100], Loss: 0.1045, Val Loss: 0.5681
Epoch [60/100], Loss: 0.1018, Val Loss: 0.5439
Epoch [61/100], Loss: 0.1282, Val Loss: 0.5371
Epoch [62/100], Loss: 0.3119, Val Loss: 0.5992
Epoch [63/100], Loss: 0.1472, Val Loss: 0.5623
Epoch [64/100], Loss: 0.2165, Val Loss: 0.5807
Epoch [65/100], Loss: 0.2425, Val Loss: 0.5709
Epoch [66/100], Loss: 0.2439, Val Loss: 0.5520
Epoch [67/100], Loss: 0.1838, Val Loss: 0.5882
Epoch [68/100], Loss: 0.1938, Val Loss: 0.5603
Epoch [69/100], Loss: 0.2371, Val Loss: 0.5589
Epoch [70/100], Loss: 0.2523, Val Loss: 0.5755
Epoch [71/100], Loss: 0.4474, Val Loss: 0.5456
Epoch [72/100], Loss: 0.1259, Val Loss: 0.6221
Epoch [73/100], Loss: 0.2770, Val Loss: 0.5422
Epoch [74/100], Loss: 0.3023, Val Loss: 0.5765
Epoch [75/100], Loss: 0.1759, Val Loss: 0.5615
Epoch [76/100], Loss: 0.1795, Val Loss: 0.5891
Epoch [77/100], Loss: 0.2190, Val Loss: 0.5210
Epoch [78/100], Loss: 0.1723, Val Loss: 0.5620
Epoch [79/100], Loss: 0.0954, Val Loss: 0.5398
Epoch [80/100], Loss: 0.1186, Val Loss: 0.5981
Epoch [81/100], Loss: 2.0580, Val Loss: 0.5221
Epoch [82/100], Loss: 0.0936, Val Loss: 0.5069
Epoch [83/100], Loss: 0.1055, Val Loss: 0.5536
Epoch [84/100], Loss: 0.0647, Val Loss: 0.5634
Epoch [85/100], Loss: 0.0952, Val Loss: 0.5938
Epoch [86/100], Loss: 0.1021, Val Loss: 0.5403
Epoch [87/100], Loss: 0.1436, Val Loss: 0.5443
Epoch [88/100], Loss: 0.1412, Val Loss: 0.5537
Epoch [89/100], Loss: 0.4079, Val Loss: 0.5238
Epoch [90/100], Loss: 0.0429, Val Loss: 0.5251
Epoch [91/100], Loss: 0.0908, Val Loss: 0.5519
Epoch [92/100], Loss: 0.1628, Val Loss: 0.5291
Epoch [93/100], Loss: 0.2090, Val Loss: 0.5260
Epoch [94/100], Loss: 0.1912, Val Loss: 0.5488
Epoch [95/100], Loss: 0.0518, Val Loss: 0.5594
Epoch [96/100], Loss: 0.0786, Val Loss: 0.5611
Epoch [97/100], Loss: 0.1107, Val Loss: 0.5181
Epoch [98/100], Loss: 0.1358, Val Loss: 0.5298
Epoch [99/100], Loss: 0.0716, Val Loss: 0.5437
Epoch [100/100], Loss: 0.4947, Val Loss: 0.5380
Runtime: 0:02:21.712667
R^2 Score: 0.8811
RMSE: 0.7807
MAE: 0.2233
MAPE: 18.94%
TruncatedSVD_100MLP with layer size: [128, 64, 32] - Result:
Epoch [1/100], Loss: 0.1103, Val Loss: 0.8277
Epoch [2/100], Loss: 0.3391, Val Loss: 0.7799
Epoch [3/100], Loss: 0.1369, Val Loss: 0.8323
Epoch [4/100], Loss: 0.1384, Val Loss: 0.9717
Epoch [5/100], Loss: 0.1429, Val Loss: 0.8215
Epoch [6/100], Loss: 0.4421, Val Loss: 0.7656
Epoch [7/100], Loss: 0.2776, Val Loss: 0.7586
Epoch [8/100], Loss: 0.2456, Val Loss: 0.8044
Epoch [9/100], Loss: 0.2630, Val Loss: 0.7775
Epoch [10/100], Loss: 0.3896, Val Loss: 0.7789
Epoch [11/100], Loss: 0.5404, Val Loss: 0.8317
Epoch [12/100], Loss: 0.4248, Val Loss: 0.7117
Epoch [13/100], Loss: 0.1459, Val Loss: 0.7444
Epoch [14/100], Loss: 0.4947, Val Loss: 0.6403
Epoch [15/100], Loss: 0.7592, Val Loss: 0.7785
Epoch [16/100], Loss: 0.0858, Val Loss: 0.6383
Epoch [17/100], Loss: 0.2747, Val Loss: 0.7471
Epoch [18/100], Loss: 0.1582, Val Loss: 0.6630
Epoch [19/100], Loss: 0.2304, Val Loss: 0.9441
Epoch [20/100], Loss: 0.3676, Val Loss: 0.7447
Epoch [21/100], Loss: 0.3720, Val Loss: 0.6912
Epoch [22/100], Loss: 4.1830, Val Loss: 0.7081
Epoch [23/100], Loss: 0.1936, Val Loss: 0.8097
Epoch [24/100], Loss: 0.1254, Val Loss: 0.8238
Epoch [25/100], Loss: 0.1520, Val Loss: 0.6716
Epoch [26/100], Loss: 0.1128, Val Loss: 0.7208
Epoch [27/100], Loss: 0.0820, Val Loss: 0.6467
Epoch [28/100], Loss: 0.6307, Val Loss: 0.7986
Epoch [29/100], Loss: 1.9868, Val Loss: 0.6461
Epoch [30/100], Loss: 0.3220, Val Loss: 0.7275
Epoch [31/100], Loss: 0.3373, Val Loss: 0.6758
Epoch [32/100], Loss: 0.1880, Val Loss: 0.6270
Epoch [33/100], Loss: 0.1820, Val Loss: 0.6237
Epoch [34/100], Loss: 0.3686, Val Loss: 0.9401
Epoch [35/100], Loss: 0.3043, Val Loss: 0.6219
Epoch [36/100], Loss: 0.0767, Val Loss: 0.6489
Epoch [37/100], Loss: 0.0977, Val Loss: 0.6427
Epoch [38/100], Loss: 0.1943, Val Loss: 0.6611
Epoch [39/100], Loss: 0.0830, Val Loss: 0.6571
Epoch [40/100], Loss: 1.1500, Val Loss: 0.6917
TruncatedSVD_100MLP with layer size: [64, 48, 32] - Result:
Epoch [1/100], Loss: 0.1232, Val Loss: 0.8774
Epoch [2/100], Loss: 0.7028, Val Loss: 1.1038
Epoch [3/100], Loss: 0.1438, Val Loss: 0.8042
Epoch [4/100], Loss: 0.4811, Val Loss: 0.9523
Epoch [5/100], Loss: 0.4935, Val Loss: 0.7863
Epoch [6/100], Loss: 0.2072, Val Loss: 0.7512
Epoch [7/100], Loss: 0.0743, Val Loss: 0.7279
Epoch [8/100], Loss: 0.7608, Val Loss: 0.8063
Epoch [9/100], Loss: 0.0856, Val Loss: 0.7551
Epoch [10/100], Loss: 0.2908, Val Loss: 0.7336
Epoch [11/100], Loss: 0.7008, Val Loss: 0.7857
Epoch [12/100], Loss: 1.1999, Val Loss: 0.6914
Epoch [13/100], Loss: 0.2429, Val Loss: 0.7055
Epoch [14/100], Loss: 0.1365, Val Loss: 1.1199
Epoch [15/100], Loss: 0.3244, Val Loss: 0.7298
Epoch [16/100], Loss: 0.3537, Val Loss: 0.6407
Epoch [17/100], Loss: 0.0829, Val Loss: 0.6248
Epoch [18/100], Loss: 1.7752, Val Loss: 0.6945
Epoch [19/100], Loss: 0.1307, Val Loss: 0.6293
Epoch [20/100], Loss: 0.1131, Val Loss: 0.7373
Epoch [21/100], Loss: 0.5510, Val Loss: 0.6654
Epoch [22/100], Loss: 0.4023, Val Loss: 0.7146
Epoch [23/100], Loss: 0.2046, Val Loss: 0.8523
Epoch [24/100], Loss: 0.2450, Val Loss: 0.6389
Epoch [25/100], Loss: 0.4259, Val Loss: 0.7445
Epoch [26/100], Loss: 0.3302, Val Loss: 0.6813
Epoch [27/100], Loss: 0.1435, Val Loss: 0.6544
Epoch [28/100], Loss: 0.2464, Val Loss: 0.6214
Epoch [29/100], Loss: 0.1908, Val Loss: 0.7186
Epoch [30/100], Loss: 0.1041, Val Loss: 0.5723
Epoch [31/100], Loss: 0.2292, Val Loss: 0.6088
Epoch [32/100], Loss: 0.1973, Val Loss: 0.6007
Epoch [33/100], Loss: 0.4668, Val Loss: 0.6086
Epoch [34/100], Loss: 0.7191, Val Loss: 0.6071
Epoch [35/100], Loss: 0.3592, Val Loss: 0.6743
Epoch [36/100], Loss: 0.4880, Val Loss: 0.6956
Epoch [37/100], Loss: 0.1971, Val Loss: 0.6405
Epoch [38/100], Loss: 0.2249, Val Loss: 0.6000
Epoch [39/100], Loss: 0.2187, Val Loss: 0.6094
Epoch [40/100], Loss: 0.3878, Val Loss: 0.6107
Epoch [41/100], Loss: 0.1310, Val Loss: 0.7070
Epoch [42/100], Loss: 0.1817, Val Loss: 0.6104
Epoch [43/100], Loss: 1.6900, Val Loss: 0.6035
Epoch [44/100], Loss: 0.8566, Val Loss: 0.6023
Epoch [45/100], Loss: 0.1652, Val Loss: 0.5755
Epoch [46/100], Loss: 0.6629, Val Loss: 0.6274
Epoch [47/100], Loss: 0.2251, Val Loss: 0.5634
Epoch [48/100], Loss: 0.3291, Val Loss: 0.5790
Epoch [49/100], Loss: 0.1926, Val Loss: 0.6993
Epoch [50/100], Loss: 0.3069, Val Loss: 0.5867
Epoch [51/100], Loss: 0.1769, Val Loss: 0.5728
Epoch [52/100], Loss: 0.1280, Val Loss: 0.5880
Epoch [53/100], Loss: 0.2018, Val Loss: 0.6011
Epoch [54/100], Loss: 0.1213, Val Loss: 0.5940
Epoch [55/100], Loss: 0.2244, Val Loss: 0.5650
Epoch [56/100], Loss: 0.2283, Val Loss: 0.6408
Epoch [57/100], Loss: 0.1619, Val Loss: 0.6594
Epoch [58/100], Loss: 0.0649, Val Loss: 0.5785
Epoch [59/100], Loss: 0.1730, Val Loss: 0.5745
Epoch [60/100], Loss: 0.1656, Val Loss: 0.5838
Epoch [61/100], Loss: 0.2813, Val Loss: 0.5957
Epoch [62/100], Loss: 0.0795, Val Loss: 0.5896
Epoch [63/100], Loss: 0.1638, Val Loss: 0.5615
Epoch [64/100], Loss: 0.1267, Val Loss: 0.7186
Epoch [65/100], Loss: 0.6011, Val Loss: 0.6154
Epoch [66/100], Loss: 0.2388, Val Loss: 0.6033
Epoch [67/100], Loss: 0.1867, Val Loss: 0.5915
Epoch [68/100], Loss: 0.2077, Val Loss: 0.5624
Epoch [69/100], Loss: 0.1904, Val Loss: 0.5581
Epoch [70/100], Loss: 0.0727, Val Loss: 0.5928
Epoch [71/100], Loss: 0.1580, Val Loss: 0.5403
Epoch [72/100], Loss: 0.1182, Val Loss: 0.5715
Epoch [73/100], Loss: 0.2002, Val Loss: 0.5359
Epoch [74/100], Loss: 0.1009, Val Loss: 0.5421
Epoch [75/100], Loss: 0.0807, Val Loss: 0.5526
Epoch [76/100], Loss: 1.4334, Val Loss: 0.5841
Epoch [77/100], Loss: 0.4050, Val Loss: 0.5746
Epoch [78/100], Loss: 0.2209, Val Loss: 0.5729
Epoch [79/100], Loss: 0.0647, Val Loss: 0.5304
Epoch [80/100], Loss: 0.1208, Val Loss: 0.5792
Epoch [81/100], Loss: 0.8665, Val Loss: 0.5503
Epoch [82/100], Loss: 0.2100, Val Loss: 0.5628
Epoch [83/100], Loss: 0.1076, Val Loss: 0.5872
Epoch [84/100], Loss: 0.2264, Val Loss: 0.5543
Epoch [85/100], Loss: 0.0869, Val Loss: 0.5671
Epoch [86/100], Loss: 0.3182, Val Loss: 0.5883
Epoch [87/100], Loss: 0.2296, Val Loss: 0.5266
Epoch [88/100], Loss: 0.0623, Val Loss: 0.5402
Epoch [89/100], Loss: 0.1809, Val Loss: 0.5487
Epoch [90/100], Loss: 0.4323, Val Loss: 0.5518
Epoch [91/100], Loss: 0.0583, Val Loss: 0.5641
Epoch [92/100], Loss: 0.1243, Val Loss: 0.5483
Epoch [93/100], Loss: 0.1325, Val Loss: 0.5446
Epoch [94/100], Loss: 0.2251, Val Loss: 0.5557
Epoch [95/100], Loss: 0.2188, Val Loss: 0.5241
Epoch [96/100], Loss: 0.0570, Val Loss: 0.5844
Epoch [97/100], Loss: 0.1126, Val Loss: 0.5321
Epoch [98/100], Loss: 0.4038, Val Loss: 0.5575
Epoch [99/100], Loss: 0.1447, Val Loss: 0.5996
Epoch [100/100], Loss: 0.0708, Val Loss: 0.5646
Runtime: 0:02:30.530525
R^2 Score: 0.8406
RMSE: 0.9040
MAE: 0.2245
MAPE: 18.50%
TruncatedSVD_100MLP with layer size: [64, 32, 16] - Result:
Epoch [1/100], Loss: 0.3186, Val Loss: 1.0126
Epoch [2/100], Loss: 0.1090, Val Loss: 0.8635
Epoch [3/100], Loss: 0.6931, Val Loss: 0.7933
Epoch [4/100], Loss: 0.1244, Val Loss: 0.9423
Epoch [5/100], Loss: 0.2494, Val Loss: 0.7871
Epoch [6/100], Loss: 0.2971, Val Loss: 0.7833
Epoch [7/100], Loss: 0.5884, Val Loss: 0.7404
Epoch [8/100], Loss: 1.1631, Val Loss: 0.8018
Epoch [9/100], Loss: 0.3291, Val Loss: 0.9642
Epoch [10/100], Loss: 0.2031, Val Loss: 0.7457
Epoch [11/100], Loss: 0.1947, Val Loss: 0.7689
Epoch [12/100], Loss: 0.2186, Val Loss: 0.8018
Epoch [13/100], Loss: 1.0566, Val Loss: 0.7614
Epoch [14/100], Loss: 0.1408, Val Loss: 0.7009
Epoch [15/100], Loss: 0.2646, Val Loss: 0.8226
Epoch [16/100], Loss: 0.0639, Val Loss: 0.6900
Epoch [17/100], Loss: 0.2973, Val Loss: 0.6924
Epoch [18/100], Loss: 0.1039, Val Loss: 0.6659
Epoch [19/100], Loss: 0.2540, Val Loss: 0.7369
Epoch [20/100], Loss: 0.8165, Val Loss: 0.7104
Epoch [21/100], Loss: 0.0817, Val Loss: 0.6939
Epoch [22/100], Loss: 0.1311, Val Loss: 0.7242
Epoch [23/100], Loss: 0.3120, Val Loss: 0.7562
Epoch [24/100], Loss: 0.3804, Val Loss: 0.7077
Epoch [25/100], Loss: 0.2497, Val Loss: 0.7503
Epoch [26/100], Loss: 0.4924, Val Loss: 0.6959
Epoch [27/100], Loss: 0.1746, Val Loss: 0.6726
Epoch [28/100], Loss: 1.5365, Val Loss: 1.0056
Epoch [29/100], Loss: 0.3485, Val Loss: 0.7049
Epoch [30/100], Loss: 0.0787, Val Loss: 0.6546
Epoch [31/100], Loss: 0.2742, Val Loss: 0.6790
Epoch [32/100], Loss: 0.1342, Val Loss: 0.6388
Epoch [33/100], Loss: 0.0622, Val Loss: 0.6553
Epoch [34/100], Loss: 0.1595, Val Loss: 0.6494
Epoch [35/100], Loss: 0.3894, Val Loss: 0.7130
Epoch [36/100], Loss: 0.1351, Val Loss: 0.6640
Epoch [37/100], Loss: 0.2374, Val Loss: 0.6426
Epoch [38/100], Loss: 0.2199, Val Loss: 0.6404
Epoch [39/100], Loss: 0.3991, Val Loss: 0.6236
Epoch [40/100], Loss: 0.1435, Val Loss: 0.6587
Epoch [41/100], Loss: 0.0989, Val Loss: 0.6632
Epoch [42/100], Loss: 0.1377, Val Loss: 0.6437
Epoch [43/100], Loss: 0.0867, Val Loss: 0.6311
Epoch [44/100], Loss: 0.1310, Val Loss: 0.6778
Epoch [45/100], Loss: 0.3656, Val Loss: 0.5986
Epoch [46/100], Loss: 0.1280, Val Loss: 0.6841
Epoch [47/100], Loss: 0.2900, Val Loss: 0.6474
Epoch [48/100], Loss: 0.1442, Val Loss: 0.6229
Epoch [49/100], Loss: 0.0652, Val Loss: 0.7700
Epoch [50/100], Loss: 0.1318, Val Loss: 0.6350
Epoch [51/100], Loss: 0.1871, Val Loss: 0.6477
Epoch [52/100], Loss: 0.1514, Val Loss: 0.6627
Epoch [53/100], Loss: 0.3329, Val Loss: 0.6088
Epoch [54/100], Loss: 0.4159, Val Loss: 0.6112
Epoch [55/100], Loss: 0.5991, Val Loss: 0.5964
Epoch [56/100], Loss: 0.2072, Val Loss: 0.6038
Epoch [57/100], Loss: 0.2628, Val Loss: 0.6683
Epoch [58/100], Loss: 3.4291, Val Loss: 0.6189
Epoch [59/100], Loss: 0.2245, Val Loss: 0.6033
Epoch [60/100], Loss: 0.2075, Val Loss: 0.7533
Epoch [61/100], Loss: 0.8540, Val Loss: 0.6085
Epoch [62/100], Loss: 0.0623, Val Loss: 0.6205
Epoch [63/100], Loss: 0.5165, Val Loss: 0.5922
Epoch [64/100], Loss: 0.2275, Val Loss: 0.5991
Epoch [65/100], Loss: 0.2183, Val Loss: 0.5794
Epoch [66/100], Loss: 0.1474, Val Loss: 0.6157
Epoch [67/100], Loss: 0.1443, Val Loss: 0.6062
Epoch [68/100], Loss: 0.1599, Val Loss: 0.5767
Epoch [69/100], Loss: 0.2701, Val Loss: 0.5545
Epoch [70/100], Loss: 0.0776, Val Loss: 0.5795
Epoch [71/100], Loss: 0.2375, Val Loss: 0.5821
Epoch [72/100], Loss: 0.1814, Val Loss: 0.5632
Epoch [73/100], Loss: 0.0768, Val Loss: 0.6258
Epoch [74/100], Loss: 0.1672, Val Loss: 0.6270
Epoch [75/100], Loss: 0.1338, Val Loss: 0.5614
Epoch [76/100], Loss: 0.1479, Val Loss: 0.6067
Epoch [77/100], Loss: 0.1699, Val Loss: 0.6129
Epoch [78/100], Loss: 0.1254, Val Loss: 0.5997
Epoch [79/100], Loss: 0.6619, Val Loss: 0.5586
Epoch [80/100], Loss: 0.0846, Val Loss: 0.6316
Epoch [81/100], Loss: 0.0720, Val Loss: 0.6492
Epoch [82/100], Loss: 0.8072, Val Loss: 0.6221
Epoch [83/100], Loss: 0.0179, Val Loss: 0.5867
Epoch [84/100], Loss: 0.1348, Val Loss: 0.5759
Epoch [85/100], Loss: 0.1163, Val Loss: 0.5813
Epoch [86/100], Loss: 0.1854, Val Loss: 0.5691
Epoch [87/100], Loss: 0.1928, Val Loss: 0.5401
Epoch [88/100], Loss: 0.4053, Val Loss: 0.5827
Epoch [89/100], Loss: 0.0684, Val Loss: 0.5598
Epoch [90/100], Loss: 0.0677, Val Loss: 0.6303
Epoch [91/100], Loss: 0.3317, Val Loss: 0.5817
Epoch [92/100], Loss: 0.0937, Val Loss: 0.5760
Epoch [93/100], Loss: 0.2552, Val Loss: 0.5383
Epoch [94/100], Loss: 0.1747, Val Loss: 0.6206
Epoch [95/100], Loss: 0.1155, Val Loss: 0.5958
Epoch [96/100], Loss: 0.1259, Val Loss: 0.5541
Epoch [97/100], Loss: 0.7665, Val Loss: 0.6815
Epoch [98/100], Loss: 0.2502, Val Loss: 0.6910
Epoch [99/100], Loss: 0.0530, Val Loss: 0.6378
Epoch [100/100], Loss: 0.1806, Val Loss: 0.5792
Runtime: 0:02:27.742837
R^2 Score: 0.8570
RMSE: 0.8562
MAE: 0.2437
MAPE: 20.64%
MLP with layer size: [492] - Result:
Epoch [1/50], Loss: 1.3839, Val Loss: 1.0455
Epoch [2/50], Loss: 0.0800, Val Loss: 0.7381
Epoch [3/50], Loss: 1.8393, Val Loss: 0.6777
Epoch [4/50], Loss: 0.2399, Val Loss: 0.6812
Epoch [5/50], Loss: 0.1400, Val Loss: 0.7063
Epoch [6/50], Loss: 0.1137, Val Loss: 0.6329
Epoch [7/50], Loss: 0.2376, Val Loss: 0.6317
Epoch [8/50], Loss: 0.1186, Val Loss: 0.6528
Epoch [9/50], Loss: 0.9245, Val Loss: 0.6541
Epoch [10/50], Loss: 0.1164, Val Loss: 0.6117
Epoch [11/50], Loss: 0.1964, Val Loss: 0.5732
Epoch [12/50], Loss: 0.2081, Val Loss: 0.5941
Epoch [13/50], Loss: 0.1516, Val Loss: 0.6062
Epoch [14/50], Loss: 0.0939, Val Loss: 0.5725
Epoch [15/50], Loss: 0.4768, Val Loss: 0.5948
Epoch [16/50], Loss: 0.0393, Val Loss: 0.5746
Epoch [17/50], Loss: 0.0833, Val Loss: 0.6141
Epoch [18/50], Loss: 0.2694, Val Loss: 0.5975
Epoch [19/50], Loss: 0.4473, Val Loss: 0.5732
Epoch [20/50], Loss: 0.1504, Val Loss: 0.6156
Epoch [21/50], Loss: 0.0554, Val Loss: 0.6125
Epoch [22/50], Loss: 0.2138, Val Loss: 0.5834
Epoch [23/50], Loss: 0.0987, Val Loss: 0.5902
Epoch [24/50], Loss: 0.4984, Val Loss: 0.5793
Epoch [25/50], Loss: 0.1478, Val Loss: 0.5892
Early stopping at epoch 25
Runtime: 0:03:19.930554
R^2 Score: 0.7486
RMSE: 1.1353
MAE: 0.2247
MAPE: 22.55%
TruncatedSVD_50
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/100], Loss: 0.5633, Val Loss: 0.9854
Epoch [2/100], Loss: 2.2050, Val Loss: 0.8529
Epoch [3/100], Loss: 0.9353, Val Loss: 0.9714
Epoch [4/100], Loss: 0.2904, Val Loss: 0.7738
Epoch [5/100], Loss: 0.5164, Val Loss: 0.7785
Epoch [6/100], Loss: 0.4361, Val Loss: 0.7448
Epoch [7/100], Loss: 0.1703, Val Loss: 0.7809
Epoch [8/100], Loss: 0.7553, Val Loss: 0.7215
Epoch [9/100], Loss: 0.4649, Val Loss: 0.7845
Epoch [10/100], Loss: 0.1451, Val Loss: 0.6897
Epoch [11/100], Loss: 0.1125, Val Loss: 0.7613
Epoch [12/100], Loss: 0.1064, Val Loss: 0.7606
Epoch [13/100], Loss: 0.8062, Val Loss: 0.8289
Epoch [14/100], Loss: 0.1569, Val Loss: 0.6560
Epoch [15/100], Loss: 0.8540, Val Loss: 0.6474
Epoch [16/100], Loss: 0.6455, Val Loss: 0.7019
Epoch [17/100], Loss: 0.1052, Val Loss: 0.8713
Epoch [18/100], Loss: 0.2002, Val Loss: 0.6788
Epoch [19/100], Loss: 0.0920, Val Loss: 0.6431
Epoch [20/100], Loss: 0.0737, Val Loss: 0.6665
Epoch [21/100], Loss: 0.4523, Val Loss: 0.6760
Epoch [22/100], Loss: 0.4371, Val Loss: 0.6985
Epoch [23/100], Loss: 0.3005, Val Loss: 0.7053
Epoch [24/100], Loss: 0.4285, Val Loss: 0.7034
Epoch [25/100], Loss: 1.0096, Val Loss: 0.6191
Epoch [26/100], Loss: 0.0649, Val Loss: 0.6167
Epoch [27/100], Loss: 0.3742, Val Loss: 0.6739
Epoch [28/100], Loss: 0.1975, Val Loss: 0.6066
Epoch [29/100], Loss: 0.1415, Val Loss: 0.6861
Epoch [30/100], Loss: 0.2240, Val Loss: 0.6260
Epoch [31/100], Loss: 0.1019, Val Loss: 0.7199
Epoch [32/100], Loss: 0.1958, Val Loss: 0.6610
Epoch [33/100], Loss: 0.3629, Val Loss: 0.6608
Epoch [34/100], Loss: 0.1809, Val Loss: 0.6944
Epoch [35/100], Loss: 0.0817, Val Loss: 0.6397
Epoch [36/100], Loss: 0.9814, Val Loss: 0.6534
Epoch [37/100], Loss: 0.4207, Val Loss: 0.7401
Epoch [38/100], Loss: 0.1612, Val Loss: 0.7115
Epoch [39/100], Loss: 0.9077, Val Loss: 0.6521
Epoch [40/100], Loss: 0.5767, Val Loss: 0.6622
Epoch [41/100], Loss: 0.2544, Val Loss: 0.8900
Epoch [42/100], Loss: 0.2003, Val Loss: 0.7461
Epoch [43/100], Loss: 0.4869, Val Loss: 0.6500
Epoch [44/100], Loss: 0.6829, Val Loss: 0.6619
Epoch [45/100], Loss: 0.1376, Val Loss: 0.6024
Epoch [46/100], Loss: 0.3131, Val Loss: 0.5876
Epoch [47/100], Loss: 0.4712, Val Loss: 0.6406
Epoch [48/100], Loss: 0.1575, Val Loss: 0.6553
Epoch [49/100], Loss: 0.2400, Val Loss: 0.5929
Epoch [50/100], Loss: 0.2573, Val Loss: 0.5820
Epoch [51/100], Loss: 0.3295, Val Loss: 0.5942
Epoch [52/100], Loss: 0.1953, Val Loss: 0.5785
Epoch [53/100], Loss: 0.1385, Val Loss: 0.5831
Epoch [54/100], Loss: 0.1452, Val Loss: 0.5885
Epoch [55/100], Loss: 0.4309, Val Loss: 0.6063
Epoch [56/100], Loss: 0.2029, Val Loss: 0.6215
Epoch [57/100], Loss: 0.4601, Val Loss: 0.5892
Epoch [58/100], Loss: 0.1505, Val Loss: 0.5652
Epoch [59/100], Loss: 0.4530, Val Loss: 0.5843
Epoch [60/100], Loss: 0.2578, Val Loss: 0.5968
Epoch [61/100], Loss: 0.3842, Val Loss: 0.5947
Epoch [62/100], Loss: 0.6523, Val Loss: 0.5493
Epoch [63/100], Loss: 0.2691, Val Loss: 0.6147
Epoch [64/100], Loss: 0.2290, Val Loss: 0.5760
Epoch [65/100], Loss: 0.2689, Val Loss: 0.6341
Epoch [66/100], Loss: 0.1283, Val Loss: 0.6305
Epoch [67/100], Loss: 0.1979, Val Loss: 0.5854
Epoch [68/100], Loss: 0.1141, Val Loss: 0.5735
Epoch [69/100], Loss: 0.8753, Val Loss: 0.7031
Epoch [70/100], Loss: 0.6667, Val Loss: 0.6205
Epoch [71/100], Loss: 0.1793, Val Loss: 0.6467
Epoch [72/100], Loss: 0.2320, Val Loss: 0.5853
Epoch [73/100], Loss: 0.1206, Val Loss: 0.6558
Epoch [74/100], Loss: 0.3365, Val Loss: 0.5662
Epoch [75/100], Loss: 0.2761, Val Loss: 0.5885
Epoch [76/100], Loss: 0.0883, Val Loss: 0.6601
Epoch [77/100], Loss: 0.3003, Val Loss: 0.5943
Epoch [78/100], Loss: 1.2970, Val Loss: 0.5722
Epoch [79/100], Loss: 0.1293, Val Loss: 0.5816
Epoch [80/100], Loss: 0.3107, Val Loss: 0.6073
Epoch [81/100], Loss: 0.1584, Val Loss: 0.5468
Epoch [82/100], Loss: 0.5057, Val Loss: 0.5434
Epoch [83/100], Loss: 0.1364, Val Loss: 0.6291
Epoch [84/100], Loss: 0.4932, Val Loss: 0.5958
Epoch [85/100], Loss: 0.1772, Val Loss: 0.5955
Epoch [86/100], Loss: 0.3158, Val Loss: 0.6461
Epoch [87/100], Loss: 0.2711, Val Loss: 0.5537
Epoch [88/100], Loss: 0.1000, Val Loss: 0.5484
Epoch [89/100], Loss: 0.2229, Val Loss: 0.5844
Epoch [90/100], Loss: 0.1407, Val Loss: 0.6786
Epoch [91/100], Loss: 0.0816, Val Loss: 0.5625
Epoch [92/100], Loss: 0.1009, Val Loss: 0.6377
Epoch [93/100], Loss: 0.2160, Val Loss: 0.6359
Epoch [94/100], Loss: 0.3040, Val Loss: 0.5517
Epoch [95/100], Loss: 0.3081, Val Loss: 0.5632
Epoch [96/100], Loss: 0.1313, Val Loss: 0.5799
Epoch [97/100], Loss: 0.1227, Val Loss: 0.5939
Epoch [98/100], Loss: 0.3119, Val Loss: 0.6065
Epoch [99/100], Loss: 0.3193, Val Loss: 0.5854
Epoch [100/100], Loss: 0.1257, Val Loss: 0.5556
Runtime: 0:02:51.126983
R^2 Score: 0.8955
RMSE: 0.7320
MAE: 0.2033
MAPE: 16.33%
TruncatedSVD_50
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/100], Loss: 0.3442, Val Loss: 0.9616
Epoch [2/100], Loss: 0.5260, Val Loss: 0.8438
Epoch [3/100], Loss: 1.3549, Val Loss: 0.8856
Epoch [4/100], Loss: 0.1725, Val Loss: 0.8534
Epoch [5/100], Loss: 0.2044, Val Loss: 0.7954
Epoch [6/100], Loss: 0.1082, Val Loss: 0.7910
Epoch [7/100], Loss: 0.3119, Val Loss: 0.8127
Epoch [8/100], Loss: 0.7123, Val Loss: 0.7987
Epoch [9/100], Loss: 0.3703, Val Loss: 0.7428
Epoch [10/100], Loss: 0.4743, Val Loss: 0.7215
Epoch [11/100], Loss: 1.4275, Val Loss: 0.7142
Epoch [12/100], Loss: 0.3368, Val Loss: 0.8324
Epoch [13/100], Loss: 0.1288, Val Loss: 0.7539
Epoch [14/100], Loss: 0.4033, Val Loss: 0.7635
Epoch [15/100], Loss: 0.1482, Val Loss: 0.6732
Epoch [16/100], Loss: 1.0735, Val Loss: 0.6773
Epoch [17/100], Loss: 0.3146, Val Loss: 0.6745
Epoch [18/100], Loss: 0.0983, Val Loss: 0.7212
Epoch [19/100], Loss: 0.2375, Val Loss: 0.6931
Epoch [20/100], Loss: 0.0714, Val Loss: 0.7155
Epoch [21/100], Loss: 1.1953, Val Loss: 0.7426
Epoch [22/100], Loss: 0.1480, Val Loss: 0.6642
Epoch [23/100], Loss: 0.1589, Val Loss: 0.6580
Epoch [24/100], Loss: 0.2229, Val Loss: 0.7681
Epoch [25/100], Loss: 0.1588, Val Loss: 0.8873
Epoch [26/100], Loss: 0.7293, Val Loss: 0.9562
Epoch [27/100], Loss: 0.1157, Val Loss: 0.6178
Epoch [28/100], Loss: 0.1392, Val Loss: 0.6366
Epoch [29/100], Loss: 0.1600, Val Loss: 0.6593
Epoch [30/100], Loss: 0.4486, Val Loss: 0.6823
Epoch [31/100], Loss: 1.5436, Val Loss: 0.6052
Epoch [32/100], Loss: 0.3144, Val Loss: 0.6167
Epoch [33/100], Loss: 0.5079, Val Loss: 0.6046
Epoch [34/100], Loss: 0.6688, Val Loss: 0.6377
Epoch [35/100], Loss: 0.1596, Val Loss: 0.5792
Epoch [36/100], Loss: 0.1264, Val Loss: 0.6241
Epoch [37/100], Loss: 0.3380, Val Loss: 0.6100
Epoch [38/100], Loss: 0.1491, Val Loss: 0.5842
Epoch [39/100], Loss: 0.1176, Val Loss: 0.6789
Epoch [40/100], Loss: 0.2782, Val Loss: 0.6366
Epoch [41/100], Loss: 0.0879, Val Loss: 0.6254
Epoch [42/100], Loss: 0.0922, Val Loss: 0.6321
Epoch [43/100], Loss: 1.5869, Val Loss: 0.5868
Epoch [44/100], Loss: 0.4618, Val Loss: 0.6079
Epoch [45/100], Loss: 0.2892, Val Loss: 0.5774
Epoch [46/100], Loss: 0.2989, Val Loss: 0.6064
Epoch [47/100], Loss: 0.1161, Val Loss: 0.6186
Epoch [48/100], Loss: 0.2852, Val Loss: 0.5694
Epoch [49/100], Loss: 0.3176, Val Loss: 0.6350
Epoch [50/100], Loss: 0.2181, Val Loss: 0.5709
Epoch [51/100], Loss: 0.7857, Val Loss: 0.5725
Epoch [52/100], Loss: 0.1285, Val Loss: 0.5656
Epoch [53/100], Loss: 0.1591, Val Loss: 0.5719
Epoch [54/100], Loss: 0.1528, Val Loss: 0.6380
Epoch [55/100], Loss: 0.3544, Val Loss: 0.6925
Epoch [56/100], Loss: 0.2994, Val Loss: 0.7122
Epoch [57/100], Loss: 0.0679, Val Loss: 0.5508
Epoch [58/100], Loss: 0.0485, Val Loss: 0.5516
Epoch [59/100], Loss: 1.0135, Val Loss: 0.5883
Epoch [60/100], Loss: 0.2527, Val Loss: 0.6207
Epoch [61/100], Loss: 0.1377, Val Loss: 0.6247
Epoch [62/100], Loss: 0.9181, Val Loss: 0.5613
Epoch [63/100], Loss: 0.1819, Val Loss: 0.5385
Epoch [64/100], Loss: 0.1921, Val Loss: 0.5497
Epoch [65/100], Loss: 0.2027, Val Loss: 0.7683
Epoch [66/100], Loss: 0.1248, Val Loss: 0.5987
Epoch [67/100], Loss: 0.1088, Val Loss: 0.5772
Epoch [68/100], Loss: 0.1478, Val Loss: 0.5672
Epoch [69/100], Loss: 0.1897, Val Loss: 0.6092
Epoch [70/100], Loss: 0.0988, Val Loss: 0.6687
Epoch [71/100], Loss: 0.1626, Val Loss: 0.5910
Epoch [72/100], Loss: 0.1870, Val Loss: 0.5838
Epoch [73/100], Loss: 1.7303, Val Loss: 0.5827
Epoch [74/100], Loss: 0.0837, Val Loss: 0.5581
Epoch [75/100], Loss: 0.5903, Val Loss: 0.5848
Epoch [76/100], Loss: 0.0855, Val Loss: 0.5506
Epoch [77/100], Loss: 0.2606, Val Loss: 0.5291
Epoch [78/100], Loss: 0.3348, Val Loss: 0.5880
Epoch [79/100], Loss: 0.1080, Val Loss: 0.6144
Epoch [80/100], Loss: 0.1850, Val Loss: 0.5605
Epoch [81/100], Loss: 0.0675, Val Loss: 0.6184
Epoch [82/100], Loss: 0.1705, Val Loss: 0.5731
Epoch [83/100], Loss: 0.7148, Val Loss: 0.5842
Epoch [84/100], Loss: 0.1717, Val Loss: 0.5954
Epoch [85/100], Loss: 0.2773, Val Loss: 0.6029
Epoch [86/100], Loss: 0.0639, Val Loss: 0.5308
Epoch [87/100], Loss: 0.3859, Val Loss: 0.6191
Epoch [88/100], Loss: 0.1262, Val Loss: 0.6853
Epoch [89/100], Loss: 0.4051, Val Loss: 0.5618
Epoch [90/100], Loss: 0.2277, Val Loss: 0.5522
Epoch [91/100], Loss: 0.4470, Val Loss: 0.5585
Epoch [92/100], Loss: 0.1599, Val Loss: 0.5452
Epoch [93/100], Loss: 0.2410, Val Loss: 0.5994
Epoch [94/100], Loss: 0.8577, Val Loss: 0.5561
Epoch [95/100], Loss: 0.1863, Val Loss: 0.5412
Epoch [96/100], Loss: 0.1550, Val Loss: 0.5571
Epoch [97/100], Loss: 0.0963, Val Loss: 0.5515
Epoch [98/100], Loss: 0.1380, Val Loss: 0.5781
Epoch [99/100], Loss: 0.0496, Val Loss: 0.5172
Epoch [100/100], Loss: 0.1092, Val Loss: 0.6020
Runtime: 0:02:28.574863
R^2 Score: 0.7952
RMSE: 1.0247
MAE: 0.2494
MAPE: 20.82%
TruncatedSVD_50
MLP with layer size: [32, 16] - Result:
Epoch [1/100], Loss: 0.6044, Val Loss: 1.2113
Epoch [2/100], Loss: 0.9541, Val Loss: 1.0860
Epoch [3/100], Loss: 0.8711, Val Loss: 1.0343
Epoch [4/100], Loss: 0.3389, Val Loss: 0.9908
Epoch [5/100], Loss: 0.6104, Val Loss: 0.9505
Epoch [6/100], Loss: 0.1779, Val Loss: 0.9351
Epoch [7/100], Loss: 0.5507, Val Loss: 0.9258
Epoch [8/100], Loss: 0.2191, Val Loss: 0.8962
Epoch [9/100], Loss: 0.3341, Val Loss: 0.8745
Epoch [10/100], Loss: 0.2709, Val Loss: 0.8600
Epoch [11/100], Loss: 0.8224, Val Loss: 0.8446
Epoch [12/100], Loss: 1.5649, Val Loss: 0.8659
Epoch [13/100], Loss: 0.7811, Val Loss: 0.8325
Epoch [14/100], Loss: 0.1530, Val Loss: 0.8114
Epoch [15/100], Loss: 0.9303, Val Loss: 0.8514
Epoch [16/100], Loss: 0.5988, Val Loss: 0.8207
Epoch [17/100], Loss: 0.1821, Val Loss: 0.8293
Epoch [18/100], Loss: 0.1459, Val Loss: 0.7938
Epoch [19/100], Loss: 0.3348, Val Loss: 0.7983
Epoch [20/100], Loss: 0.0722, Val Loss: 0.7717
Epoch [21/100], Loss: 2.4540, Val Loss: 0.7680
Epoch [22/100], Loss: 0.5755, Val Loss: 0.7673
Epoch [23/100], Loss: 0.0730, Val Loss: 0.8331
Epoch [24/100], Loss: 0.1401, Val Loss: 0.8434
Epoch [25/100], Loss: 0.2701, Val Loss: 0.7836
Epoch [26/100], Loss: 0.2660, Val Loss: 0.7616
Epoch [27/100], Loss: 0.4340, Val Loss: 0.7703
Epoch [28/100], Loss: 0.1714, Val Loss: 0.7618
Epoch [29/100], Loss: 0.1295, Val Loss: 0.7574
Epoch [30/100], Loss: 0.1175, Val Loss: 0.7447
Epoch [31/100], Loss: 0.2053, Val Loss: 0.7881
Epoch [32/100], Loss: 0.1584, Val Loss: 0.7403
Epoch [33/100], Loss: 0.2541, Val Loss: 0.7560
Epoch [34/100], Loss: 0.2034, Val Loss: 0.7905
Epoch [35/100], Loss: 0.2424, Val Loss: 0.7585
Epoch [36/100], Loss: 0.1336, Val Loss: 0.7504
Epoch [37/100], Loss: 1.4936, Val Loss: 0.7474
Epoch [38/100], Loss: 0.3097, Val Loss: 0.7714
Epoch [39/100], Loss: 0.2705, Val Loss: 0.7237
Epoch [40/100], Loss: 0.1017, Val Loss: 0.7338
Epoch [41/100], Loss: 0.1117, Val Loss: 0.7345
Epoch [42/100], Loss: 0.1193, Val Loss: 0.7560
Epoch [43/100], Loss: 0.1509, Val Loss: 0.7171
Epoch [44/100], Loss: 0.4946, Val Loss: 0.7289
Epoch [45/100], Loss: 0.6836, Val Loss: 0.7441
Epoch [46/100], Loss: 0.1974, Val Loss: 0.7324
Epoch [47/100], Loss: 0.3200, Val Loss: 0.7242
Epoch [48/100], Loss: 0.1962, Val Loss: 0.7560
Epoch [49/100], Loss: 0.2832, Val Loss: 0.7087
Epoch [50/100], Loss: 2.2968, Val Loss: 0.7463
Epoch [51/100], Loss: 0.1738, Val Loss: 0.7545
Epoch [52/100], Loss: 0.3292, Val Loss: 0.7057
Epoch [53/100], Loss: 0.5008, Val Loss: 0.7187
Epoch [54/100], Loss: 0.1342, Val Loss: 0.7175
Epoch [55/100], Loss: 0.1102, Val Loss: 0.7468
Epoch [56/100], Loss: 0.3902, Val Loss: 0.7211
Epoch [57/100], Loss: 0.2581, Val Loss: 0.7792
Epoch [58/100], Loss: 0.3484, Val Loss: 0.7108
Epoch [59/100], Loss: 0.0884, Val Loss: 0.7447
Epoch [60/100], Loss: 1.3683, Val Loss: 0.7573
Epoch [61/100], Loss: 0.6128, Val Loss: 0.7667
Epoch [62/100], Loss: 0.1946, Val Loss: 0.7214
Epoch [63/100], Loss: 0.2706, Val Loss: 0.7374
Epoch [64/100], Loss: 0.3878, Val Loss: 0.6920
Epoch [65/100], Loss: 0.2240, Val Loss: 0.7150
Epoch [66/100], Loss: 0.5666, Val Loss: 0.6874
Epoch [67/100], Loss: 0.4034, Val Loss: 0.7271
Epoch [68/100], Loss: 0.4997, Val Loss: 0.7213
Epoch [69/100], Loss: 0.3796, Val Loss: 0.7321
Epoch [70/100], Loss: 0.5751, Val Loss: 0.7152
Epoch [71/100], Loss: 1.4735, Val Loss: 0.7164
Epoch [72/100], Loss: 0.1990, Val Loss: 0.7666
Epoch [73/100], Loss: 0.2493, Val Loss: 0.6917
Epoch [74/100], Loss: 0.1205, Val Loss: 0.6918
Epoch [75/100], Loss: 0.5360, Val Loss: 0.7612
Epoch [76/100], Loss: 0.1396, Val Loss: 0.7149
Epoch [77/100], Loss: 0.2360, Val Loss: 0.7116
Epoch [78/100], Loss: 0.4561, Val Loss: 0.6899
Epoch [79/100], Loss: 0.3617, Val Loss: 0.7105
Epoch [80/100], Loss: 0.0985, Val Loss: 0.7003
Epoch [81/100], Loss: 0.4245, Val Loss: 0.6851
Epoch [82/100], Loss: 0.2298, Val Loss: 0.7100
Epoch [83/100], Loss: 0.4568, Val Loss: 0.7163
Epoch [84/100], Loss: 0.3954, Val Loss: 0.6967
Epoch [85/100], Loss: 0.1570, Val Loss: 0.6832
Epoch [86/100], Loss: 0.0549, Val Loss: 0.6803
Epoch [87/100], Loss: 0.1490, Val Loss: 0.7012
Epoch [88/100], Loss: 0.1411, Val Loss: 0.7034
Epoch [89/100], Loss: 0.3396, Val Loss: 0.6765
Epoch [90/100], Loss: 0.1615, Val Loss: 0.7033
Epoch [91/100], Loss: 1.4114, Val Loss: 0.6806
Epoch [92/100], Loss: 0.4136, Val Loss: 0.6751
Epoch [93/100], Loss: 0.1012, Val Loss: 0.7414
Epoch [94/100], Loss: 0.2327, Val Loss: 0.6801
Epoch [95/100], Loss: 0.1186, Val Loss: 0.6647
Epoch [96/100], Loss: 0.2666, Val Loss: 0.6854
Epoch [97/100], Loss: 0.2113, Val Loss: 0.6609
Epoch [98/100], Loss: 0.2154, Val Loss: 0.6699
Epoch [99/100], Loss: 0.1426, Val Loss: 0.6663
Epoch [100/100], Loss: 0.1960, Val Loss: 0.6747
Runtime: 0:01:10.252818
R^2 Score: 0.8418
RMSE: 0.9006
MAE: 0.2774
MAPE: 25.06%
TruncatedSVD_50
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/100], Loss: 0.1790, Val Loss: 0.9589
Epoch [2/100], Loss: 0.2545, Val Loss: 0.8657
Epoch [3/100], Loss: 0.7269, Val Loss: 0.8371
Epoch [4/100], Loss: 1.1281, Val Loss: 1.0911
Epoch [5/100], Loss: 0.4167, Val Loss: 0.8010
Epoch [6/100], Loss: 0.2951, Val Loss: 0.7629
Epoch [7/100], Loss: 0.1431, Val Loss: 0.7714
Epoch [8/100], Loss: 0.3495, Val Loss: 0.8519
Epoch [9/100], Loss: 0.3043, Val Loss: 0.7575
Epoch [10/100], Loss: 0.2313, Val Loss: 0.7504
Epoch [11/100], Loss: 0.2132, Val Loss: 0.7636
Epoch [12/100], Loss: 0.2554, Val Loss: 0.7704
Epoch [13/100], Loss: 0.2241, Val Loss: 0.9234
Epoch [14/100], Loss: 0.2141, Val Loss: 0.7091
Epoch [15/100], Loss: 0.2680, Val Loss: 0.7920
Epoch [16/100], Loss: 2.0831, Val Loss: 0.8520
Epoch [17/100], Loss: 0.2576, Val Loss: 0.7972
Epoch [18/100], Loss: 0.1339, Val Loss: 0.6978
Epoch [19/100], Loss: 0.2465, Val Loss: 0.7155
Epoch [20/100], Loss: 0.1201, Val Loss: 0.7522
Epoch [21/100], Loss: 0.0866, Val Loss: 0.7038
Epoch [22/100], Loss: 0.1237, Val Loss: 0.7257
Epoch [23/100], Loss: 0.3523, Val Loss: 0.6985
Epoch [24/100], Loss: 0.8682, Val Loss: 0.7214
Epoch [25/100], Loss: 0.2180, Val Loss: 0.6739
Epoch [26/100], Loss: 0.4494, Val Loss: 0.6612
Epoch [27/100], Loss: 0.1941, Val Loss: 0.6487
Epoch [28/100], Loss: 1.1999, Val Loss: 0.7439
Epoch [29/100], Loss: 0.2616, Val Loss: 0.7540
Epoch [30/100], Loss: 0.0349, Val Loss: 0.7191
Epoch [31/100], Loss: 2.2863, Val Loss: 0.7331
Epoch [32/100], Loss: 0.1080, Val Loss: 0.6866
Epoch [33/100], Loss: 0.1760, Val Loss: 0.7260
Epoch [34/100], Loss: 0.7270, Val Loss: 0.6491
Epoch [35/100], Loss: 0.2260, Val Loss: 0.6477
Epoch [36/100], Loss: 1.2558, Val Loss: 0.6991
Epoch [37/100], Loss: 0.4581, Val Loss: 0.6851
Epoch [38/100], Loss: 0.0869, Val Loss: 0.6728
Epoch [39/100], Loss: 0.0846, Val Loss: 0.7253
Epoch [40/100], Loss: 0.1766, Val Loss: 0.6381
Epoch [41/100], Loss: 0.4325, Val Loss: 0.6531
Epoch [42/100], Loss: 0.2895, Val Loss: 0.6515
Epoch [43/100], Loss: 0.1140, Val Loss: 0.6683
Epoch [44/100], Loss: 0.1691, Val Loss: 0.6224
Epoch [45/100], Loss: 0.1230, Val Loss: 0.6983
Epoch [46/100], Loss: 1.0150, Val Loss: 0.6332
Epoch [47/100], Loss: 0.1501, Val Loss: 0.6214
Epoch [48/100], Loss: 0.5897, Val Loss: 0.6297
Epoch [49/100], Loss: 0.4645, Val Loss: 0.8067
Epoch [50/100], Loss: 0.3663, Val Loss: 0.6501
Epoch [51/100], Loss: 0.0315, Val Loss: 0.6213
Epoch [52/100], Loss: 0.2179, Val Loss: 0.6501
Epoch [53/100], Loss: 0.0750, Val Loss: 0.6344
Epoch [54/100], Loss: 0.4387, Val Loss: 0.6049
Epoch [55/100], Loss: 0.2502, Val Loss: 0.6577
Epoch [56/100], Loss: 0.0287, Val Loss: 0.5926
Epoch [57/100], Loss: 0.1161, Val Loss: 0.5859
Epoch [58/100], Loss: 0.4397, Val Loss: 0.6310
Epoch [59/100], Loss: 0.1459, Val Loss: 0.6293
Epoch [60/100], Loss: 0.1375, Val Loss: 0.7011
Epoch [61/100], Loss: 0.1811, Val Loss: 0.5976
Epoch [62/100], Loss: 0.2718, Val Loss: 0.6244
Epoch [63/100], Loss: 0.8822, Val Loss: 0.6516
Epoch [64/100], Loss: 0.1448, Val Loss: 0.6428
Epoch [65/100], Loss: 0.4969, Val Loss: 0.5975
Epoch [66/100], Loss: 0.2283, Val Loss: 0.6038
Epoch [67/100], Loss: 0.1087, Val Loss: 0.6187
Epoch [68/100], Loss: 0.4212, Val Loss: 0.6261
Epoch [69/100], Loss: 1.9661, Val Loss: 0.6036
Epoch [70/100], Loss: 0.5626, Val Loss: 0.5823
Epoch [71/100], Loss: 0.3611, Val Loss: 0.6068
Epoch [72/100], Loss: 0.6724, Val Loss: 0.5998
Epoch [73/100], Loss: 0.5351, Val Loss: 0.5857
Epoch [74/100], Loss: 0.1867, Val Loss: 0.6260
Epoch [75/100], Loss: 0.0827, Val Loss: 0.6322
Epoch [76/100], Loss: 0.2088, Val Loss: 0.7189
Epoch [77/100], Loss: 0.6457, Val Loss: 0.5944
Epoch [78/100], Loss: 0.2112, Val Loss: 0.5875
Epoch [79/100], Loss: 0.2828, Val Loss: 0.5763
Epoch [80/100], Loss: 0.2058, Val Loss: 0.5901
Epoch [81/100], Loss: 0.1435, Val Loss: 0.6220
Epoch [82/100], Loss: 0.1049, Val Loss: 0.6098
Epoch [83/100], Loss: 0.0615, Val Loss: 0.5700
Epoch [84/100], Loss: 0.0698, Val Loss: 0.6957
Epoch [85/100], Loss: 0.0682, Val Loss: 0.5968
Epoch [86/100], Loss: 0.3083, Val Loss: 0.6101
Epoch [87/100], Loss: 0.1733, Val Loss: 0.6099
Epoch [88/100], Loss: 0.1130, Val Loss: 0.6483
Epoch [89/100], Loss: 0.1506, Val Loss: 0.6522
Epoch [90/100], Loss: 0.6085, Val Loss: 0.5663
Epoch [91/100], Loss: 0.0835, Val Loss: 0.5852
Epoch [92/100], Loss: 0.2976, Val Loss: 0.6145
Epoch [93/100], Loss: 0.3880, Val Loss: 0.6403
Epoch [94/100], Loss: 0.2298, Val Loss: 0.5762
Epoch [95/100], Loss: 0.4573, Val Loss: 0.6593
Epoch [96/100], Loss: 0.1423, Val Loss: 0.6110
Epoch [97/100], Loss: 0.0592, Val Loss: 0.5723
Epoch [98/100], Loss: 0.5519, Val Loss: 0.6668
Epoch [99/100], Loss: 0.5152, Val Loss: 0.5697
Epoch [100/100], Loss: 0.9926, Val Loss: 0.5766
Runtime: 0:04:47.443388
TruncatedSVD_50
MLP with layer size: [32] - Result:
Epoch [1/100], Loss: 1.0018, Val Loss: 1.1053
Epoch [2/100], Loss: 0.4669, Val Loss: 1.0171
Epoch [3/100], Loss: 0.2885, Val Loss: 0.9812
Epoch [4/100], Loss: 1.6928, Val Loss: 0.9555
Epoch [5/100], Loss: 0.3505, Val Loss: 0.9162
Epoch [6/100], Loss: 0.1961, Val Loss: 0.9169
Epoch [7/100], Loss: 0.2444, Val Loss: 0.8861
Epoch [8/100], Loss: 0.4397, Val Loss: 0.8727
Epoch [9/100], Loss: 0.3744, Val Loss: 0.8919
Epoch [10/100], Loss: 0.5570, Val Loss: 0.8408
Epoch [11/100], Loss: 0.4729, Val Loss: 0.8860
Epoch [12/100], Loss: 0.3990, Val Loss: 0.8217
Epoch [13/100], Loss: 0.4897, Val Loss: 0.8223
Epoch [14/100], Loss: 0.3528, Val Loss: 0.8655
Epoch [15/100], Loss: 0.3025, Val Loss: 0.8297
Epoch [16/100], Loss: 0.1747, Val Loss: 0.8494
Epoch [17/100], Loss: 0.1988, Val Loss: 0.8306
Epoch [18/100], Loss: 0.3672, Val Loss: 0.7937
Epoch [19/100], Loss: 0.2151, Val Loss: 0.8039
Epoch [20/100], Loss: 0.3459, Val Loss: 0.8331
Epoch [21/100], Loss: 0.8527, Val Loss: 0.7935
Epoch [22/100], Loss: 0.4950, Val Loss: 0.7811
Epoch [23/100], Loss: 0.4716, Val Loss: 0.7884
Epoch [24/100], Loss: 2.3450, Val Loss: 0.7761
Epoch [25/100], Loss: 0.3308, Val Loss: 0.8106
Epoch [26/100], Loss: 0.2176, Val Loss: 0.8003
Epoch [27/100], Loss: 0.3441, Val Loss: 0.8000
Epoch [28/100], Loss: 0.4678, Val Loss: 0.7919
Epoch [29/100], Loss: 0.1730, Val Loss: 0.7874
Epoch [30/100], Loss: 0.2471, Val Loss: 0.7731
Epoch [31/100], Loss: 0.1766, Val Loss: 0.8172
Epoch [32/100], Loss: 0.3767, Val Loss: 0.7957
Epoch [33/100], Loss: 1.7768, Val Loss: 0.7933
Epoch [34/100], Loss: 0.2403, Val Loss: 0.8074
Epoch [35/100], Loss: 0.4912, Val Loss: 0.7765
Epoch [36/100], Loss: 0.7584, Val Loss: 0.7763
Epoch [37/100], Loss: 0.1902, Val Loss: 0.8200
Epoch [38/100], Loss: 0.6525, Val Loss: 0.7641
Epoch [39/100], Loss: 0.1988, Val Loss: 0.7889
Epoch [40/100], Loss: 2.2444, Val Loss: 0.7806
Epoch [41/100], Loss: 0.2319, Val Loss: 0.7888
Epoch [42/100], Loss: 0.3791, Val Loss: 0.8490
Epoch [43/100], Loss: 0.2365, Val Loss: 0.8443
Epoch [44/100], Loss: 0.4067, Val Loss: 0.7939
Epoch [45/100], Loss: 0.4712, Val Loss: 0.8465
Epoch [46/100], Loss: 0.3324, Val Loss: 0.7893
Epoch [47/100], Loss: 0.2749, Val Loss: 0.7801
Epoch [48/100], Loss: 0.1543, Val Loss: 0.8198
Epoch [49/100], Loss: 0.5137, Val Loss: 0.7587
Epoch [50/100], Loss: 0.1742, Val Loss: 0.7688
Epoch [51/100], Loss: 0.2743, Val Loss: 0.7435
Epoch [52/100], Loss: 0.1085, Val Loss: 0.7846
Epoch [53/100], Loss: 0.1107, Val Loss: 0.7791
Epoch [54/100], Loss: 0.2529, Val Loss: 0.8302
Epoch [55/100], Loss: 0.5748, Val Loss: 0.8198
Epoch [56/100], Loss: 0.7015, Val Loss: 0.8081
Epoch [57/100], Loss: 0.2833, Val Loss: 0.7889
Epoch [58/100], Loss: 0.1534, Val Loss: 0.7827
Epoch [59/100], Loss: 0.1388, Val Loss: 0.7497
Epoch [60/100], Loss: 0.0988, Val Loss: 0.7762
Epoch [61/100], Loss: 0.2719, Val Loss: 0.7772
Epoch [62/100], Loss: 0.6416, Val Loss: 0.7757
Epoch [63/100], Loss: 0.3618, Val Loss: 0.7898
Epoch [64/100], Loss: 0.6037, Val Loss: 0.7672
Epoch [65/100], Loss: 0.1339, Val Loss: 0.7878
Epoch [66/100], Loss: 0.6898, Val Loss: 0.7633
Epoch [67/100], Loss: 0.2581, Val Loss: 0.8060
Epoch [68/100], Loss: 0.1419, Val Loss: 0.7621
Epoch [69/100], Loss: 0.2046, Val Loss: 0.7625
Epoch [70/100], Loss: 0.1129, Val Loss: 0.7850
Early stopping at epoch 70
Runtime: 0:01:19.770634
TruncatedSVD_50
MLP with layer size: [32, 16] - Result:
Epoch [1/100], Loss: 0.4052, Val Loss: 1.0208
Epoch [2/100], Loss: 0.2937, Val Loss: 0.9562
Epoch [3/100], Loss: 0.1077, Val Loss: 0.8351
Epoch [4/100], Loss: 0.2817, Val Loss: 0.8095
Epoch [5/100], Loss: 0.3803, Val Loss: 0.7845
Epoch [6/100], Loss: 0.3337, Val Loss: 0.8075
Epoch [7/100], Loss: 0.2828, Val Loss: 0.7526
Epoch [8/100], Loss: 0.5239, Val Loss: 0.7813
Epoch [9/100], Loss: 2.4467, Val Loss: 0.7442
Epoch [10/100], Loss: 0.1910, Val Loss: 0.7452
Epoch [11/100], Loss: 0.3323, Val Loss: 0.7533
Epoch [12/100], Loss: 0.2737, Val Loss: 0.7539
Epoch [13/100], Loss: 0.2603, Val Loss: 0.7646
Epoch [14/100], Loss: 0.0988, Val Loss: 0.7334
Epoch [15/100], Loss: 0.3398, Val Loss: 0.7436
Epoch [16/100], Loss: 0.2904, Val Loss: 0.7177
Epoch [17/100], Loss: 0.2010, Val Loss: 0.7136
Epoch [18/100], Loss: 0.1354, Val Loss: 0.7415
Epoch [19/100], Loss: 1.5469, Val Loss: 0.7353
Epoch [20/100], Loss: 0.3143, Val Loss: 0.6856
Epoch [21/100], Loss: 0.1022, Val Loss: 0.6923
Epoch [22/100], Loss: 0.1607, Val Loss: 0.7006
Epoch [23/100], Loss: 0.2177, Val Loss: 0.6797
Epoch [24/100], Loss: 0.1704, Val Loss: 0.6954
Epoch [25/100], Loss: 0.5710, Val Loss: 0.6856
Epoch [26/100], Loss: 1.0148, Val Loss: 0.6678
Epoch [27/100], Loss: 0.4716, Val Loss: 0.6728
Epoch [28/100], Loss: 0.4090, Val Loss: 0.6717
Epoch [29/100], Loss: 0.3663, Val Loss: 0.7203
Epoch [30/100], Loss: 1.3022, Val Loss: 0.6955
Epoch [31/100], Loss: 0.1317, Val Loss: 0.6641
Epoch [32/100], Loss: 0.0778, Val Loss: 0.6566
Epoch [33/100], Loss: 0.1165, Val Loss: 0.6342
Epoch [34/100], Loss: 0.3115, Val Loss: 0.6281
Epoch [35/100], Loss: 0.3324, Val Loss: 0.6438
Epoch [36/100], Loss: 0.1120, Val Loss: 0.6632
Epoch [37/100], Loss: 0.3160, Val Loss: 0.6271
Epoch [38/100], Loss: 0.2051, Val Loss: 0.7394
Epoch [39/100], Loss: 0.4410, Val Loss: 0.6783
Epoch [40/100], Loss: 0.1611, Val Loss: 0.6352
Epoch [41/100], Loss: 0.2153, Val Loss: 0.6318
Epoch [42/100], Loss: 0.3265, Val Loss: 0.6104
Epoch [43/100], Loss: 1.3040, Val Loss: 0.6479
Epoch [44/100], Loss: 0.0565, Val Loss: 0.6044
Epoch [45/100], Loss: 0.5343, Val Loss: 0.6112
Epoch [46/100], Loss: 0.2822, Val Loss: 0.6319
Epoch [47/100], Loss: 0.4369, Val Loss: 0.6023
Epoch [48/100], Loss: 0.1304, Val Loss: 0.6905
Epoch [49/100], Loss: 0.2912, Val Loss: 0.5917
Epoch [50/100], Loss: 2.7595, Val Loss: 0.7360
Epoch [51/100], Loss: 0.1231, Val Loss: 0.5954
Epoch [52/100], Loss: 0.1184, Val Loss: 0.5894
Epoch [53/100], Loss: 0.7821, Val Loss: 0.6306
Epoch [54/100], Loss: 0.2185, Val Loss: 0.5970
Epoch [55/100], Loss: 0.1007, Val Loss: 0.5903
Epoch [56/100], Loss: 0.7548, Val Loss: 0.6410
Epoch [57/100], Loss: 0.5166, Val Loss: 0.6378
Epoch [58/100], Loss: 0.1311, Val Loss: 0.5820
Epoch [59/100], Loss: 0.1593, Val Loss: 0.6206
Epoch [60/100], Loss: 0.6994, Val Loss: 0.5868
Epoch [61/100], Loss: 0.1070, Val Loss: 0.6090
Epoch [62/100], Loss: 0.1798, Val Loss: 0.6470
Epoch [63/100], Loss: 0.1924, Val Loss: 0.5925
Epoch [64/100], Loss: 0.0868, Val Loss: 0.6260
Epoch [65/100], Loss: 0.2023, Val Loss: 0.5757
Epoch [66/100], Loss: 0.1562, Val Loss: 0.6310
Epoch [67/100], Loss: 0.1846, Val Loss: 0.7646
Epoch [68/100], Loss: 0.2114, Val Loss: 0.5833
Epoch [69/100], Loss: 0.9201, Val Loss: 0.6168
Epoch [70/100], Loss: 0.1156, Val Loss: 0.5781
Epoch [71/100], Loss: 0.2129, Val Loss: 0.5982
Epoch [72/100], Loss: 0.4493, Val Loss: 0.5855
Epoch [73/100], Loss: 0.3953, Val Loss: 0.5728
Epoch [74/100], Loss: 0.1383, Val Loss: 0.6126
Epoch [75/100], Loss: 0.2331, Val Loss: 0.5822
Epoch [76/100], Loss: 0.1907, Val Loss: 0.5404
Epoch [77/100], Loss: 0.5643, Val Loss: 0.5500
Epoch [78/100], Loss: 0.1041, Val Loss: 0.6185
Epoch [79/100], Loss: 0.5470, Val Loss: 0.6569
Epoch [80/100], Loss: 0.1930, Val Loss: 0.5761
Epoch [81/100], Loss: 0.6048, Val Loss: 0.5661
Epoch [82/100], Loss: 0.3210, Val Loss: 0.5845
Epoch [83/100], Loss: 0.1280, Val Loss: 0.6290
Epoch [84/100], Loss: 0.5586, Val Loss: 0.5741
Epoch [85/100], Loss: 0.1613, Val Loss: 0.5501
Epoch [86/100], Loss: 0.2454, Val Loss: 0.5887
Epoch [87/100], Loss: 0.1516, Val Loss: 0.5836
Epoch [88/100], Loss: 0.5799, Val Loss: 0.5521
Epoch [89/100], Loss: 0.2441, Val Loss: 0.5775
Epoch [90/100], Loss: 0.3476, Val Loss: 0.5704
Epoch [91/100], Loss: 0.5660, Val Loss: 0.5769
Epoch [92/100], Loss: 0.1931, Val Loss: 0.5809
Epoch [93/100], Loss: 0.2292, Val Loss: 0.5874
Epoch [94/100], Loss: 0.2038, Val Loss: 0.5687
Epoch [95/100], Loss: 0.3927, Val Loss: 0.5797
Early stopping at epoch 95
Runtime: 0:01:59.840342
R^2 Score: 0.8402
RMSE: 0.9052
MAE: 0.2545
MAPE: 22.55%
TruncatedSVD_50
MLP with layer size: [32, 16, 8] - Result:
Epoch [1/100], Loss: 0.8826, Val Loss: 1.0514
Epoch [2/100], Loss: 0.8235, Val Loss: 0.9274
Epoch [3/100], Loss: 1.3966, Val Loss: 0.8837
Epoch [4/100], Loss: 1.1550, Val Loss: 0.9086
Epoch [5/100], Loss: 1.4699, Val Loss: 0.9661
Epoch [6/100], Loss: 0.0848, Val Loss: 0.8209
Epoch [7/100], Loss: 0.1851, Val Loss: 0.8021
Epoch [8/100], Loss: 0.5427, Val Loss: 0.7870
Epoch [9/100], Loss: 0.7324, Val Loss: 0.7660
Epoch [10/100], Loss: 0.1644, Val Loss: 0.7960
Epoch [11/100], Loss: 0.2853, Val Loss: 0.7527
Epoch [12/100], Loss: 0.4364, Val Loss: 0.7454
Epoch [13/100], Loss: 0.8323, Val Loss: 0.7395
Epoch [14/100], Loss: 0.6976, Val Loss: 0.8280
Epoch [15/100], Loss: 0.1593, Val Loss: 0.7653
Epoch [16/100], Loss: 0.7504, Val Loss: 0.7177
Epoch [17/100], Loss: 0.3422, Val Loss: 0.8161
Epoch [18/100], Loss: 0.8649, Val Loss: 0.7360
Epoch [19/100], Loss: 0.3204, Val Loss: 0.7322
Epoch [20/100], Loss: 0.2868, Val Loss: 0.7237
Epoch [21/100], Loss: 0.6207, Val Loss: 0.7158
Epoch [22/100], Loss: 0.7217, Val Loss: 0.7832
Epoch [23/100], Loss: 2.1574, Val Loss: 0.7057
Epoch [24/100], Loss: 0.1571, Val Loss: 0.7164
Epoch [25/100], Loss: 0.1026, Val Loss: 0.6990
Epoch [26/100], Loss: 0.1061, Val Loss: 0.7158
Epoch [27/100], Loss: 0.6664, Val Loss: 0.8873
Epoch [28/100], Loss: 0.3632, Val Loss: 0.7328
Epoch [29/100], Loss: 0.3395, Val Loss: 0.6853
Epoch [30/100], Loss: 0.2416, Val Loss: 0.7138
Epoch [31/100], Loss: 0.1251, Val Loss: 0.7427
Epoch [32/100], Loss: 0.5056, Val Loss: 0.7075
Epoch [33/100], Loss: 0.2605, Val Loss: 0.6671
Epoch [34/100], Loss: 0.2305, Val Loss: 0.7054
Epoch [35/100], Loss: 0.0949, Val Loss: 0.6754
Epoch [36/100], Loss: 0.1969, Val Loss: 0.6620
Epoch [37/100], Loss: 0.1867, Val Loss: 0.6745
Epoch [38/100], Loss: 0.3210, Val Loss: 0.7066
Epoch [39/100], Loss: 1.3962, Val Loss: 0.7101
Epoch [40/100], Loss: 0.9949, Val Loss: 0.6732
Epoch [41/100], Loss: 2.6854, Val Loss: 0.6652
Epoch [42/100], Loss: 0.1175, Val Loss: 0.6618
Epoch [43/100], Loss: 0.9506, Val Loss: 0.7116
Epoch [44/100], Loss: 0.9288, Val Loss: 0.7365
Epoch [45/100], Loss: 0.1548, Val Loss: 0.6491
Epoch [46/100], Loss: 0.6504, Val Loss: 0.7688
Epoch [47/100], Loss: 0.2290, Val Loss: 0.6843
Epoch [48/100], Loss: 0.1723, Val Loss: 0.6979
Epoch [49/100], Loss: 0.5291, Val Loss: 0.6497
Epoch [50/100], Loss: 0.1874, Val Loss: 0.7469
Epoch [51/100], Loss: 0.1338, Val Loss: 0.6787
Epoch [52/100], Loss: 0.2927, Val Loss: 0.7034
Epoch [53/100], Loss: 0.8652, Val Loss: 0.6927
Epoch [54/100], Loss: 0.1578, Val Loss: 0.6631
Epoch [55/100], Loss: 0.0764, Val Loss: 0.6661
Epoch [56/100], Loss: 0.2618, Val Loss: 0.6748
Epoch [57/100], Loss: 0.1757, Val Loss: 0.6120
Epoch [58/100], Loss: 0.6668, Val Loss: 0.6091
Epoch [59/100], Loss: 0.9236, Val Loss: 0.6310
Epoch [60/100], Loss: 0.2625, Val Loss: 0.6284
Epoch [61/100], Loss: 0.2373, Val Loss: 0.6292
Epoch [62/100], Loss: 0.1889, Val Loss: 0.6440
Epoch [63/100], Loss: 0.0864, Val Loss: 0.6305
Epoch [64/100], Loss: 0.4121, Val Loss: 0.5998
Epoch [65/100], Loss: 0.3563, Val Loss: 0.6029
Epoch [66/100], Loss: 0.0790, Val Loss: 0.6162
Epoch [67/100], Loss: 0.1635, Val Loss: 0.7023
Epoch [68/100], Loss: 2.0214, Val Loss: 0.6272
Epoch [69/100], Loss: 0.1305, Val Loss: 0.6010
Epoch [70/100], Loss: 0.1103, Val Loss: 0.6206
Epoch [71/100], Loss: 0.2125, Val Loss: 0.6464
Epoch [72/100], Loss: 0.3260, Val Loss: 0.6631
Epoch [73/100], Loss: 0.1374, Val Loss: 0.6386
Epoch [74/100], Loss: 0.3766, Val Loss: 0.6157
Epoch [75/100], Loss: 1.1809, Val Loss: 0.6327
Epoch [76/100], Loss: 0.2272, Val Loss: 0.6327
Epoch [77/100], Loss: 0.3455, Val Loss: 0.6028
Epoch [78/100], Loss: 0.1560, Val Loss: 0.6166
Epoch [79/100], Loss: 0.3729, Val Loss: 0.6259
Epoch [80/100], Loss: 0.1556, Val Loss: 0.5889
Epoch [81/100], Loss: 0.1662, Val Loss: 0.5908
Epoch [82/100], Loss: 0.1424, Val Loss: 0.6451
Epoch [83/100], Loss: 0.1328, Val Loss: 0.6851
Epoch [84/100], Loss: 0.1700, Val Loss: 0.5880
Epoch [85/100], Loss: 0.1687, Val Loss: 0.5854
Epoch [86/100], Loss: 0.2359, Val Loss: 0.6512
Epoch [87/100], Loss: 0.1026, Val Loss: 0.7348
Epoch [88/100], Loss: 0.3510, Val Loss: 0.5937
Epoch [89/100], Loss: 0.0840, Val Loss: 0.6160
Epoch [90/100], Loss: 0.2483, Val Loss: 0.6158
Epoch [91/100], Loss: 0.0843, Val Loss: 0.6220
Epoch [92/100], Loss: 0.5623, Val Loss: 0.6816
Epoch [93/100], Loss: 0.1921, Val Loss: 0.6369
Epoch [94/100], Loss: 0.9550, Val Loss: 0.7315
Epoch [95/100], Loss: 2.3302, Val Loss: 0.6261
Epoch [96/100], Loss: 0.1116, Val Loss: 0.6003
Epoch [97/100], Loss: 0.8483, Val Loss: 0.5997
Epoch [98/100], Loss: 0.1301, Val Loss: 0.6080
Epoch [99/100], Loss: 0.2151, Val Loss: 0.6126
Epoch [100/100], Loss: 0.7314, Val Loss: 0.6408
Runtime: 0:02:31.818513
R^2 Score: 0.8865
RMSE: 0.7628
MAE: 0.2547
MAPE: 24.83%
TruncatedSVD_50
MLP with layer size: [32, 16, 8, 4] - Result:
Epoch [1/100], Loss: 0.2349, Val Loss: 0.9994
Epoch [2/100], Loss: 0.8683, Val Loss: 0.9237
Epoch [3/100], Loss: 0.2189, Val Loss: 0.8795
Epoch [4/100], Loss: 0.4725, Val Loss: 0.9103
Epoch [5/100], Loss: 0.4733, Val Loss: 0.8171
Epoch [6/100], Loss: 0.2673, Val Loss: 0.8487
Epoch [7/100], Loss: 0.2320, Val Loss: 0.9231
Epoch [8/100], Loss: 0.3878, Val Loss: 0.8058
Epoch [9/100], Loss: 1.0091, Val Loss: 0.7616
Epoch [10/100], Loss: 0.4501, Val Loss: 0.8382
Epoch [11/100], Loss: 0.5332, Val Loss: 0.7569
Epoch [12/100], Loss: 0.2903, Val Loss: 0.8839
Epoch [13/100], Loss: 0.7213, Val Loss: 0.7363
Epoch [14/100], Loss: 0.6702, Val Loss: 0.8489
Epoch [15/100], Loss: 0.3221, Val Loss: 0.7520
Epoch [16/100], Loss: 0.1873, Val Loss: 0.8574
Epoch [17/100], Loss: 0.1120, Val Loss: 0.7457
Epoch [18/100], Loss: 0.1511, Val Loss: 0.7905
Epoch [19/100], Loss: 0.1280, Val Loss: 0.8488
Epoch [20/100], Loss: 0.2433, Val Loss: 0.7618
Epoch [21/100], Loss: 0.1538, Val Loss: 0.8055
Epoch [22/100], Loss: 0.3649, Val Loss: 0.7239
Epoch [23/100], Loss: 0.7288, Val Loss: 0.7277
Epoch [24/100], Loss: 0.7181, Val Loss: 0.8115
Epoch [25/100], Loss: 0.1920, Val Loss: 0.9459
Epoch [26/100], Loss: 0.0997, Val Loss: 0.7511
TruncatedSVD_50
MLP with layer size: [32, 16, 8] - Result:
Epoch [1/100], Loss: 1.1443, Val Loss: 1.1148
Epoch [2/100], Loss: 0.5835, Val Loss: 0.8886
Epoch [3/100], Loss: 0.2537, Val Loss: 0.8894
Epoch [4/100], Loss: 0.5607, Val Loss: 0.8574
Epoch [5/100], Loss: 0.0959, Val Loss: 0.8136
Epoch [6/100], Loss: 0.1430, Val Loss: 0.8823
Epoch [7/100], Loss: 0.2081, Val Loss: 0.8709
Epoch [8/100], Loss: 0.5288, Val Loss: 1.0453
Epoch [9/100], Loss: 0.1882, Val Loss: 0.8289
Epoch [10/100], Loss: 0.5136, Val Loss: 0.7495
Epoch [11/100], Loss: 0.0973, Val Loss: 0.8225
Epoch [12/100], Loss: 0.4180, Val Loss: 0.7280
Epoch [13/100], Loss: 0.2098, Val Loss: 0.7644
Epoch [14/100], Loss: 0.1339, Val Loss: 0.7858
Epoch [15/100], Loss: 0.0532, Val Loss: 0.7524
Epoch [16/100], Loss: 0.3299, Val Loss: 0.7629
Epoch [17/100], Loss: 0.1759, Val Loss: 0.7572
Epoch [18/100], Loss: 0.1179, Val Loss: 0.9214
Epoch [19/100], Loss: 0.1356, Val Loss: 0.7720
Epoch [20/100], Loss: 0.3861, Val Loss: 0.7415
Epoch [21/100], Loss: 0.0972, Val Loss: 0.7426
Epoch [22/100], Loss: 0.6703, Val Loss: 0.7382
Epoch [23/100], Loss: 0.5526, Val Loss: 0.6920
Epoch [24/100], Loss: 0.1318, Val Loss: 0.7208
Epoch [25/100], Loss: 0.2247, Val Loss: 0.7334
Epoch [26/100], Loss: 0.9779, Val Loss: 0.7035
Epoch [27/100], Loss: 0.5098, Val Loss: 0.6710
Epoch [28/100], Loss: 0.3876, Val Loss: 0.7094
Epoch [29/100], Loss: 0.3874, Val Loss: 0.7057
Epoch [30/100], Loss: 0.1173, Val Loss: 0.6760
Epoch [31/100], Loss: 0.4253, Val Loss: 0.6855
Epoch [32/100], Loss: 0.1810, Val Loss: 0.6723
Epoch [33/100], Loss: 0.2811, Val Loss: 0.6969
Epoch [34/100], Loss: 0.2840, Val Loss: 0.6771
Epoch [35/100], Loss: 0.3074, Val Loss: 0.6752
Epoch [36/100], Loss: 0.1916, Val Loss: 0.7137
Epoch [37/100], Loss: 0.1039, Val Loss: 0.6827
Epoch [38/100], Loss: 0.2443, Val Loss: 0.6649
Epoch [39/100], Loss: 0.3654, Val Loss: 0.6740
Epoch [40/100], Loss: 0.7839, Val Loss: 0.6665
Epoch [41/100], Loss: 5.3982, Val Loss: 0.6503
Epoch [42/100], Loss: 0.3433, Val Loss: 0.6695
Epoch [43/100], Loss: 0.1537, Val Loss: 0.6517
Epoch [44/100], Loss: 0.2692, Val Loss: 0.6646
Epoch [45/100], Loss: 0.0881, Val Loss: 0.6769
Epoch [46/100], Loss: 0.1822, Val Loss: 0.6559
Epoch [47/100], Loss: 0.5904, Val Loss: 0.6822
Epoch [48/100], Loss: 0.1687, Val Loss: 0.6198
Epoch [49/100], Loss: 0.9026, Val Loss: 0.6348
Epoch [50/100], Loss: 0.3960, Val Loss: 0.6089
Epoch [51/100], Loss: 0.2305, Val Loss: 0.6373
Epoch [52/100], Loss: 0.4180, Val Loss: 0.6341
Epoch [53/100], Loss: 0.8203, Val Loss: 0.6786
Epoch [54/100], Loss: 0.1321, Val Loss: 0.6634
Epoch [55/100], Loss: 0.3018, Val Loss: 0.6230
Epoch [56/100], Loss: 0.1913, Val Loss: 0.6550
Epoch [57/100], Loss: 0.1405, Val Loss: 0.8077
Epoch [58/100], Loss: 0.2820, Val Loss: 0.6262
Epoch [59/100], Loss: 0.0891, Val Loss: 0.6586
Epoch [60/100], Loss: 0.2102, Val Loss: 0.6157
Epoch [61/100], Loss: 0.3123, Val Loss: 0.6008
Epoch [62/100], Loss: 0.1537, Val Loss: 0.6541
Epoch [63/100], Loss: 0.0955, Val Loss: 0.6140
Epoch [64/100], Loss: 0.1141, Val Loss: 0.6146
Epoch [65/100], Loss: 0.4002, Val Loss: 0.5953
Epoch [66/100], Loss: 0.3255, Val Loss: 0.6067
Epoch [67/100], Loss: 0.2221, Val Loss: 0.6107
Epoch [68/100], Loss: 0.1005, Val Loss: 0.6252
Epoch [69/100], Loss: 0.2793, Val Loss: 0.6299
Epoch [70/100], Loss: 0.1047, Val Loss: 0.6194
Epoch [71/100], Loss: 0.1037, Val Loss: 0.6134
Epoch [72/100], Loss: 0.1413, Val Loss: 0.6230
Epoch [73/100], Loss: 0.0449, Val Loss: 0.6206
Epoch [74/100], Loss: 0.1457, Val Loss: 0.6128
Epoch [75/100], Loss: 0.1354, Val Loss: 0.6385
Epoch [76/100], Loss: 0.5927, Val Loss: 0.7209
Epoch [77/100], Loss: 0.0939, Val Loss: 0.5932
Epoch [78/100], Loss: 0.5575, Val Loss: 0.6043
Epoch [79/100], Loss: 0.3659, Val Loss: 0.6411
Epoch [80/100], Loss: 0.0994, Val Loss: 0.5802
Epoch [81/100], Loss: 0.1679, Val Loss: 0.6732
Epoch [82/100], Loss: 0.3387, Val Loss: 0.6326
Epoch [83/100], Loss: 0.1883, Val Loss: 0.5772
Epoch [84/100], Loss: 0.2415, Val Loss: 0.7214
Epoch [85/100], Loss: 0.5966, Val Loss: 0.6190
Epoch [86/100], Loss: 0.1242, Val Loss: 0.5759
Epoch [87/100], Loss: 0.1418, Val Loss: 0.6041
Epoch [88/100], Loss: 0.2433, Val Loss: 0.6273
Epoch [89/100], Loss: 0.2158, Val Loss: 0.5799
Epoch [90/100], Loss: 0.7608, Val Loss: 0.6355
Epoch [91/100], Loss: 0.1620, Val Loss: 0.6173
Epoch [92/100], Loss: 0.4952, Val Loss: 0.5861
Epoch [93/100], Loss: 0.1402, Val Loss: 0.5861
Epoch [94/100], Loss: 0.2900, Val Loss: 0.6303
Epoch [95/100], Loss: 0.1839, Val Loss: 0.6591
Epoch [96/100], Loss: 0.9010, Val Loss: 0.6145
Epoch [97/100], Loss: 0.1136, Val Loss: 0.6676
Epoch [98/100], Loss: 0.3456, Val Loss: 0.6250
Epoch [99/100], Loss: 0.2894, Val Loss: 0.6293
Epoch [100/100], Loss: 0.0984, Val Loss: 0.6187
Runtime: 0:03:26.797715
R^2 Score: 0.8391
RMSE: 0.9083
MAE: 0.2844
MAPE: 26.41%
TruncatedSVD_50
MLP with layer size: [41, 20, 10] - Result:
Epoch [1/100], Loss: 2.5503, Val Loss: 0.9951
Epoch [2/100], Loss: 0.2581, Val Loss: 0.8974
Epoch [3/100], Loss: 0.2110, Val Loss: 0.9877
Epoch [4/100], Loss: 0.3218, Val Loss: 0.8652
Epoch [5/100], Loss: 0.6968, Val Loss: 0.8309
Epoch [6/100], Loss: 0.2211, Val Loss: 0.7964
Epoch [7/100], Loss: 0.2932, Val Loss: 0.8006
Epoch [8/100], Loss: 0.6582, Val Loss: 0.8734
Epoch [9/100], Loss: 0.3057, Val Loss: 0.7578
Epoch [10/100], Loss: 1.7654, Val Loss: 0.7642
Epoch [11/100], Loss: 0.2885, Val Loss: 0.7701
Epoch [12/100], Loss: 0.2376, Val Loss: 0.7466
Epoch [13/100], Loss: 0.3024, Val Loss: 0.7503
Epoch [14/100], Loss: 0.3631, Val Loss: 0.7224
Epoch [15/100], Loss: 0.9230, Val Loss: 0.7450
Epoch [16/100], Loss: 0.6199, Val Loss: 0.7079
Epoch [17/100], Loss: 0.2217, Val Loss: 0.7225
Epoch [18/100], Loss: 0.1288, Val Loss: 0.7109
Epoch [19/100], Loss: 1.0952, Val Loss: 0.7837
Epoch [20/100], Loss: 0.6322, Val Loss: 0.7278
Epoch [21/100], Loss: 0.3669, Val Loss: 0.7022
Epoch [22/100], Loss: 0.2677, Val Loss: 0.8173
Epoch [23/100], Loss: 0.0508, Val Loss: 0.6941
Epoch [24/100], Loss: 0.1145, Val Loss: 0.7393
Epoch [25/100], Loss: 0.1779, Val Loss: 0.7004
Epoch [26/100], Loss: 0.2078, Val Loss: 0.6980
Epoch [27/100], Loss: 0.4726, Val Loss: 0.6946
Epoch [28/100], Loss: 0.1712, Val Loss: 0.7635
Epoch [29/100], Loss: 0.4889, Val Loss: 0.7599
Epoch [30/100], Loss: 0.8742, Val Loss: 0.6680
Epoch [31/100], Loss: 0.5179, Val Loss: 0.6609
Epoch [32/100], Loss: 0.0561, Val Loss: 0.6594
Epoch [33/100], Loss: 0.4069, Val Loss: 0.6764
Epoch [34/100], Loss: 0.8025, Val Loss: 0.6875
Epoch [35/100], Loss: 0.0614, Val Loss: 0.6667
Epoch [36/100], Loss: 0.1861, Val Loss: 0.6642
Epoch [37/100], Loss: 0.4948, Val Loss: 0.6297
Epoch [38/100], Loss: 0.1636, Val Loss: 0.6748
Epoch [39/100], Loss: 0.2120, Val Loss: 0.6529
Epoch [40/100], Loss: 0.7328, Val Loss: 0.6651
Epoch [41/100], Loss: 0.2426, Val Loss: 0.6436
Epoch [42/100], Loss: 0.1595, Val Loss: 0.6209
Epoch [43/100], Loss: 0.4427, Val Loss: 0.6631
Epoch [44/100], Loss: 0.0880, Val Loss: 0.6168
Epoch [45/100], Loss: 0.1962, Val Loss: 0.6261
Epoch [46/100], Loss: 0.5806, Val Loss: 0.6410
Epoch [47/100], Loss: 0.2268, Val Loss: 0.5913
Epoch [48/100], Loss: 0.2591, Val Loss: 0.8186
Epoch [49/100], Loss: 0.3398, Val Loss: 0.6179
Epoch [50/100], Loss: 0.3263, Val Loss: 0.6075
Epoch [51/100], Loss: 0.1583, Val Loss: 0.6194
Epoch [52/100], Loss: 0.4937, Val Loss: 0.6224
Epoch [53/100], Loss: 1.0737, Val Loss: 0.6330
Epoch [54/100], Loss: 0.3282, Val Loss: 0.6006
Epoch [55/100], Loss: 0.2098, Val Loss: 0.6273
Epoch [56/100], Loss: 0.0634, Val Loss: 0.6138
Epoch [57/100], Loss: 0.1174, Val Loss: 0.6922
Epoch [58/100], Loss: 0.0744, Val Loss: 0.6031
Epoch [59/100], Loss: 0.4710, Val Loss: 0.6231
Epoch [60/100], Loss: 0.5155, Val Loss: 0.6134
Epoch [61/100], Loss: 0.8675, Val Loss: 0.5768
Epoch [62/100], Loss: 0.5432, Val Loss: 0.6439
Epoch [63/100], Loss: 0.0738, Val Loss: 0.6373
Epoch [64/100], Loss: 0.1950, Val Loss: 0.6768
Epoch [65/100], Loss: 0.4599, Val Loss: 0.7829
Epoch [66/100], Loss: 0.3657, Val Loss: 0.5956
Epoch [67/100], Loss: 0.1176, Val Loss: 0.6298
Epoch [68/100], Loss: 2.6025, Val Loss: 0.7258
Epoch [69/100], Loss: 0.9855, Val Loss: 0.6299
Epoch [70/100], Loss: 0.6572, Val Loss: 0.5688
Epoch [71/100], Loss: 0.3221, Val Loss: 0.6568
Epoch [72/100], Loss: 0.2865, Val Loss: 0.6797
Epoch [73/100], Loss: 0.5032, Val Loss: 0.6362
Epoch [74/100], Loss: 0.2389, Val Loss: 0.6537
Epoch [75/100], Loss: 0.5402, Val Loss: 0.5715
Epoch [76/100], Loss: 0.1590, Val Loss: 0.5867
Epoch [77/100], Loss: 0.0981, Val Loss: 0.5860
Epoch [78/100], Loss: 0.0852, Val Loss: 0.6392
Epoch [79/100], Loss: 0.2452, Val Loss: 0.6206
Epoch [80/100], Loss: 1.2408, Val Loss: 0.5798
Epoch [81/100], Loss: 0.1376, Val Loss: 0.6026
Epoch [82/100], Loss: 0.2976, Val Loss: 0.5563
Epoch [83/100], Loss: 0.1419, Val Loss: 0.6179
Epoch [84/100], Loss: 0.4204, Val Loss: 0.5624
Epoch [85/100], Loss: 0.2672, Val Loss: 0.5845
Epoch [86/100], Loss: 0.3575, Val Loss: 0.6467
Epoch [87/100], Loss: 0.1467, Val Loss: 0.6036
Epoch [88/100], Loss: 0.2249, Val Loss: 0.5938
Epoch [89/100], Loss: 0.2882, Val Loss: 0.6077
Epoch [90/100], Loss: 0.0957, Val Loss: 0.6505
Epoch [91/100], Loss: 0.1455, Val Loss: 0.6237
Epoch [92/100], Loss: 0.0894, Val Loss: 0.5577
Epoch [93/100], Loss: 0.0805, Val Loss: 0.5461
Epoch [94/100], Loss: 0.1463, Val Loss: 0.5596
Epoch [95/100], Loss: 0.1962, Val Loss: 0.5964
Epoch [96/100], Loss: 0.1249, Val Loss: 0.6886
Epoch [97/100], Loss: 0.1616, Val Loss: 0.5823
Epoch [98/100], Loss: 0.1195, Val Loss: 0.5841
Epoch [99/100], Loss: 1.0151, Val Loss: 0.6007
Epoch [100/100], Loss: 0.7943, Val Loss: 0.5648
Runtime: 0:02:34.438893
R^2 Score: 0.8832
RMSE: 0.7739
MAE: 0.2316
MAPE: 23.40%
TruncatedSVD_50
MLP with layer size: [41, 20, 10] - Result:
Epoch [1/100], Loss: 1.1610, Val Loss: 0.9533
Epoch [2/100], Loss: 0.8966, Val Loss: 0.9499
Epoch [3/100], Loss: 0.6304, Val Loss: 0.8716
Epoch [4/100], Loss: 0.9241, Val Loss: 1.1047
Epoch [5/100], Loss: 0.1497, Val Loss: 0.9626
Epoch [6/100], Loss: 0.3814, Val Loss: 0.7635
Epoch [7/100], Loss: 0.1770, Val Loss: 0.7954
Epoch [8/100], Loss: 0.3260, Val Loss: 0.8963
Epoch [9/100], Loss: 0.8783, Val Loss: 0.8011
Epoch [10/100], Loss: 0.6005, Val Loss: 0.7804
Epoch [11/100], Loss: 0.3122, Val Loss: 0.7679
Epoch [12/100], Loss: 0.8098, Val Loss: 0.8987
Epoch [13/100], Loss: 0.1980, Val Loss: 0.8848
Epoch [14/100], Loss: 0.2706, Val Loss: 1.0743
Epoch [15/100], Loss: 0.1666, Val Loss: 0.7759
Epoch [16/100], Loss: 0.3388, Val Loss: 0.7733
Epoch [17/100], Loss: 0.1865, Val Loss: 0.7459
Epoch [18/100], Loss: 0.1995, Val Loss: 0.7763
Epoch [19/100], Loss: 0.2613, Val Loss: 0.7514
Epoch [20/100], Loss: 0.3881, Val Loss: 0.6871
Epoch [21/100], Loss: 0.1984, Val Loss: 0.7161
Epoch [22/100], Loss: 0.2729, Val Loss: 0.7394
Epoch [23/100], Loss: 0.2613, Val Loss: 0.6674
Epoch [24/100], Loss: 0.2978, Val Loss: 0.9349
Epoch [25/100], Loss: 2.5465, Val Loss: 0.9171
Epoch [26/100], Loss: 0.1537, Val Loss: 0.7337
Epoch [27/100], Loss: 0.2989, Val Loss: 0.7883
Epoch [28/100], Loss: 1.1512, Val Loss: 0.6969
Epoch [29/100], Loss: 0.5260, Val Loss: 0.7127
Epoch [30/100], Loss: 0.2186, Val Loss: 0.6688
Epoch [31/100], Loss: 0.2240, Val Loss: 0.6676
Epoch [32/100], Loss: 0.4640, Val Loss: 0.6824
Epoch [33/100], Loss: 0.3800, Val Loss: 0.7746
Epoch [34/100], Loss: 0.2910, Val Loss: 1.1823
Epoch [35/100], Loss: 0.4038, Val Loss: 0.6812
Epoch [36/100], Loss: 0.6226, Val Loss: 0.7025
Epoch [37/100], Loss: 0.2219, Val Loss: 0.6645
Epoch [38/100], Loss: 0.2950, Val Loss: 0.8277
Epoch [39/100], Loss: 0.2094, Val Loss: 0.6554
Epoch [40/100], Loss: 0.2191, Val Loss: 0.6539
Epoch [41/100], Loss: 0.2771, Val Loss: 0.6625
Epoch [42/100], Loss: 0.2106, Val Loss: 0.6335
Epoch [43/100], Loss: 0.4583, Val Loss: 0.6404
Epoch [44/100], Loss: 0.9205, Val Loss: 0.6930
Epoch [45/100], Loss: 0.1839, Val Loss: 0.6517
Epoch [46/100], Loss: 0.7182, Val Loss: 0.9106
Epoch [47/100], Loss: 0.4231, Val Loss: 0.6975
Epoch [48/100], Loss: 0.4005, Val Loss: 0.6512
Epoch [49/100], Loss: 0.2108, Val Loss: 0.6643
Epoch [50/100], Loss: 0.3351, Val Loss: 0.6573
Epoch [51/100], Loss: 0.9069, Val Loss: 0.6018
Epoch [52/100], Loss: 0.3172, Val Loss: 0.7691
Epoch [53/100], Loss: 0.3982, Val Loss: 0.6834
Epoch [54/100], Loss: 0.2469, Val Loss: 0.6495
Epoch [55/100], Loss: 0.3005, Val Loss: 0.6195
Epoch [56/100], Loss: 0.1992, Val Loss: 0.8558
Epoch [57/100], Loss: 0.0931, Val Loss: 0.6883
Epoch [58/100], Loss: 0.2384, Val Loss: 0.6295
Epoch [59/100], Loss: 0.3907, Val Loss: 0.7404
Epoch [60/100], Loss: 0.1512, Val Loss: 0.6889
Epoch [61/100], Loss: 0.3784, Val Loss: 0.7021
Epoch [62/100], Loss: 0.3899, Val Loss: 0.6438
Epoch [63/100], Loss: 1.0400, Val Loss: 0.9128
Epoch [64/100], Loss: 0.4389, Val Loss: 0.6966
Epoch [65/100], Loss: 0.4375, Val Loss: 0.6584
Epoch [66/100], Loss: 0.4161, Val Loss: 0.6296
Epoch [67/100], Loss: 0.2114, Val Loss: 0.6724
Epoch [68/100], Loss: 0.2074, Val Loss: 0.7646
Epoch [69/100], Loss: 0.3035, Val Loss: 0.8161
Epoch [70/100], Loss: 0.3478, Val Loss: 0.5923
Epoch [71/100], Loss: 0.3617, Val Loss: 0.6879
Epoch [72/100], Loss: 0.3252, Val Loss: 0.6450
Epoch [73/100], Loss: 0.5741, Val Loss: 0.6264
Epoch [74/100], Loss: 1.3196, Val Loss: 0.6661
Epoch [75/100], Loss: 0.2429, Val Loss: 0.7196
Epoch [76/100], Loss: 0.2538, Val Loss: 0.7178
Epoch [77/100], Loss: 0.4592, Val Loss: 0.5798
Epoch [78/100], Loss: 0.6140, Val Loss: 0.6547
Epoch [79/100], Loss: 0.3259, Val Loss: 0.6470
Epoch [80/100], Loss: 0.1807, Val Loss: 0.6873
Epoch [81/100], Loss: 0.1459, Val Loss: 1.2556
Epoch [82/100], Loss: 0.2468, Val Loss: 0.7041
Epoch [83/100], Loss: 0.2278, Val Loss: 0.7561
Epoch [84/100], Loss: 0.3479, Val Loss: 0.6966
Epoch [85/100], Loss: 0.2492, Val Loss: 0.6885
Epoch [86/100], Loss: 0.2308, Val Loss: 0.6473
Epoch [87/100], Loss: 1.7045, Val Loss: 0.8597
Epoch [88/100], Loss: 0.2221, Val Loss: 0.6095
Epoch [89/100], Loss: 0.5440, Val Loss: 0.6848
Epoch [90/100], Loss: 0.9547, Val Loss: 0.6180
Epoch [91/100], Loss: 0.2514, Val Loss: 0.5981
Epoch [92/100], Loss: 0.2770, Val Loss: 0.7080
Epoch [93/100], Loss: 0.2671, Val Loss: 0.6729
Epoch [94/100], Loss: 0.3591, Val Loss: 0.6375
Epoch [95/100], Loss: 1.3236, Val Loss: 0.6614
Epoch [96/100], Loss: 0.1910, Val Loss: 0.6675
Early stopping at epoch 96
Runtime: 0:02:25.326996
TruncatedSVD_50
MLP with layer size: [41, 20, 10] - Result:
Epoch [1/100], Loss: 0.1999, Val Loss: 1.0075
Epoch [2/100], Loss: 0.2067, Val Loss: 0.9158
Epoch [3/100], Loss: 4.9246, Val Loss: 0.8611
Epoch [4/100], Loss: 0.2792, Val Loss: 0.8431
Epoch [5/100], Loss: 0.6826, Val Loss: 0.7894
Epoch [6/100], Loss: 1.6838, Val Loss: 0.8364
Epoch [7/100], Loss: 0.1161, Val Loss: 0.8767
Epoch [8/100], Loss: 0.2458, Val Loss: 0.8181
Epoch [9/100], Loss: 0.2488, Val Loss: 0.7581
Epoch [10/100], Loss: 1.4202, Val Loss: 0.7616
Epoch [11/100], Loss: 0.2407, Val Loss: 0.7774
Epoch [12/100], Loss: 0.1167, Val Loss: 0.7585
Epoch [13/100], Loss: 0.2699, Val Loss: 0.8075
Epoch [14/100], Loss: 0.1538, Val Loss: 0.7835
Epoch [15/100], Loss: 0.7748, Val Loss: 0.7476
Epoch [16/100], Loss: 0.2164, Val Loss: 0.7041
Epoch [17/100], Loss: 0.6697, Val Loss: 0.6932
Epoch [18/100], Loss: 0.4540, Val Loss: 0.6800
Epoch [19/100], Loss: 0.0861, Val Loss: 0.7096
Epoch [20/100], Loss: 0.2035, Val Loss: 0.6767
Epoch [21/100], Loss: 1.2283, Val Loss: 0.6678
Epoch [22/100], Loss: 0.4805, Val Loss: 0.6623
Epoch [23/100], Loss: 0.3297, Val Loss: 0.6510
Epoch [24/100], Loss: 0.7524, Val Loss: 0.6571
Epoch [25/100], Loss: 0.1960, Val Loss: 0.6621
Epoch [26/100], Loss: 0.1042, Val Loss: 0.6390
Epoch [27/100], Loss: 0.6646, Val Loss: 0.6263
Epoch [28/100], Loss: 0.1539, Val Loss: 0.6289
Epoch [29/100], Loss: 1.6298, Val Loss: 0.6104
Epoch [30/100], Loss: 0.1779, Val Loss: 0.6172
Epoch [31/100], Loss: 0.0681, Val Loss: 0.6159
Epoch [32/100], Loss: 0.4917, Val Loss: 0.6439
Epoch [33/100], Loss: 0.8202, Val Loss: 0.6171
Epoch [34/100], Loss: 0.5520, Val Loss: 0.6078
Epoch [35/100], Loss: 0.5215, Val Loss: 0.6171
Epoch [36/100], Loss: 0.4298, Val Loss: 0.6526
Epoch [37/100], Loss: 0.1460, Val Loss: 0.6843
Epoch [38/100], Loss: 0.3313, Val Loss: 0.6016
Epoch [39/100], Loss: 0.3876, Val Loss: 0.6081
Epoch [40/100], Loss: 0.2959, Val Loss: 0.5967
Epoch [41/100], Loss: 0.3832, Val Loss: 0.6099
Epoch [42/100], Loss: 0.6010, Val Loss: 0.5929
Epoch [43/100], Loss: 0.2907, Val Loss: 0.6317
Epoch [44/100], Loss: 0.3386, Val Loss: 0.8506
Epoch [45/100], Loss: 0.3002, Val Loss: 0.6296
Epoch [46/100], Loss: 0.2932, Val Loss: 0.6033
Epoch [47/100], Loss: 0.4164, Val Loss: 0.6170
Epoch [48/100], Loss: 0.1557, Val Loss: 0.5804
Epoch [49/100], Loss: 0.1407, Val Loss: 0.5800
Epoch [50/100], Loss: 0.1460, Val Loss: 0.6003
Epoch [51/100], Loss: 0.0634, Val Loss: 0.5695
Epoch [52/100], Loss: 0.3218, Val Loss: 0.5697
Epoch [53/100], Loss: 0.2039, Val Loss: 0.6057
Epoch [54/100], Loss: 0.2407, Val Loss: 0.6070
Epoch [55/100], Loss: 0.2146, Val Loss: 0.5790
Epoch [56/100], Loss: 0.2399, Val Loss: 0.6071
Epoch [57/100], Loss: 0.3669, Val Loss: 0.6940
Epoch [58/100], Loss: 0.1317, Val Loss: 0.5960
Epoch [59/100], Loss: 0.1410, Val Loss: 0.5773
Epoch [60/100], Loss: 0.7993, Val Loss: 0.6107
Epoch [61/100], Loss: 0.0679, Val Loss: 0.5902
Epoch [62/100], Loss: 0.2731, Val Loss: 0.5865
Epoch [63/100], Loss: 0.9952, Val Loss: 0.5789
Epoch [64/100], Loss: 0.1148, Val Loss: 0.5724
Epoch [65/100], Loss: 0.1617, Val Loss: 0.6833
Epoch [66/100], Loss: 0.1531, Val Loss: 0.5918
Epoch [67/100], Loss: 0.2040, Val Loss: 0.5862
Epoch [68/100], Loss: 0.2864, Val Loss: 0.6146
Epoch [69/100], Loss: 0.1980, Val Loss: 0.5764
Epoch [70/100], Loss: 0.2196, Val Loss: 0.5831
Epoch [71/100], Loss: 0.3046, Val Loss: 0.5648
Epoch [72/100], Loss: 0.2865, Val Loss: 0.5766
Epoch [73/100], Loss: 0.0495, Val Loss: 0.5751
Epoch [74/100], Loss: 1.0706, Val Loss: 0.5644
Epoch [75/100], Loss: 0.6053, Val Loss: 0.5708
Epoch [76/100], Loss: 0.4567, Val Loss: 0.5535
Epoch [77/100], Loss: 0.1347, Val Loss: 0.6038
Epoch [78/100], Loss: 0.1329, Val Loss: 0.5831
Epoch [79/100], Loss: 0.1230, Val Loss: 0.5932
Epoch [80/100], Loss: 0.4011, Val Loss: 0.5832
Epoch [81/100], Loss: 0.1214, Val Loss: 0.6034
Epoch [82/100], Loss: 0.2162, Val Loss: 0.5979
Epoch [83/100], Loss: 0.1312, Val Loss: 0.5719
Epoch [84/100], Loss: 0.3177, Val Loss: 0.7193
Epoch [85/100], Loss: 0.1017, Val Loss: 0.5735
Epoch [86/100], Loss: 0.2987, Val Loss: 0.5665
Epoch [87/100], Loss: 0.2531, Val Loss: 0.5950
Epoch [88/100], Loss: 0.4171, Val Loss: 0.5931
Epoch [89/100], Loss: 0.0874, Val Loss: 0.5561
Epoch [90/100], Loss: 0.2353, Val Loss: 0.5645
Epoch [91/100], Loss: 0.2066, Val Loss: 0.5915
Epoch [92/100], Loss: 0.9211, Val Loss: 0.5609
Epoch [93/100], Loss: 0.1600, Val Loss: 0.5659
Epoch [94/100], Loss: 0.1572, Val Loss: 0.6121
Epoch [95/100], Loss: 0.1062, Val Loss: 0.6315
Epoch [96/100], Loss: 0.1504, Val Loss: 0.5828
Epoch [97/100], Loss: 1.4223, Val Loss: 0.6232
Epoch [98/100], Loss: 0.2223, Val Loss: 0.6004
Epoch [99/100], Loss: 0.1497, Val Loss: 0.5666
Epoch [100/100], Loss: 0.1072, Val Loss: 0.5955
Runtime: 0:02:29.436678
R^2 Score: 0.8684
RMSE: 0.8213
MAE: 0.2445
MAPE: 23.06%
TruncatedSVD_50
MLP with layer size: [41, 20, 10] - Result:
Epoch [1/100], Loss: 0.1952, Val Loss: 0.9766
Epoch [2/100], Loss: 0.4585, Val Loss: 0.8515
Epoch [3/100], Loss: 0.2118, Val Loss: 0.9174
Epoch [4/100], Loss: 0.1435, Val Loss: 0.8368
Epoch [5/100], Loss: 0.3749, Val Loss: 0.9186
Epoch [6/100], Loss: 1.0392, Val Loss: 0.7633
Epoch [7/100], Loss: 0.9896, Val Loss: 0.7659
Epoch [8/100], Loss: 0.1104, Val Loss: 0.7456
Epoch [9/100], Loss: 0.3112, Val Loss: 0.9282
Epoch [10/100], Loss: 0.1413, Val Loss: 0.7098
Epoch [11/100], Loss: 0.5640, Val Loss: 0.7287
Epoch [12/100], Loss: 0.2421, Val Loss: 1.1275
Epoch [13/100], Loss: 0.3050, Val Loss: 0.7169
Epoch [14/100], Loss: 0.3806, Val Loss: 0.6693
Epoch [15/100], Loss: 0.6961, Val Loss: 0.6627
Epoch [16/100], Loss: 0.4290, Val Loss: 0.6643
Epoch [17/100], Loss: 0.5507, Val Loss: 0.6688
Epoch [18/100], Loss: 0.6028, Val Loss: 0.7549
Epoch [19/100], Loss: 5.0894, Val Loss: 0.6982
Epoch [20/100], Loss: 0.4229, Val Loss: 0.6943
Epoch [21/100], Loss: 0.2104, Val Loss: 0.6608
Epoch [22/100], Loss: 1.2553, Val Loss: 1.0862
Epoch [23/100], Loss: 0.1247, Val Loss: 0.6559
Epoch [24/100], Loss: 0.7288, Val Loss: 0.6469
Epoch [25/100], Loss: 0.4962, Val Loss: 0.7212
Epoch [26/100], Loss: 0.1303, Val Loss: 0.6935
Epoch [27/100], Loss: 0.2032, Val Loss: 0.6578
Epoch [28/100], Loss: 0.0521, Val Loss: 0.6332
Epoch [29/100], Loss: 0.2702, Val Loss: 0.6372
Epoch [30/100], Loss: 0.2905, Val Loss: 1.2405
Epoch [31/100], Loss: 0.1041, Val Loss: 0.6210
Epoch [32/100], Loss: 0.0911, Val Loss: 0.7421
Epoch [33/100], Loss: 0.1370, Val Loss: 0.6708
Epoch [34/100], Loss: 0.1073, Val Loss: 0.6212
Epoch [35/100], Loss: 0.1025, Val Loss: 0.6251
Epoch [36/100], Loss: 0.0619, Val Loss: 0.6465
Epoch [37/100], Loss: 0.1046, Val Loss: 0.6262
Epoch [38/100], Loss: 0.2604, Val Loss: 0.6409
Epoch [39/100], Loss: 0.1507, Val Loss: 0.5975
Epoch [40/100], Loss: 0.0990, Val Loss: 0.5985
Epoch [41/100], Loss: 0.1714, Val Loss: 0.6606
Epoch [42/100], Loss: 0.5691, Val Loss: 0.5992
Epoch [43/100], Loss: 0.4445, Val Loss: 0.5818
Epoch [44/100], Loss: 0.5831, Val Loss: 0.6208
Epoch [45/100], Loss: 0.1097, Val Loss: 0.6001
Epoch [46/100], Loss: 0.1926, Val Loss: 0.6055
Epoch [47/100], Loss: 0.7250, Val Loss: 0.6511
Epoch [48/100], Loss: 0.2073, Val Loss: 0.6533
Epoch [49/100], Loss: 0.0856, Val Loss: 0.5900
Epoch [50/100], Loss: 0.1619, Val Loss: 0.5979
Epoch [51/100], Loss: 0.3182, Val Loss: 0.6246
Epoch [52/100], Loss: 0.2886, Val Loss: 0.6012
Epoch [53/100], Loss: 0.2523, Val Loss: 0.6135
Epoch [54/100], Loss: 0.4767, Val Loss: 0.5625
Epoch [55/100], Loss: 0.1199, Val Loss: 0.6104
Epoch [56/100], Loss: 0.1521, Val Loss: 0.6231
Epoch [57/100], Loss: 0.2056, Val Loss: 0.6017
Epoch [58/100], Loss: 0.1190, Val Loss: 0.6078
Epoch [59/100], Loss: 0.3428, Val Loss: 0.6613
Epoch [60/100], Loss: 0.9743, Val Loss: 0.6296
Epoch [61/100], Loss: 0.0935, Val Loss: 0.6337
Epoch [62/100], Loss: 0.1765, Val Loss: 0.6196
Epoch [63/100], Loss: 0.1946, Val Loss: 0.6406
Epoch [64/100], Loss: 0.3169, Val Loss: 0.7060
Epoch [65/100], Loss: 0.0903, Val Loss: 0.6943
Epoch [66/100], Loss: 0.2085, Val Loss: 0.7119
Epoch [67/100], Loss: 0.1032, Val Loss: 0.5970
Epoch [68/100], Loss: 0.1798, Val Loss: 0.5654
Epoch [69/100], Loss: 0.3365, Val Loss: 0.5861
Epoch [70/100], Loss: 0.1470, Val Loss: 0.7106
Epoch [71/100], Loss: 0.5119, Val Loss: 0.5692
Epoch [72/100], Loss: 0.1936, Val Loss: 0.5735
Epoch [73/100], Loss: 0.3275, Val Loss: 0.5784
Epoch [74/100], Loss: 0.1338, Val Loss: 0.5678
Epoch [75/100], Loss: 0.1281, Val Loss: 0.5914
Epoch [76/100], Loss: 0.5868, Val Loss: 0.5623
Epoch [77/100], Loss: 0.9036, Val Loss: 0.5894
Epoch [78/100], Loss: 0.5189, Val Loss: 0.5728
Epoch [79/100], Loss: 0.2507, Val Loss: 0.5469
Epoch [80/100], Loss: 0.2937, Val Loss: 0.5497
Epoch [81/100], Loss: 0.1794, Val Loss: 0.5669
Epoch [82/100], Loss: 0.1227, Val Loss: 0.6267
Epoch [83/100], Loss: 0.0938, Val Loss: 0.5985
Epoch [84/100], Loss: 0.0693, Val Loss: 0.5787
Epoch [85/100], Loss: 0.1140, Val Loss: 0.7004
Epoch [86/100], Loss: 0.0707, Val Loss: 0.5754
Epoch [87/100], Loss: 0.0935, Val Loss: 0.5983
Epoch [88/100], Loss: 0.6738, Val Loss: 0.5984
Epoch [89/100], Loss: 0.2332, Val Loss: 0.5950
Epoch [90/100], Loss: 0.1517, Val Loss: 0.6105
Epoch [91/100], Loss: 0.0907, Val Loss: 0.5808
Epoch [92/100], Loss: 0.4927, Val Loss: 0.5888
Epoch [93/100], Loss: 0.2780, Val Loss: 0.6187
Epoch [94/100], Loss: 0.6737, Val Loss: 0.5921
Epoch [95/100], Loss: 0.1324, Val Loss: 0.5426
Epoch [96/100], Loss: 0.1181, Val Loss: 0.6392
Epoch [97/100], Loss: 0.2159, Val Loss: 0.5717
Epoch [98/100], Loss: 0.1964, Val Loss: 0.5956
Epoch [99/100], Loss: 0.0940, Val Loss: 0.6449
Epoch [100/100], Loss: 0.0720, Val Loss: 0.5646
Runtime: 0:02:30.397106
R^2 Score: 0.8078
RMSE: 0.9926
MAE: 0.2508
MAPE: 22.25%
TruncatedSVD_50
MLP with layer size: [41, 20, 10] - Result:
Epoch [1/100], Loss: 1.8537, Val Loss: 1.8793
Epoch [2/100], Loss: 0.9310, Val Loss: 1.8321
Epoch [3/100], Loss: 0.5580, Val Loss: 1.8931
Epoch [4/100], Loss: 0.9456, Val Loss: 1.8911
Epoch [5/100], Loss: 2.7172, Val Loss: 1.8837
Epoch [6/100], Loss: 3.7364, Val Loss: 1.8745
Epoch [7/100], Loss: 0.6027, Val Loss: 1.8801
Epoch [8/100], Loss: 1.1653, Val Loss: 1.8875
Epoch [9/100], Loss: 0.8871, Val Loss: 1.8857
Epoch [10/100], Loss: 1.0259, Val Loss: 1.8947
Epoch [11/100], Loss: 1.0264, Val Loss: 1.8937
Epoch [12/100], Loss: 2.1518, Val Loss: 1.8942
Epoch [13/100], Loss: 0.9835, Val Loss: 1.8926
Epoch [14/100], Loss: 0.7529, Val Loss: 1.8989
Epoch [15/100], Loss: 0.8993, Val Loss: 1.8732
Epoch [16/100], Loss: 0.6126, Val Loss: 1.9009
Epoch [17/100], Loss: 0.6161, Val Loss: 1.8907
Epoch [18/100], Loss: 0.6331, Val Loss: 1.8967
Epoch [19/100], Loss: 0.9471, Val Loss: 1.8949
Epoch [20/100], Loss: 3.9875, Val Loss: 1.8949
Epoch [21/100], Loss: 1.2876, Val Loss: 1.8939
Early stopping at epoch 21
Runtime: 0:00:36.467872
R^2 Score: -0.0002
RMSE: 2.2646
MAE: 1.0342
MAPE: 151.02%
TruncatedSVD_50
MLP with layer size: [41, 20, 10] - Result:
TruncatedSVD_50
MLP with layer size: [41, 20, 10] - Result:
Epoch [1/100], Loss: 0.6599, Val Loss: 1.0723
Epoch [2/100], Loss: 2.9149, Val Loss: 1.2277
Epoch [3/100], Loss: 0.3572, Val Loss: 1.6916
Epoch [4/100], Loss: 0.3284, Val Loss: 1.0138
Epoch [5/100], Loss: 0.4728, Val Loss: 0.9635
Epoch [6/100], Loss: 0.4321, Val Loss: 0.8926
Epoch [7/100], Loss: 0.3551, Val Loss: 0.9365
Epoch [8/100], Loss: 1.3102, Val Loss: 1.0946
Epoch [9/100], Loss: 0.4954, Val Loss: 0.9616
Epoch [10/100], Loss: 0.3973, Val Loss: 1.0002
Epoch [11/100], Loss: 0.5532, Val Loss: 1.3279
Epoch [12/100], Loss: 0.6307, Val Loss: 1.0773
Epoch [13/100], Loss: 0.2868, Val Loss: 0.9915
Epoch [14/100], Loss: 0.4279, Val Loss: 1.0154
Epoch [15/100], Loss: 0.2136, Val Loss: 1.0298
Epoch [16/100], Loss: 0.6174, Val Loss: 1.3667
Epoch [17/100], Loss: 0.3522, Val Loss: 0.8775
Epoch [18/100], Loss: 0.3438, Val Loss: 1.0024
Epoch [19/100], Loss: 0.4892, Val Loss: 0.9438
Epoch [20/100], Loss: 1.9821, Val Loss: 0.8944
Epoch [21/100], Loss: 0.3451, Val Loss: 1.4496
Epoch [22/100], Loss: 0.3804, Val Loss: 1.4503
Epoch [23/100], Loss: 0.4968, Val Loss: 1.0492
Epoch [24/100], Loss: 0.8951, Val Loss: 0.9698
Epoch [25/100], Loss: 0.3214, Val Loss: 0.8441
Epoch [26/100], Loss: 0.3889, Val Loss: 1.1124
Epoch [27/100], Loss: 0.3440, Val Loss: 0.9484
Epoch [28/100], Loss: 0.4985, Val Loss: 0.9970
Epoch [29/100], Loss: 0.2902, Val Loss: 0.8143
Epoch [30/100], Loss: 0.2304, Val Loss: 0.9493
Epoch [31/100], Loss: 1.1210, Val Loss: 0.8342
Epoch [32/100], Loss: 0.3911, Val Loss: 0.9924
Epoch [33/100], Loss: 0.2959, Val Loss: 0.8857
Epoch [34/100], Loss: 0.6634, Val Loss: 0.8632
Epoch [35/100], Loss: 1.3659, Val Loss: 1.0032
Epoch [36/100], Loss: 0.3315, Val Loss: 0.9651
Epoch [37/100], Loss: 0.5522, Val Loss: 1.0265
Epoch [38/100], Loss: 0.6935, Val Loss: 0.9269
Epoch [39/100], Loss: 0.7742, Val Loss: 0.9053
Epoch [40/100], Loss: 0.6726, Val Loss: 1.0161
Epoch [41/100], Loss: 0.6160, Val Loss: 1.0704
Epoch [42/100], Loss: 0.5411, Val Loss: 1.0488
Epoch [43/100], Loss: 0.3712, Val Loss: 0.9965
Epoch [44/100], Loss: 1.5898, Val Loss: 0.9237
Epoch [45/100], Loss: 1.0124, Val Loss: 0.8736
Epoch [46/100], Loss: 0.1797, Val Loss: 1.0033
Epoch [47/100], Loss: 0.3801, Val Loss: 0.9547
Epoch [48/100], Loss: 1.0392, Val Loss: 0.9237
Early stopping at epoch 48
Runtime: 0:01:19.206072
R^2 Score: 0.6735
RMSE: 1.2938
MAE: 0.5091
MAPE: 74.63%
TruncatedSVD_50
MLP with layer size: [64, 32, 16] - Result:
Epoch [1/100], Loss: 0.8930, Val Loss: 1.9005
Epoch [2/100], Loss: 0.6191, Val Loss: 1.8947
Epoch [3/100], Loss: 5.6158, Val Loss: 1.8946
Epoch [4/100], Loss: 0.7331, Val Loss: 1.8944
Epoch [5/100], Loss: 1.0275, Val Loss: 1.9026
Epoch [6/100], Loss: 0.8877, Val Loss: 1.9023
Epoch [7/100], Loss: 0.4816, Val Loss: 1.8988
Epoch [8/100], Loss: 2.2160, Val Loss: 1.8946
Epoch [9/100], Loss: 2.7025, Val Loss: 1.9023
Epoch [10/100], Loss: 0.7803, Val Loss: 1.8964
Epoch [11/100], Loss: 0.9447, Val Loss: 1.9058
Epoch [12/100], Loss: 1.0240, Val Loss: 1.9045
Epoch [13/100], Loss: 0.5752, Val Loss: 1.8971
Epoch [14/100], Loss: 2.7652, Val Loss: 1.8966
Epoch [15/100], Loss: 2.2407, Val Loss: 1.8950
Epoch [16/100], Loss: 0.6440, Val Loss: 1.9009
Epoch [17/100], Loss: 0.7848, Val Loss: 1.8946
Epoch [18/100], Loss: 0.7736, Val Loss: 1.8947
Epoch [19/100], Loss: 0.5169, Val Loss: 1.9100
Epoch [20/100], Loss: 0.7359, Val Loss: 1.8946
Epoch [21/100], Loss: 0.5600, Val Loss: 1.8947
Epoch [22/100], Loss: 0.6750, Val Loss: 1.9227
Epoch [23/100], Loss: 0.9247, Val Loss: 1.9009
Epoch [24/100], Loss: 0.8550, Val Loss: 1.8939
Epoch [25/100], Loss: 0.8049, Val Loss: 1.8939
Epoch [26/100], Loss: 4.0755, Val Loss: 1.8939
Epoch [27/100], Loss: 0.7886, Val Loss: 1.8951
Epoch [28/100], Loss: 4.0607, Val Loss: 1.8968
Epoch [29/100], Loss: 0.7256, Val Loss: 1.8939
Epoch [30/100], Loss: 0.5095, Val Loss: 1.9083
Epoch [31/100], Loss: 4.8340, Val Loss: 4.7376
Epoch [32/100], Loss: 4.2932, Val Loss: 2.1234
Epoch [33/100], Loss: 1.1649, Val Loss: 1.8963
Epoch [34/100], Loss: 2.6179, Val Loss: 2.9493
Epoch [35/100], Loss: 3.4537, Val Loss: 3.3106
Epoch [36/100], Loss: 1.1967, Val Loss: 2.0198
Epoch [37/100], Loss: 0.9741, Val Loss: 1.8993
Epoch [38/100], Loss: 0.8096, Val Loss: 1.8938
Epoch [39/100], Loss: 2.9515, Val Loss: 1.8945
Epoch [40/100], Loss: 0.7379, Val Loss: 1.9056
Epoch [41/100], Loss: 0.6120, Val Loss: 1.8937
Epoch [42/100], Loss: 0.7550, Val Loss: 1.8940
Epoch [43/100], Loss: 0.9805, Val Loss: 1.8978
Epoch [44/100], Loss: 1.0441, Val Loss: 1.8944
Epoch [45/100], Loss: 0.7207, Val Loss: 1.8956
Epoch [46/100], Loss: 0.6698, Val Loss: 1.8944
Epoch [47/100], Loss: 3.8553, Val Loss: 3.8156
Epoch [48/100], Loss: 2.2984, Val Loss: 1.8964
Epoch [49/100], Loss: 0.5914, Val Loss: 1.8943
Epoch [50/100], Loss: 2.4589, Val Loss: 1.8938
TruncatedSVD_50 + Dropout
MLP with layer size: [128, 64, 32] - Result:
Epoch [1/100], Loss: 0.5827, Val Loss: 0.9117
Epoch [2/100], Loss: 0.1983, Val Loss: 0.8808
Epoch [3/100], Loss: 0.1845, Val Loss: 0.8542
Epoch [4/100], Loss: 0.2966, Val Loss: 0.7686
Epoch [5/100], Loss: 0.2858, Val Loss: 0.8002
Epoch [6/100], Loss: 0.4950, Val Loss: 0.9140
Epoch [7/100], Loss: 0.4076, Val Loss: 0.7500
Epoch [8/100], Loss: 0.4155, Val Loss: 0.7360
Epoch [9/100], Loss: 1.2245, Val Loss: 0.7196
Epoch [10/100], Loss: 0.3434, Val Loss: 1.0154
Epoch [11/100], Loss: 0.5432, Val Loss: 0.7259
Epoch [12/100], Loss: 0.2332, Val Loss: 0.7105
Epoch [13/100], Loss: 0.1705, Val Loss: 0.7020
Epoch [14/100], Loss: 0.7430, Val Loss: 0.8893
Epoch [15/100], Loss: 0.3273, Val Loss: 0.6624
Epoch [16/100], Loss: 0.3287, Val Loss: 0.7114
Epoch [17/100], Loss: 0.2183, Val Loss: 0.6522
Epoch [18/100], Loss: 2.3315, Val Loss: 0.6851
Epoch [19/100], Loss: 0.1458, Val Loss: 0.7565
Epoch [20/100], Loss: 0.1659, Val Loss: 0.6976
Epoch [21/100], Loss: 0.1127, Val Loss: 0.7847
Epoch [22/100], Loss: 0.1470, Val Loss: 0.8083
Epoch [23/100], Loss: 0.1518, Val Loss: 0.7115
Epoch [24/100], Loss: 0.7305, Val Loss: 0.7345
Epoch [25/100], Loss: 0.2189, Val Loss: 0.6343
Epoch [26/100], Loss: 0.2468, Val Loss: 0.7065
Epoch [27/100], Loss: 0.1830, Val Loss: 0.6276
Epoch [28/100], Loss: 0.1019, Val Loss: 0.6490
Epoch [29/100], Loss: 0.2118, Val Loss: 0.6739
Epoch [30/100], Loss: 0.2708, Val Loss: 0.6700
Epoch [31/100], Loss: 0.3029, Val Loss: 0.6756
Epoch [32/100], Loss: 0.1592, Val Loss: 0.7147
Epoch [33/100], Loss: 0.2249, Val Loss: 0.6655
Epoch [34/100], Loss: 1.3446, Val Loss: 0.6350
Epoch [35/100], Loss: 0.1382, Val Loss: 0.6982
Epoch [36/100], Loss: 0.2063, Val Loss: 0.6672
Epoch [37/100], Loss: 0.4324, Val Loss: 0.6099
Epoch [38/100], Loss: 0.2905, Val Loss: 0.6106
Epoch [39/100], Loss: 0.1601, Val Loss: 0.6482
Epoch [40/100], Loss: 0.1950, Val Loss: 0.6282
Epoch [41/100], Loss: 0.2181, Val Loss: 0.6076
Epoch [42/100], Loss: 0.2145, Val Loss: 0.7400
Epoch [43/100], Loss: 0.1580, Val Loss: 0.5793
Epoch [44/100], Loss: 0.9190, Val Loss: 0.5776
Epoch [45/100], Loss: 0.2955, Val Loss: 0.6261
Epoch [46/100], Loss: 0.1329, Val Loss: 0.6255
Epoch [47/100], Loss: 0.1751, Val Loss: 0.6164
Epoch [48/100], Loss: 0.0896, Val Loss: 0.6450
Epoch [49/100], Loss: 1.4921, Val Loss: 0.6561
Epoch [50/100], Loss: 0.3658, Val Loss: 0.5625
Epoch [51/100], Loss: 0.2807, Val Loss: 0.5688
Epoch [52/100], Loss: 0.2533, Val Loss: 0.6091
Epoch [53/100], Loss: 1.2471, Val Loss: 0.6893
Epoch [54/100], Loss: 0.2731, Val Loss: 0.6053
Epoch [55/100], Loss: 0.1575, Val Loss: 0.5970
Epoch [56/100], Loss: 1.3608, Val Loss: 0.6140
Epoch [57/100], Loss: 0.1494, Val Loss: 0.7642
Epoch [58/100], Loss: 0.3657, Val Loss: 0.5905
Epoch [59/100], Loss: 0.1688, Val Loss: 0.6447
Epoch [60/100], Loss: 0.2880, Val Loss: 0.6159
Epoch [61/100], Loss: 0.2750, Val Loss: 0.6138
Epoch [62/100], Loss: 0.1943, Val Loss: 0.5838
Epoch [63/100], Loss: 0.1972, Val Loss: 0.5784
Epoch [64/100], Loss: 1.1390, Val Loss: 0.5524
Epoch [65/100], Loss: 0.2623, Val Loss: 0.7461
Epoch [66/100], Loss: 0.2342, Val Loss: 0.6015
Epoch [67/100], Loss: 0.8332, Val Loss: 0.6277
Epoch [68/100], Loss: 0.2788, Val Loss: 0.6494
Epoch [69/100], Loss: 1.4139, Val Loss: 0.5933
Epoch [70/100], Loss: 0.2830, Val Loss: 0.5861
Epoch [71/100], Loss: 0.6002, Val Loss: 0.5818
Epoch [72/100], Loss: 0.2114, Val Loss: 0.6339
Epoch [73/100], Loss: 0.1542, Val Loss: 0.6091
Epoch [74/100], Loss: 0.1736, Val Loss: 0.6134
Epoch [75/100], Loss: 0.3887, Val Loss: 0.5819
Epoch [76/100], Loss: 0.3506, Val Loss: 0.5898
Epoch [77/100], Loss: 0.1537, Val Loss: 0.5970
Epoch [78/100], Loss: 0.3144, Val Loss: 0.5558
Epoch [79/100], Loss: 0.1325, Val Loss: 0.5836
Epoch [80/100], Loss: 0.4771, Val Loss: 0.5590
Epoch [81/100], Loss: 0.1725, Val Loss: 0.6249
Epoch [82/100], Loss: 1.0092, Val Loss: 0.7508
Epoch [83/100], Loss: 0.1874, Val Loss: 0.5858
Epoch [84/100], Loss: 1.5540, Val Loss: 0.5792
Epoch [85/100], Loss: 0.2210, Val Loss: 0.5649
Epoch [86/100], Loss: 0.1184, Val Loss: 0.5927
Epoch [87/100], Loss: 0.2131, Val Loss: 0.6530
Epoch [88/100], Loss: 0.2489, Val Loss: 0.5959
Epoch [89/100], Loss: 0.3242, Val Loss: 0.6647
Epoch [90/100], Loss: 0.1305, Val Loss: 0.5226
Epoch [91/100], Loss: 0.1074, Val Loss: 0.5822
Epoch [92/100], Loss: 0.1305, Val Loss: 0.5623
Epoch [93/100], Loss: 0.3191, Val Loss: 0.5689
Epoch [94/100], Loss: 0.8498, Val Loss: 0.5904
Epoch [95/100], Loss: 0.2143, Val Loss: 0.5518
Epoch [96/100], Loss: 0.1867, Val Loss: 0.5793
Epoch [97/100], Loss: 0.8360, Val Loss: 0.5729
Epoch [98/100], Loss: 0.3852, Val Loss: 0.6216
Epoch [99/100], Loss: 0.2816, Val Loss: 0.5473
Epoch [100/100], Loss: 0.4336, Val Loss: 0.5539
Runtime: 0:02:52.044698
R^2 Score: 0.8759
RMSE: 0.7978
MAE: 0.2297
MAPE: 22.31%
TruncatedSVD_50
MLP with layer size: [128, 64, 32] - Result:
Epoch [1/100], Loss: 0.7387, Val Loss: 0.9946
Epoch [2/100], Loss: 1.8051, Val Loss: 0.8910
Epoch [3/100], Loss: 0.1557, Val Loss: 0.8396
Epoch [4/100], Loss: 0.4474, Val Loss: 0.8400
Epoch [5/100], Loss: 0.1310, Val Loss: 0.8063
Epoch [6/100], Loss: 3.0578, Val Loss: 0.7542
Epoch [7/100], Loss: 0.8720, Val Loss: 0.7790
Epoch [8/100], Loss: 0.3851, Val Loss: 0.8086
Epoch [9/100], Loss: 0.4185, Val Loss: 0.7680
Epoch [10/100], Loss: 0.5160, Val Loss: 0.7862
Epoch [11/100], Loss: 0.1758, Val Loss: 0.8756
Epoch [12/100], Loss: 0.1671, Val Loss: 0.7369
Epoch [13/100], Loss: 0.2648, Val Loss: 0.7752
Epoch [14/100], Loss: 0.1567, Val Loss: 0.7446
Epoch [15/100], Loss: 0.4342, Val Loss: 0.7537
Epoch [16/100], Loss: 0.1589, Val Loss: 0.7996
Epoch [17/100], Loss: 0.2299, Val Loss: 0.7126
Epoch [18/100], Loss: 0.2648, Val Loss: 0.7233
Epoch [19/100], Loss: 0.6384, Val Loss: 0.9160
Epoch [20/100], Loss: 0.3341, Val Loss: 0.7151
Epoch [21/100], Loss: 0.3183, Val Loss: 0.7253
Epoch [22/100], Loss: 2.0368, Val Loss: 0.7379
Epoch [23/100], Loss: 0.9361, Val Loss: 0.8876
Epoch [24/100], Loss: 0.2880, Val Loss: 0.6814
Epoch [25/100], Loss: 0.2453, Val Loss: 0.6900
Epoch [26/100], Loss: 0.2363, Val Loss: 0.6739
Epoch [27/100], Loss: 0.3047, Val Loss: 0.6850
Epoch [28/100], Loss: 0.1931, Val Loss: 0.6768
Epoch [29/100], Loss: 0.2484, Val Loss: 0.6532
Epoch [30/100], Loss: 0.8620, Val Loss: 0.7225
Epoch [31/100], Loss: 0.1416, Val Loss: 0.6604
Epoch [32/100], Loss: 0.0972, Val Loss: 0.7092
Epoch [33/100], Loss: 0.1453, Val Loss: 0.7057
Epoch [34/100], Loss: 0.3624, Val Loss: 0.6852
Epoch [35/100], Loss: 0.1212, Val Loss: 0.7913
Epoch [36/100], Loss: 0.2392, Val Loss: 0.7816
Epoch [37/100], Loss: 0.5667, Val Loss: 0.7100
Epoch [38/100], Loss: 0.5556, Val Loss: 0.6637
Epoch [39/100], Loss: 1.5481, Val Loss: 0.7142
Epoch [40/100], Loss: 7.9214, Val Loss: 0.6454
Epoch [41/100], Loss: 0.2276, Val Loss: 0.6950
Epoch [42/100], Loss: 0.1481, Val Loss: 0.6957
Epoch [43/100], Loss: 0.3095, Val Loss: 0.6570
Epoch [44/100], Loss: 0.2036, Val Loss: 0.6808
Epoch [45/100], Loss: 0.1980, Val Loss: 0.7127
Epoch [46/100], Loss: 0.1805, Val Loss: 0.6396
Epoch [47/100], Loss: 0.6593, Val Loss: 0.6144
Epoch [48/100], Loss: 0.5934, Val Loss: 0.7120
Epoch [49/100], Loss: 0.2213, Val Loss: 0.6636
Epoch [50/100], Loss: 0.2897, Val Loss: 0.6782
Epoch [51/100], Loss: 0.8679, Val Loss: 0.6348
Epoch [52/100], Loss: 0.4674, Val Loss: 0.6905
Epoch [53/100], Loss: 0.2789, Val Loss: 0.6355
Epoch [54/100], Loss: 0.1825, Val Loss: 0.7335
Epoch [55/100], Loss: 0.1367, Val Loss: 0.6453
Epoch [56/100], Loss: 0.1876, Val Loss: 0.6060
Epoch [57/100], Loss: 1.5638, Val Loss: 0.6832
Epoch [58/100], Loss: 0.1651, Val Loss: 0.6154
Epoch [59/100], Loss: 1.9052, Val Loss: 0.6434
Epoch [60/100], Loss: 0.3652, Val Loss: 0.6385
Epoch [61/100], Loss: 0.2183, Val Loss: 0.6968
Epoch [62/100], Loss: 0.2868, Val Loss: 0.6378
Epoch [63/100], Loss: 0.4338, Val Loss: 0.6818
Epoch [64/100], Loss: 0.3119, Val Loss: 0.6117
Epoch [65/100], Loss: 0.1900, Val Loss: 0.6049
Epoch [66/100], Loss: 0.1895, Val Loss: 0.6019
Epoch [67/100], Loss: 0.4176, Val Loss: 0.6444
Epoch [68/100], Loss: 1.8894, Val Loss: 0.5995
Epoch [69/100], Loss: 0.1671, Val Loss: 0.6098
Epoch [70/100], Loss: 0.1116, Val Loss: 0.7050
Epoch [71/100], Loss: 0.1751, Val Loss: 0.6107
Epoch [72/100], Loss: 0.0815, Val Loss: 0.6070
Epoch [73/100], Loss: 1.3230, Val Loss: 0.6583
Epoch [74/100], Loss: 0.2133, Val Loss: 0.6286
Epoch [75/100], Loss: 0.2620, Val Loss: 0.6969
Epoch [76/100], Loss: 1.0130, Val Loss: 0.6146
Epoch [77/100], Loss: 0.4204, Val Loss: 0.5780
Epoch [78/100], Loss: 0.1949, Val Loss: 0.6211
Epoch [79/100], Loss: 1.2375, Val Loss: 0.6278
Epoch [80/100], Loss: 0.3953, Val Loss: 0.5705
Epoch [81/100], Loss: 0.1989, Val Loss: 0.5968
Epoch [82/100], Loss: 0.5379, Val Loss: 0.6259
Epoch [83/100], Loss: 0.6967, Val Loss: 0.5937
Epoch [84/100], Loss: 0.3352, Val Loss: 0.5900
Epoch [85/100], Loss: 2.4669, Val Loss: 0.5780
Epoch [86/100], Loss: 0.4081, Val Loss: 0.6165
Epoch [87/100], Loss: 0.2651, Val Loss: 0.6131
Epoch [88/100], Loss: 0.3477, Val Loss: 0.5938
Epoch [89/100], Loss: 0.3218, Val Loss: 0.5671
Epoch [90/100], Loss: 0.2943, Val Loss: 0.5682
Epoch [91/100], Loss: 0.1665, Val Loss: 0.6349
Epoch [92/100], Loss: 0.1962, Val Loss: 0.5931
Epoch [93/100], Loss: 0.8080, Val Loss: 0.6387
Epoch [94/100], Loss: 0.4947, Val Loss: 0.6115
Epoch [95/100], Loss: 0.2976, Val Loss: 0.5946
Epoch [96/100], Loss: 0.7618, Val Loss: 0.6138
Epoch [97/100], Loss: 0.8720, Val Loss: 0.6193
Epoch [98/100], Loss: 0.7967, Val Loss: 0.5973
Epoch [99/100], Loss: 0.5194, Val Loss: 0.5941
Epoch [100/100], Loss: 0.4447, Val Loss: 0.5551
Runtime: 0:02:52.163302
Optimized hyperparameter at Trial 625 finished with value: 0.44183426088661204 and parameters:             {'weight_decay': 2.1976866367050964e-05, 'batch_size': 32, 'n_units_l1': 36, 'n_units_l2': 46, 'n_units_l3': 22}.            Best is trial 625 with value: 0.44183426088661204.: Suggested LR = 0.005222369451075792
TruncatedSVD_50
MLP with layer size: [36, 46, 22] - Result:
Epoch [1/25], Loss: 0.2205, Val Loss: 1.0658
Epoch [2/25], Loss: 0.4215, Val Loss: 1.1417
Epoch [3/25], Loss: 0.3202, Val Loss: 1.0405
Epoch [4/25], Loss: 0.1874, Val Loss: 1.0900
Epoch [5/25], Loss: 3.8541, Val Loss: 0.9128
Epoch [6/25], Loss: 0.3506, Val Loss: 0.9734
Epoch [7/25], Loss: 0.6239, Val Loss: 0.9182
Epoch [8/25], Loss: 0.2123, Val Loss: 1.0369
Epoch [9/25], Loss: 0.1888, Val Loss: 1.0608
Epoch [10/25], Loss: 0.2761, Val Loss: 1.0963
Epoch [11/25], Loss: 0.9177, Val Loss: 0.9808
Epoch [12/25], Loss: 0.1457, Val Loss: 0.8932
Epoch [13/25], Loss: 0.3612, Val Loss: 0.8538
Epoch [14/25], Loss: 0.1337, Val Loss: 1.0477
Epoch [15/25], Loss: 0.8661, Val Loss: 0.9195
Epoch [16/25], Loss: 0.0832, Val Loss: 0.9119
Epoch [17/25], Loss: 0.9931, Val Loss: 0.9720
Epoch [18/25], Loss: 0.8121, Val Loss: 0.8740
Epoch [19/25], Loss: 0.2757, Val Loss: 0.9008
Epoch [20/25], Loss: 0.1291, Val Loss: 0.9263
Epoch [21/25], Loss: 0.1594, Val Loss: 0.9217
Epoch [22/25], Loss: 2.0047, Val Loss: 0.9328
Epoch [23/25], Loss: 0.1334, Val Loss: 0.7761
Epoch [24/25], Loss: 0.2751, Val Loss: 0.9236
Epoch [25/25], Loss: 0.5753, Val Loss: 0.9588
Runtime: 0:00:38.118138
R^2 Score: 0.8483
RMSE: 0.8081
MAE: 0.2785
MAPE: 25.96%
Optimized hyperparameter at Trial 625 finished with value: 0.44183426088661204 and parameters:             {'weight_decay': 2.1976866367050964e-05, 'batch_size': 32, 'n_units_l1': 36, 'n_units_l2': 46, 'n_units_l3': 22}.            Best is trial 625 with value: 0.44183426088661204.: Suggested LR = 0.005222369451075792
TruncatedSVD_50
MLP with layer size: [36, 46, 22] - Result:
Epoch [1/100], Loss: 0.3730, Val Loss: 0.7784
Epoch [2/100], Loss: 0.1519, Val Loss: 0.8262
Epoch [3/100], Loss: 0.1546, Val Loss: 0.8507
Epoch [4/100], Loss: 0.0450, Val Loss: 0.7740
Epoch [5/100], Loss: 0.1464, Val Loss: 0.8039
Epoch [6/100], Loss: 0.1591, Val Loss: 0.9004
Epoch [7/100], Loss: 0.1731, Val Loss: 1.2797
Epoch [8/100], Loss: 0.2295, Val Loss: 0.8782
Epoch [9/100], Loss: 0.1006, Val Loss: 0.8645
Epoch [10/100], Loss: 0.7788, Val Loss: 0.8571
Epoch [11/100], Loss: 0.2843, Val Loss: 0.7967
Epoch [12/100], Loss: 1.7263, Val Loss: 0.7976
Epoch [13/100], Loss: 0.1117, Val Loss: 0.8770
Epoch [14/100], Loss: 0.1920, Val Loss: 0.8536
Epoch [15/100], Loss: 0.4972, Val Loss: 0.8962
Epoch [16/100], Loss: 1.0469, Val Loss: 1.0163
Epoch [17/100], Loss: 0.4709, Val Loss: 0.8249
Epoch [18/100], Loss: 0.1400, Val Loss: 0.9203
Epoch [19/100], Loss: 0.1580, Val Loss: 0.7867
Epoch [20/100], Loss: 0.3636, Val Loss: 0.7825
Epoch [21/100], Loss: 0.3326, Val Loss: 0.8144
Epoch [22/100], Loss: 0.1022, Val Loss: 0.8736
Epoch [23/100], Loss: 0.1955, Val Loss: 0.8010
Early stopping at epoch 23
Runtime: 0:00:35.986786
R^2 Score: 0.9130
RMSE: 0.6118
MAE: 0.2332
MAPE: 21.42%
Optimized hyperparameter at Trial 625 finished with value: 0.44183426088661204 and parameters:             {'weight_decay': 2.1976866367050964e-05, 'batch_size': 32, 'n_units_l1': 36, 'n_units_l2': 46, 'n_units_l3': 22}.            Best is trial 625 with value: 0.44183426088661204.: Suggested LR = 0.005222369451075792
TruncatedSVD_50
MLP with layer size: [36, 46, 22] - Result:
Epoch [1/100], Loss: 2.7452, Val Loss: 1.3660
Epoch [2/100], Loss: 0.4011, Val Loss: 1.0637
Epoch [3/100], Loss: 0.5688, Val Loss: 1.0441
Epoch [4/100], Loss: 0.1580, Val Loss: 1.0214
Epoch [5/100], Loss: 0.3109, Val Loss: 0.9862
Epoch [6/100], Loss: 1.0040, Val Loss: 1.0703
Epoch [7/100], Loss: 0.1445, Val Loss: 1.0509
Epoch [8/100], Loss: 0.2697, Val Loss: 1.1504
Epoch [9/100], Loss: 0.5331, Val Loss: 0.9490
Epoch [10/100], Loss: 0.4924, Val Loss: 0.9779
Epoch [11/100], Loss: 0.3716, Val Loss: 0.9274
Epoch [12/100], Loss: 0.2030, Val Loss: 0.9747
Epoch [13/100], Loss: 1.4277, Val Loss: 0.8983
Epoch [14/100], Loss: 5.4990, Val Loss: 0.9203
Epoch [15/100], Loss: 0.1472, Val Loss: 0.8503
Epoch [16/100], Loss: 0.6510, Val Loss: 0.8353
Epoch [17/100], Loss: 0.1352, Val Loss: 0.8909
Epoch [18/100], Loss: 0.1722, Val Loss: 0.8463
Epoch [19/100], Loss: 0.1121, Val Loss: 0.8450
Epoch [20/100], Loss: 0.2453, Val Loss: 0.8519
Epoch [21/100], Loss: 0.1154, Val Loss: 0.9047
Epoch [22/100], Loss: 1.5798, Val Loss: 0.8202
Epoch [23/100], Loss: 0.2600, Val Loss: 0.7679
Epoch [24/100], Loss: 0.3759, Val Loss: 0.8779
Epoch [25/100], Loss: 2.8012, Val Loss: 0.7578
Epoch [26/100], Loss: 0.1114, Val Loss: 0.9235
Epoch [27/100], Loss: 0.4219, Val Loss: 0.8509
Epoch [28/100], Loss: 0.1660, Val Loss: 0.8058
Epoch [29/100], Loss: 0.2062, Val Loss: 0.8584
Epoch [30/100], Loss: 0.1341, Val Loss: 0.7169
Epoch [31/100], Loss: 0.3650, Val Loss: 0.8745
Epoch [32/100], Loss: 0.1627, Val Loss: 0.9499
Epoch [33/100], Loss: 0.2456, Val Loss: 0.7953
Epoch [34/100], Loss: 0.4510, Val Loss: 0.8010
Epoch [35/100], Loss: 0.4876, Val Loss: 0.8102
Epoch [36/100], Loss: 0.4356, Val Loss: 0.7469
Epoch [37/100], Loss: 0.1693, Val Loss: 0.7692
Epoch [38/100], Loss: 0.1740, Val Loss: 0.8183
Epoch [39/100], Loss: 0.2359, Val Loss: 0.7713
Epoch [40/100], Loss: 0.1682, Val Loss: 0.8485
Epoch [41/100], Loss: 0.3175, Val Loss: 0.7994
Epoch [42/100], Loss: 1.3200, Val Loss: 0.7373
Epoch [43/100], Loss: 0.0843, Val Loss: 0.7498
Epoch [44/100], Loss: 1.2528, Val Loss: 0.7343
Epoch [45/100], Loss: 0.4396, Val Loss: 0.7765
Epoch [46/100], Loss: 0.7070, Val Loss: 0.7503
Epoch [47/100], Loss: 0.2748, Val Loss: 0.7812
Epoch [48/100], Loss: 1.8705, Val Loss: 0.9479
Epoch [49/100], Loss: 0.1830, Val Loss: 0.8086
Early stopping at epoch 49
Runtime: 0:01:16.946153
R^2 Score: 0.8543
RMSE: 0.7920
MAE: 0.2641
MAPE: 20.42%
Optimized hyperparameter at Trial 625 finished with value: 0.44183426088661204 and parameters:             {'weight_decay': 2.1976866367050964e-05, 'batch_size': 32, 'n_units_l1': 36, 'n_units_l2': 46, 'n_units_l3': 22}.            Best is trial 625 with value: 0.44183426088661204.: Suggested LR = 0.005222369451075792
TruncatedSVD_50
MLP with layer size: [36, 46, 22] - Result:
Epoch [1/100], Loss: 0.2365, Val Loss: 1.4223
Epoch [2/100], Loss: 0.1773, Val Loss: 1.0896
Epoch [3/100], Loss: 0.1532, Val Loss: 0.9570
Epoch [4/100], Loss: 0.1032, Val Loss: 0.9756
Epoch [5/100], Loss: 0.7450, Val Loss: 0.9719
Epoch [6/100], Loss: 0.1817, Val Loss: 1.0016
Epoch [7/100], Loss: 0.3407, Val Loss: 1.0367
Epoch [8/100], Loss: 0.3739, Val Loss: 0.9313
Epoch [9/100], Loss: 0.2212, Val Loss: 0.9497
Epoch [10/100], Loss: 0.2116, Val Loss: 1.1580
Epoch [11/100], Loss: 0.1846, Val Loss: 0.9236
Epoch [12/100], Loss: 0.1136, Val Loss: 1.2611
Epoch [13/100], Loss: 0.1876, Val Loss: 0.8791
Epoch [14/100], Loss: 0.5716, Val Loss: 0.7684
Epoch [15/100], Loss: 0.2097, Val Loss: 0.9619
Epoch [16/100], Loss: 0.1557, Val Loss: 0.8336
Epoch [17/100], Loss: 0.3800, Val Loss: 0.9270
Epoch [18/100], Loss: 0.4659, Val Loss: 0.9066
Epoch [19/100], Loss: 0.2882, Val Loss: 0.8821
Epoch [20/100], Loss: 0.1967, Val Loss: 0.9735
Epoch [21/100], Loss: 0.1796, Val Loss: 0.9527
Epoch [22/100], Loss: 0.2238, Val Loss: 0.7785
Epoch [23/100], Loss: 0.5728, Val Loss: 1.0402
Epoch [24/100], Loss: 0.2410, Val Loss: 0.8584
Epoch [25/100], Loss: 0.2630, Val Loss: 0.8486
Epoch [26/100], Loss: 0.2532, Val Loss: 0.8580
Epoch [27/100], Loss: 0.2470, Val Loss: 0.9100
Epoch [28/100], Loss: 0.6115, Val Loss: 0.8483
Epoch [29/100], Loss: 0.1542, Val Loss: 0.9165
Epoch [30/100], Loss: 0.4712, Val Loss: 0.8790
Epoch [31/100], Loss: 0.1247, Val Loss: 0.9700
Epoch [32/100], Loss: 1.4112, Val Loss: 0.8454
Epoch [33/100], Loss: 0.1578, Val Loss: 0.8806
Epoch [34/100], Loss: 0.0932, Val Loss: 0.8930
Epoch [35/100], Loss: 1.1746, Val Loss: 1.0234
Epoch [36/100], Loss: 0.5151, Val Loss: 0.8656
Epoch [37/100], Loss: 0.1385, Val Loss: 0.8494
Epoch [38/100], Loss: 0.0992, Val Loss: 0.8275
Epoch [39/100], Loss: 1.5886, Val Loss: 0.8547
Epoch [40/100], Loss: 0.3854, Val Loss: 0.9160
Epoch [41/100], Loss: 0.2741, Val Loss: 0.8895
Epoch [42/100], Loss: 0.2711, Val Loss: 0.8878
Epoch [43/100], Loss: 0.2501, Val Loss: 0.8235
Epoch [44/100], Loss: 0.2232, Val Loss: 0.8898
Epoch [45/100], Loss: 0.1652, Val Loss: 0.9128
Epoch [46/100], Loss: 0.1614, Val Loss: 0.8594
Epoch [47/100], Loss: 0.2664, Val Loss: 0.9024
Epoch [48/100], Loss: 0.4264, Val Loss: 0.9034
Epoch [49/100], Loss: 0.3420, Val Loss: 0.8645
Epoch [50/100], Loss: 0.2557, Val Loss: 0.8882
Epoch [51/100], Loss: 0.3493, Val Loss: 0.8845
Epoch [52/100], Loss: 0.1188, Val Loss: 0.9110
Epoch [53/100], Loss: 0.1581, Val Loss: 0.8555
Early stopping at epoch 53
Runtime: 0:01:20.271321
R^2 Score: 0.9313
RMSE: 0.5437
MAE: 0.2110
MAPE: 19.39%
Optimized hyperparameter at Trial 625 finished with value: 0.44183426088661204 and parameters:             {'weight_decay': 2.1976866367050964e-05, 'batch_size': 32, 'n_units_l1': 36, 'n_units_l2': 46, 'n_units_l3': 22}.            Best is trial 625 with value: 0.44183426088661204.: Suggested LR = 0.005222369451075792
TruncatedSVD_50
MLP with layer size: [36, 46, 22] - Result:
Epoch [1/100], Loss: 0.7340, Val Loss: 0.9562
Epoch [2/100], Loss: 0.3900, Val Loss: 0.8136
Epoch [3/100], Loss: 0.3887, Val Loss: 0.9263
Epoch [4/100], Loss: 1.5523, Val Loss: 0.8585
Epoch [5/100], Loss: 0.1272, Val Loss: 0.9161
Epoch [6/100], Loss: 0.2233, Val Loss: 0.7791
Epoch [7/100], Loss: 0.3018, Val Loss: 0.8324
Epoch [8/100], Loss: 0.6202, Val Loss: 1.0902
Epoch [9/100], Loss: 0.2779, Val Loss: 0.7102
Epoch [10/100], Loss: 0.3123, Val Loss: 0.7610
Epoch [11/100], Loss: 0.2451, Val Loss: 0.7345
Epoch [12/100], Loss: 2.8011, Val Loss: 0.8013
Epoch [13/100], Loss: 0.3737, Val Loss: 0.7085
Epoch [14/100], Loss: 0.9714, Val Loss: 0.6927
Epoch [15/100], Loss: 1.0465, Val Loss: 1.3158
Epoch [16/100], Loss: 0.4401, Val Loss: 0.7384
Epoch [17/100], Loss: 0.6827, Val Loss: 0.6948
Epoch [18/100], Loss: 0.1997, Val Loss: 0.7073
Epoch [19/100], Loss: 0.1863, Val Loss: 0.6842
Epoch [20/100], Loss: 0.8135, Val Loss: 0.6734
Epoch [21/100], Loss: 0.2770, Val Loss: 0.6691
Epoch [22/100], Loss: 0.2966, Val Loss: 0.7217
Epoch [23/100], Loss: 0.1688, Val Loss: 0.6537
Epoch [24/100], Loss: 0.2386, Val Loss: 0.7871
Epoch [25/100], Loss: 0.3222, Val Loss: 0.6369
Epoch [26/100], Loss: 0.1957, Val Loss: 0.7342
Epoch [27/100], Loss: 0.3986, Val Loss: 0.6923
Epoch [28/100], Loss: 0.1815, Val Loss: 0.8242
Epoch [29/100], Loss: 0.4455, Val Loss: 0.6540
Epoch [30/100], Loss: 0.4427, Val Loss: 0.6963
Epoch [31/100], Loss: 0.0890, Val Loss: 0.5768
Epoch [32/100], Loss: 0.1053, Val Loss: 0.6554
Epoch [33/100], Loss: 0.3008, Val Loss: 0.6544
Epoch [34/100], Loss: 0.1762, Val Loss: 0.6362
Epoch [35/100], Loss: 0.3391, Val Loss: 0.6979
Epoch [36/100], Loss: 0.2309, Val Loss: 0.5977
Epoch [37/100], Loss: 0.0679, Val Loss: 0.6935
Epoch [38/100], Loss: 0.2448, Val Loss: 0.6903
Epoch [39/100], Loss: 0.1065, Val Loss: 0.6029
Epoch [40/100], Loss: 0.0874, Val Loss: 0.6053
Epoch [41/100], Loss: 0.5428, Val Loss: 0.7264
Epoch [42/100], Loss: 0.1798, Val Loss: 0.6440
Epoch [43/100], Loss: 0.1998, Val Loss: 0.6082
Epoch [44/100], Loss: 0.0894, Val Loss: 0.6536
Epoch [45/100], Loss: 0.1317, Val Loss: 0.5776
Epoch [46/100], Loss: 0.1190, Val Loss: 0.7489
Epoch [47/100], Loss: 0.3533, Val Loss: 0.6249
Epoch [48/100], Loss: 0.7438, Val Loss: 0.6459
Epoch [49/100], Loss: 0.2745, Val Loss: 0.6229
Epoch [50/100], Loss: 0.2664, Val Loss: 0.6837
Epoch [51/100], Loss: 0.0711, Val Loss: 0.6651
Epoch [52/100], Loss: 0.1084, Val Loss: 0.6321
Epoch [53/100], Loss: 0.1755, Val Loss: 0.6258
Epoch [54/100], Loss: 0.4366, Val Loss: 0.6361
Epoch [55/100], Loss: 1.4823, Val Loss: 0.6824
Epoch [56/100], Loss: 0.4671, Val Loss: 0.5874
Epoch [57/100], Loss: 0.5509, Val Loss: 0.6041
Epoch [58/100], Loss: 0.3677, Val Loss: 0.6525
Epoch [59/100], Loss: 0.1350, Val Loss: 0.6186
Epoch [60/100], Loss: 0.2032, Val Loss: 0.6447
Epoch [61/100], Loss: 0.1487, Val Loss: 0.6160
Epoch [62/100], Loss: 0.1062, Val Loss: 0.6055
Epoch [63/100], Loss: 0.1249, Val Loss: 0.6301
Epoch [64/100], Loss: 0.3615, Val Loss: 0.5929
Epoch [65/100], Loss: 0.1709, Val Loss: 0.6059
Epoch [66/100], Loss: 0.2009, Val Loss: 0.6840
Epoch [67/100], Loss: 0.8618, Val Loss: 0.5734
Epoch [68/100], Loss: 0.1066, Val Loss: 0.6168
Epoch [69/100], Loss: 0.9761, Val Loss: 0.6846
Epoch [70/100], Loss: 0.4206, Val Loss: 0.6102
Epoch [71/100], Loss: 0.0489, Val Loss: 0.6098
Epoch [72/100], Loss: 1.2786, Val Loss: 0.5964
Epoch [73/100], Loss: 0.1474, Val Loss: 0.5806
Epoch [74/100], Loss: 0.3105, Val Loss: 0.6668
Epoch [75/100], Loss: 0.3135, Val Loss: 0.5807
Epoch [76/100], Loss: 0.2085, Val Loss: 0.5930
Epoch [77/100], Loss: 0.0869, Val Loss: 0.5812
Epoch [78/100], Loss: 0.1141, Val Loss: 0.6558
Epoch [79/100], Loss: 0.2436, Val Loss: 0.5964
Epoch [80/100], Loss: 0.2729, Val Loss: 0.6209
Epoch [81/100], Loss: 0.0583, Val Loss: 0.6037
Epoch [82/100], Loss: 0.2994, Val Loss: 0.5869
Epoch [83/100], Loss: 0.1998, Val Loss: 0.5810
Epoch [84/100], Loss: 0.0952, Val Loss: 0.5804
Epoch [85/100], Loss: 0.0738, Val Loss: 0.5602
Epoch [86/100], Loss: 0.4497, Val Loss: 0.6413
Epoch [87/100], Loss: 0.1447, Val Loss: 0.5781
Epoch [88/100], Loss: 0.1170, Val Loss: 0.6591
Epoch [89/100], Loss: 1.1554, Val Loss: 0.6060
Epoch [90/100], Loss: 0.3337, Val Loss: 0.6351
Epoch [91/100], Loss: 0.1270, Val Loss: 0.5576
Epoch [92/100], Loss: 0.8543, Val Loss: 0.5653
Epoch [93/100], Loss: 0.1372, Val Loss: 0.6059
Epoch [94/100], Loss: 0.1161, Val Loss: 0.5516
Epoch [95/100], Loss: 0.6038, Val Loss: 0.5646
Epoch [96/100], Loss: 0.2870, Val Loss: 0.5749
Epoch [97/100], Loss: 0.0920, Val Loss: 0.5951
Epoch [98/100], Loss: 0.0868, Val Loss: 0.5927
Epoch [99/100], Loss: 0.3441, Val Loss: 0.6087
Epoch [100/100], Loss: 0.1482, Val Loss: 0.5963
Runtime: 0:02:33.251914
R^2 Score: 0.8367
RMSE: 0.9151
MAE: 0.2331
MAPE: 20.93%
Optimized hyperparameter at Trial 625 finished with value: 0.44183426088661204 and parameters:             {'weight_decay': 2.1976866367050964e-05, 'batch_size': 32, 'n_units_l1': 36, 'n_units_l2': 46, 'n_units_l3': 22}.            Best is trial 625 with value: 0.44183426088661204.: Suggested LR = 0.005222369451075792
TruncatedSVD_50
MLP with layer size: [36, 46, 22] - Result:
Epoch [1/100], Loss: 0.1262, Val Loss: 0.5811
Epoch [2/100], Loss: 0.1059, Val Loss: 0.5524
Epoch [3/100], Loss: 0.1162, Val Loss: 0.5558
Epoch [4/100], Loss: 0.1912, Val Loss: 0.6176
Epoch [5/100], Loss: 0.1066, Val Loss: 0.5590
Epoch [6/100], Loss: 0.6282, Val Loss: 0.8331
Epoch [7/100], Loss: 0.6031, Val Loss: 0.6557
Epoch [8/100], Loss: 0.0629, Val Loss: 0.6176
Epoch [9/100], Loss: 0.3738, Val Loss: 0.5593
Epoch [10/100], Loss: 0.0791, Val Loss: 0.6515
Epoch [11/100], Loss: 0.2632, Val Loss: 0.5778
Epoch [12/100], Loss: 0.1055, Val Loss: 0.6239
Epoch [13/100], Loss: 0.0757, Val Loss: 0.6017
Epoch [14/100], Loss: 0.2246, Val Loss: 0.6343
Epoch [15/100], Loss: 0.1479, Val Loss: 0.5794
Epoch [16/100], Loss: 0.1701, Val Loss: 0.5450
Epoch [17/100], Loss: 0.3537, Val Loss: 0.6144
Epoch [18/100], Loss: 0.1338, Val Loss: 0.6002
Epoch [19/100], Loss: 0.2253, Val Loss: 0.6276
Epoch [20/100], Loss: 0.1637, Val Loss: 0.5793
Epoch [21/100], Loss: 0.4622, Val Loss: 0.6494
Epoch [22/100], Loss: 0.1212, Val Loss: 0.6395
Epoch [23/100], Loss: 0.4323, Val Loss: 0.6413
Epoch [24/100], Loss: 0.2799, Val Loss: 0.5790
Epoch [25/100], Loss: 0.1713, Val Loss: 0.6043
Epoch [26/100], Loss: 0.1568, Val Loss: 0.5779
Epoch [27/100], Loss: 0.0250, Val Loss: 0.6441
Epoch [28/100], Loss: 0.3770, Val Loss: 0.5876
Epoch [29/100], Loss: 0.1625, Val Loss: 0.5756
Epoch [30/100], Loss: 0.0844, Val Loss: 0.6055
Epoch [31/100], Loss: 0.7564, Val Loss: 0.6636
Epoch [32/100], Loss: 0.1215, Val Loss: 0.5772
Epoch [33/100], Loss: 0.1843, Val Loss: 0.5850
Epoch [34/100], Loss: 0.2750, Val Loss: 0.5776
Epoch [35/100], Loss: 0.1174, Val Loss: 0.5715
Early stopping at epoch 35
Runtime: 0:00:55.632297
R^2 Score: 0.8573
RMSE: 0.8553
MAE: 0.2297
MAPE: 20.73%
Optimized hyperparameter at Trial 625 finished with value: 0.44183426088661204 and parameters:             {'weight_decay': 2.1976866367050964e-05, 'batch_size': 32, 'n_units_l1': 36, 'n_units_l2': 46, 'n_units_l3': 22}.            Best is trial 625 with value: 0.44183426088661204.: Suggested LR = 0.005222369451075792
TruncatedSVD_50
MLP with layer size: [36, 46, 22] - Result:
Epoch [1/100], Loss: 0.1408, Val Loss: 1.2084
Epoch [2/100], Loss: 1.2051, Val Loss: 1.2150
Epoch [3/100], Loss: 0.4057, Val Loss: 1.0018
Epoch [4/100], Loss: 0.8875, Val Loss: 1.0068
Epoch [5/100], Loss: 1.8122, Val Loss: 0.9086
Epoch [6/100], Loss: 0.3465, Val Loss: 0.9406
Epoch [7/100], Loss: 0.4979, Val Loss: 1.0724
Epoch [8/100], Loss: 0.2181, Val Loss: 1.0341
Epoch [9/100], Loss: 0.1160, Val Loss: 0.9588
Epoch [10/100], Loss: 0.2189, Val Loss: 0.9563
Epoch [11/100], Loss: 0.2302, Val Loss: 0.9869
Epoch [12/100], Loss: 0.5563, Val Loss: 0.9238
Epoch [13/100], Loss: 0.2626, Val Loss: 0.9544
Epoch [14/100], Loss: 0.1192, Val Loss: 0.8919
Epoch [15/100], Loss: 0.1334, Val Loss: 0.8951
Epoch [16/100], Loss: 0.1536, Val Loss: 0.9231
Epoch [17/100], Loss: 0.1288, Val Loss: 0.8611
Epoch [18/100], Loss: 0.0849, Val Loss: 0.8027
Epoch [19/100], Loss: 0.0803, Val Loss: 0.9157
Epoch [20/100], Loss: 0.5705, Val Loss: 0.8602
Epoch [21/100], Loss: 0.5814, Val Loss: 0.8787
Epoch [22/100], Loss: 0.8913, Val Loss: 0.8502
Epoch [23/100], Loss: 0.0975, Val Loss: 0.9468
Epoch [24/100], Loss: 0.5848, Val Loss: 0.9362
Epoch [25/100], Loss: 0.3040, Val Loss: 0.8585
Epoch [26/100], Loss: 0.1118, Val Loss: 0.8758
Epoch [27/100], Loss: 0.2798, Val Loss: 0.8196
Epoch [28/100], Loss: 0.1846, Val Loss: 0.8206
Epoch [29/100], Loss: 0.2852, Val Loss: 0.8225
Epoch [30/100], Loss: 0.0884, Val Loss: 0.7889
Epoch [31/100], Loss: 0.5348, Val Loss: 0.8423
Epoch [32/100], Loss: 0.0803, Val Loss: 0.7827
Epoch [33/100], Loss: 0.2014, Val Loss: 0.8354
Epoch [34/100], Loss: 0.1822, Val Loss: 0.8142
Epoch [35/100], Loss: 0.2938, Val Loss: 0.7508
Epoch [36/100], Loss: 0.2632, Val Loss: 0.7731
Epoch [37/100], Loss: 0.1751, Val Loss: 0.7713
Epoch [38/100], Loss: 0.3869, Val Loss: 0.9262
Epoch [39/100], Loss: 0.4407, Val Loss: 0.7711
Epoch [40/100], Loss: 0.7685, Val Loss: 0.8611
Epoch [41/100], Loss: 0.1337, Val Loss: 0.7526
Epoch [42/100], Loss: 0.1004, Val Loss: 1.0561
Epoch [43/100], Loss: 0.1269, Val Loss: 0.7787
Epoch [44/100], Loss: 1.1442, Val Loss: 0.8008
Epoch [45/100], Loss: 0.9041, Val Loss: 0.7473
Epoch [46/100], Loss: 0.2171, Val Loss: 0.8783
Epoch [47/100], Loss: 0.1180, Val Loss: 0.8583
Epoch [48/100], Loss: 0.0965, Val Loss: 0.8361
Epoch [49/100], Loss: 0.2959, Val Loss: 0.7931
Epoch [50/100], Loss: 0.2230, Val Loss: 0.8091
Epoch [51/100], Loss: 0.1327, Val Loss: 0.7783
Epoch [52/100], Loss: 0.1721, Val Loss: 0.8510
Epoch [53/100], Loss: 0.1360, Val Loss: 0.7681
Epoch [54/100], Loss: 0.5876, Val Loss: 0.8644
Epoch [55/100], Loss: 0.1833, Val Loss: 0.7403
Epoch [56/100], Loss: 0.3263, Val Loss: 0.7555
Epoch [57/100], Loss: 0.1181, Val Loss: 0.8173
Epoch [58/100], Loss: 0.1459, Val Loss: 0.8296
Epoch [59/100], Loss: 0.1278, Val Loss: 0.8468
Epoch [60/100], Loss: 0.1551, Val Loss: 0.7687
Epoch [61/100], Loss: 0.1830, Val Loss: 0.8293
Epoch [62/100], Loss: 0.3374, Val Loss: 0.8903
Epoch [63/100], Loss: 0.3974, Val Loss: 0.7565
Epoch [64/100], Loss: 0.1954, Val Loss: 0.7375
Epoch [65/100], Loss: 0.3496, Val Loss: 0.7902
Epoch [66/100], Loss: 0.6640, Val Loss: 0.7756
Epoch [67/100], Loss: 0.1546, Val Loss: 0.7918
Epoch [68/100], Loss: 0.3271, Val Loss: 0.7473
Epoch [69/100], Loss: 0.2485, Val Loss: 0.7222
Epoch [70/100], Loss: 0.2912, Val Loss: 0.7714
Epoch [71/100], Loss: 0.2463, Val Loss: 0.7600
Epoch [72/100], Loss: 0.3367, Val Loss: 0.7576
Epoch [73/100], Loss: 0.1275, Val Loss: 0.7729
Epoch [74/100], Loss: 0.3697, Val Loss: 0.8425
Epoch [75/100], Loss: 0.3216, Val Loss: 0.7073
Epoch [76/100], Loss: 0.3449, Val Loss: 0.7415
Epoch [77/100], Loss: 0.3244, Val Loss: 0.8160
Epoch [78/100], Loss: 0.1837, Val Loss: 0.7744
Epoch [79/100], Loss: 0.3127, Val Loss: 0.7335
Epoch [80/100], Loss: 0.0974, Val Loss: 0.8382
Epoch [81/100], Loss: 0.1220, Val Loss: 0.7127
Epoch [82/100], Loss: 0.3595, Val Loss: 0.8209
Epoch [83/100], Loss: 0.2303, Val Loss: 0.7788
Epoch [84/100], Loss: 0.6907, Val Loss: 0.9458
Epoch [85/100], Loss: 0.2628, Val Loss: 0.7608
Epoch [86/100], Loss: 0.3253, Val Loss: 0.8058
Epoch [87/100], Loss: 0.1295, Val Loss: 0.7856
Epoch [88/100], Loss: 0.4065, Val Loss: 0.8161
Epoch [89/100], Loss: 0.0668, Val Loss: 0.8497
Epoch [90/100], Loss: 0.3272, Val Loss: 0.8086
Epoch [91/100], Loss: 0.8862, Val Loss: 0.8107
Epoch [92/100], Loss: 0.7974, Val Loss: 0.8279
Epoch [93/100], Loss: 0.2542, Val Loss: 0.8168
Epoch [94/100], Loss: 0.1318, Val Loss: 0.7606
Early stopping at epoch 94
Runtime: 0:02:19.555405
R^2 Score: 0.8974
RMSE: 0.6643
MAE: 0.2319
MAPE: 23.01%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/100], Loss: 0.4167, Val Loss: 0.9047
Epoch [2/100], Loss: 0.2119, Val Loss: 1.1051
Epoch [3/100], Loss: 0.1045, Val Loss: 0.8556
Epoch [4/100], Loss: 0.2352, Val Loss: 0.9401
Epoch [5/100], Loss: 0.4313, Val Loss: 0.8588
Epoch [6/100], Loss: 0.2528, Val Loss: 0.7175
Epoch [7/100], Loss: 0.1128, Val Loss: 0.8139
Epoch [8/100], Loss: 0.2116, Val Loss: 0.6641
Epoch [9/100], Loss: 0.1678, Val Loss: 0.7227
Epoch [10/100], Loss: 0.1570, Val Loss: 0.6754
Epoch [11/100], Loss: 0.2881, Val Loss: 0.6446
Epoch [12/100], Loss: 0.2023, Val Loss: 0.6488
Epoch [13/100], Loss: 0.1599, Val Loss: 0.6526
Epoch [14/100], Loss: 0.1655, Val Loss: 0.6470
Epoch [15/100], Loss: 0.2248, Val Loss: 0.6255
Epoch [16/100], Loss: 0.6631, Val Loss: 0.6080
Epoch [17/100], Loss: 0.6412, Val Loss: 0.6209
Epoch [18/100], Loss: 0.2591, Val Loss: 0.6333
Epoch [19/100], Loss: 0.0698, Val Loss: 0.5775
Epoch [20/100], Loss: 0.0990, Val Loss: 0.6031
Epoch [21/100], Loss: 0.1900, Val Loss: 0.5931
Epoch [22/100], Loss: 0.1172, Val Loss: 0.5326
Epoch [23/100], Loss: 0.2322, Val Loss: 0.5174
Epoch [24/100], Loss: 0.1291, Val Loss: 0.5810
Epoch [25/100], Loss: 0.1557, Val Loss: 0.5466
Epoch [26/100], Loss: 0.3838, Val Loss: 0.5437
Epoch [27/100], Loss: 0.0899, Val Loss: 0.5167
Epoch [28/100], Loss: 1.0545, Val Loss: 0.4898
Epoch [29/100], Loss: 0.3328, Val Loss: 0.5577
Epoch [30/100], Loss: 0.0595, Val Loss: 0.6586
Epoch [31/100], Loss: 2.3492, Val Loss: 0.5097
Epoch [32/100], Loss: 0.2919, Val Loss: 0.7105
Epoch [33/100], Loss: 0.2493, Val Loss: 0.5954
Epoch [34/100], Loss: 0.0872, Val Loss: 0.5106
Epoch [35/100], Loss: 1.9488, Val Loss: 0.6007
Epoch [36/100], Loss: 0.1356, Val Loss: 0.5042
Epoch [37/100], Loss: 0.4920, Val Loss: 0.5644
Epoch [38/100], Loss: 0.1655, Val Loss: 0.5158
Epoch [39/100], Loss: 1.6469, Val Loss: 0.6361
Epoch [40/100], Loss: 0.1487, Val Loss: 0.5422
Epoch [41/100], Loss: 0.1730, Val Loss: 0.5169
Epoch [42/100], Loss: 0.1265, Val Loss: 0.5149
Epoch [43/100], Loss: 0.1574, Val Loss: 0.5640
Epoch [44/100], Loss: 0.1537, Val Loss: 0.6143
Epoch [45/100], Loss: 0.0509, Val Loss: 0.4836
Epoch [46/100], Loss: 0.0671, Val Loss: 0.5739
Epoch [47/100], Loss: 0.1645, Val Loss: 0.5189
Epoch [48/100], Loss: 0.0968, Val Loss: 0.5667
Epoch [49/100], Loss: 0.0528, Val Loss: 0.5523
Epoch [50/100], Loss: 0.1250, Val Loss: 0.5787
Epoch [51/100], Loss: 0.2187, Val Loss: 0.5300
Epoch [52/100], Loss: 0.4239, Val Loss: 0.4893
Epoch [53/100], Loss: 0.2410, Val Loss: 0.4726
Epoch [54/100], Loss: 0.1132, Val Loss: 0.5316
Epoch [55/100], Loss: 0.3577, Val Loss: 0.5321
Epoch [56/100], Loss: 0.0809, Val Loss: 0.4799
Epoch [57/100], Loss: 0.2592, Val Loss: 0.4947
Epoch [58/100], Loss: 0.1065, Val Loss: 0.5387
Epoch [59/100], Loss: 0.2188, Val Loss: 0.5328
Epoch [60/100], Loss: 0.1254, Val Loss: 0.4764
Epoch [61/100], Loss: 0.1675, Val Loss: 0.4916
Epoch [62/100], Loss: 0.2965, Val Loss: 0.4873
Epoch [63/100], Loss: 0.1827, Val Loss: 0.5151
Epoch [64/100], Loss: 0.1742, Val Loss: 0.5062
Epoch [65/100], Loss: 0.0380, Val Loss: 0.4694
Epoch [66/100], Loss: 0.1960, Val Loss: 0.5302
Epoch [67/100], Loss: 0.0897, Val Loss: 0.5486
Epoch [68/100], Loss: 0.0736, Val Loss: 0.4611
Epoch [69/100], Loss: 0.1832, Val Loss: 0.4668
Epoch [70/100], Loss: 0.3973, Val Loss: 0.4818
Epoch [71/100], Loss: 0.1229, Val Loss: 0.4933
Epoch [72/100], Loss: 0.1474, Val Loss: 0.4540
Epoch [73/100], Loss: 0.2196, Val Loss: 0.5301
Epoch [74/100], Loss: 0.4027, Val Loss: 0.4667
Epoch [75/100], Loss: 0.1596, Val Loss: 0.4741
Epoch [76/100], Loss: 0.4852, Val Loss: 0.4923
Epoch [77/100], Loss: 0.2999, Val Loss: 0.4895
Epoch [78/100], Loss: 0.0551, Val Loss: 0.5356
Epoch [79/100], Loss: 0.0785, Val Loss: 0.4499
Epoch [80/100], Loss: 0.0669, Val Loss: 0.4765
Epoch [81/100], Loss: 0.2984, Val Loss: 0.5519
Epoch [82/100], Loss: 0.0463, Val Loss: 0.4922
Epoch [83/100], Loss: 0.2505, Val Loss: 0.5360
Epoch [84/100], Loss: 0.0751, Val Loss: 0.5159
Epoch [85/100], Loss: 0.0883, Val Loss: 0.4721
Epoch [86/100], Loss: 0.2457, Val Loss: 0.4967
Epoch [87/100], Loss: 0.2758, Val Loss: 0.4415
Epoch [88/100], Loss: 0.2805, Val Loss: 0.4556
Epoch [89/100], Loss: 0.0479, Val Loss: 0.5119
Epoch [90/100], Loss: 0.2152, Val Loss: 0.4443
Epoch [91/100], Loss: 0.3216, Val Loss: 0.4496
Epoch [92/100], Loss: 0.1297, Val Loss: 0.4637
Epoch [93/100], Loss: 0.0936, Val Loss: 0.4409
Epoch [94/100], Loss: 0.2909, Val Loss: 0.5307
Epoch [95/100], Loss: 0.2456, Val Loss: 0.4897
Epoch [96/100], Loss: 0.3678, Val Loss: 0.4834
Epoch [97/100], Loss: 0.2709, Val Loss: 0.4602
Epoch [98/100], Loss: 0.2161, Val Loss: 0.4436
Epoch [99/100], Loss: 0.0738, Val Loss: 0.6268
Epoch [100/100], Loss: 0.2146, Val Loss: 0.5121
Runtime: 0:00:44.771226
R^2 Score: 0.8970
RMSE: 0.6286
MAE: 0.2069
MAPE: 17.08%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/100], Loss: 0.3308, Val Loss: 1.0487
Epoch [2/100], Loss: 0.2280, Val Loss: 0.8497
Epoch [3/100], Loss: 2.7642, Val Loss: 0.8636
Epoch [4/100], Loss: 0.0702, Val Loss: 0.7576
Epoch [5/100], Loss: 0.3075, Val Loss: 0.7002
Epoch [6/100], Loss: 0.0777, Val Loss: 0.7689
Epoch [7/100], Loss: 0.6741, Val Loss: 0.7128
Epoch [8/100], Loss: 0.4273, Val Loss: 0.7146
Epoch [9/100], Loss: 0.1641, Val Loss: 0.7673
Epoch [10/100], Loss: 0.7985, Val Loss: 0.7690
Epoch [11/100], Loss: 0.0841, Val Loss: 0.7409
Epoch [12/100], Loss: 0.3084, Val Loss: 0.6598
Epoch [13/100], Loss: 0.3664, Val Loss: 0.6093
Epoch [14/100], Loss: 0.6072, Val Loss: 0.6256
Epoch [15/100], Loss: 0.2743, Val Loss: 0.6595
Epoch [16/100], Loss: 0.3126, Val Loss: 0.6189
Epoch [17/100], Loss: 0.7010, Val Loss: 0.6358
Epoch [18/100], Loss: 0.2177, Val Loss: 0.7080
Epoch [19/100], Loss: 0.2379, Val Loss: 0.6767
Epoch [20/100], Loss: 0.1254, Val Loss: 0.6252
Epoch [21/100], Loss: 0.7124, Val Loss: 0.5535
Epoch [22/100], Loss: 0.1662, Val Loss: 0.6718
Epoch [23/100], Loss: 0.3902, Val Loss: 0.8809
Epoch [24/100], Loss: 0.1169, Val Loss: 0.6883
Epoch [25/100], Loss: 0.9244, Val Loss: 0.6218
Epoch [26/100], Loss: 0.0646, Val Loss: 0.5729
Epoch [27/100], Loss: 0.3219, Val Loss: 0.5642
Epoch [28/100], Loss: 0.0952, Val Loss: 0.6154
Epoch [29/100], Loss: 0.7309, Val Loss: 0.5905
Epoch [30/100], Loss: 0.1204, Val Loss: 0.5838
Epoch [31/100], Loss: 0.6136, Val Loss: 0.6161
Epoch [32/100], Loss: 0.2452, Val Loss: 0.7689
Epoch [33/100], Loss: 1.5424, Val Loss: 0.5453
Epoch [34/100], Loss: 0.4454, Val Loss: 0.6426
Epoch [35/100], Loss: 0.2219, Val Loss: 0.6114
Epoch [36/100], Loss: 0.5710, Val Loss: 0.5832
Epoch [37/100], Loss: 0.1190, Val Loss: 0.6566
Epoch [38/100], Loss: 0.0617, Val Loss: 0.6097
Epoch [39/100], Loss: 0.0997, Val Loss: 0.6807
Epoch [40/100], Loss: 0.2795, Val Loss: 0.5427
Epoch [41/100], Loss: 0.0833, Val Loss: 0.5871
Epoch [42/100], Loss: 1.6988, Val Loss: 0.6198
Epoch [43/100], Loss: 0.6062, Val Loss: 0.5390
Epoch [44/100], Loss: 0.5074, Val Loss: 0.5756
Epoch [45/100], Loss: 0.7622, Val Loss: 0.5113
Epoch [46/100], Loss: 0.2156, Val Loss: 0.5120
Epoch [47/100], Loss: 0.5916, Val Loss: 0.5871
Epoch [48/100], Loss: 0.2160, Val Loss: 0.5326
Epoch [49/100], Loss: 0.0624, Val Loss: 0.5130
Epoch [50/100], Loss: 0.0833, Val Loss: 0.6112
Epoch [51/100], Loss: 0.7209, Val Loss: 0.5540
Epoch [52/100], Loss: 0.2857, Val Loss: 0.5236
Epoch [53/100], Loss: 0.0799, Val Loss: 0.5357
Epoch [54/100], Loss: 0.2320, Val Loss: 0.5580
Epoch [55/100], Loss: 0.1995, Val Loss: 0.5635
Epoch [56/100], Loss: 0.6798, Val Loss: 0.5179
Epoch [57/100], Loss: 0.3123, Val Loss: 0.5775
Epoch [58/100], Loss: 0.0796, Val Loss: 0.5067
Epoch [59/100], Loss: 0.3911, Val Loss: 0.6064
Epoch [60/100], Loss: 0.1721, Val Loss: 0.5719
Epoch [61/100], Loss: 0.3033, Val Loss: 0.6641
Epoch [62/100], Loss: 0.1708, Val Loss: 0.5165
Epoch [63/100], Loss: 0.2236, Val Loss: 0.5422
Epoch [64/100], Loss: 0.0666, Val Loss: 0.5396
Epoch [65/100], Loss: 0.0694, Val Loss: 0.5946
Epoch [66/100], Loss: 0.1497, Val Loss: 0.5230
Epoch [67/100], Loss: 0.6624, Val Loss: 0.5887
Epoch [68/100], Loss: 0.1545, Val Loss: 0.5765
Epoch [69/100], Loss: 0.2811, Val Loss: 0.5494
Epoch [70/100], Loss: 0.1297, Val Loss: 0.5841
Epoch [71/100], Loss: 1.6604, Val Loss: 0.6341
Epoch [72/100], Loss: 0.1522, Val Loss: 0.5869
Epoch [73/100], Loss: 0.0550, Val Loss: 0.5481
Epoch [74/100], Loss: 0.1416, Val Loss: 0.5209
Epoch [75/100], Loss: 0.2198, Val Loss: 0.5392
Epoch [76/100], Loss: 0.0934, Val Loss: 0.5249
Epoch [77/100], Loss: 0.3132, Val Loss: 0.4983
Epoch [78/100], Loss: 0.3762, Val Loss: 0.5091
Epoch [79/100], Loss: 0.0649, Val Loss: 0.5195
Epoch [80/100], Loss: 0.3925, Val Loss: 0.5456
Epoch [81/100], Loss: 0.1990, Val Loss: 0.5392
Epoch [82/100], Loss: 0.1008, Val Loss: 0.5037
Epoch [83/100], Loss: 0.0672, Val Loss: 0.5832
Epoch [84/100], Loss: 0.1839, Val Loss: 0.5136
Epoch [85/100], Loss: 0.1373, Val Loss: 0.5698
Epoch [86/100], Loss: 1.4438, Val Loss: 0.5059
Epoch [87/100], Loss: 0.2291, Val Loss: 0.5398
Epoch [88/100], Loss: 0.0411, Val Loss: 0.5502
Epoch [89/100], Loss: 0.4397, Val Loss: 0.5121
Epoch [90/100], Loss: 0.1089, Val Loss: 0.5148
Epoch [91/100], Loss: 0.1202, Val Loss: 0.5020
Epoch [92/100], Loss: 0.1057, Val Loss: 0.5344
Epoch [93/100], Loss: 0.1667, Val Loss: 0.4947
Epoch [94/100], Loss: 0.1360, Val Loss: 0.5580
Epoch [95/100], Loss: 0.0883, Val Loss: 0.5785
Epoch [96/100], Loss: 0.0983, Val Loss: 0.5102
Epoch [97/100], Loss: 0.6977, Val Loss: 0.5299
Epoch [98/100], Loss: 0.0905, Val Loss: 0.5216
Epoch [99/100], Loss: 0.1126, Val Loss: 0.5852
Epoch [100/100], Loss: 0.0998, Val Loss: 0.4995
Runtime: 0:00:45.157799
R^2 Score: 0.8882
RMSE: 0.6549
MAE: 0.1986
MAPE: 15.37%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/250], Loss: 0.3488, Val Loss: 0.5525
Epoch [2/250], Loss: 0.1192, Val Loss: 0.5108
Epoch [3/250], Loss: 0.1912, Val Loss: 0.6739
Epoch [4/250], Loss: 0.0659, Val Loss: 0.5226
Epoch [5/250], Loss: 0.1759, Val Loss: 0.5205
Epoch [6/250], Loss: 0.0748, Val Loss: 0.5291
Epoch [7/250], Loss: 0.1662, Val Loss: 0.5125
Epoch [8/250], Loss: 0.0973, Val Loss: 0.4974
Epoch [9/250], Loss: 0.1023, Val Loss: 0.5121
Epoch [10/250], Loss: 0.4883, Val Loss: 0.5222
Epoch [11/250], Loss: 0.4070, Val Loss: 0.5072
Epoch [12/250], Loss: 0.0168, Val Loss: 0.5238
Epoch [13/250], Loss: 0.3686, Val Loss: 0.5006
Epoch [14/250], Loss: 0.0817, Val Loss: 0.5259
Epoch [15/250], Loss: 0.0848, Val Loss: 0.5353
Epoch [16/250], Loss: 0.1112, Val Loss: 0.4703
Epoch [17/250], Loss: 0.0435, Val Loss: 0.5136
Epoch [18/250], Loss: 0.1802, Val Loss: 0.4793
Epoch [19/250], Loss: 0.0878, Val Loss: 0.4763
Epoch [20/250], Loss: 0.0330, Val Loss: 0.5705
Epoch [21/250], Loss: 0.1091, Val Loss: 0.5152
Epoch [22/250], Loss: 0.2416, Val Loss: 0.4972
Epoch [23/250], Loss: 0.1502, Val Loss: 0.4981
Epoch [24/250], Loss: 0.1328, Val Loss: 0.5023
Epoch [25/250], Loss: 0.0968, Val Loss: 0.5427
Epoch [26/250], Loss: 0.4152, Val Loss: 0.5326
Epoch [27/250], Loss: 0.5762, Val Loss: 0.5029
Epoch [28/250], Loss: 0.1080, Val Loss: 0.5132
Epoch [29/250], Loss: 0.5084, Val Loss: 0.5040
Epoch [30/250], Loss: 0.0478, Val Loss: 0.5291
Epoch [31/250], Loss: 0.0857, Val Loss: 0.5322
Epoch [32/250], Loss: 0.1085, Val Loss: 0.6746
Epoch [33/250], Loss: 0.0765, Val Loss: 0.4980
Epoch [34/250], Loss: 0.2743, Val Loss: 0.5382
Epoch [35/250], Loss: 0.5524, Val Loss: 0.5351
Early stopping at epoch 35
Runtime: 0:00:17.026906
R^2 Score: 0.8805
RMSE: 0.6772
MAE: 0.2032
MAPE: 16.22%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/250], Loss: 0.1160, Val Loss: 0.4765
Epoch [2/250], Loss: 0.0752, Val Loss: 0.4646
Epoch [3/250], Loss: 1.0329, Val Loss: 0.4891
Epoch [4/250], Loss: 0.4768, Val Loss: 0.4975
Epoch [5/250], Loss: 0.0869, Val Loss: 0.5475
Epoch [6/250], Loss: 0.0602, Val Loss: 0.4946
Epoch [7/250], Loss: 0.1752, Val Loss: 0.4954
Epoch [8/250], Loss: 0.0792, Val Loss: 0.4803
Epoch [9/250], Loss: 0.2245, Val Loss: 0.5344
Epoch [10/250], Loss: 0.0964, Val Loss: 0.5437
Epoch [11/250], Loss: 0.2246, Val Loss: 0.4935
Epoch [12/250], Loss: 0.2098, Val Loss: 0.4867
Epoch [13/250], Loss: 0.0849, Val Loss: 0.4989
Epoch [14/250], Loss: 0.2643, Val Loss: 0.5294
Epoch [15/250], Loss: 0.0952, Val Loss: 0.4850
Epoch [16/250], Loss: 0.0696, Val Loss: 0.5021
Epoch [17/250], Loss: 0.3734, Val Loss: 0.4848
Epoch [18/250], Loss: 0.2211, Val Loss: 0.5034
Epoch [19/250], Loss: 0.0657, Val Loss: 0.5026
Epoch [20/250], Loss: 0.1031, Val Loss: 0.5265
Epoch [21/250], Loss: 0.0736, Val Loss: 0.5221
Epoch [22/250], Loss: 0.1123, Val Loss: 0.5470
Epoch [23/250], Loss: 0.0420, Val Loss: 0.4976
Epoch [24/250], Loss: 0.2605, Val Loss: 0.5052
Epoch [25/250], Loss: 0.2762, Val Loss: 0.5375
Epoch [26/250], Loss: 0.0748, Val Loss: 0.5053
Epoch [27/250], Loss: 0.0726, Val Loss: 0.5107
Epoch [28/250], Loss: 0.2724, Val Loss: 0.5273
Epoch [29/250], Loss: 0.1156, Val Loss: 0.4976
Epoch [30/250], Loss: 0.1038, Val Loss: 0.4808
Epoch [31/250], Loss: 0.4292, Val Loss: 0.5267
Epoch [32/250], Loss: 0.4462, Val Loss: 0.5254
Epoch [33/250], Loss: 0.1191, Val Loss: 0.5006
Epoch [34/250], Loss: 0.0936, Val Loss: 0.4667
Epoch [35/250], Loss: 0.2405, Val Loss: 0.5491
Epoch [36/250], Loss: 0.1229, Val Loss: 0.5018
Epoch [37/250], Loss: 0.4104, Val Loss: 0.5005
Epoch [38/250], Loss: 0.2272, Val Loss: 0.5412
Epoch [39/250], Loss: 0.0774, Val Loss: 0.5234
Epoch [40/250], Loss: 0.4977, Val Loss: 0.5150
Epoch [41/250], Loss: 0.0634, Val Loss: 0.5197
Epoch [42/250], Loss: 0.3651, Val Loss: 0.4870
Epoch [43/250], Loss: 0.2088, Val Loss: 0.5337
Epoch [44/250], Loss: 0.0684, Val Loss: 0.4912
Epoch [45/250], Loss: 0.1096, Val Loss: 0.4748
Epoch [46/250], Loss: 0.0441, Val Loss: 0.5427
Epoch [47/250], Loss: 0.0777, Val Loss: 0.4720
Epoch [48/250], Loss: 0.1360, Val Loss: 0.5118
Epoch [49/250], Loss: 0.1691, Val Loss: 0.6140
Epoch [50/250], Loss: 0.0514, Val Loss: 0.4999
Epoch [51/250], Loss: 0.2309, Val Loss: 0.6131
Epoch [52/250], Loss: 0.6516, Val Loss: 0.5168
Epoch [53/250], Loss: 0.0954, Val Loss: 0.5458
Epoch [54/250], Loss: 0.1542, Val Loss: 0.4969
Epoch [55/250], Loss: 0.1656, Val Loss: 0.4901
Epoch [56/250], Loss: 0.2619, Val Loss: 0.5065
Epoch [57/250], Loss: 0.0604, Val Loss: 0.5244
Epoch [58/250], Loss: 0.7284, Val Loss: 0.5704
Epoch [59/250], Loss: 0.0861, Val Loss: 0.5022
Epoch [60/250], Loss: 0.1416, Val Loss: 0.5013
Epoch [61/250], Loss: 0.0769, Val Loss: 0.4971
Epoch [62/250], Loss: 0.0537, Val Loss: 0.4992
Epoch [63/250], Loss: 0.0871, Val Loss: 0.4966
Epoch [64/250], Loss: 0.2432, Val Loss: 0.5738
Epoch [65/250], Loss: 0.0760, Val Loss: 0.5745
Epoch [66/250], Loss: 0.0968, Val Loss: 0.5146
Epoch [67/250], Loss: 0.1216, Val Loss: 0.5029
Epoch [68/250], Loss: 0.0618, Val Loss: 0.5096
Epoch [69/250], Loss: 0.0785, Val Loss: 0.4958
Epoch [70/250], Loss: 0.1017, Val Loss: 0.4836
Epoch [71/250], Loss: 0.0567, Val Loss: 0.5036
Epoch [72/250], Loss: 0.1386, Val Loss: 0.4756
Epoch [73/250], Loss: 0.5838, Val Loss: 0.4789
Epoch [74/250], Loss: 0.1648, Val Loss: 0.5720
Epoch [75/250], Loss: 0.0602, Val Loss: 0.5058
Epoch [76/250], Loss: 0.1430, Val Loss: 0.4906
Epoch [77/250], Loss: 0.0583, Val Loss: 0.4908
Epoch [78/250], Loss: 0.9020, Val Loss: 0.5332
Epoch [79/250], Loss: 0.2215, Val Loss: 0.5282
Epoch [80/250], Loss: 0.1251, Val Loss: 0.4764
Epoch [81/250], Loss: 0.1571, Val Loss: 0.4883
Epoch [82/250], Loss: 0.1525, Val Loss: 0.4713
Epoch [83/250], Loss: 0.0289, Val Loss: 0.5013
Early stopping at epoch 83
Runtime: 0:00:36.156665
R^2 Score: 0.9045
RMSE: 0.6055
MAE: 0.1847
MAPE: 14.22%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/250], Loss: 0.2047, Val Loss: 0.6927
Epoch [2/250], Loss: 0.1433, Val Loss: 0.4830
Epoch [3/250], Loss: 0.2870, Val Loss: 0.4503
Epoch [4/250], Loss: 1.1639, Val Loss: 0.4094
Epoch [5/250], Loss: 0.2466, Val Loss: 0.4478
Epoch [6/250], Loss: 0.0895, Val Loss: 0.4408
Epoch [7/250], Loss: 0.1410, Val Loss: 0.5454
Epoch [8/250], Loss: 0.0925, Val Loss: 0.4800
Epoch [9/250], Loss: 0.1766, Val Loss: 0.4746
Epoch [10/250], Loss: 0.1253, Val Loss: 0.4194
Epoch [11/250], Loss: 0.0799, Val Loss: 0.4798
Epoch [12/250], Loss: 0.1662, Val Loss: 0.5207
Epoch [13/250], Loss: 0.1251, Val Loss: 0.4756
Epoch [14/250], Loss: 0.4071, Val Loss: 0.4238
Epoch [15/250], Loss: 0.0561, Val Loss: 0.4385
Epoch [16/250], Loss: 0.2174, Val Loss: 0.4850
Epoch [17/250], Loss: 0.5013, Val Loss: 0.4523
Epoch [18/250], Loss: 0.0549, Val Loss: 0.4862
Epoch [19/250], Loss: 0.5689, Val Loss: 0.6559
Epoch [20/250], Loss: 0.2002, Val Loss: 0.5405
Epoch [21/250], Loss: 0.0642, Val Loss: 0.5537
Epoch [22/250], Loss: 0.1171, Val Loss: 0.5021
Epoch [23/250], Loss: 0.1433, Val Loss: 0.4832
Epoch [24/250], Loss: 0.1795, Val Loss: 0.4986
Epoch [25/250], Loss: 0.1840, Val Loss: 0.4846
Epoch [26/250], Loss: 0.1031, Val Loss: 0.4730
Epoch [27/250], Loss: 0.6187, Val Loss: 0.4491
Epoch [28/250], Loss: 0.1723, Val Loss: 0.5314
Epoch [29/250], Loss: 0.4501, Val Loss: 0.4567
Epoch [30/250], Loss: 0.4498, Val Loss: 0.4892
Epoch [31/250], Loss: 0.0812, Val Loss: 0.4502
Epoch [32/250], Loss: 0.1027, Val Loss: 0.4371
Epoch [33/250], Loss: 0.0541, Val Loss: 0.4426
Epoch [34/250], Loss: 0.3211, Val Loss: 0.4305
Epoch [35/250], Loss: 0.0944, Val Loss: 0.4837
Epoch [36/250], Loss: 0.1957, Val Loss: 0.4786
Epoch [37/250], Loss: 0.5572, Val Loss: 0.4584
Epoch [38/250], Loss: 0.1171, Val Loss: 0.4503
Epoch [39/250], Loss: 0.1010, Val Loss: 0.4891
Epoch [40/250], Loss: 0.0529, Val Loss: 0.4693
Epoch [41/250], Loss: 0.1210, Val Loss: 0.5397
Epoch [42/250], Loss: 0.1270, Val Loss: 0.4813
Epoch [43/250], Loss: 0.6566, Val Loss: 0.4806
Epoch [44/250], Loss: 0.2381, Val Loss: 0.5162
Epoch [45/250], Loss: 0.1022, Val Loss: 0.4551
Epoch [46/250], Loss: 0.3833, Val Loss: 0.4707
Epoch [47/250], Loss: 0.0753, Val Loss: 0.5093
Epoch [48/250], Loss: 0.1471, Val Loss: 0.4672
Epoch [49/250], Loss: 0.0552, Val Loss: 0.4779
Epoch [50/250], Loss: 0.1472, Val Loss: 0.4569
Epoch [51/250], Loss: 0.2951, Val Loss: 0.4631
Epoch [52/250], Loss: 0.1060, Val Loss: 0.5229
Epoch [53/250], Loss: 0.3825, Val Loss: 0.5086
Early stopping at epoch 53
Runtime: 0:01:18.012485
R^2 Score: 0.8676
RMSE: 0.8241
MAE: 0.2029
MAPE: 15.54%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/250], Loss: 0.1797, Val Loss: 0.5428
Epoch [2/250], Loss: 0.1832, Val Loss: 0.5196
Epoch [3/250], Loss: 0.0749, Val Loss: 0.6204
Epoch [4/250], Loss: 0.1458, Val Loss: 0.4805
Epoch [5/250], Loss: 0.1124, Val Loss: 0.4991
Epoch [6/250], Loss: 0.2023, Val Loss: 0.5228
Epoch [7/250], Loss: 0.1674, Val Loss: 0.5713
Epoch [8/250], Loss: 0.1133, Val Loss: 0.5598
Epoch [9/250], Loss: 0.1285, Val Loss: 0.5122
Epoch [10/250], Loss: 0.3246, Val Loss: 0.5295
Epoch [11/250], Loss: 0.3172, Val Loss: 0.5259
Epoch [12/250], Loss: 0.2422, Val Loss: 0.4766
Epoch [13/250], Loss: 0.2706, Val Loss: 0.4890
Epoch [14/250], Loss: 0.2578, Val Loss: 0.6728
Epoch [15/250], Loss: 0.0894, Val Loss: 0.5616
Epoch [16/250], Loss: 0.0941, Val Loss: 0.5221
Epoch [17/250], Loss: 0.1117, Val Loss: 0.5089
Epoch [18/250], Loss: 0.3267, Val Loss: 0.5586
Epoch [19/250], Loss: 0.0593, Val Loss: 0.4744
Epoch [20/250], Loss: 0.0847, Val Loss: 0.4886
Epoch [21/250], Loss: 0.1077, Val Loss: 0.4918
Epoch [22/250], Loss: 0.3411, Val Loss: 0.5243
Epoch [23/250], Loss: 0.2843, Val Loss: 0.5269
Epoch [24/250], Loss: 0.3620, Val Loss: 0.5062
Epoch [25/250], Loss: 0.1250, Val Loss: 0.4786
Epoch [26/250], Loss: 0.3707, Val Loss: 0.5363
Epoch [27/250], Loss: 0.0784, Val Loss: 0.5124
Epoch [28/250], Loss: 0.0570, Val Loss: 0.4986
Epoch [29/250], Loss: 0.0572, Val Loss: 0.5475
Epoch [30/250], Loss: 0.2609, Val Loss: 0.5076
Epoch [31/250], Loss: 0.3073, Val Loss: 0.5279
Epoch [32/250], Loss: 0.5059, Val Loss: 0.6145
Epoch [33/250], Loss: 0.1068, Val Loss: 0.4886
Epoch [34/250], Loss: 0.1071, Val Loss: 0.5155
Epoch [35/250], Loss: 0.1083, Val Loss: 0.4821
Epoch [36/250], Loss: 0.1368, Val Loss: 0.4716
Epoch [37/250], Loss: 0.2057, Val Loss: 0.4823
Epoch [38/250], Loss: 0.1594, Val Loss: 0.4954
Epoch [39/250], Loss: 0.1357, Val Loss: 0.4806
Epoch [40/250], Loss: 0.2925, Val Loss: 0.5174
Epoch [41/250], Loss: 0.2506, Val Loss: 0.4647
Epoch [42/250], Loss: 2.6652, Val Loss: 0.5175
Epoch [43/250], Loss: 0.1254, Val Loss: 0.5003
Epoch [44/250], Loss: 0.0562, Val Loss: 0.4844
Epoch [45/250], Loss: 0.5052, Val Loss: 0.5245
Epoch [46/250], Loss: 0.3448, Val Loss: 0.4955
Epoch [47/250], Loss: 0.0667, Val Loss: 0.4815
Epoch [48/250], Loss: 0.1398, Val Loss: 0.5104
Epoch [49/250], Loss: 0.0716, Val Loss: 0.4881
Epoch [50/250], Loss: 0.2321, Val Loss: 0.4878
Epoch [51/250], Loss: 0.0616, Val Loss: 0.5272
Epoch [52/250], Loss: 0.3083, Val Loss: 0.5036
Epoch [53/250], Loss: 0.2966, Val Loss: 0.4896
Epoch [54/250], Loss: 0.0551, Val Loss: 0.4834
Epoch [55/250], Loss: 0.0463, Val Loss: 0.5014
Epoch [56/250], Loss: 0.2258, Val Loss: 0.5273
Epoch [57/250], Loss: 0.0994, Val Loss: 0.5636
Epoch [58/250], Loss: 0.3931, Val Loss: 0.5004
Epoch [59/250], Loss: 0.3168, Val Loss: 0.4713
Epoch [60/250], Loss: 0.2317, Val Loss: 0.4674
Epoch [61/250], Loss: 0.0435, Val Loss: 0.4817
Epoch [62/250], Loss: 0.2607, Val Loss: 0.5255
Epoch [63/250], Loss: 0.1302, Val Loss: 0.5772
Epoch [64/250], Loss: 0.1011, Val Loss: 0.5274
Epoch [65/250], Loss: 0.7162, Val Loss: 0.4893
Epoch [66/250], Loss: 0.0525, Val Loss: 0.5094
Epoch [67/250], Loss: 0.1140, Val Loss: 0.4787
Epoch [68/250], Loss: 0.3568, Val Loss: 0.4911
Epoch [69/250], Loss: 0.1473, Val Loss: 0.4983
Epoch [70/250], Loss: 0.1804, Val Loss: 0.5025
Epoch [71/250], Loss: 0.1231, Val Loss: 0.5115
Epoch [72/250], Loss: 0.0763, Val Loss: 0.5002
Epoch [73/250], Loss: 0.2437, Val Loss: 0.5207
Epoch [74/250], Loss: 0.2572, Val Loss: 0.4923
Epoch [75/250], Loss: 0.0906, Val Loss: 0.4965
Epoch [76/250], Loss: 0.2510, Val Loss: 0.4597
Epoch [77/250], Loss: 0.1585, Val Loss: 0.5293
Epoch [78/250], Loss: 0.0605, Val Loss: 0.5198
Epoch [79/250], Loss: 0.1324, Val Loss: 0.4625
Epoch [80/250], Loss: 0.1391, Val Loss: 0.4877
Epoch [81/250], Loss: 0.0572, Val Loss: 0.5396
Epoch [82/250], Loss: 0.2889, Val Loss: 0.5236
Epoch [83/250], Loss: 0.0980, Val Loss: 0.5260
Epoch [84/250], Loss: 0.1402, Val Loss: 0.5118
Epoch [85/250], Loss: 0.1345, Val Loss: 0.5199
Epoch [86/250], Loss: 0.4173, Val Loss: 0.4887
Epoch [87/250], Loss: 0.1789, Val Loss: 0.4835
Epoch [88/250], Loss: 0.1375, Val Loss: 0.5048
Epoch [89/250], Loss: 0.1314, Val Loss: 0.4784
Epoch [90/250], Loss: 0.1805, Val Loss: 0.5227
Epoch [91/250], Loss: 0.2800, Val Loss: 0.5177
Epoch [92/250], Loss: 0.1345, Val Loss: 0.5293
Epoch [93/250], Loss: 0.0374, Val Loss: 0.4909
Epoch [94/250], Loss: 0.2025, Val Loss: 0.4680
Epoch [95/250], Loss: 0.1787, Val Loss: 0.5064
Epoch [96/250], Loss: 0.0576, Val Loss: 0.5513
Epoch [97/250], Loss: 0.0868, Val Loss: 0.5065
Epoch [98/250], Loss: 0.1239, Val Loss: 0.5169
Epoch [99/250], Loss: 0.1662, Val Loss: 0.5051
Epoch [100/250], Loss: 0.2300, Val Loss: 0.4808
Epoch [101/250], Loss: 0.1676, Val Loss: 0.4912
Epoch [102/250], Loss: 0.0657, Val Loss: 0.5021
Epoch [103/250], Loss: 0.0752, Val Loss: 0.5368
Epoch [104/250], Loss: 0.5949, Val Loss: 0.4781
Epoch [105/250], Loss: 0.2912, Val Loss: 0.5366
Epoch [106/250], Loss: 0.2123, Val Loss: 0.5053
Epoch [107/250], Loss: 0.1573, Val Loss: 0.4864
Epoch [108/250], Loss: 0.3134, Val Loss: 0.5696
Epoch [109/250], Loss: 0.0435, Val Loss: 0.4895
Epoch [110/250], Loss: 0.1601, Val Loss: 0.4944
Epoch [111/250], Loss: 0.0798, Val Loss: 0.4934
Epoch [112/250], Loss: 0.1407, Val Loss: 0.5116
Epoch [113/250], Loss: 0.4888, Val Loss: 0.4986
Epoch [114/250], Loss: 0.3574, Val Loss: 0.4910
Epoch [115/250], Loss: 0.1026, Val Loss: 0.4809
Epoch [116/250], Loss: 0.3513, Val Loss: 0.4589
Epoch [117/250], Loss: 0.0984, Val Loss: 0.4895
Epoch [118/250], Loss: 0.1183, Val Loss: 0.5093
Epoch [119/250], Loss: 0.3285, Val Loss: 0.4799
Epoch [120/250], Loss: 0.1163, Val Loss: 0.4977
Epoch [121/250], Loss: 0.0696, Val Loss: 0.4583
Epoch [122/250], Loss: 0.1037, Val Loss: 0.5510
Epoch [123/250], Loss: 0.0451, Val Loss: 0.5325
Epoch [124/250], Loss: 0.0852, Val Loss: 0.4901
Epoch [125/250], Loss: 0.0987, Val Loss: 0.5339
Epoch [126/250], Loss: 0.0718, Val Loss: 0.5023
Epoch [127/250], Loss: 0.6565, Val Loss: 0.5267
Epoch [128/250], Loss: 0.1820, Val Loss: 0.4807
Epoch [129/250], Loss: 0.0806, Val Loss: 0.4851
Epoch [130/250], Loss: 0.1222, Val Loss: 0.4714
Epoch [131/250], Loss: 0.2108, Val Loss: 0.4571
Epoch [132/250], Loss: 0.1307, Val Loss: 0.4862
Epoch [133/250], Loss: 0.1123, Val Loss: 0.4894
Epoch [134/250], Loss: 1.0035, Val Loss: 0.5622
Epoch [135/250], Loss: 0.0554, Val Loss: 0.4933
Epoch [136/250], Loss: 0.0773, Val Loss: 0.4975
Epoch [137/250], Loss: 0.1320, Val Loss: 0.4878
Epoch [138/250], Loss: 0.0858, Val Loss: 0.4740
Epoch [139/250], Loss: 0.0546, Val Loss: 0.4953
Epoch [140/250], Loss: 0.1789, Val Loss: 0.4731
Epoch [141/250], Loss: 0.0724, Val Loss: 0.5105
Epoch [142/250], Loss: 0.0801, Val Loss: 0.5190
Epoch [143/250], Loss: 0.2786, Val Loss: 0.4847
Epoch [144/250], Loss: 0.1559, Val Loss: 0.4746
Epoch [145/250], Loss: 0.1533, Val Loss: 0.5042
Epoch [146/250], Loss: 0.0944, Val Loss: 0.5009
Epoch [147/250], Loss: 0.0681, Val Loss: 0.5160
Epoch [148/250], Loss: 0.1804, Val Loss: 0.4972
Epoch [149/250], Loss: 0.1687, Val Loss: 0.4741
Epoch [150/250], Loss: 0.1836, Val Loss: 0.4820
Epoch [151/250], Loss: 0.1322, Val Loss: 0.5763
Epoch [152/250], Loss: 0.1126, Val Loss: 0.4857
Epoch [153/250], Loss: 0.3441, Val Loss: 0.4975
Epoch [154/250], Loss: 0.1062, Val Loss: 0.4793
Epoch [155/250], Loss: 0.1369, Val Loss: 0.5364
Epoch [156/250], Loss: 0.2888, Val Loss: 0.4847
Epoch [157/250], Loss: 0.0794, Val Loss: 0.4780
Epoch [158/250], Loss: 0.0637, Val Loss: 0.4857
Epoch [159/250], Loss: 0.1702, Val Loss: 0.4955
Epoch [160/250], Loss: 0.1332, Val Loss: 0.5103
Epoch [161/250], Loss: 0.0754, Val Loss: 0.4928
Epoch [162/250], Loss: 0.3646, Val Loss: 0.4876
Epoch [163/250], Loss: 0.3081, Val Loss: 0.4783
Epoch [164/250], Loss: 0.6890, Val Loss: 0.5288
Epoch [165/250], Loss: 0.4881, Val Loss: 0.4696
Epoch [166/250], Loss: 0.1419, Val Loss: 0.4771
Epoch [167/250], Loss: 0.1499, Val Loss: 0.5020
Epoch [168/250], Loss: 0.2328, Val Loss: 0.4667
Epoch [169/250], Loss: 0.1050, Val Loss: 0.4893
Epoch [170/250], Loss: 0.1340, Val Loss: 0.4640
Epoch [171/250], Loss: 0.1351, Val Loss: 0.5418
Epoch [172/250], Loss: 0.0297, Val Loss: 0.4955
Epoch [173/250], Loss: 0.0847, Val Loss: 0.5735
Epoch [174/250], Loss: 0.1873, Val Loss: 0.5260
Epoch [175/250], Loss: 0.2763, Val Loss: 0.4953
Epoch [176/250], Loss: 0.0530, Val Loss: 0.5362
Epoch [177/250], Loss: 0.6526, Val Loss: 0.5050
Epoch [178/250], Loss: 0.0809, Val Loss: 0.4970
Epoch [179/250], Loss: 0.2548, Val Loss: 0.5017
Epoch [180/250], Loss: 0.4193, Val Loss: 0.5380
Epoch [181/250], Loss: 0.0925, Val Loss: 0.5377
Epoch [182/250], Loss: 0.0952, Val Loss: 0.5216
Epoch [183/250], Loss: 0.0315, Val Loss: 0.5614
Epoch [184/250], Loss: 0.2171, Val Loss: 0.4922
Epoch [185/250], Loss: 0.0581, Val Loss: 0.4687
Epoch [186/250], Loss: 0.1126, Val Loss: 0.4910
Epoch [187/250], Loss: 0.1267, Val Loss: 0.4873
Epoch [188/250], Loss: 0.1156, Val Loss: 0.4969
Epoch [189/250], Loss: 0.1247, Val Loss: 0.4919
Epoch [190/250], Loss: 0.1160, Val Loss: 0.4904
Epoch [191/250], Loss: 0.0552, Val Loss: 0.4880
Epoch [192/250], Loss: 0.0405, Val Loss: 0.5166
Epoch [193/250], Loss: 0.3399, Val Loss: 0.4945
Epoch [194/250], Loss: 0.0516, Val Loss: 0.4998
Epoch [195/250], Loss: 0.4242, Val Loss: 0.4972
Epoch [196/250], Loss: 0.0998, Val Loss: 0.5531
Epoch [197/250], Loss: 0.0979, Val Loss: 0.5033
Epoch [198/250], Loss: 0.3111, Val Loss: 0.4810
Epoch [199/250], Loss: 0.0977, Val Loss: 0.5103
Epoch [200/250], Loss: 0.1280, Val Loss: 0.5131
Epoch [201/250], Loss: 0.2173, Val Loss: 0.5526
Epoch [202/250], Loss: 0.1314, Val Loss: 0.4789
Epoch [203/250], Loss: 0.3239, Val Loss: 0.4884
Epoch [204/250], Loss: 0.1374, Val Loss: 0.5281
Epoch [205/250], Loss: 0.4097, Val Loss: 0.4718
Epoch [206/250], Loss: 0.1404, Val Loss: 0.4941
Epoch [207/250], Loss: 0.2379, Val Loss: 0.4900
Epoch [208/250], Loss: 0.1902, Val Loss: 0.4907
Epoch [209/250], Loss: 0.0329, Val Loss: 0.5225
Epoch [210/250], Loss: 0.2585, Val Loss: 0.5215
Epoch [211/250], Loss: 0.1187, Val Loss: 0.4808
Epoch [212/250], Loss: 0.2282, Val Loss: 0.4778
Epoch [213/250], Loss: 0.1557, Val Loss: 0.4951
Epoch [214/250], Loss: 0.1827, Val Loss: 0.4995
Epoch [215/250], Loss: 0.1745, Val Loss: 0.4907
Epoch [216/250], Loss: 0.1268, Val Loss: 0.4753
Epoch [217/250], Loss: 0.1719, Val Loss: 0.5224
Epoch [218/250], Loss: 0.1118, Val Loss: 0.5036
Epoch [219/250], Loss: 0.2426, Val Loss: 0.5235
Epoch [220/250], Loss: 0.1529, Val Loss: 0.5024
Epoch [221/250], Loss: 0.2628, Val Loss: 0.4875
Epoch [222/250], Loss: 0.2733, Val Loss: 0.4836
Epoch [223/250], Loss: 0.0570, Val Loss: 0.5261
Epoch [224/250], Loss: 0.3978, Val Loss: 0.5049
Epoch [225/250], Loss: 0.1137, Val Loss: 0.5305
Epoch [226/250], Loss: 0.1206, Val Loss: 0.5590
Epoch [227/250], Loss: 0.2233, Val Loss: 0.5031
Epoch [228/250], Loss: 0.0898, Val Loss: 0.5053
Epoch [229/250], Loss: 0.1733, Val Loss: 0.5033
Epoch [230/250], Loss: 0.3999, Val Loss: 0.4919
Early stopping at epoch 230
Runtime: 0:05:26.888709
R^2 Score: 0.9082
RMSE: 0.6861
MAE: 0.1876
MAPE: 14.55%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/250], Loss: 0.2845, Val Loss: 0.8833
Epoch [2/250], Loss: 0.2581, Val Loss: 0.8322
Epoch [3/250], Loss: 0.4122, Val Loss: 0.7818
Epoch [4/250], Loss: 1.2431, Val Loss: 0.7808
Epoch [5/250], Loss: 0.0970, Val Loss: 0.8121
Epoch [6/250], Loss: 0.1409, Val Loss: 0.9422
Epoch [7/250], Loss: 0.0658, Val Loss: 0.8294
Epoch [8/250], Loss: 0.4021, Val Loss: 0.7233
Epoch [9/250], Loss: 0.4534, Val Loss: 0.7974
Epoch [10/250], Loss: 0.4964, Val Loss: 0.6871
Epoch [11/250], Loss: 0.1004, Val Loss: 0.7220
Epoch [12/250], Loss: 0.1375, Val Loss: 0.6697
Epoch [13/250], Loss: 0.4527, Val Loss: 0.6226
Epoch [14/250], Loss: 0.4697, Val Loss: 0.6967
Epoch [15/250], Loss: 0.9844, Val Loss: 0.6139
Epoch [16/250], Loss: 1.2404, Val Loss: 0.6095
Epoch [17/250], Loss: 0.0282, Val Loss: 0.5874
Epoch [18/250], Loss: 0.1528, Val Loss: 0.5840
Epoch [19/250], Loss: 0.7988, Val Loss: 0.6233
Epoch [20/250], Loss: 0.2158, Val Loss: 0.6053
Epoch [21/250], Loss: 0.2263, Val Loss: 0.6623
Epoch [22/250], Loss: 0.4222, Val Loss: 0.6560
Epoch [23/250], Loss: 0.1299, Val Loss: 0.6932
Epoch [24/250], Loss: 0.1026, Val Loss: 0.5930
Epoch [25/250], Loss: 2.9307, Val Loss: 0.6747
Epoch [26/250], Loss: 0.0953, Val Loss: 0.6549
Epoch [27/250], Loss: 0.1070, Val Loss: 0.5996
Epoch [28/250], Loss: 0.0976, Val Loss: 0.5706
Epoch [29/250], Loss: 0.1121, Val Loss: 0.6031
Epoch [30/250], Loss: 0.0807, Val Loss: 0.6268
Epoch [31/250], Loss: 0.0667, Val Loss: 0.6156
Epoch [32/250], Loss: 0.1141, Val Loss: 0.5828
Epoch [33/250], Loss: 0.0609, Val Loss: 0.5936
Epoch [34/250], Loss: 0.2095, Val Loss: 0.7060
Epoch [35/250], Loss: 1.1329, Val Loss: 0.5827
Epoch [36/250], Loss: 0.2310, Val Loss: 0.5879
Epoch [37/250], Loss: 0.7184, Val Loss: 0.5662
Epoch [38/250], Loss: 0.2189, Val Loss: 0.5494
Epoch [39/250], Loss: 0.1163, Val Loss: 0.5512
Epoch [40/250], Loss: 0.1323, Val Loss: 0.5783
Epoch [41/250], Loss: 0.1107, Val Loss: 0.5647
Epoch [42/250], Loss: 0.4438, Val Loss: 0.5756
Epoch [43/250], Loss: 0.1312, Val Loss: 0.5671
Epoch [44/250], Loss: 0.2385, Val Loss: 0.5597
Epoch [45/250], Loss: 0.1956, Val Loss: 0.6189
Epoch [46/250], Loss: 0.0894, Val Loss: 0.5374
Epoch [47/250], Loss: 0.0877, Val Loss: 0.6021
Epoch [48/250], Loss: 0.1762, Val Loss: 0.5873
Epoch [49/250], Loss: 0.0836, Val Loss: 0.5316
Epoch [50/250], Loss: 0.2977, Val Loss: 0.5616
Epoch [51/250], Loss: 0.1418, Val Loss: 0.5648
Epoch [52/250], Loss: 0.1904, Val Loss: 0.6052
Epoch [53/250], Loss: 0.1925, Val Loss: 0.5885
Epoch [54/250], Loss: 0.5475, Val Loss: 0.5690
Epoch [55/250], Loss: 0.2164, Val Loss: 0.6732
Epoch [56/250], Loss: 0.0959, Val Loss: 0.5577
Epoch [57/250], Loss: 0.1056, Val Loss: 0.5774
Epoch [58/250], Loss: 0.0664, Val Loss: 0.5569
Epoch [59/250], Loss: 0.1238, Val Loss: 0.6644
Epoch [60/250], Loss: 0.3116, Val Loss: 0.5334
Epoch [61/250], Loss: 0.0858, Val Loss: 0.6208
Epoch [62/250], Loss: 0.1306, Val Loss: 0.5998
Epoch [63/250], Loss: 0.0955, Val Loss: 0.5575
Epoch [64/250], Loss: 0.5499, Val Loss: 0.5734
Epoch [65/250], Loss: 0.6205, Val Loss: 0.5452
Epoch [66/250], Loss: 0.7164, Val Loss: 0.5661
Epoch [67/250], Loss: 0.0875, Val Loss: 0.5227
Epoch [68/250], Loss: 0.1015, Val Loss: 0.5661
Epoch [69/250], Loss: 0.1739, Val Loss: 0.5480
Epoch [70/250], Loss: 0.2088, Val Loss: 0.5479
Epoch [71/250], Loss: 0.0766, Val Loss: 0.5890
Epoch [72/250], Loss: 0.1001, Val Loss: 0.5368
Epoch [73/250], Loss: 2.3918, Val Loss: 0.6261
Epoch [74/250], Loss: 0.2128, Val Loss: 0.6083
Epoch [75/250], Loss: 0.3821, Val Loss: 0.5257
Epoch [76/250], Loss: 1.1281, Val Loss: 0.6005
Epoch [77/250], Loss: 0.0983, Val Loss: 0.5353
Epoch [78/250], Loss: 0.0941, Val Loss: 0.5357
Epoch [79/250], Loss: 0.3894, Val Loss: 0.5620
Epoch [80/250], Loss: 0.0435, Val Loss: 0.6044
Epoch [81/250], Loss: 0.1934, Val Loss: 0.5407
Epoch [82/250], Loss: 0.2651, Val Loss: 0.5698
Epoch [83/250], Loss: 0.1913, Val Loss: 0.5621
Epoch [84/250], Loss: 0.2872, Val Loss: 0.5359
Epoch [85/250], Loss: 0.0917, Val Loss: 0.5866
Epoch [86/250], Loss: 0.4760, Val Loss: 0.6016
Epoch [87/250], Loss: 0.0770, Val Loss: 0.5672
Epoch [88/250], Loss: 0.5668, Val Loss: 0.5748
Epoch [89/250], Loss: 0.1530, Val Loss: 0.5739
Epoch [90/250], Loss: 0.1681, Val Loss: 0.5616
Epoch [91/250], Loss: 0.5251, Val Loss: 0.5214
Epoch [92/250], Loss: 0.0881, Val Loss: 0.5815
Epoch [93/250], Loss: 0.1822, Val Loss: 0.5738
Epoch [94/250], Loss: 0.0635, Val Loss: 0.5306
Epoch [95/250], Loss: 0.0702, Val Loss: 0.5460
Epoch [96/250], Loss: 0.6852, Val Loss: 0.5723
Epoch [97/250], Loss: 0.6671, Val Loss: 0.5557
Epoch [98/250], Loss: 0.1303, Val Loss: 0.5701
Epoch [99/250], Loss: 0.0756, Val Loss: 0.5347
Epoch [100/250], Loss: 0.2362, Val Loss: 0.5430
Epoch [101/250], Loss: 0.0936, Val Loss: 0.6234
Epoch [102/250], Loss: 0.3130, Val Loss: 0.5994
Epoch [103/250], Loss: 0.3001, Val Loss: 0.5758
Epoch [104/250], Loss: 0.6106, Val Loss: 0.5415
Epoch [105/250], Loss: 0.0596, Val Loss: 0.5326
Epoch [106/250], Loss: 0.0887, Val Loss: 0.5341
Epoch [107/250], Loss: 0.1072, Val Loss: 0.5222
Epoch [108/250], Loss: 0.0856, Val Loss: 0.5467
Epoch [109/250], Loss: 0.1812, Val Loss: 0.5575
Epoch [110/250], Loss: 0.3563, Val Loss: 0.5564
Epoch [111/250], Loss: 0.0706, Val Loss: 0.5350
Epoch [112/250], Loss: 0.1248, Val Loss: 0.5478
Epoch [113/250], Loss: 0.0692, Val Loss: 0.5751
Epoch [114/250], Loss: 0.0421, Val Loss: 0.5500
Epoch [115/250], Loss: 0.0883, Val Loss: 0.5650
Epoch [116/250], Loss: 0.6058, Val Loss: 0.5444
Epoch [117/250], Loss: 0.1281, Val Loss: 0.6126
Epoch [118/250], Loss: 0.1983, Val Loss: 0.5146
Epoch [119/250], Loss: 0.0866, Val Loss: 0.5023
Epoch [120/250], Loss: 0.1536, Val Loss: 0.5089
Epoch [121/250], Loss: 0.1864, Val Loss: 0.6540
Epoch [122/250], Loss: 0.1012, Val Loss: 0.5825
Epoch [123/250], Loss: 0.3439, Val Loss: 0.5322
Epoch [124/250], Loss: 0.7440, Val Loss: 0.5723
Epoch [125/250], Loss: 0.1831, Val Loss: 0.5381
Epoch [126/250], Loss: 0.2048, Val Loss: 0.5305
Epoch [127/250], Loss: 0.0409, Val Loss: 0.6045
Epoch [128/250], Loss: 0.1062, Val Loss: 0.5161
Epoch [129/250], Loss: 0.1495, Val Loss: 0.5325
Epoch [130/250], Loss: 0.1781, Val Loss: 0.5303
Epoch [131/250], Loss: 0.2759, Val Loss: 0.5472
Epoch [132/250], Loss: 0.0550, Val Loss: 0.5657
Epoch [133/250], Loss: 0.1520, Val Loss: 0.5099
Epoch [134/250], Loss: 0.1137, Val Loss: 0.5139
Epoch [135/250], Loss: 0.0534, Val Loss: 0.5333
Epoch [136/250], Loss: 0.3115, Val Loss: 0.5486
Epoch [137/250], Loss: 0.5826, Val Loss: 0.5348
Epoch [138/250], Loss: 0.1047, Val Loss: 0.5819
Epoch [139/250], Loss: 0.0602, Val Loss: 0.5684
Epoch [140/250], Loss: 0.1268, Val Loss: 0.5228
Epoch [141/250], Loss: 0.0814, Val Loss: 0.5231
Epoch [142/250], Loss: 0.3689, Val Loss: 0.5158
Epoch [143/250], Loss: 0.0662, Val Loss: 0.5733
Epoch [144/250], Loss: 0.0487, Val Loss: 0.5666
Epoch [145/250], Loss: 0.1850, Val Loss: 0.5162
Epoch [146/250], Loss: 0.3300, Val Loss: 0.5176
Epoch [147/250], Loss: 0.3435, Val Loss: 0.5186
Epoch [148/250], Loss: 0.3714, Val Loss: 0.5987
Epoch [149/250], Loss: 0.0986, Val Loss: 0.5633
Epoch [150/250], Loss: 0.1364, Val Loss: 0.5635
Epoch [151/250], Loss: 0.1063, Val Loss: 0.5608
Epoch [152/250], Loss: 0.5540, Val Loss: 0.5081
Epoch [153/250], Loss: 0.0423, Val Loss: 0.5347
Epoch [154/250], Loss: 0.2786, Val Loss: 0.5645
Epoch [155/250], Loss: 0.2179, Val Loss: 0.5470
Epoch [156/250], Loss: 0.0997, Val Loss: 0.5349
Epoch [157/250], Loss: 0.2241, Val Loss: 0.5947
Epoch [158/250], Loss: 0.2382, Val Loss: 0.5003
Epoch [159/250], Loss: 0.0470, Val Loss: 0.5563
Epoch [160/250], Loss: 0.1328, Val Loss: 0.5200
Epoch [161/250], Loss: 0.6712, Val Loss: 0.5491
Epoch [162/250], Loss: 0.0669, Val Loss: 0.5284
Epoch [163/250], Loss: 0.1758, Val Loss: 0.5012
Epoch [164/250], Loss: 0.1056, Val Loss: 0.4937
Epoch [165/250], Loss: 0.4038, Val Loss: 0.5590
Epoch [166/250], Loss: 0.0933, Val Loss: 0.5249
Epoch [167/250], Loss: 0.4311, Val Loss: 0.6307
Epoch [168/250], Loss: 0.2921, Val Loss: 0.5374
Epoch [169/250], Loss: 0.5785, Val Loss: 0.5869
Epoch [170/250], Loss: 0.3158, Val Loss: 0.4844
Epoch [171/250], Loss: 0.0520, Val Loss: 0.5070
Epoch [172/250], Loss: 0.0568, Val Loss: 0.5027
Epoch [173/250], Loss: 0.0725, Val Loss: 0.5009
Epoch [174/250], Loss: 0.0943, Val Loss: 0.4985
Epoch [175/250], Loss: 0.2529, Val Loss: 0.4701
Epoch [176/250], Loss: 0.1659, Val Loss: 0.5669
Epoch [177/250], Loss: 0.3028, Val Loss: 0.5321
Epoch [178/250], Loss: 0.1218, Val Loss: 0.5193
Epoch [179/250], Loss: 0.0920, Val Loss: 0.4900
Epoch [180/250], Loss: 0.1542, Val Loss: 0.5273
Epoch [181/250], Loss: 0.2396, Val Loss: 0.5290
Epoch [182/250], Loss: 0.1534, Val Loss: 0.5268
Epoch [183/250], Loss: 0.1400, Val Loss: 0.4880
Epoch [184/250], Loss: 0.8421, Val Loss: 0.5451
Epoch [185/250], Loss: 0.0861, Val Loss: 0.6512
Epoch [186/250], Loss: 0.3047, Val Loss: 0.5324
Epoch [187/250], Loss: 0.1718, Val Loss: 0.4959
Epoch [188/250], Loss: 0.4266, Val Loss: 0.5731
Epoch [189/250], Loss: 0.2591, Val Loss: 0.5131
Epoch [190/250], Loss: 0.1154, Val Loss: 0.4939
Epoch [191/250], Loss: 0.0324, Val Loss: 0.5131
Epoch [192/250], Loss: 0.4291, Val Loss: 0.5034
Epoch [193/250], Loss: 0.1024, Val Loss: 0.5126
Epoch [194/250], Loss: 0.1737, Val Loss: 0.4938
Epoch [195/250], Loss: 0.2518, Val Loss: 0.5106
Epoch [196/250], Loss: 0.2573, Val Loss: 0.4993
Epoch [197/250], Loss: 0.1536, Val Loss: 0.5700
Epoch [198/250], Loss: 0.1176, Val Loss: 0.5126
Epoch [199/250], Loss: 0.0929, Val Loss: 0.5423
Epoch [200/250], Loss: 0.1625, Val Loss: 0.4756
Epoch [201/250], Loss: 0.2140, Val Loss: 0.5514
Epoch [202/250], Loss: 0.3376, Val Loss: 0.4886
Epoch [203/250], Loss: 0.1619, Val Loss: 0.5745
Epoch [204/250], Loss: 0.2642, Val Loss: 0.5933
Epoch [205/250], Loss: 0.0352, Val Loss: 0.5150
Epoch [206/250], Loss: 0.1160, Val Loss: 0.4714
Epoch [207/250], Loss: 4.8492, Val Loss: 0.6114
Epoch [208/250], Loss: 0.5134, Val Loss: 0.5474
Epoch [209/250], Loss: 0.2922, Val Loss: 0.5375
Epoch [210/250], Loss: 0.2052, Val Loss: 0.5260
Epoch [211/250], Loss: 0.1336, Val Loss: 0.5120
Epoch [212/250], Loss: 0.3104, Val Loss: 0.5352
Epoch [213/250], Loss: 0.2733, Val Loss: 0.4930
Epoch [214/250], Loss: 0.3551, Val Loss: 0.5012
Epoch [215/250], Loss: 0.0507, Val Loss: 0.4878
Epoch [216/250], Loss: 0.1215, Val Loss: 0.5089
Epoch [217/250], Loss: 0.2050, Val Loss: 0.4892
Epoch [218/250], Loss: 0.0852, Val Loss: 0.5006
Epoch [219/250], Loss: 0.0754, Val Loss: 0.4943
Epoch [220/250], Loss: 0.2159, Val Loss: 0.5123
Epoch [221/250], Loss: 0.1082, Val Loss: 0.4820
Epoch [222/250], Loss: 0.2194, Val Loss: 0.4987
Epoch [223/250], Loss: 0.8287, Val Loss: 0.4816
Epoch [224/250], Loss: 0.2380, Val Loss: 0.5142
Epoch [225/250], Loss: 0.1798, Val Loss: 0.4888
Epoch [226/250], Loss: 0.2206, Val Loss: 0.4925
Epoch [227/250], Loss: 0.2175, Val Loss: 0.5296
Epoch [228/250], Loss: 0.1482, Val Loss: 0.5337
Epoch [229/250], Loss: 0.0595, Val Loss: 0.5192
Epoch [230/250], Loss: 0.6266, Val Loss: 0.5265
Epoch [231/250], Loss: 0.3805, Val Loss: 0.5307
Epoch [232/250], Loss: 0.1831, Val Loss: 0.5306
Epoch [233/250], Loss: 0.0974, Val Loss: 0.5003
Epoch [234/250], Loss: 0.1700, Val Loss: 0.5255
Epoch [235/250], Loss: 0.1089, Val Loss: 0.5000
Epoch [236/250], Loss: 0.0739, Val Loss: 0.5480
Epoch [237/250], Loss: 0.1203, Val Loss: 0.5668
Epoch [238/250], Loss: 0.0568, Val Loss: 0.5097
Epoch [239/250], Loss: 0.1115, Val Loss: 0.5045
Epoch [240/250], Loss: 0.0542, Val Loss: 0.5511
Epoch [241/250], Loss: 0.0554, Val Loss: 0.5095
Epoch [242/250], Loss: 0.1540, Val Loss: 0.4863
Epoch [243/250], Loss: 0.1089, Val Loss: 0.5080
Epoch [244/250], Loss: 0.1450, Val Loss: 0.5345
Epoch [245/250], Loss: 0.4754, Val Loss: 0.5499
Epoch [246/250], Loss: 0.1342, Val Loss: 0.5052
Epoch [247/250], Loss: 0.0966, Val Loss: 0.5115
Epoch [248/250], Loss: 0.4351, Val Loss: 0.5021
Epoch [249/250], Loss: 0.1535, Val Loss: 0.5026
Epoch [250/250], Loss: 0.3121, Val Loss: 0.5006
Runtime: 0:05:11.869188
R^2 Score: 0.9060
RMSE: 0.6943
MAE: 0.1808
MAPE: 14.37%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 55, 25] - Result:
Epoch [1/250], Loss: 0.7946, Val Loss: 0.9577
Epoch [2/250], Loss: 0.3701, Val Loss: 0.9415
Epoch [3/250], Loss: 0.4038, Val Loss: 0.8746
Epoch [4/250], Loss: 0.7251, Val Loss: 0.8315
Epoch [5/250], Loss: 1.2548, Val Loss: 0.7919
Epoch [6/250], Loss: 1.0178, Val Loss: 0.7862
Epoch [7/250], Loss: 0.6204, Val Loss: 0.7935
Epoch [8/250], Loss: 0.1193, Val Loss: 0.8138
Epoch [9/250], Loss: 0.6296, Val Loss: 0.7591
Epoch [10/250], Loss: 0.0860, Val Loss: 0.7350
Epoch [11/250], Loss: 0.1193, Val Loss: 1.3740
Epoch [12/250], Loss: 0.9026, Val Loss: 0.6606
Epoch [13/250], Loss: 0.2492, Val Loss: 0.6531
Epoch [14/250], Loss: 0.5196, Val Loss: 0.7305
Epoch [15/250], Loss: 0.1360, Val Loss: 0.6768
Epoch [16/250], Loss: 0.1135, Val Loss: 0.6861
Epoch [17/250], Loss: 0.1703, Val Loss: 0.6187
Epoch [18/250], Loss: 0.6510, Val Loss: 0.6055
Epoch [19/250], Loss: 0.2351, Val Loss: 0.6067
Epoch [20/250], Loss: 0.1570, Val Loss: 0.8249
Epoch [21/250], Loss: 0.6091, Val Loss: 0.5880
Epoch [22/250], Loss: 0.0923, Val Loss: 0.6363
Epoch [23/250], Loss: 0.2151, Val Loss: 0.6053
Epoch [24/250], Loss: 0.1482, Val Loss: 0.5775
Epoch [25/250], Loss: 0.5002, Val Loss: 0.6911
Epoch [26/250], Loss: 0.1175, Val Loss: 0.5682
Epoch [27/250], Loss: 0.3240, Val Loss: 0.5824
Epoch [28/250], Loss: 0.2135, Val Loss: 0.6108
Epoch [29/250], Loss: 0.1252, Val Loss: 0.5901
Epoch [30/250], Loss: 0.3928, Val Loss: 0.6184
Epoch [31/250], Loss: 0.7356, Val Loss: 0.5898
Epoch [32/250], Loss: 0.8912, Val Loss: 0.6017
Epoch [33/250], Loss: 0.5038, Val Loss: 0.5970
Epoch [34/250], Loss: 0.2072, Val Loss: 0.5793
Epoch [35/250], Loss: 0.3444, Val Loss: 0.5831
Epoch [36/250], Loss: 0.2287, Val Loss: 0.6228
Epoch [37/250], Loss: 0.1810, Val Loss: 0.5817
Epoch [38/250], Loss: 0.1101, Val Loss: 0.5916
Epoch [39/250], Loss: 0.8743, Val Loss: 0.5889
Epoch [40/250], Loss: 0.1127, Val Loss: 0.5944
Epoch [41/250], Loss: 0.0463, Val Loss: 0.6135
Epoch [42/250], Loss: 0.1553, Val Loss: 0.5704
Epoch [43/250], Loss: 0.2498, Val Loss: 0.5845
Epoch [44/250], Loss: 0.4632, Val Loss: 0.5775
Epoch [45/250], Loss: 0.3867, Val Loss: 0.6009
Epoch [46/250], Loss: 1.2695, Val Loss: 0.6509
Epoch [47/250], Loss: 0.4965, Val Loss: 0.6141
Epoch [48/250], Loss: 0.3078, Val Loss: 0.5954
Epoch [49/250], Loss: 0.1055, Val Loss: 0.5968
Epoch [50/250], Loss: 0.5551, Val Loss: 0.5872
Epoch [51/250], Loss: 0.3035, Val Loss: 0.6045
Epoch [52/250], Loss: 0.1976, Val Loss: 0.5626
Epoch [53/250], Loss: 0.0978, Val Loss: 0.6167
Epoch [54/250], Loss: 0.1005, Val Loss: 0.5580
Epoch [55/250], Loss: 0.1023, Val Loss: 0.5943
Epoch [56/250], Loss: 0.1258, Val Loss: 0.5722
Epoch [57/250], Loss: 0.1651, Val Loss: 0.5941
Epoch [58/250], Loss: 0.1176, Val Loss: 0.5625
Epoch [59/250], Loss: 0.0509, Val Loss: 0.5979
Epoch [60/250], Loss: 0.1273, Val Loss: 0.5520
Epoch [61/250], Loss: 0.0457, Val Loss: 0.5646
Epoch [62/250], Loss: 0.0660, Val Loss: 0.6022
Epoch [63/250], Loss: 0.2889, Val Loss: 0.5743
Epoch [64/250], Loss: 0.5125, Val Loss: 0.5713
Epoch [65/250], Loss: 0.1476, Val Loss: 0.5439
Epoch [66/250], Loss: 0.1973, Val Loss: 0.5362
Epoch [67/250], Loss: 0.0663, Val Loss: 0.5475
Epoch [68/250], Loss: 0.2713, Val Loss: 0.5773
Epoch [69/250], Loss: 0.0724, Val Loss: 0.6203
Epoch [70/250], Loss: 0.0535, Val Loss: 0.5466
Epoch [71/250], Loss: 0.1504, Val Loss: 0.5293
Epoch [72/250], Loss: 0.0759, Val Loss: 0.5400
Epoch [73/250], Loss: 0.1588, Val Loss: 0.5424
Epoch [74/250], Loss: 0.3400, Val Loss: 0.5511
Epoch [75/250], Loss: 0.2139, Val Loss: 0.5725
Epoch [76/250], Loss: 0.0970, Val Loss: 0.6359
Epoch [77/250], Loss: 0.1988, Val Loss: 0.5776
Epoch [78/250], Loss: 0.6462, Val Loss: 0.5626
Epoch [79/250], Loss: 0.1371, Val Loss: 0.6002
Epoch [80/250], Loss: 0.1633, Val Loss: 0.5358
Epoch [81/250], Loss: 0.0500, Val Loss: 0.6003
Epoch [82/250], Loss: 0.3253, Val Loss: 0.5491
Epoch [83/250], Loss: 0.1720, Val Loss: 0.5525
Epoch [84/250], Loss: 0.1757, Val Loss: 0.5586
Epoch [85/250], Loss: 0.1805, Val Loss: 0.6239
Epoch [86/250], Loss: 0.2008, Val Loss: 0.7105
Epoch [87/250], Loss: 0.2288, Val Loss: 0.5731
Epoch [88/250], Loss: 0.1021, Val Loss: 0.6062
Epoch [89/250], Loss: 0.2417, Val Loss: 0.6288
Epoch [90/250], Loss: 0.6319, Val Loss: 0.6446
Epoch [91/250], Loss: 0.1106, Val Loss: 0.6030
Epoch [92/250], Loss: 0.5814, Val Loss: 0.5765
Epoch [93/250], Loss: 0.2433, Val Loss: 0.5738
Epoch [94/250], Loss: 0.1971, Val Loss: 0.6526
Epoch [95/250], Loss: 0.0957, Val Loss: 0.5848
Epoch [96/250], Loss: 0.1958, Val Loss: 0.5594
Epoch [97/250], Loss: 0.5785, Val Loss: 0.5516
Epoch [98/250], Loss: 0.2264, Val Loss: 0.5603
Epoch [99/250], Loss: 0.0656, Val Loss: 0.5763
Epoch [100/250], Loss: 0.0961, Val Loss: 0.6155
Epoch [101/250], Loss: 0.0785, Val Loss: 0.5688
Epoch [102/250], Loss: 0.2581, Val Loss: 0.6043
Epoch [103/250], Loss: 0.0788, Val Loss: 0.5801
Epoch [104/250], Loss: 0.3117, Val Loss: 0.5637
Epoch [105/250], Loss: 0.0642, Val Loss: 0.5693
Epoch [106/250], Loss: 0.0657, Val Loss: 0.5234
Epoch [107/250], Loss: 0.1699, Val Loss: 0.5971
Epoch [108/250], Loss: 0.3331, Val Loss: 0.5411
Epoch [109/250], Loss: 0.1154, Val Loss: 0.6556
Epoch [110/250], Loss: 0.3541, Val Loss: 0.5395
Epoch [111/250], Loss: 0.2978, Val Loss: 0.5984
Epoch [112/250], Loss: 0.2979, Val Loss: 0.5813
Epoch [113/250], Loss: 0.4622, Val Loss: 0.5400
Epoch [114/250], Loss: 0.0888, Val Loss: 0.5403
Epoch [115/250], Loss: 0.2671, Val Loss: 0.6173
Epoch [116/250], Loss: 0.3717, Val Loss: 0.5514
Epoch [117/250], Loss: 0.0633, Val Loss: 0.5438
Epoch [118/250], Loss: 0.1567, Val Loss: 0.5572
Epoch [119/250], Loss: 0.0719, Val Loss: 0.5691
Epoch [120/250], Loss: 0.2636, Val Loss: 0.6576
Epoch [121/250], Loss: 0.2560, Val Loss: 0.5519
Epoch [122/250], Loss: 0.1307, Val Loss: 0.5437
Epoch [123/250], Loss: 1.3354, Val Loss: 0.5188
Epoch [124/250], Loss: 0.2871, Val Loss: 0.5495
Epoch [125/250], Loss: 0.0675, Val Loss: 0.5884
Epoch [126/250], Loss: 0.2074, Val Loss: 0.5390
Epoch [127/250], Loss: 0.0657, Val Loss: 0.5566
Epoch [128/250], Loss: 0.0596, Val Loss: 0.5654
Epoch [129/250], Loss: 0.1653, Val Loss: 0.5500
Epoch [130/250], Loss: 0.2282, Val Loss: 0.5466
Epoch [131/250], Loss: 0.3319, Val Loss: 0.5333
Epoch [132/250], Loss: 0.2651, Val Loss: 0.5636
Epoch [133/250], Loss: 0.1346, Val Loss: 0.5576
Epoch [134/250], Loss: 0.0342, Val Loss: 0.5464
Epoch [135/250], Loss: 0.0746, Val Loss: 0.5547
Epoch [136/250], Loss: 0.1272, Val Loss: 0.5927
Epoch [137/250], Loss: 0.0976, Val Loss: 0.5459
Epoch [138/250], Loss: 0.1162, Val Loss: 0.5664
Epoch [139/250], Loss: 0.0350, Val Loss: 0.5407
Epoch [140/250], Loss: 0.0825, Val Loss: 0.5780
Epoch [141/250], Loss: 0.7062, Val Loss: 0.5318
Epoch [142/250], Loss: 0.1389, Val Loss: 0.5403
Epoch [143/250], Loss: 0.2527, Val Loss: 0.5505
TruncatedSVD_50
MLP with layer size: [111, 55, 25] - Result:
Epoch [1/90], Loss: 0.1249, Val Loss: 0.5356
Epoch [2/90], Loss: 0.1544, Val Loss: 0.5603
Epoch [3/90], Loss: 0.2535, Val Loss: 0.5364
Epoch [4/90], Loss: 0.2410, Val Loss: 0.5254
Epoch [5/90], Loss: 0.1075, Val Loss: 0.5656
Epoch [6/90], Loss: 0.2685, Val Loss: 0.5931
Epoch [7/90], Loss: 0.0859, Val Loss: 0.5842
Epoch [8/90], Loss: 0.0702, Val Loss: 0.5662
Epoch [9/90], Loss: 0.3889, Val Loss: 0.5347
Epoch [10/90], Loss: 0.2327, Val Loss: 0.5305
Epoch [11/90], Loss: 0.3328, Val Loss: 0.5357
Epoch [12/90], Loss: 0.1874, Val Loss: 0.5391
Epoch [13/90], Loss: 0.2055, Val Loss: 0.5158
Epoch [14/90], Loss: 0.1083, Val Loss: 0.5228
Epoch [15/90], Loss: 0.1554, Val Loss: 0.5625
Epoch [16/90], Loss: 0.1805, Val Loss: 0.5611
Epoch [17/90], Loss: 0.3067, Val Loss: 0.5440
Epoch [18/90], Loss: 0.1176, Val Loss: 0.5389
Epoch [19/90], Loss: 0.1777, Val Loss: 0.5563
Epoch [20/90], Loss: 0.1619, Val Loss: 0.5354
Epoch [21/90], Loss: 0.2291, Val Loss: 0.5876
Epoch [22/90], Loss: 0.0787, Val Loss: 0.5684
Epoch [23/90], Loss: 0.3209, Val Loss: 0.5339
Epoch [24/90], Loss: 0.3449, Val Loss: 0.5544
Epoch [25/90], Loss: 0.0798, Val Loss: 0.5233
Epoch [26/90], Loss: 0.0828, Val Loss: 0.5543
Epoch [27/90], Loss: 0.1368, Val Loss: 0.5504
Epoch [28/90], Loss: 0.0464, Val Loss: 0.5164
Epoch [29/90], Loss: 0.3665, Val Loss: 0.5294
Epoch [30/90], Loss: 0.2142, Val Loss: 0.5203
Epoch [31/90], Loss: 0.2017, Val Loss: 0.5509
Epoch [32/90], Loss: 0.1147, Val Loss: 0.5323
Epoch [33/90], Loss: 0.3463, Val Loss: 0.5286
Epoch [34/90], Loss: 0.1966, Val Loss: 0.5084
Epoch [35/90], Loss: 0.2022, Val Loss: 0.5267
Epoch [36/90], Loss: 0.2211, Val Loss: 0.5441
Epoch [37/90], Loss: 0.6601, Val Loss: 0.5142
Epoch [38/90], Loss: 0.1490, Val Loss: 0.5141
Epoch [39/90], Loss: 0.0489, Val Loss: 0.5219
Epoch [40/90], Loss: 0.1452, Val Loss: 0.5478
Epoch [41/90], Loss: 0.2598, Val Loss: 0.5203
Epoch [42/90], Loss: 0.8557, Val Loss: 0.5284
Epoch [43/90], Loss: 0.0964, Val Loss: 0.5498
Epoch [44/90], Loss: 0.0558, Val Loss: 0.5206
Epoch [45/90], Loss: 0.1632, Val Loss: 0.5498
Epoch [46/90], Loss: 1.1371, Val Loss: 0.5404
Epoch [47/90], Loss: 0.0497, Val Loss: 0.5346
Epoch [48/90], Loss: 0.1001, Val Loss: 0.5411
Epoch [49/90], Loss: 0.1062, Val Loss: 0.4994
Epoch [50/90], Loss: 0.1398, Val Loss: 0.5254
Epoch [51/90], Loss: 0.0451, Val Loss: 0.5438
Epoch [52/90], Loss: 0.5530, Val Loss: 0.5275
Epoch [53/90], Loss: 0.0536, Val Loss: 0.5470
Epoch [54/90], Loss: 0.3915, Val Loss: 0.5886
Epoch [55/90], Loss: 0.2302, Val Loss: 0.5297
Epoch [56/90], Loss: 0.1354, Val Loss: 0.5550
Epoch [57/90], Loss: 0.0915, Val Loss: 0.5110
Epoch [58/90], Loss: 0.1625, Val Loss: 0.5468
Epoch [59/90], Loss: 0.0979, Val Loss: 0.5104
Epoch [60/90], Loss: 0.0301, Val Loss: 0.5388
Epoch [61/90], Loss: 0.0782, Val Loss: 0.5272
Epoch [62/90], Loss: 0.0603, Val Loss: 0.6139
Epoch [63/90], Loss: 0.1639, Val Loss: 0.5079
Epoch [64/90], Loss: 0.1120, Val Loss: 0.5163
Epoch [65/90], Loss: 0.0642, Val Loss: 0.5491
Epoch [66/90], Loss: 0.0739, Val Loss: 0.5478
Epoch [67/90], Loss: 0.1970, Val Loss: 0.4982
Epoch [68/90], Loss: 0.2368, Val Loss: 0.5207
Epoch [69/90], Loss: 0.0890, Val Loss: 0.5186
Epoch [70/90], Loss: 0.1104, Val Loss: 0.5357
Epoch [71/90], Loss: 0.3248, Val Loss: 0.5070
Epoch [72/90], Loss: 0.2157, Val Loss: 0.5133
Epoch [73/90], Loss: 0.6751, Val Loss: 0.5252
Epoch [74/90], Loss: 0.4508, Val Loss: 0.5737
Epoch [75/90], Loss: 0.0488, Val Loss: 0.5239
Epoch [76/90], Loss: 0.0474, Val Loss: 0.5823
Epoch [77/90], Loss: 0.1994, Val Loss: 0.5084
Epoch [78/90], Loss: 0.2397, Val Loss: 0.5598
Epoch [79/90], Loss: 0.0901, Val Loss: 0.5293
Epoch [80/90], Loss: 0.1048, Val Loss: 0.5006
Epoch [81/90], Loss: 0.1386, Val Loss: 0.5614
Epoch [82/90], Loss: 0.7697, Val Loss: 0.6363
Epoch [83/90], Loss: 0.3537, Val Loss: 0.5451
Epoch [84/90], Loss: 0.1809, Val Loss: 0.5491
Epoch [85/90], Loss: 0.0572, Val Loss: 0.5157
Epoch [86/90], Loss: 0.1907, Val Loss: 0.5383
Epoch [87/90], Loss: 0.3903, Val Loss: 0.5540
Epoch [88/90], Loss: 0.1411, Val Loss: 0.5237
Epoch [89/90], Loss: 0.1611, Val Loss: 0.5302
Epoch [90/90], Loss: 1.5588, Val Loss: 0.5664
Runtime: 0:01:52.960259
R^2 Score: 0.9103
RMSE: 0.6780
MAE: 0.1895
MAPE: 15.93%
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1979, Val Loss: 0.8959
Epoch [2/120], Loss: 0.6831, Val Loss: 1.0866
Epoch [3/120], Loss: 0.3215, Val Loss: 0.8238
Epoch [4/120], Loss: 0.3460, Val Loss: 0.7457
Epoch [5/120], Loss: 0.4599, Val Loss: 0.8200
Epoch [6/120], Loss: 0.1103, Val Loss: 0.8336
Epoch [7/120], Loss: 0.2019, Val Loss: 0.7163
Epoch [8/120], Loss: 2.1087, Val Loss: 0.7055
Epoch [9/120], Loss: 0.2246, Val Loss: 0.7525
Epoch [10/120], Loss: 4.2440, Val Loss: 0.6652
Epoch [11/120], Loss: 0.3486, Val Loss: 0.7213
Epoch [12/120], Loss: 0.2121, Val Loss: 0.7146
Epoch [13/120], Loss: 0.1662, Val Loss: 0.6682
Epoch [14/120], Loss: 0.2418, Val Loss: 0.7802
Epoch [15/120], Loss: 0.1145, Val Loss: 0.6334
Epoch [16/120], Loss: 0.2199, Val Loss: 0.6695
Epoch [17/120], Loss: 0.1651, Val Loss: 0.6485
Epoch [18/120], Loss: 0.5587, Val Loss: 0.6845
Epoch [19/120], Loss: 0.5416, Val Loss: 0.7358
Epoch [20/120], Loss: 0.9283, Val Loss: 0.6487
Epoch [21/120], Loss: 0.2388, Val Loss: 0.6445
Epoch [22/120], Loss: 0.1239, Val Loss: 0.6270
Epoch [23/120], Loss: 0.1779, Val Loss: 0.6047
Epoch [24/120], Loss: 0.3039, Val Loss: 0.6176
Epoch [25/120], Loss: 0.1500, Val Loss: 0.6487
Epoch [26/120], Loss: 0.2447, Val Loss: 0.6912
Epoch [27/120], Loss: 0.4335, Val Loss: 0.5762
Epoch [28/120], Loss: 0.0522, Val Loss: 0.6505
Epoch [29/120], Loss: 0.0835, Val Loss: 0.5867
Epoch [30/120], Loss: 0.0511, Val Loss: 0.5697
Epoch [31/120], Loss: 0.2037, Val Loss: 0.6673
Epoch [32/120], Loss: 0.0659, Val Loss: 0.5823
Epoch [33/120], Loss: 0.0893, Val Loss: 0.6100
Epoch [34/120], Loss: 0.1979, Val Loss: 0.7486
Epoch [35/120], Loss: 0.1628, Val Loss: 0.5929
Epoch [36/120], Loss: 0.2751, Val Loss: 0.6865
Epoch [37/120], Loss: 0.3297, Val Loss: 0.6244
Epoch [38/120], Loss: 0.4037, Val Loss: 0.6253
Epoch [39/120], Loss: 0.7232, Val Loss: 0.6499
Epoch [40/120], Loss: 0.3093, Val Loss: 0.6455
Epoch [41/120], Loss: 0.4480, Val Loss: 0.6049
Epoch [42/120], Loss: 0.3790, Val Loss: 0.6413
Epoch [43/120], Loss: 0.1584, Val Loss: 0.6090
Epoch [44/120], Loss: 0.2329, Val Loss: 0.5504
Epoch [45/120], Loss: 0.2762, Val Loss: 0.6168
Epoch [46/120], Loss: 0.4468, Val Loss: 0.5775
Epoch [47/120], Loss: 0.1095, Val Loss: 0.5739
Epoch [48/120], Loss: 0.5889, Val Loss: 0.5877
Epoch [49/120], Loss: 0.0879, Val Loss: 0.5740
Epoch [50/120], Loss: 0.1488, Val Loss: 0.6339
Epoch [51/120], Loss: 0.5337, Val Loss: 0.5459
Epoch [52/120], Loss: 0.2730, Val Loss: 0.5634
Epoch [53/120], Loss: 0.1015, Val Loss: 0.5367
Epoch [54/120], Loss: 0.4104, Val Loss: 0.5610
Epoch [55/120], Loss: 0.1209, Val Loss: 0.5564
Epoch [56/120], Loss: 0.1459, Val Loss: 0.5724
Epoch [57/120], Loss: 0.0308, Val Loss: 0.5737
Epoch [58/120], Loss: 0.0793, Val Loss: 0.6655
Epoch [59/120], Loss: 0.3276, Val Loss: 0.6442
Epoch [60/120], Loss: 0.1158, Val Loss: 0.5253
Epoch [61/120], Loss: 0.8937, Val Loss: 0.5485
Epoch [62/120], Loss: 0.1979, Val Loss: 0.5294
Epoch [63/120], Loss: 0.2799, Val Loss: 0.5451
Epoch [64/120], Loss: 0.4052, Val Loss: 0.6057
Epoch [65/120], Loss: 0.0834, Val Loss: 0.5620
Epoch [66/120], Loss: 0.0724, Val Loss: 0.5522
Epoch [67/120], Loss: 0.0787, Val Loss: 0.5248
Epoch [68/120], Loss: 0.6429, Val Loss: 0.5817
Epoch [69/120], Loss: 0.1569, Val Loss: 0.5572
Epoch [70/120], Loss: 0.3952, Val Loss: 0.5323
Epoch [71/120], Loss: 0.2324, Val Loss: 0.5334
Epoch [72/120], Loss: 0.0882, Val Loss: 0.5370
Epoch [73/120], Loss: 0.1120, Val Loss: 0.5329
Epoch [74/120], Loss: 0.2137, Val Loss: 0.5642
Epoch [75/120], Loss: 0.1437, Val Loss: 0.5258
Epoch [76/120], Loss: 0.0729, Val Loss: 0.5424
Epoch [77/120], Loss: 0.2634, Val Loss: 0.6032
Epoch [78/120], Loss: 0.0916, Val Loss: 0.5732
Epoch [79/120], Loss: 0.1124, Val Loss: 0.6210
Epoch [80/120], Loss: 0.1346, Val Loss: 0.5536
Epoch [81/120], Loss: 0.1055, Val Loss: 0.5307
Epoch [82/120], Loss: 0.1151, Val Loss: 0.5528
Epoch [83/120], Loss: 0.0629, Val Loss: 0.5222
Epoch [84/120], Loss: 0.1534, Val Loss: 0.5706
Epoch [85/120], Loss: 0.0445, Val Loss: 0.5281
Epoch [86/120], Loss: 0.1785, Val Loss: 0.5111
Epoch [87/120], Loss: 0.0992, Val Loss: 0.5464
Epoch [88/120], Loss: 0.1237, Val Loss: 0.5381
Epoch [89/120], Loss: 0.7238, Val Loss: 0.5169
Epoch [90/120], Loss: 0.2281, Val Loss: 0.5908
Epoch [91/120], Loss: 0.1071, Val Loss: 0.5717
Epoch [92/120], Loss: 0.1021, Val Loss: 0.5190
Epoch [93/120], Loss: 0.6736, Val Loss: 0.5311
Epoch [94/120], Loss: 0.0686, Val Loss: 0.5228
Epoch [95/120], Loss: 0.2648, Val Loss: 0.5191
Epoch [96/120], Loss: 0.2889, Val Loss: 0.5907
Epoch [97/120], Loss: 0.1704, Val Loss: 0.5106
Epoch [98/120], Loss: 0.4712, Val Loss: 0.5308
Epoch [99/120], Loss: 0.1031, Val Loss: 0.5694
Epoch [100/120], Loss: 0.3569, Val Loss: 0.5352
Epoch [101/120], Loss: 0.2032, Val Loss: 0.5512
Epoch [102/120], Loss: 0.2801, Val Loss: 0.6068
Epoch [103/120], Loss: 0.1381, Val Loss: 0.6115
Epoch [104/120], Loss: 0.1925, Val Loss: 0.5528
Epoch [105/120], Loss: 0.2099, Val Loss: 0.5222
Epoch [106/120], Loss: 0.0336, Val Loss: 0.5456
Epoch [107/120], Loss: 0.2779, Val Loss: 0.5066
Epoch [108/120], Loss: 0.2878, Val Loss: 0.5113
Epoch [109/120], Loss: 0.2209, Val Loss: 0.5203
Epoch [110/120], Loss: 0.1802, Val Loss: 0.5780
Epoch [111/120], Loss: 0.1699, Val Loss: 0.5282
Epoch [112/120], Loss: 0.0521, Val Loss: 0.5090
Epoch [113/120], Loss: 0.5329, Val Loss: 0.5128
Epoch [114/120], Loss: 0.1641, Val Loss: 0.6074
Epoch [115/120], Loss: 0.1718, Val Loss: 0.5260
Epoch [116/120], Loss: 0.1603, Val Loss: 0.6052
Epoch [117/120], Loss: 0.1888, Val Loss: 0.5368
Epoch [118/120], Loss: 0.2273, Val Loss: 0.5206
Epoch [119/120], Loss: 0.0615, Val Loss: 0.5231
Epoch [120/120], Loss: 0.5407, Val Loss: 0.6885
Runtime: 0:02:26.271350
R^2 Score: 0.8882
RMSE: 0.7570
MAE: 0.2548
MAPE: 20.58%
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.2389, Val Loss: 0.9736
Epoch [2/120], Loss: 0.6760, Val Loss: 0.8083
Epoch [3/120], Loss: 0.1376, Val Loss: 0.7214
Epoch [4/120], Loss: 0.4126, Val Loss: 0.6669
Epoch [5/120], Loss: 0.1230, Val Loss: 0.8944
Epoch [6/120], Loss: 1.6475, Val Loss: 0.6428
Epoch [7/120], Loss: 0.1653, Val Loss: 0.8553
Epoch [8/120], Loss: 0.6018, Val Loss: 0.7939
Epoch [9/120], Loss: 0.3748, Val Loss: 0.6604
Epoch [10/120], Loss: 0.1254, Val Loss: 0.6924
Epoch [11/120], Loss: 0.1880, Val Loss: 0.6555
Epoch [12/120], Loss: 0.2102, Val Loss: 0.6135
Epoch [13/120], Loss: 0.1502, Val Loss: 0.7032
Epoch [14/120], Loss: 0.2980, Val Loss: 0.6621
Epoch [15/120], Loss: 0.1893, Val Loss: 0.6205
Epoch [16/120], Loss: 1.4612, Val Loss: 0.6550
Epoch [17/120], Loss: 0.0572, Val Loss: 0.7057
Epoch [18/120], Loss: 0.3781, Val Loss: 0.6112
Epoch [19/120], Loss: 0.3601, Val Loss: 0.5809
Epoch [20/120], Loss: 0.2538, Val Loss: 0.7302
Epoch [21/120], Loss: 0.1842, Val Loss: 0.6335
Epoch [22/120], Loss: 1.7607, Val Loss: 0.5515
Epoch [23/120], Loss: 0.1252, Val Loss: 0.5657
Epoch [24/120], Loss: 0.5400, Val Loss: 0.6037
Epoch [25/120], Loss: 0.7815, Val Loss: 0.5376
Epoch [26/120], Loss: 0.1636, Val Loss: 0.6022
Epoch [27/120], Loss: 0.1553, Val Loss: 0.5649
Epoch [28/120], Loss: 0.7034, Val Loss: 0.6153
Epoch [29/120], Loss: 0.1183, Val Loss: 0.5980
Epoch [30/120], Loss: 0.2644, Val Loss: 0.6006
Epoch [31/120], Loss: 0.2106, Val Loss: 0.5362
Epoch [32/120], Loss: 0.4222, Val Loss: 0.5963
Epoch [33/120], Loss: 0.2202, Val Loss: 0.5778
Epoch [34/120], Loss: 0.3222, Val Loss: 0.6092
Epoch [35/120], Loss: 0.5668, Val Loss: 0.5763
Epoch [36/120], Loss: 0.0730, Val Loss: 0.5363
Epoch [37/120], Loss: 0.1929, Val Loss: 0.5646
Epoch [38/120], Loss: 0.1150, Val Loss: 0.5946
Epoch [39/120], Loss: 0.5041, Val Loss: 0.5677
Epoch [40/120], Loss: 0.1627, Val Loss: 0.5637
Epoch [41/120], Loss: 0.0988, Val Loss: 0.5246
Epoch [42/120], Loss: 0.6586, Val Loss: 0.5368
Epoch [43/120], Loss: 0.1297, Val Loss: 0.5254
Epoch [44/120], Loss: 0.9392, Val Loss: 0.5422
Epoch [45/120], Loss: 0.1293, Val Loss: 0.5347
Epoch [46/120], Loss: 0.6539, Val Loss: 0.6364
Epoch [47/120], Loss: 1.7075, Val Loss: 0.5373
Epoch [48/120], Loss: 0.9059, Val Loss: 0.5404
Epoch [49/120], Loss: 0.6542, Val Loss: 0.5079
Epoch [50/120], Loss: 0.2458, Val Loss: 0.5412
Epoch [51/120], Loss: 0.0666, Val Loss: 0.5899
Epoch [52/120], Loss: 0.6156, Val Loss: 0.5554
Epoch [53/120], Loss: 0.1918, Val Loss: 0.5498
Epoch [54/120], Loss: 0.0643, Val Loss: 0.5581
Epoch [55/120], Loss: 0.2406, Val Loss: 0.7012
Epoch [56/120], Loss: 0.4846, Val Loss: 0.4948
Epoch [57/120], Loss: 0.7872, Val Loss: 0.4919
Epoch [58/120], Loss: 0.1440, Val Loss: 0.5087
Epoch [59/120], Loss: 0.0902, Val Loss: 0.6973
Epoch [60/120], Loss: 0.8545, Val Loss: 0.5556
Epoch [61/120], Loss: 0.4478, Val Loss: 0.5076
Epoch [62/120], Loss: 0.5147, Val Loss: 0.5359
Epoch [63/120], Loss: 0.1595, Val Loss: 0.5347
Epoch [64/120], Loss: 0.0800, Val Loss: 0.5410
Epoch [65/120], Loss: 0.5162, Val Loss: 0.5075
Epoch [66/120], Loss: 0.1425, Val Loss: 0.4990
Epoch [67/120], Loss: 0.0630, Val Loss: 0.6425
Epoch [68/120], Loss: 0.1178, Val Loss: 0.5286
Epoch [69/120], Loss: 0.7710, Val Loss: 0.4919
Epoch [70/120], Loss: 0.2003, Val Loss: 0.6677
Epoch [71/120], Loss: 0.8867, Val Loss: 0.5162
Epoch [72/120], Loss: 0.1386, Val Loss: 0.5155
Epoch [73/120], Loss: 1.3138, Val Loss: 0.4989
Epoch [74/120], Loss: 0.2434, Val Loss: 0.5011
Epoch [75/120], Loss: 0.2587, Val Loss: 0.5621
Epoch [76/120], Loss: 0.3096, Val Loss: 0.5350
Epoch [77/120], Loss: 0.1407, Val Loss: 0.5413
Epoch [78/120], Loss: 0.0674, Val Loss: 0.5565
Epoch [79/120], Loss: 0.2144, Val Loss: 0.4970
Epoch [80/120], Loss: 0.5547, Val Loss: 0.4874
Epoch [81/120], Loss: 0.0266, Val Loss: 0.5001
Epoch [82/120], Loss: 0.2306, Val Loss: 0.4822
Epoch [83/120], Loss: 0.2443, Val Loss: 0.5202
Epoch [84/120], Loss: 0.0791, Val Loss: 0.5295
Epoch [85/120], Loss: 0.3017, Val Loss: 0.4784
Epoch [86/120], Loss: 0.3224, Val Loss: 0.4762
Epoch [87/120], Loss: 0.0795, Val Loss: 0.5749
Epoch [88/120], Loss: 0.1907, Val Loss: 0.4742
Epoch [89/120], Loss: 0.1757, Val Loss: 0.5214
Epoch [90/120], Loss: 0.4754, Val Loss: 0.5205
Epoch [91/120], Loss: 0.2144, Val Loss: 0.5048
Epoch [92/120], Loss: 0.2162, Val Loss: 0.5040
Epoch [93/120], Loss: 0.2360, Val Loss: 0.5770
Epoch [94/120], Loss: 0.0847, Val Loss: 0.5231
Epoch [95/120], Loss: 0.0704, Val Loss: 0.5521
Epoch [96/120], Loss: 0.1250, Val Loss: 0.4848
Epoch [97/120], Loss: 0.7923, Val Loss: 0.4954
Epoch [98/120], Loss: 0.2374, Val Loss: 0.4824
Epoch [99/120], Loss: 0.1627, Val Loss: 0.4899
Epoch [100/120], Loss: 0.4350, Val Loss: 0.5555
Epoch [101/120], Loss: 2.0542, Val Loss: 0.4980
Epoch [102/120], Loss: 0.1832, Val Loss: 0.5101
Epoch [103/120], Loss: 0.0460, Val Loss: 0.4979
Epoch [104/120], Loss: 1.0513, Val Loss: 0.5037
Epoch [105/120], Loss: 0.9708, Val Loss: 0.5613
Epoch [106/120], Loss: 0.0949, Val Loss: 0.5012
Epoch [107/120], Loss: 0.0567, Val Loss: 0.4911
Epoch [108/120], Loss: 0.0688, Val Loss: 0.4850
Epoch [109/120], Loss: 0.8158, Val Loss: 0.5076
Epoch [110/120], Loss: 0.2771, Val Loss: 0.4568
Epoch [111/120], Loss: 0.1216, Val Loss: 0.5058
Epoch [112/120], Loss: 0.3520, Val Loss: 0.4976
Epoch [113/120], Loss: 0.3977, Val Loss: 0.5169
Epoch [114/120], Loss: 0.2002, Val Loss: 0.4679
Epoch [115/120], Loss: 0.0824, Val Loss: 0.5257
Epoch [116/120], Loss: 0.6169, Val Loss: 0.4698
Epoch [117/120], Loss: 0.2050, Val Loss: 0.4675
Epoch [118/120], Loss: 0.2399, Val Loss: 0.4876
Epoch [119/120], Loss: 0.4028, Val Loss: 0.4881
Epoch [120/120], Loss: 0.2021, Val Loss: 0.6181
Runtime: 0:03:06.477564
R^2 Score: 0.9132
RMSE: 0.6771
MAE: 0.2059
MAPE: 15.95%
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.3798, Val Loss: 0.9600
Epoch [2/120], Loss: 0.1076, Val Loss: 0.8404
Epoch [3/120], Loss: 0.1070, Val Loss: 0.8499
Epoch [4/120], Loss: 0.1649, Val Loss: 0.7758
Epoch [5/120], Loss: 0.4863, Val Loss: 0.7700
Epoch [6/120], Loss: 0.3133, Val Loss: 0.7653
Epoch [7/120], Loss: 0.6118, Val Loss: 0.8869
Epoch [8/120], Loss: 0.1329, Val Loss: 0.7335
Epoch [9/120], Loss: 0.2035, Val Loss: 0.6687
Epoch [10/120], Loss: 0.7222, Val Loss: 0.6797
Epoch [11/120], Loss: 0.6468, Val Loss: 0.7371
Epoch [12/120], Loss: 0.2882, Val Loss: 0.7524
Epoch [13/120], Loss: 0.2971, Val Loss: 0.7311
Epoch [14/120], Loss: 0.3162, Val Loss: 0.6969
Epoch [15/120], Loss: 0.1483, Val Loss: 0.6727
Epoch [16/120], Loss: 0.2635, Val Loss: 0.6826
Epoch [17/120], Loss: 0.1527, Val Loss: 0.6545
Epoch [18/120], Loss: 1.4674, Val Loss: 0.7364
Epoch [19/120], Loss: 0.1109, Val Loss: 0.6096
Epoch [20/120], Loss: 0.2049, Val Loss: 0.7125
Epoch [21/120], Loss: 0.2035, Val Loss: 0.6392
Epoch [22/120], Loss: 0.1722, Val Loss: 0.6335
Epoch [23/120], Loss: 0.4598, Val Loss: 0.6038
Epoch [24/120], Loss: 0.8987, Val Loss: 0.6340
Epoch [25/120], Loss: 0.0960, Val Loss: 0.6358
Epoch [26/120], Loss: 0.1147, Val Loss: 0.7622
Epoch [27/120], Loss: 0.4749, Val Loss: 0.6056
Epoch [28/120], Loss: 0.0613, Val Loss: 0.6306
Epoch [29/120], Loss: 0.0409, Val Loss: 0.7031
Epoch [30/120], Loss: 0.0882, Val Loss: 0.5749
Epoch [31/120], Loss: 0.3840, Val Loss: 0.8500
Epoch [32/120], Loss: 0.4220, Val Loss: 0.6212
Epoch [33/120], Loss: 0.5004, Val Loss: 0.6586
Epoch [34/120], Loss: 0.2639, Val Loss: 0.6207
Epoch [35/120], Loss: 0.0878, Val Loss: 0.6484
Epoch [36/120], Loss: 0.5030, Val Loss: 0.5966
Epoch [37/120], Loss: 0.1701, Val Loss: 0.6034
Epoch [38/120], Loss: 0.3954, Val Loss: 0.6546
Epoch [39/120], Loss: 0.2073, Val Loss: 0.5686
Epoch [40/120], Loss: 0.6730, Val Loss: 0.6462
Epoch [41/120], Loss: 0.1091, Val Loss: 0.6357
Epoch [42/120], Loss: 0.6894, Val Loss: 0.6018
Epoch [43/120], Loss: 0.0853, Val Loss: 0.6832
Epoch [44/120], Loss: 0.1613, Val Loss: 0.6789
Epoch [45/120], Loss: 0.4071, Val Loss: 0.7088
Epoch [46/120], Loss: 0.5282, Val Loss: 0.6220
Epoch [47/120], Loss: 0.1805, Val Loss: 0.6669
Epoch [48/120], Loss: 0.0439, Val Loss: 0.5922
Epoch [49/120], Loss: 0.1439, Val Loss: 0.5819
Epoch [50/120], Loss: 0.1311, Val Loss: 0.6258
Epoch [51/120], Loss: 0.1002, Val Loss: 0.6332
Epoch [52/120], Loss: 0.5377, Val Loss: 0.6163
Epoch [53/120], Loss: 0.4330, Val Loss: 0.5890
Epoch [54/120], Loss: 0.0688, Val Loss: 0.7250
Epoch [55/120], Loss: 0.2525, Val Loss: 0.6591
Epoch [56/120], Loss: 0.1107, Val Loss: 0.6058
Epoch [57/120], Loss: 1.1590, Val Loss: 0.5697
Epoch [58/120], Loss: 0.0903, Val Loss: 0.5519
Epoch [59/120], Loss: 0.3801, Val Loss: 0.5523
Epoch [60/120], Loss: 0.4215, Val Loss: 0.6009
Epoch [61/120], Loss: 0.3767, Val Loss: 0.5861
Epoch [62/120], Loss: 0.2622, Val Loss: 0.5670
Epoch [63/120], Loss: 0.4984, Val Loss: 0.7827
Epoch [64/120], Loss: 0.2082, Val Loss: 0.6137
Epoch [65/120], Loss: 0.2364, Val Loss: 0.5531
Epoch [66/120], Loss: 0.1371, Val Loss: 0.5312
Epoch [67/120], Loss: 0.1263, Val Loss: 0.5620
Epoch [68/120], Loss: 0.2741, Val Loss: 0.5882
Epoch [69/120], Loss: 0.0667, Val Loss: 0.5601
Epoch [70/120], Loss: 0.0921, Val Loss: 0.5334
Epoch [71/120], Loss: 0.2281, Val Loss: 0.5571
Epoch [72/120], Loss: 0.1064, Val Loss: 0.6117
Epoch [73/120], Loss: 0.6761, Val Loss: 0.5467
Epoch [74/120], Loss: 0.6260, Val Loss: 0.5554
Epoch [75/120], Loss: 0.3228, Val Loss: 0.5569
Epoch [76/120], Loss: 0.0695, Val Loss: 0.5887
Epoch [77/120], Loss: 0.2118, Val Loss: 0.5599
Epoch [78/120], Loss: 0.0664, Val Loss: 0.6041
Epoch [79/120], Loss: 0.6205, Val Loss: 0.5320
Epoch [80/120], Loss: 0.1027, Val Loss: 0.5928
Epoch [81/120], Loss: 0.0888, Val Loss: 0.5303
Epoch [82/120], Loss: 0.1247, Val Loss: 0.5472
Epoch [83/120], Loss: 0.0627, Val Loss: 0.5618
Epoch [84/120], Loss: 0.1350, Val Loss: 0.5649
Epoch [85/120], Loss: 0.1130, Val Loss: 0.5800
Epoch [86/120], Loss: 0.2864, Val Loss: 0.5915
Epoch [87/120], Loss: 0.2507, Val Loss: 0.5332
Epoch [88/120], Loss: 0.1512, Val Loss: 0.5754
Epoch [89/120], Loss: 0.1287, Val Loss: 0.6122
Epoch [90/120], Loss: 0.0997, Val Loss: 0.6090
Epoch [91/120], Loss: 0.4184, Val Loss: 0.5818
Epoch [92/120], Loss: 0.1366, Val Loss: 0.5556
Epoch [93/120], Loss: 0.1768, Val Loss: 0.6099
Epoch [94/120], Loss: 0.2120, Val Loss: 0.5472
Epoch [95/120], Loss: 0.3458, Val Loss: 0.5340
Epoch [96/120], Loss: 0.1174, Val Loss: 0.5448
Epoch [97/120], Loss: 0.1148, Val Loss: 0.5550
Epoch [98/120], Loss: 0.1902, Val Loss: 0.5645
Epoch [99/120], Loss: 0.2004, Val Loss: 0.5304
Epoch [100/120], Loss: 0.3293, Val Loss: 0.5593
Epoch [101/120], Loss: 0.2025, Val Loss: 0.5492
Epoch [102/120], Loss: 0.1136, Val Loss: 0.5803
Epoch [103/120], Loss: 0.3069, Val Loss: 0.5315
Epoch [104/120], Loss: 0.7500, Val Loss: 0.5347
Epoch [105/120], Loss: 0.0983, Val Loss: 0.5384
Epoch [106/120], Loss: 0.1914, Val Loss: 0.5314
Epoch [107/120], Loss: 0.2025, Val Loss: 0.5527
Epoch [108/120], Loss: 0.1832, Val Loss: 0.5259
Epoch [109/120], Loss: 5.8681, Val Loss: 0.5401
Epoch [110/120], Loss: 0.0955, Val Loss: 0.5553
Epoch [111/120], Loss: 0.1485, Val Loss: 0.5998
Epoch [112/120], Loss: 0.0510, Val Loss: 0.5557
Epoch [113/120], Loss: 0.1441, Val Loss: 0.5288
Epoch [114/120], Loss: 0.0778, Val Loss: 0.5317
Epoch [115/120], Loss: 0.1324, Val Loss: 0.5301
Epoch [116/120], Loss: 0.2698, Val Loss: 0.5396
Epoch [117/120], Loss: 0.2330, Val Loss: 0.5269
Epoch [118/120], Loss: 0.2021, Val Loss: 0.5735
Epoch [119/120], Loss: 0.3364, Val Loss: 0.5437
Epoch [120/120], Loss: 0.3247, Val Loss: 0.5084
Runtime: 0:03:07.469154
R^2 Score: 0.9107
RMSE: 0.6769
MAE: 0.1978
MAPE: 17.59%
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1215, Val Loss: 0.5348
Epoch [2/120], Loss: 0.0944, Val Loss: 0.5237
Epoch [3/120], Loss: 0.3997, Val Loss: 0.5210
Epoch [4/120], Loss: 0.1076, Val Loss: 0.5398
Epoch [5/120], Loss: 0.7631, Val Loss: 0.5189
Epoch [6/120], Loss: 0.1255, Val Loss: 0.5540
Epoch [7/120], Loss: 0.5789, Val Loss: 0.5917
Epoch [8/120], Loss: 0.8460, Val Loss: 0.5389
Epoch [9/120], Loss: 0.1121, Val Loss: 0.5268
Epoch [10/120], Loss: 0.1356, Val Loss: 0.5415
Epoch [11/120], Loss: 0.5208, Val Loss: 0.5731
Epoch [12/120], Loss: 0.3524, Val Loss: 0.5910
Epoch [13/120], Loss: 0.4159, Val Loss: 0.5243
Epoch [14/120], Loss: 0.0763, Val Loss: 0.5415
Epoch [15/120], Loss: 0.1165, Val Loss: 0.5229
Epoch [16/120], Loss: 0.5103, Val Loss: 0.6148
Epoch [17/120], Loss: 0.2680, Val Loss: 0.5063
Epoch [18/120], Loss: 0.1337, Val Loss: 0.5196
Epoch [19/120], Loss: 0.4235, Val Loss: 0.5525
Epoch [20/120], Loss: 0.1070, Val Loss: 0.5568
Epoch [21/120], Loss: 0.1832, Val Loss: 0.5469
Epoch [22/120], Loss: 0.1527, Val Loss: 0.5684
Epoch [23/120], Loss: 0.1867, Val Loss: 0.4944
Epoch [24/120], Loss: 0.0995, Val Loss: 0.5863
Epoch [25/120], Loss: 0.1521, Val Loss: 0.5099
Epoch [26/120], Loss: 0.0792, Val Loss: 0.5223
Epoch [27/120], Loss: 0.2033, Val Loss: 0.5333
Epoch [28/120], Loss: 0.1037, Val Loss: 0.5565
Epoch [29/120], Loss: 0.5715, Val Loss: 0.5427
Epoch [30/120], Loss: 0.2717, Val Loss: 0.5288
Epoch [31/120], Loss: 0.0656, Val Loss: 0.5301
Epoch [32/120], Loss: 0.1066, Val Loss: 0.5619
Epoch [33/120], Loss: 0.1316, Val Loss: 0.5610
Epoch [34/120], Loss: 0.1003, Val Loss: 0.5731
Epoch [35/120], Loss: 0.0736, Val Loss: 0.5182
Epoch [36/120], Loss: 1.1427, Val Loss: 0.6609
Epoch [37/120], Loss: 0.1259, Val Loss: 0.5721
Epoch [38/120], Loss: 0.0886, Val Loss: 0.5575
Epoch [39/120], Loss: 0.4495, Val Loss: 0.5673
Epoch [40/120], Loss: 0.1026, Val Loss: 0.5056
Epoch [41/120], Loss: 0.1168, Val Loss: 0.4978
Epoch [42/120], Loss: 0.1375, Val Loss: 0.5323
Epoch [43/120], Loss: 0.1327, Val Loss: 0.5310
Epoch [44/120], Loss: 0.1040, Val Loss: 0.5952
Epoch [45/120], Loss: 0.6655, Val Loss: 0.5290
Epoch [46/120], Loss: 0.1853, Val Loss: 0.5344
Epoch [47/120], Loss: 0.3150, Val Loss: 0.5217
Epoch [48/120], Loss: 0.3006, Val Loss: 0.5494
Epoch [49/120], Loss: 0.0945, Val Loss: 0.5678
Epoch [50/120], Loss: 0.1716, Val Loss: 0.5773
Epoch [51/120], Loss: 0.2312, Val Loss: 0.5906
Epoch [52/120], Loss: 0.1001, Val Loss: 0.5455
Epoch [53/120], Loss: 0.4612, Val Loss: 0.5209
Epoch [54/120], Loss: 0.1464, Val Loss: 0.5178
Epoch [55/120], Loss: 0.4893, Val Loss: 0.5302
Epoch [56/120], Loss: 0.0980, Val Loss: 0.5528
Epoch [57/120], Loss: 0.1213, Val Loss: 0.5898
Epoch [58/120], Loss: 0.1827, Val Loss: 0.5379
Epoch [59/120], Loss: 0.8872, Val Loss: 0.5351
Epoch [60/120], Loss: 0.4757, Val Loss: 0.5218
Epoch [61/120], Loss: 0.1898, Val Loss: 0.5168
Epoch [62/120], Loss: 0.6126, Val Loss: 0.5627
Epoch [63/120], Loss: 0.1230, Val Loss: 0.5128
Epoch [64/120], Loss: 0.0968, Val Loss: 0.5166
Epoch [65/120], Loss: 0.5151, Val Loss: 0.5408
Epoch [66/120], Loss: 0.1510, Val Loss: 0.5096
Epoch [67/120], Loss: 0.2266, Val Loss: 0.5293
Epoch [68/120], Loss: 0.0963, Val Loss: 0.5688
Epoch [69/120], Loss: 0.1783, Val Loss: 0.6289
Epoch [70/120], Loss: 0.1248, Val Loss: 0.5175
Early stopping at epoch 70
Runtime: 0:01:49.065793
R^2 Score: 0.9374
RMSE: 0.5664
MAE: 0.1886
MAPE: 17.41%
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0601, Val Loss: 0.5352
Epoch [2/120], Loss: 0.2010, Val Loss: 0.5213
Epoch [3/120], Loss: 0.1428, Val Loss: 0.4956
Epoch [4/120], Loss: 0.1345, Val Loss: 0.5633
Epoch [5/120], Loss: 0.0868, Val Loss: 0.5159
Epoch [6/120], Loss: 0.2151, Val Loss: 0.5179
Epoch [7/120], Loss: 0.3066, Val Loss: 0.5218
Epoch [8/120], Loss: 0.0664, Val Loss: 0.5513
Epoch [9/120], Loss: 0.3797, Val Loss: 0.5438
Epoch [10/120], Loss: 0.1934, Val Loss: 0.5078
Epoch [11/120], Loss: 0.6911, Val Loss: 0.5402
Epoch [12/120], Loss: 0.2442, Val Loss: 0.5250
Epoch [13/120], Loss: 0.1217, Val Loss: 0.6083
Epoch [14/120], Loss: 0.0567, Val Loss: 0.5040
Epoch [15/120], Loss: 0.0905, Val Loss: 0.5313
Epoch [16/120], Loss: 0.1291, Val Loss: 0.5076
Epoch [17/120], Loss: 0.1131, Val Loss: 0.5055
Epoch [18/120], Loss: 0.5108, Val Loss: 0.5426
Epoch [19/120], Loss: 0.1957, Val Loss: 0.4845
Epoch [20/120], Loss: 0.1305, Val Loss: 0.5239
Epoch [21/120], Loss: 0.1254, Val Loss: 0.5806
Epoch [22/120], Loss: 0.1476, Val Loss: 0.4998
Epoch [23/120], Loss: 0.0683, Val Loss: 0.4924
Epoch [24/120], Loss: 0.3724, Val Loss: 0.5226
Epoch [25/120], Loss: 0.6866, Val Loss: 0.5282
Epoch [26/120], Loss: 0.1293, Val Loss: 0.5276
Epoch [27/120], Loss: 0.7493, Val Loss: 0.4987
Epoch [28/120], Loss: 0.3631, Val Loss: 0.5184
Epoch [29/120], Loss: 0.0704, Val Loss: 0.6334
Epoch [30/120], Loss: 0.1595, Val Loss: 0.5287
Epoch [31/120], Loss: 0.2983, Val Loss: 0.5272
Epoch [32/120], Loss: 0.0696, Val Loss: 0.5305
Epoch [33/120], Loss: 0.2244, Val Loss: 0.6230
Epoch [34/120], Loss: 0.1335, Val Loss: 0.6635
Epoch [35/120], Loss: 0.1287, Val Loss: 0.5144
Epoch [36/120], Loss: 0.7147, Val Loss: 0.5049
Epoch [37/120], Loss: 0.0943, Val Loss: 0.5351
Epoch [38/120], Loss: 0.2869, Val Loss: 0.5635
Epoch [39/120], Loss: 0.3364, Val Loss: 0.5403
Epoch [40/120], Loss: 0.0767, Val Loss: 0.5268
Epoch [41/120], Loss: 0.1244, Val Loss: 0.5423
Epoch [42/120], Loss: 0.1370, Val Loss: 0.5176
Epoch [43/120], Loss: 0.6963, Val Loss: 0.5955
Epoch [44/120], Loss: 0.0651, Val Loss: 0.5413
Epoch [45/120], Loss: 0.0850, Val Loss: 0.5538
Epoch [46/120], Loss: 0.1011, Val Loss: 0.5427
Epoch [47/120], Loss: 0.1351, Val Loss: 0.5480
Epoch [48/120], Loss: 0.0941, Val Loss: 0.5081
Early stopping at epoch 48
Runtime: 0:01:20.876481
R^2 Score: 0.9227
RMSE: 0.6296
MAE: 0.1954
MAPE: 17.38%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 1.0344, Val Loss: 0.8045
Epoch [2/120], Loss: 2.3658, Val Loss: 0.7639
Epoch [3/120], Loss: 0.1740, Val Loss: 0.8520
Epoch [4/120], Loss: 0.2969, Val Loss: 0.7103
Epoch [5/120], Loss: 0.1644, Val Loss: 0.7553
Epoch [6/120], Loss: 0.4745, Val Loss: 0.7021
Epoch [7/120], Loss: 2.3504, Val Loss: 0.7102
Epoch [8/120], Loss: 0.2239, Val Loss: 0.6882
Epoch [9/120], Loss: 0.6484, Val Loss: 0.7452
Epoch [10/120], Loss: 0.1393, Val Loss: 0.6919
Epoch [11/120], Loss: 0.1292, Val Loss: 0.6740
Epoch [12/120], Loss: 3.2877, Val Loss: 0.6490
Epoch [13/120], Loss: 0.0379, Val Loss: 0.8066
Epoch [14/120], Loss: 0.0777, Val Loss: 0.6393
Epoch [15/120], Loss: 0.2274, Val Loss: 0.6483
Epoch [16/120], Loss: 0.4783, Val Loss: 0.6229
Epoch [17/120], Loss: 0.0811, Val Loss: 0.6472
Epoch [18/120], Loss: 0.1094, Val Loss: 0.6725
Epoch [19/120], Loss: 0.4586, Val Loss: 0.8012
Epoch [20/120], Loss: 0.1583, Val Loss: 0.6639
Epoch [21/120], Loss: 0.1150, Val Loss: 0.7820
Epoch [22/120], Loss: 0.0895, Val Loss: 0.6009
Epoch [23/120], Loss: 0.0737, Val Loss: 0.5761
Epoch [24/120], Loss: 0.1844, Val Loss: 0.7291
Epoch [25/120], Loss: 0.2628, Val Loss: 0.5519
Epoch [26/120], Loss: 0.3670, Val Loss: 0.5644
Epoch [27/120], Loss: 0.4913, Val Loss: 0.5685
Epoch [28/120], Loss: 0.5095, Val Loss: 0.6640
Epoch [29/120], Loss: 0.0664, Val Loss: 0.6070
Epoch [30/120], Loss: 0.1059, Val Loss: 0.6672
Epoch [31/120], Loss: 0.1304, Val Loss: 0.5510
Epoch [32/120], Loss: 0.0512, Val Loss: 0.5708
Epoch [33/120], Loss: 0.0729, Val Loss: 0.6040
Epoch [34/120], Loss: 2.1340, Val Loss: 0.5699
Epoch [35/120], Loss: 0.3854, Val Loss: 0.6868
Epoch [36/120], Loss: 0.1431, Val Loss: 0.5500
Epoch [37/120], Loss: 0.1231, Val Loss: 0.5915
Epoch [38/120], Loss: 0.1824, Val Loss: 0.5744
Epoch [39/120], Loss: 0.2287, Val Loss: 0.5705
Epoch [40/120], Loss: 0.4954, Val Loss: 0.5579
Epoch [41/120], Loss: 0.9575, Val Loss: 0.6898
Epoch [42/120], Loss: 0.1950, Val Loss: 0.5554
Epoch [43/120], Loss: 0.1154, Val Loss: 0.6332
Epoch [44/120], Loss: 0.4926, Val Loss: 0.5508
Epoch [45/120], Loss: 0.3925, Val Loss: 0.5565
Epoch [46/120], Loss: 0.9886, Val Loss: 0.5642
Epoch [47/120], Loss: 0.0951, Val Loss: 0.5657
Epoch [48/120], Loss: 1.1700, Val Loss: 0.5372
Epoch [49/120], Loss: 0.3671, Val Loss: 0.6212
Epoch [50/120], Loss: 0.2349, Val Loss: 0.5438
Epoch [51/120], Loss: 0.6179, Val Loss: 0.6560
Epoch [52/120], Loss: 0.4240, Val Loss: 0.5585
Epoch [53/120], Loss: 0.2051, Val Loss: 0.5816
Epoch [54/120], Loss: 0.0800, Val Loss: 0.5715
Epoch [55/120], Loss: 0.0525, Val Loss: 0.5112
Epoch [56/120], Loss: 0.2995, Val Loss: 0.5926
Epoch [57/120], Loss: 0.1079, Val Loss: 0.5483
Epoch [58/120], Loss: 0.3026, Val Loss: 0.5683
Epoch [59/120], Loss: 0.0833, Val Loss: 0.7069
Epoch [60/120], Loss: 0.1199, Val Loss: 0.5607
Epoch [61/120], Loss: 0.0615, Val Loss: 0.6733
Epoch [62/120], Loss: 0.2912, Val Loss: 0.6495
Epoch [63/120], Loss: 0.0615, Val Loss: 0.5333
Epoch [64/120], Loss: 0.1463, Val Loss: 0.5566
Epoch [65/120], Loss: 0.2102, Val Loss: 0.5486
Epoch [66/120], Loss: 0.0865, Val Loss: 0.5659
Epoch [67/120], Loss: 0.1574, Val Loss: 0.5493
Epoch [68/120], Loss: 0.2432, Val Loss: 0.5599
Epoch [69/120], Loss: 0.1971, Val Loss: 0.5896
Epoch [70/120], Loss: 0.0633, Val Loss: 0.5570
Epoch [71/120], Loss: 0.2952, Val Loss: 0.5688
Epoch [72/120], Loss: 0.0702, Val Loss: 0.5918
Epoch [73/120], Loss: 0.0913, Val Loss: 0.5551
Epoch [74/120], Loss: 0.0654, Val Loss: 0.6664
Epoch [75/120], Loss: 0.1929, Val Loss: 0.5494
Epoch [76/120], Loss: 0.1429, Val Loss: 0.5529
Epoch [77/120], Loss: 0.4403, Val Loss: 0.5211
Epoch [78/120], Loss: 0.1493, Val Loss: 0.6024
Epoch [79/120], Loss: 0.3676, Val Loss: 0.5549
Epoch [80/120], Loss: 0.2638, Val Loss: 0.5386
Epoch [81/120], Loss: 0.5658, Val Loss: 0.5851
Epoch [82/120], Loss: 0.2439, Val Loss: 0.5251
Epoch [83/120], Loss: 0.5720, Val Loss: 0.5644
Epoch [84/120], Loss: 0.1607, Val Loss: 0.5513
Early stopping at epoch 84
Runtime: 0:02:04.254771
R^2 Score: 0.9036
RMSE: 0.7138
MAE: 0.2077
MAPE: 16.17%
Using optimizer: Adam
With PSO (1200 iter) initialization
Standard data
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.2560, Val Loss: 0.8224
Epoch [2/120], Loss: 0.6421, Val Loss: 0.6734
Epoch [3/120], Loss: 0.9558, Val Loss: 0.7498
Epoch [4/120], Loss: 0.5802, Val Loss: 0.6537
Epoch [5/120], Loss: 0.4506, Val Loss: 0.6645
Epoch [6/120], Loss: 0.6330, Val Loss: 0.6842
Epoch [7/120], Loss: 0.2076, Val Loss: 0.6923
Epoch [8/120], Loss: 0.2447, Val Loss: 0.7299
Epoch [9/120], Loss: 1.4789, Val Loss: 0.6369
Epoch [10/120], Loss: 1.4729, Val Loss: 0.5998
Epoch [11/120], Loss: 0.0924, Val Loss: 0.6409
Epoch [12/120], Loss: 1.5404, Val Loss: 0.5999
Epoch [13/120], Loss: 0.4722, Val Loss: 0.5959
Epoch [14/120], Loss: 0.0981, Val Loss: 0.5777
Epoch [15/120], Loss: 0.0874, Val Loss: 0.5784
Epoch [16/120], Loss: 0.3150, Val Loss: 0.6014
Epoch [17/120], Loss: 0.1238, Val Loss: 0.6100
Epoch [18/120], Loss: 0.0900, Val Loss: 0.6179
Epoch [19/120], Loss: 4.1327, Val Loss: 0.6303
Epoch [20/120], Loss: 0.0792, Val Loss: 0.5976
Epoch [21/120], Loss: 0.1978, Val Loss: 0.5599
Epoch [22/120], Loss: 0.4621, Val Loss: 0.6324
Epoch [23/120], Loss: 0.2378, Val Loss: 0.5569
Epoch [24/120], Loss: 0.3674, Val Loss: 0.5433
Epoch [25/120], Loss: 0.2479, Val Loss: 0.5416
Epoch [26/120], Loss: 0.2271, Val Loss: 0.5032
Epoch [27/120], Loss: 0.3751, Val Loss: 0.5516
Epoch [28/120], Loss: 0.2147, Val Loss: 0.6857
Epoch [29/120], Loss: 0.4183, Val Loss: 0.5397
Epoch [30/120], Loss: 0.1316, Val Loss: 0.5598
Epoch [31/120], Loss: 0.1850, Val Loss: 0.5971
Epoch [32/120], Loss: 0.1547, Val Loss: 0.6213
Epoch [33/120], Loss: 0.2014, Val Loss: 0.5172
Epoch [34/120], Loss: 0.2820, Val Loss: 0.5751
Epoch [35/120], Loss: 0.5189, Val Loss: 0.5493
Epoch [36/120], Loss: 0.0868, Val Loss: 0.6220
Epoch [37/120], Loss: 0.6445, Val Loss: 0.6057
Epoch [38/120], Loss: 0.2932, Val Loss: 0.5696
Epoch [39/120], Loss: 0.2026, Val Loss: 0.5356
Epoch [40/120], Loss: 0.1073, Val Loss: 0.5128
Epoch [41/120], Loss: 0.4102, Val Loss: 0.5376
Epoch [42/120], Loss: 0.1607, Val Loss: 0.5266
Epoch [43/120], Loss: 0.3791, Val Loss: 0.5147
Epoch [44/120], Loss: 0.2983, Val Loss: 0.4941
Epoch [45/120], Loss: 0.1105, Val Loss: 0.5024
Epoch [46/120], Loss: 0.1107, Val Loss: 0.5596
Epoch [47/120], Loss: 0.1369, Val Loss: 0.6222
Epoch [48/120], Loss: 0.0982, Val Loss: 0.5212
Epoch [49/120], Loss: 0.0973, Val Loss: 0.5484
Epoch [50/120], Loss: 0.2336, Val Loss: 0.5944
Epoch [51/120], Loss: 0.1332, Val Loss: 0.5444
Epoch [52/120], Loss: 0.1818, Val Loss: 0.5102
Epoch [53/120], Loss: 0.2695, Val Loss: 0.4746
Epoch [54/120], Loss: 0.1750, Val Loss: 0.5574
Epoch [55/120], Loss: 0.1666, Val Loss: 0.5495
Epoch [56/120], Loss: 0.0966, Val Loss: 0.5340
Epoch [57/120], Loss: 0.0805, Val Loss: 0.5117
Epoch [58/120], Loss: 0.1416, Val Loss: 0.5291
Epoch [59/120], Loss: 1.1059, Val Loss: 0.5323
Epoch [60/120], Loss: 0.1990, Val Loss: 0.5763
Epoch [61/120], Loss: 0.6556, Val Loss: 0.5282
Epoch [62/120], Loss: 0.2811, Val Loss: 0.4726
Epoch [63/120], Loss: 0.6061, Val Loss: 0.4937
Epoch [64/120], Loss: 0.0845, Val Loss: 0.5317
Epoch [65/120], Loss: 0.3430, Val Loss: 0.5583
Epoch [66/120], Loss: 0.3723, Val Loss: 0.5006
Epoch [67/120], Loss: 0.4304, Val Loss: 0.5580
Epoch [68/120], Loss: 0.1497, Val Loss: 0.4999
Epoch [69/120], Loss: 0.1439, Val Loss: 0.6062
Epoch [70/120], Loss: 0.2423, Val Loss: 0.5141
Epoch [71/120], Loss: 0.0842, Val Loss: 0.6647
Epoch [72/120], Loss: 0.3995, Val Loss: 0.6012
Epoch [73/120], Loss: 0.1028, Val Loss: 0.5378
Epoch [74/120], Loss: 0.2296, Val Loss: 0.6249
Epoch [75/120], Loss: 0.1725, Val Loss: 0.4812
Epoch [76/120], Loss: 0.0899, Val Loss: 0.5082
Epoch [77/120], Loss: 0.0855, Val Loss: 0.4909
Epoch [78/120], Loss: 0.1448, Val Loss: 0.5395
Epoch [79/120], Loss: 0.0704, Val Loss: 0.5236
Epoch [80/120], Loss: 0.2118, Val Loss: 0.5209
Epoch [81/120], Loss: 0.1755, Val Loss: 0.5131
Epoch [82/120], Loss: 0.2805, Val Loss: 0.5104
Epoch [83/120], Loss: 0.0782, Val Loss: 0.5056
Epoch [84/120], Loss: 0.3610, Val Loss: 0.4714
Epoch [85/120], Loss: 0.1550, Val Loss: 0.5723
Epoch [86/120], Loss: 0.1649, Val Loss: 0.5152
Epoch [87/120], Loss: 0.1174, Val Loss: 0.5247
Epoch [88/120], Loss: 0.2039, Val Loss: 0.5501
Epoch [89/120], Loss: 0.2466, Val Loss: 0.4953
Epoch [90/120], Loss: 0.1050, Val Loss: 0.4991
Epoch [91/120], Loss: 0.1033, Val Loss: 0.5091
Epoch [92/120], Loss: 0.2032, Val Loss: 0.5737
Epoch [93/120], Loss: 0.1359, Val Loss: 0.5408
Epoch [94/120], Loss: 1.6212, Val Loss: 0.5047
Epoch [95/120], Loss: 0.0423, Val Loss: 0.5235
Epoch [96/120], Loss: 0.1659, Val Loss: 0.5333
Epoch [97/120], Loss: 0.1277, Val Loss: 0.5833
Epoch [98/120], Loss: 0.1169, Val Loss: 0.5145
Epoch [99/120], Loss: 0.2596, Val Loss: 0.5477
Epoch [100/120], Loss: 0.3133, Val Loss: 0.5141
Epoch [101/120], Loss: 0.1583, Val Loss: 0.5298
Epoch [102/120], Loss: 0.1733, Val Loss: 0.5136
Epoch [103/120], Loss: 0.8803, Val Loss: 0.5195
Epoch [104/120], Loss: 0.3065, Val Loss: 0.5337
Epoch [105/120], Loss: 0.0925, Val Loss: 0.4906
Epoch [106/120], Loss: 0.1339, Val Loss: 0.5667
Epoch [107/120], Loss: 0.0975, Val Loss: 0.4948
Epoch [108/120], Loss: 0.1410, Val Loss: 0.5204
Epoch [109/120], Loss: 0.2070, Val Loss: 0.5178
Epoch [110/120], Loss: 0.2674, Val Loss: 0.5200
Epoch [111/120], Loss: 0.8600, Val Loss: 0.5138
Epoch [112/120], Loss: 0.1234, Val Loss: 0.5853
Epoch [113/120], Loss: 0.0522, Val Loss: 0.4717
Epoch [114/120], Loss: 0.1514, Val Loss: 0.4874
Epoch [115/120], Loss: 0.1331, Val Loss: 0.4746
Epoch [116/120], Loss: 0.1773, Val Loss: 0.5632
Epoch [117/120], Loss: 0.0478, Val Loss: 0.5307
Epoch [118/120], Loss: 0.0894, Val Loss: 0.4944
Epoch [119/120], Loss: 0.0775, Val Loss: 0.4901
Epoch [120/120], Loss: 0.1059, Val Loss: 0.5280
Runtime: 0:03:21.262885
R^2 Score: 0.8756
RMSE: 0.8106
MAE: 0.2171
MAPE: 17.26%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.3251, Val Loss: 0.8767
Epoch [2/120], Loss: 0.3510, Val Loss: 0.8663
Epoch [3/120], Loss: 0.9772, Val Loss: 0.7091
Epoch [4/120], Loss: 1.3365, Val Loss: 0.9508
Epoch [5/120], Loss: 0.3203, Val Loss: 0.7721
Epoch [6/120], Loss: 0.2047, Val Loss: 0.9010
Epoch [7/120], Loss: 2.9525, Val Loss: 0.9654
Epoch [8/120], Loss: 0.2439, Val Loss: 0.8654
Epoch [9/120], Loss: 0.1730, Val Loss: 0.7583
Epoch [10/120], Loss: 0.1710, Val Loss: 0.7578
Epoch [11/120], Loss: 0.3318, Val Loss: 0.7185
Epoch [12/120], Loss: 0.3302, Val Loss: 0.5877
Epoch [13/120], Loss: 0.1612, Val Loss: 0.7493
Epoch [14/120], Loss: 0.4208, Val Loss: 0.6848
Epoch [15/120], Loss: 1.1609, Val Loss: 0.7636
Epoch [16/120], Loss: 0.0427, Val Loss: 0.6366
Epoch [17/120], Loss: 1.4035, Val Loss: 0.7770
Epoch [18/120], Loss: 0.1269, Val Loss: 0.6582
Epoch [19/120], Loss: 1.1255, Val Loss: 0.6354
Epoch [20/120], Loss: 0.1965, Val Loss: 0.6344
Epoch [21/120], Loss: 1.4383, Val Loss: 0.8270
Epoch [22/120], Loss: 0.2554, Val Loss: 0.7225
Epoch [23/120], Loss: 0.3760, Val Loss: 0.6180
Epoch [24/120], Loss: 0.2383, Val Loss: 0.7358
Epoch [25/120], Loss: 0.1286, Val Loss: 0.7699
Epoch [26/120], Loss: 0.1462, Val Loss: 0.6318
Epoch [27/120], Loss: 1.5024, Val Loss: 0.6957
Epoch [28/120], Loss: 0.4502, Val Loss: 0.6406
Epoch [29/120], Loss: 0.1088, Val Loss: 0.5410
Epoch [30/120], Loss: 0.2011, Val Loss: 0.6338
Epoch [31/120], Loss: 0.1455, Val Loss: 0.5792
Epoch [32/120], Loss: 0.1814, Val Loss: 0.6822
Epoch [33/120], Loss: 0.2185, Val Loss: 0.6143
Epoch [34/120], Loss: 0.0873, Val Loss: 0.6538
Epoch [35/120], Loss: 0.1706, Val Loss: 0.5995
Epoch [36/120], Loss: 0.0870, Val Loss: 0.5753
Epoch [37/120], Loss: 0.1625, Val Loss: 0.5754
Epoch [38/120], Loss: 0.1029, Val Loss: 0.6745
Epoch [39/120], Loss: 0.2785, Val Loss: 0.7014
Epoch [40/120], Loss: 0.8993, Val Loss: 0.6154
Epoch [41/120], Loss: 0.0559, Val Loss: 0.5871
Epoch [42/120], Loss: 0.2374, Val Loss: 0.5256
Epoch [43/120], Loss: 0.2333, Val Loss: 0.5148
Epoch [44/120], Loss: 0.1466, Val Loss: 0.5415
Epoch [45/120], Loss: 0.1828, Val Loss: 0.5557
Epoch [46/120], Loss: 0.1425, Val Loss: 0.6397
Epoch [47/120], Loss: 0.2096, Val Loss: 0.5950
Epoch [48/120], Loss: 0.2353, Val Loss: 0.5521
Epoch [49/120], Loss: 0.3314, Val Loss: 0.5510
Epoch [50/120], Loss: 0.1506, Val Loss: 0.5840
Epoch [51/120], Loss: 0.2157, Val Loss: 0.5405
Epoch [52/120], Loss: 0.1545, Val Loss: 0.5762
Epoch [53/120], Loss: 0.2776, Val Loss: 0.6009
Epoch [54/120], Loss: 0.1238, Val Loss: 0.6517
Epoch [55/120], Loss: 0.0955, Val Loss: 0.6740
Epoch [56/120], Loss: 0.0899, Val Loss: 0.6156
Epoch [57/120], Loss: 0.2329, Val Loss: 0.5877
Epoch [58/120], Loss: 0.2622, Val Loss: 0.5329
Epoch [59/120], Loss: 0.1549, Val Loss: 0.5881
Epoch [60/120], Loss: 0.5581, Val Loss: 0.5739
Epoch [61/120], Loss: 0.1754, Val Loss: 0.5412
Epoch [62/120], Loss: 0.1551, Val Loss: 0.5705
Epoch [63/120], Loss: 0.1551, Val Loss: 0.5580
Epoch [64/120], Loss: 0.2775, Val Loss: 0.6105
Epoch [65/120], Loss: 0.8403, Val Loss: 0.5297
Epoch [66/120], Loss: 0.1064, Val Loss: 0.5468
Epoch [67/120], Loss: 0.2169, Val Loss: 0.5925
Epoch [68/120], Loss: 0.0703, Val Loss: 0.5046
Epoch [69/120], Loss: 0.4861, Val Loss: 0.6693
Epoch [70/120], Loss: 0.0434, Val Loss: 0.6393
Epoch [71/120], Loss: 0.1235, Val Loss: 0.6002
Epoch [72/120], Loss: 0.3330, Val Loss: 0.5919
Epoch [73/120], Loss: 0.4465, Val Loss: 0.5650
Epoch [74/120], Loss: 0.1364, Val Loss: 0.5253
Epoch [75/120], Loss: 0.1119, Val Loss: 0.5540
Epoch [76/120], Loss: 0.3729, Val Loss: 0.5586
Epoch [77/120], Loss: 0.0958, Val Loss: 0.6028
Epoch [78/120], Loss: 0.1314, Val Loss: 0.6729
Epoch [79/120], Loss: 0.2683, Val Loss: 0.5218
Epoch [80/120], Loss: 0.0950, Val Loss: 0.5306
Epoch [81/120], Loss: 0.0811, Val Loss: 0.5088
Epoch [82/120], Loss: 0.2651, Val Loss: 0.5561
Epoch [83/120], Loss: 0.5593, Val Loss: 0.5895
Epoch [84/120], Loss: 0.2151, Val Loss: 0.5280
Epoch [85/120], Loss: 0.7014, Val Loss: 0.5228
Epoch [86/120], Loss: 0.2819, Val Loss: 0.5185
Epoch [87/120], Loss: 0.2106, Val Loss: 0.5433
Epoch [88/120], Loss: 0.0537, Val Loss: 0.6634
Epoch [89/120], Loss: 0.2842, Val Loss: 0.5315
Epoch [90/120], Loss: 0.0682, Val Loss: 0.5539
Epoch [91/120], Loss: 0.0644, Val Loss: 0.5379
Epoch [92/120], Loss: 0.4299, Val Loss: 0.5260
Epoch [93/120], Loss: 0.2046, Val Loss: 0.6199
Epoch [94/120], Loss: 0.1364, Val Loss: 0.5263
Epoch [95/120], Loss: 0.6379, Val Loss: 0.5675
Epoch [96/120], Loss: 0.1704, Val Loss: 0.5631
Epoch [97/120], Loss: 0.1209, Val Loss: 0.6003
Epoch [98/120], Loss: 0.1481, Val Loss: 0.5526
Epoch [99/120], Loss: 0.2422, Val Loss: 0.5919
Epoch [100/120], Loss: 0.0982, Val Loss: 0.5243
Epoch [101/120], Loss: 0.1752, Val Loss: 0.5613
Epoch [102/120], Loss: 0.2284, Val Loss: 0.5265
Epoch [103/120], Loss: 0.0989, Val Loss: 0.5422
Epoch [104/120], Loss: 0.3864, Val Loss: 0.5876
Epoch [105/120], Loss: 0.1167, Val Loss: 0.5081
Epoch [106/120], Loss: 0.2799, Val Loss: 0.5483
Epoch [107/120], Loss: 0.1475, Val Loss: 0.5412
Epoch [108/120], Loss: 0.4935, Val Loss: 0.5622
Epoch [109/120], Loss: 0.0761, Val Loss: 0.5974
Epoch [110/120], Loss: 0.1386, Val Loss: 0.5255
Epoch [111/120], Loss: 0.1987, Val Loss: 0.5315
Epoch [112/120], Loss: 0.5553, Val Loss: 0.5227
Epoch [113/120], Loss: 0.8067, Val Loss: 0.5818
Epoch [114/120], Loss: 0.0733, Val Loss: 0.5626
Epoch [115/120], Loss: 0.2557, Val Loss: 0.5289
Epoch [116/120], Loss: 0.4056, Val Loss: 0.5512
Epoch [117/120], Loss: 0.2559, Val Loss: 0.5387
Epoch [118/120], Loss: 0.0414, Val Loss: 0.5797
Epoch [119/120], Loss: 0.3202, Val Loss: 0.5273
Epoch [120/120], Loss: 0.3025, Val Loss: 0.5423
Runtime: 0:03:02.105447
R^2 Score: 0.9026
RMSE: 0.7172
MAE: 0.2219
MAPE: 18.78%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 576 finished with value: 0.2586706328428974             and parameters: {'weight_decay': 7.412033842835223e-05, 'batch_size': 32, 'n_units_l1': 49, 'n_units_l2': 61, 'n_units_l3': 61}.            Suggested LR = 0.002875959500670433
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.5234, Val Loss: 0.8776
Epoch [2/120], Loss: 1.6499, Val Loss: 0.7562
Epoch [3/120], Loss: 0.4592, Val Loss: 0.7117
Epoch [4/120], Loss: 0.0829, Val Loss: 0.8044
Epoch [5/120], Loss: 0.9992, Val Loss: 1.0229
Epoch [6/120], Loss: 0.1562, Val Loss: 0.6913
Epoch [7/120], Loss: 0.3738, Val Loss: 1.0315
Epoch [8/120], Loss: 0.2236, Val Loss: 0.6568
Epoch [9/120], Loss: 0.7465, Val Loss: 0.6761
Epoch [10/120], Loss: 0.0772, Val Loss: 0.6766
Epoch [11/120], Loss: 0.0581, Val Loss: 0.7303
Epoch [12/120], Loss: 0.9545, Val Loss: 0.6112
Epoch [13/120], Loss: 0.1210, Val Loss: 0.6060
Epoch [14/120], Loss: 0.3264, Val Loss: 0.6188
Epoch [15/120], Loss: 0.3937, Val Loss: 0.6548
Epoch [16/120], Loss: 0.8503, Val Loss: 0.6387
Epoch [17/120], Loss: 0.3848, Val Loss: 1.1160
Epoch [18/120], Loss: 0.1945, Val Loss: 0.6454
Epoch [19/120], Loss: 0.0889, Val Loss: 0.9119
Epoch [20/120], Loss: 0.2159, Val Loss: 0.6120
Epoch [21/120], Loss: 0.4522, Val Loss: 0.5922
Epoch [22/120], Loss: 0.1707, Val Loss: 0.5767
Epoch [23/120], Loss: 0.3383, Val Loss: 0.5487
Epoch [24/120], Loss: 1.0066, Val Loss: 0.5738
Epoch [25/120], Loss: 0.6621, Val Loss: 0.6033
Epoch [26/120], Loss: 0.2330, Val Loss: 0.5568
Epoch [27/120], Loss: 0.2383, Val Loss: 0.6259
Epoch [28/120], Loss: 0.4948, Val Loss: 0.5588
Epoch [29/120], Loss: 0.1658, Val Loss: 0.5752
Epoch [30/120], Loss: 0.4128, Val Loss: 0.6360
Epoch [31/120], Loss: 0.1611, Val Loss: 0.5250
Epoch [32/120], Loss: 0.1292, Val Loss: 0.5881
Epoch [33/120], Loss: 0.9682, Val Loss: 0.5446
Epoch [34/120], Loss: 0.1229, Val Loss: 0.6262
Epoch [35/120], Loss: 0.5921, Val Loss: 0.5402
Epoch [36/120], Loss: 0.3078, Val Loss: 0.5742
Epoch [37/120], Loss: 0.0806, Val Loss: 0.5291
Epoch [38/120], Loss: 0.0781, Val Loss: 0.5551
Epoch [39/120], Loss: 0.7683, Val Loss: 0.8684
Epoch [40/120], Loss: 1.6312, Val Loss: 0.5814
Epoch [41/120], Loss: 0.0740, Val Loss: 0.5216
Epoch [42/120], Loss: 0.1710, Val Loss: 0.5849
Epoch [43/120], Loss: 0.4687, Val Loss: 0.6524
Epoch [44/120], Loss: 0.1211, Val Loss: 0.5796
Epoch [45/120], Loss: 0.1500, Val Loss: 0.6131
Epoch [46/120], Loss: 0.5612, Val Loss: 0.6433
Epoch [47/120], Loss: 0.1060, Val Loss: 0.5799
Epoch [48/120], Loss: 0.1083, Val Loss: 0.6009
Epoch [49/120], Loss: 0.0561, Val Loss: 0.5975
Epoch [50/120], Loss: 0.1169, Val Loss: 0.6054
Epoch [51/120], Loss: 0.1704, Val Loss: 0.5561
Epoch [52/120], Loss: 0.2259, Val Loss: 0.5707
Epoch [53/120], Loss: 0.4289, Val Loss: 0.6791
Epoch [54/120], Loss: 0.7177, Val Loss: 0.5274
Epoch [55/120], Loss: 0.3194, Val Loss: 0.6137
Epoch [56/120], Loss: 0.1413, Val Loss: 0.5830
Epoch [57/120], Loss: 0.3298, Val Loss: 0.5428
Epoch [58/120], Loss: 0.0461, Val Loss: 0.5342
Epoch [59/120], Loss: 0.1809, Val Loss: 0.6024
Epoch [60/120], Loss: 0.1296, Val Loss: 0.5498
Epoch [61/120], Loss: 0.2299, Val Loss: 0.6110
Epoch [62/120], Loss: 0.1118, Val Loss: 0.5535
Epoch [63/120], Loss: 0.4184, Val Loss: 0.5365
Epoch [64/120], Loss: 0.1139, Val Loss: 0.5730
Epoch [65/120], Loss: 0.2496, Val Loss: 0.5598
Epoch [66/120], Loss: 0.1936, Val Loss: 0.5758
Epoch [67/120], Loss: 0.1435, Val Loss: 0.5612
Epoch [68/120], Loss: 0.1046, Val Loss: 0.9399
Epoch [69/120], Loss: 0.1532, Val Loss: 0.5433
Epoch [70/120], Loss: 0.1280, Val Loss: 0.5936
Early stopping at epoch 70
Runtime: 0:01:54.061488
R^2 Score: 0.9182
RMSE: 0.6573
MAE: 0.2057
MAPE: 16.02%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.0014920707326382399
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.8564, Val Loss: 0.7988
Epoch [2/120], Loss: 0.4373, Val Loss: 0.7433
Epoch [3/120], Loss: 0.6594, Val Loss: 0.8226
Epoch [4/120], Loss: 0.7122, Val Loss: 0.6633
Epoch [5/120], Loss: 0.4787, Val Loss: 0.7382
Epoch [6/120], Loss: 0.2423, Val Loss: 1.0845
Epoch [7/120], Loss: 0.1439, Val Loss: 0.7319
Epoch [8/120], Loss: 0.6371, Val Loss: 0.6563
Epoch [9/120], Loss: 0.3098, Val Loss: 0.7120
Epoch [10/120], Loss: 0.3872, Val Loss: 0.6577
Epoch [11/120], Loss: 0.4687, Val Loss: 0.6666
Epoch [12/120], Loss: 0.2336, Val Loss: 0.6399
Epoch [13/120], Loss: 0.2978, Val Loss: 0.6524
Epoch [14/120], Loss: 0.2796, Val Loss: 0.7173
Epoch [15/120], Loss: 0.0906, Val Loss: 0.6348
Epoch [16/120], Loss: 0.1425, Val Loss: 0.6057
Epoch [17/120], Loss: 0.1153, Val Loss: 0.6990
Epoch [18/120], Loss: 0.2944, Val Loss: 0.6699
Epoch [19/120], Loss: 0.3216, Val Loss: 0.7742
Epoch [20/120], Loss: 0.2689, Val Loss: 0.6212
Epoch [21/120], Loss: 0.2298, Val Loss: 0.5946
Epoch [22/120], Loss: 0.1347, Val Loss: 0.5728
Epoch [23/120], Loss: 0.2771, Val Loss: 0.7496
Epoch [24/120], Loss: 0.1735, Val Loss: 0.6888
Epoch [25/120], Loss: 0.2767, Val Loss: 0.6347
Epoch [26/120], Loss: 0.3607, Val Loss: 0.5513
Epoch [27/120], Loss: 0.2906, Val Loss: 0.6196
Epoch [28/120], Loss: 0.0677, Val Loss: 0.6619
Epoch [29/120], Loss: 0.2104, Val Loss: 0.6056
Epoch [30/120], Loss: 0.1198, Val Loss: 0.6173
Epoch [31/120], Loss: 0.9559, Val Loss: 0.6466
Epoch [32/120], Loss: 0.1858, Val Loss: 0.7438
Epoch [33/120], Loss: 0.3649, Val Loss: 0.5813
Epoch [34/120], Loss: 0.1142, Val Loss: 0.6189
Epoch [35/120], Loss: 0.6509, Val Loss: 0.6658
Epoch [36/120], Loss: 0.1150, Val Loss: 0.6057
Epoch [37/120], Loss: 0.1779, Val Loss: 0.7457
Epoch [38/120], Loss: 0.1497, Val Loss: 0.5764
Epoch [39/120], Loss: 0.0921, Val Loss: 0.5801
Epoch [40/120], Loss: 0.2962, Val Loss: 0.6316
Epoch [41/120], Loss: 0.4715, Val Loss: 0.5590
Epoch [42/120], Loss: 0.2753, Val Loss: 0.5739
Epoch [43/120], Loss: 0.2331, Val Loss: 0.6491
Epoch [44/120], Loss: 0.2086, Val Loss: 0.5933
Epoch [45/120], Loss: 0.1359, Val Loss: 0.5717
Epoch [46/120], Loss: 0.1062, Val Loss: 0.6196
Epoch [47/120], Loss: 0.1073, Val Loss: 0.6266
Epoch [48/120], Loss: 0.2002, Val Loss: 0.5802
Epoch [49/120], Loss: 0.1827, Val Loss: 0.5806
Epoch [50/120], Loss: 1.3032, Val Loss: 0.5455
Epoch [51/120], Loss: 0.1618, Val Loss: 0.6181
Epoch [52/120], Loss: 0.2052, Val Loss: 0.5828
Epoch [53/120], Loss: 0.1220, Val Loss: 0.5448
Epoch [54/120], Loss: 0.2507, Val Loss: 0.5635
Epoch [55/120], Loss: 0.1410, Val Loss: 0.6093
Epoch [56/120], Loss: 0.1650, Val Loss: 0.5880
Epoch [57/120], Loss: 0.4226, Val Loss: 0.5659
Epoch [58/120], Loss: 0.1461, Val Loss: 0.6390
Epoch [59/120], Loss: 0.4577, Val Loss: 0.5865
Epoch [60/120], Loss: 0.1292, Val Loss: 0.6974
Epoch [61/120], Loss: 0.1239, Val Loss: 0.6444
Epoch [62/120], Loss: 0.0995, Val Loss: 0.5710
Epoch [63/120], Loss: 0.6722, Val Loss: 0.6236
Epoch [64/120], Loss: 0.1880, Val Loss: 0.6359
Epoch [65/120], Loss: 0.3648, Val Loss: 0.5579
Epoch [66/120], Loss: 0.2365, Val Loss: 0.5851
Epoch [67/120], Loss: 0.3616, Val Loss: 0.6002
Epoch [68/120], Loss: 0.2231, Val Loss: 0.6354
Epoch [69/120], Loss: 0.0958, Val Loss: 0.5535
Epoch [70/120], Loss: 0.1135, Val Loss: 0.6051
Epoch [71/120], Loss: 0.2000, Val Loss: 0.5618
Epoch [72/120], Loss: 0.1195, Val Loss: 0.6676
Epoch [73/120], Loss: 0.0794, Val Loss: 0.5890
Epoch [74/120], Loss: 0.7939, Val Loss: 0.6077
Epoch [75/120], Loss: 0.0952, Val Loss: 0.5796
Epoch [76/120], Loss: 0.3627, Val Loss: 0.6183
Epoch [77/120], Loss: 0.1803, Val Loss: 0.6449
Epoch [78/120], Loss: 0.1160, Val Loss: 0.6517
Epoch [79/120], Loss: 0.0520, Val Loss: 0.5368
Epoch [80/120], Loss: 0.1290, Val Loss: 0.5772
Epoch [81/120], Loss: 0.2006, Val Loss: 0.5396
Epoch [82/120], Loss: 0.0446, Val Loss: 0.5800
Epoch [83/120], Loss: 0.3120, Val Loss: 0.5658
Epoch [84/120], Loss: 0.3016, Val Loss: 0.5695
Epoch [85/120], Loss: 0.7121, Val Loss: 0.6413
Epoch [86/120], Loss: 0.1205, Val Loss: 0.5767
Epoch [87/120], Loss: 0.8226, Val Loss: 0.5456
Epoch [88/120], Loss: 0.0864, Val Loss: 0.5459
Epoch [89/120], Loss: 0.1702, Val Loss: 0.5878
Epoch [90/120], Loss: 0.4074, Val Loss: 0.5648
Epoch [91/120], Loss: 0.0608, Val Loss: 0.5944
Epoch [92/120], Loss: 0.0931, Val Loss: 0.5947
Epoch [93/120], Loss: 0.1025, Val Loss: 0.5742
Epoch [94/120], Loss: 0.0798, Val Loss: 0.5499
Epoch [95/120], Loss: 0.1570, Val Loss: 0.5330
Epoch [96/120], Loss: 0.8153, Val Loss: 0.5453
Epoch [97/120], Loss: 0.0653, Val Loss: 0.6268
Epoch [98/120], Loss: 0.0751, Val Loss: 0.5425
Epoch [99/120], Loss: 0.1918, Val Loss: 0.5231
Epoch [100/120], Loss: 0.2424, Val Loss: 0.5563
Epoch [101/120], Loss: 0.0875, Val Loss: 0.5600
Epoch [102/120], Loss: 0.1767, Val Loss: 0.6153
Epoch [103/120], Loss: 0.0904, Val Loss: 0.6005
Epoch [104/120], Loss: 0.0347, Val Loss: 0.5823
Epoch [105/120], Loss: 0.2155, Val Loss: 0.5368
Epoch [106/120], Loss: 0.0797, Val Loss: 0.5708
Epoch [107/120], Loss: 0.0980, Val Loss: 0.5836
Epoch [108/120], Loss: 0.4380, Val Loss: 0.5657
Epoch [109/120], Loss: 0.0771, Val Loss: 0.7328
Epoch [110/120], Loss: 0.2940, Val Loss: 0.6464
Epoch [111/120], Loss: 0.0768, Val Loss: 0.5968
Epoch [112/120], Loss: 0.1125, Val Loss: 0.5721
Epoch [113/120], Loss: 0.1046, Val Loss: 0.6101
Epoch [114/120], Loss: 0.0515, Val Loss: 0.5905
Epoch [115/120], Loss: 0.1066, Val Loss: 0.5476
Epoch [116/120], Loss: 0.0864, Val Loss: 0.6294
Epoch [117/120], Loss: 0.0599, Val Loss: 0.5372
Epoch [118/120], Loss: 0.3262, Val Loss: 0.5845
Epoch [119/120], Loss: 0.0754, Val Loss: 0.5829
Epoch [120/120], Loss: 0.0472, Val Loss: 0.5466
Runtime: 0:03:06.317770
R^2 Score: 0.9034
RMSE: 0.7143
MAE: 0.2079
MAPE: 16.20%
Using optimizer: SGD
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 1.0243088581773918e-05
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/50], Loss: 0.9697, Val Loss: 0.8581
Epoch [2/50], Loss: 0.3058, Val Loss: 0.8556
Epoch [3/50], Loss: 0.0901, Val Loss: 0.8539
Epoch [4/50], Loss: 0.8282, Val Loss: 0.8525
Epoch [5/50], Loss: 0.3800, Val Loss: 0.8524
Epoch [6/50], Loss: 0.5357, Val Loss: 0.8503
Epoch [7/50], Loss: 0.5291, Val Loss: 0.8516
Epoch [8/50], Loss: 1.3350, Val Loss: 0.8512
Epoch [9/50], Loss: 0.4656, Val Loss: 0.8490
Epoch [10/50], Loss: 0.7653, Val Loss: 0.8466
Epoch [11/50], Loss: 0.3565, Val Loss: 0.8470
Epoch [12/50], Loss: 0.4571, Val Loss: 0.8455
Epoch [13/50], Loss: 0.2599, Val Loss: 0.8440
Epoch [14/50], Loss: 0.4247, Val Loss: 0.8427
Epoch [15/50], Loss: 0.3240, Val Loss: 0.8429
Epoch [16/50], Loss: 0.5266, Val Loss: 0.8427
Epoch [17/50], Loss: 0.1303, Val Loss: 0.8402
Epoch [18/50], Loss: 0.3771, Val Loss: 0.8412
Epoch [19/50], Loss: 0.1554, Val Loss: 0.8391
Epoch [20/50], Loss: 8.3029, Val Loss: 0.8452
Epoch [21/50], Loss: 0.3534, Val Loss: 0.8393
Epoch [22/50], Loss: 0.9763, Val Loss: 0.8373
Epoch [23/50], Loss: 0.6129, Val Loss: 0.8374
Epoch [24/50], Loss: 1.0554, Val Loss: 0.8371
Epoch [25/50], Loss: 0.5601, Val Loss: 0.8369
Epoch [26/50], Loss: 0.2896, Val Loss: 0.8347
Epoch [27/50], Loss: 0.8388, Val Loss: 0.8328
Epoch [28/50], Loss: 0.4372, Val Loss: 0.8332
Epoch [29/50], Loss: 1.0814, Val Loss: 0.8330
Epoch [30/50], Loss: 0.2990, Val Loss: 0.8326
Epoch [31/50], Loss: 0.5848, Val Loss: 0.8321
Epoch [32/50], Loss: 0.6367, Val Loss: 0.8320
Epoch [33/50], Loss: 0.7351, Val Loss: 0.8304
Epoch [34/50], Loss: 0.3948, Val Loss: 0.8311
Epoch [35/50], Loss: 0.5707, Val Loss: 0.8313
Epoch [36/50], Loss: 0.6736, Val Loss: 0.8292
Epoch [37/50], Loss: 0.4192, Val Loss: 0.8294
Epoch [38/50], Loss: 1.5182, Val Loss: 0.8281
Epoch [39/50], Loss: 0.0805, Val Loss: 0.8272
Epoch [40/50], Loss: 1.4244, Val Loss: 0.8258
Epoch [41/50], Loss: 1.3393, Val Loss: 0.8269
Epoch [42/50], Loss: 1.0543, Val Loss: 0.8257
Epoch [43/50], Loss: 0.3244, Val Loss: 0.8236
Epoch [44/50], Loss: 0.7926, Val Loss: 0.8245
Epoch [45/50], Loss: 0.9130, Val Loss: 0.8250
Epoch [46/50], Loss: 0.7655, Val Loss: 0.8221
Epoch [47/50], Loss: 0.3474, Val Loss: 0.8233
Epoch [48/50], Loss: 0.2021, Val Loss: 0.8223
Epoch [49/50], Loss: 0.9296, Val Loss: 0.8204
Epoch [50/50], Loss: 1.4824, Val Loss: 0.8198
Runtime: 0:01:10.330655
R^2 Score: 0.7640
RMSE: 1.1166
MAE: 0.4559
MAPE: 46.93%
Using optimizer: RMSprop
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 1.0243088581773918e-05
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/50], Loss: 0.2156, Val Loss: 0.8445
Epoch [2/50], Loss: 0.3246, Val Loss: 0.8375
Epoch [3/50], Loss: 0.5084, Val Loss: 0.8335
Epoch [4/50], Loss: 1.6008, Val Loss: 0.8291
Epoch [5/50], Loss: 0.7066, Val Loss: 0.8240
Epoch [6/50], Loss: 1.6723, Val Loss: 0.8218
Epoch [7/50], Loss: 1.1294, Val Loss: 0.8187
Epoch [8/50], Loss: 0.5708, Val Loss: 0.8146
Epoch [9/50], Loss: 0.1891, Val Loss: 0.8116
Epoch [10/50], Loss: 0.3572, Val Loss: 0.8086
Epoch [11/50], Loss: 0.4269, Val Loss: 0.8055
Epoch [12/50], Loss: 0.3144, Val Loss: 0.8034
Epoch [13/50], Loss: 0.4683, Val Loss: 0.8002
Epoch [14/50], Loss: 0.2533, Val Loss: 0.7989
Epoch [15/50], Loss: 0.1744, Val Loss: 0.7960
Epoch [16/50], Loss: 0.2525, Val Loss: 0.7949
Epoch [17/50], Loss: 0.9341, Val Loss: 0.7901
Epoch [18/50], Loss: 0.5601, Val Loss: 0.7872
Epoch [19/50], Loss: 9.5659, Val Loss: 0.7887
Epoch [20/50], Loss: 0.4737, Val Loss: 0.7869
Epoch [21/50], Loss: 0.8850, Val Loss: 0.7848
Epoch [22/50], Loss: 0.4301, Val Loss: 0.7811
Epoch [23/50], Loss: 0.3740, Val Loss: 0.7815
Epoch [24/50], Loss: 1.1566, Val Loss: 0.7803
Epoch [25/50], Loss: 2.0563, Val Loss: 0.7775
Epoch [26/50], Loss: 0.8110, Val Loss: 0.7762
Epoch [27/50], Loss: 0.2733, Val Loss: 0.7772
Epoch [28/50], Loss: 0.9010, Val Loss: 0.7745
Epoch [29/50], Loss: 0.3862, Val Loss: 0.7728
Epoch [30/50], Loss: 0.6610, Val Loss: 0.7717
Epoch [31/50], Loss: 0.6854, Val Loss: 0.7695
Epoch [32/50], Loss: 0.3340, Val Loss: 0.7668
Epoch [33/50], Loss: 0.5303, Val Loss: 0.7658
Epoch [34/50], Loss: 0.1453, Val Loss: 0.7647
Epoch [35/50], Loss: 0.2458, Val Loss: 0.7630
Using optimizer: RMSprop
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 1.0243088581773918e-05
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.8671, Val Loss: 0.7616
Epoch [2/120], Loss: 0.3046, Val Loss: 0.7595
Epoch [3/120], Loss: 0.2583, Val Loss: 0.7577
Epoch [4/120], Loss: 0.1986, Val Loss: 0.7572
Epoch [5/120], Loss: 0.1561, Val Loss: 0.7574
Epoch [6/120], Loss: 1.2690, Val Loss: 0.7568
Epoch [7/120], Loss: 0.3348, Val Loss: 0.7531
Epoch [8/120], Loss: 0.2786, Val Loss: 0.7528
Epoch [9/120], Loss: 0.2829, Val Loss: 0.7524
Epoch [10/120], Loss: 0.2509, Val Loss: 0.7498
Epoch [11/120], Loss: 0.2369, Val Loss: 0.7506
Epoch [12/120], Loss: 0.6162, Val Loss: 0.7491
Epoch [13/120], Loss: 0.7066, Val Loss: 0.7507
Epoch [14/120], Loss: 1.8210, Val Loss: 0.7462
Epoch [15/120], Loss: 0.4182, Val Loss: 0.7460
Epoch [16/120], Loss: 0.4184, Val Loss: 0.7455
Epoch [17/120], Loss: 0.2392, Val Loss: 0.7436
Epoch [18/120], Loss: 0.0916, Val Loss: 0.7450
Epoch [19/120], Loss: 0.3084, Val Loss: 0.7430
Epoch [20/120], Loss: 0.2938, Val Loss: 0.7421
Epoch [21/120], Loss: 0.8746, Val Loss: 0.7419
Epoch [22/120], Loss: 0.2883, Val Loss: 0.7421
Epoch [23/120], Loss: 0.9088, Val Loss: 0.7422
Epoch [24/120], Loss: 0.2267, Val Loss: 0.7413
Epoch [25/120], Loss: 0.6215, Val Loss: 0.7389
Epoch [26/120], Loss: 0.1715, Val Loss: 0.7370
Epoch [27/120], Loss: 0.4835, Val Loss: 0.7393
Epoch [28/120], Loss: 0.2044, Val Loss: 0.7365
Epoch [29/120], Loss: 0.1744, Val Loss: 0.7341
Epoch [30/120], Loss: 1.0395, Val Loss: 0.7351
Epoch [31/120], Loss: 0.2518, Val Loss: 0.7356
Epoch [32/120], Loss: 0.3155, Val Loss: 0.7315
Epoch [33/120], Loss: 0.2176, Val Loss: 0.7337
Epoch [34/120], Loss: 1.0449, Val Loss: 0.7297
Epoch [35/120], Loss: 0.9861, Val Loss: 0.7298
Epoch [36/120], Loss: 0.3076, Val Loss: 0.7296
Epoch [37/120], Loss: 0.3470, Val Loss: 0.7307
Epoch [38/120], Loss: 0.1254, Val Loss: 0.7331
Epoch [39/120], Loss: 0.6403, Val Loss: 0.7290
Using optimizer: RMSprop
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 1.0243088581773918e-05
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.5989, Val Loss: 0.8467
Epoch [2/120], Loss: 2.0301, Val Loss: 0.8386
Epoch [3/120], Loss: 0.4151, Val Loss: 0.8328
Epoch [4/120], Loss: 0.3219, Val Loss: 0.8284
Epoch [5/120], Loss: 0.2633, Val Loss: 0.8251
Epoch [6/120], Loss: 0.5264, Val Loss: 0.8213
Epoch [7/120], Loss: 0.2894, Val Loss: 0.8183
Epoch [8/120], Loss: 0.5216, Val Loss: 0.8134
Epoch [9/120], Loss: 0.7572, Val Loss: 0.8108
Epoch [10/120], Loss: 0.7891, Val Loss: 0.8072
Epoch [11/120], Loss: 0.5192, Val Loss: 0.8055
Epoch [12/120], Loss: 0.4327, Val Loss: 0.8028
Epoch [13/120], Loss: 0.0820, Val Loss: 0.8014
Epoch [14/120], Loss: 0.2006, Val Loss: 0.7986
Epoch [15/120], Loss: 0.5754, Val Loss: 0.7943
Epoch [16/120], Loss: 1.0082, Val Loss: 0.7922
Epoch [17/120], Loss: 0.6329, Val Loss: 0.7905
Epoch [18/120], Loss: 2.2102, Val Loss: 0.7890
Epoch [19/120], Loss: 1.9670, Val Loss: 0.7846
Epoch [20/120], Loss: 0.2176, Val Loss: 0.7845
Epoch [21/120], Loss: 0.5669, Val Loss: 0.7842
Epoch [22/120], Loss: 0.5408, Val Loss: 0.7815
Epoch [23/120], Loss: 0.2750, Val Loss: 0.7787
Epoch [24/120], Loss: 0.4111, Val Loss: 0.7788
Epoch [25/120], Loss: 0.2581, Val Loss: 0.7772
Epoch [26/120], Loss: 0.2254, Val Loss: 0.7754
Epoch [27/120], Loss: 0.5791, Val Loss: 0.7751
Epoch [28/120], Loss: 0.5968, Val Loss: 0.7745
Epoch [29/120], Loss: 0.6974, Val Loss: 0.7711
Epoch [30/120], Loss: 0.9113, Val Loss: 0.7710
Epoch [31/120], Loss: 0.2546, Val Loss: 0.7706
Epoch [32/120], Loss: 0.8339, Val Loss: 0.7694
Epoch [33/120], Loss: 0.2477, Val Loss: 0.7689
Epoch [34/120], Loss: 0.1597, Val Loss: 0.7647
Epoch [35/120], Loss: 0.3358, Val Loss: 0.7629
Epoch [36/120], Loss: 0.0998, Val Loss: 0.7631
Epoch [37/120], Loss: 1.5751, Val Loss: 0.7606
Epoch [38/120], Loss: 0.4565, Val Loss: 0.7595
Epoch [39/120], Loss: 0.4019, Val Loss: 0.7609
Epoch [40/120], Loss: 4.4547, Val Loss: 0.7593
Epoch [41/120], Loss: 0.6134, Val Loss: 0.7553
Epoch [42/120], Loss: 0.1760, Val Loss: 0.7555
Epoch [43/120], Loss: 0.6797, Val Loss: 0.7532
Epoch [44/120], Loss: 0.0832, Val Loss: 0.7516
Epoch [45/120], Loss: 0.6655, Val Loss: 0.7530
Epoch [46/120], Loss: 0.2024, Val Loss: 0.7514
Epoch [47/120], Loss: 0.1229, Val Loss: 0.7525
Epoch [48/120], Loss: 0.2673, Val Loss: 0.7501
Epoch [49/120], Loss: 0.2933, Val Loss: 0.7491
Epoch [50/120], Loss: 1.9040, Val Loss: 0.7495
Epoch [51/120], Loss: 1.2460, Val Loss: 0.7458
Epoch [52/120], Loss: 0.2316, Val Loss: 0.7453
Epoch [53/120], Loss: 0.6127, Val Loss: 0.7433
Epoch [54/120], Loss: 0.9665, Val Loss: 0.7448
Epoch [55/120], Loss: 0.7439, Val Loss: 0.7453
Epoch [56/120], Loss: 0.2884, Val Loss: 0.7403
Epoch [57/120], Loss: 0.2153, Val Loss: 0.7411
Epoch [58/120], Loss: 0.1295, Val Loss: 0.7395
Epoch [59/120], Loss: 0.3144, Val Loss: 0.7380
Epoch [60/120], Loss: 1.7842, Val Loss: 0.7387
Epoch [61/120], Loss: 0.5044, Val Loss: 0.7392
Epoch [62/120], Loss: 0.7475, Val Loss: 0.7384
Epoch [63/120], Loss: 0.3588, Val Loss: 0.7381
Epoch [64/120], Loss: 0.3755, Val Loss: 0.7361
Epoch [65/120], Loss: 0.2474, Val Loss: 0.7372
Epoch [66/120], Loss: 0.3441, Val Loss: 0.7360
Epoch [67/120], Loss: 0.4307, Val Loss: 0.7371
Epoch [68/120], Loss: 0.3593, Val Loss: 0.7343
Epoch [69/120], Loss: 0.1883, Val Loss: 0.7338
Epoch [70/120], Loss: 0.3155, Val Loss: 0.7324
Epoch [71/120], Loss: 0.7223, Val Loss: 0.7311
Epoch [72/120], Loss: 0.5600, Val Loss: 0.7314
Epoch [73/120], Loss: 0.3609, Val Loss: 0.7317
Epoch [74/120], Loss: 0.1933, Val Loss: 0.7282
Epoch [75/120], Loss: 0.3172, Val Loss: 0.7296
Epoch [76/120], Loss: 0.3573, Val Loss: 0.7297
Epoch [77/120], Loss: 0.4354, Val Loss: 0.7287
Epoch [78/120], Loss: 1.0601, Val Loss: 0.7280
Epoch [79/120], Loss: 0.1845, Val Loss: 0.7275
Epoch [80/120], Loss: 0.2265, Val Loss: 0.7299
Epoch [81/120], Loss: 2.5415, Val Loss: 0.7312
Epoch [82/120], Loss: 0.3984, Val Loss: 0.7294
Epoch [83/120], Loss: 0.7605, Val Loss: 0.7277
Epoch [84/120], Loss: 0.3006, Val Loss: 0.7278
Epoch [85/120], Loss: 0.5494, Val Loss: 0.7274
Epoch [86/120], Loss: 0.4071, Val Loss: 0.7247
Epoch [87/120], Loss: 0.1323, Val Loss: 0.7247
Epoch [88/120], Loss: 1.1994, Val Loss: 0.7250
Epoch [89/120], Loss: 0.1382, Val Loss: 0.7248
Epoch [90/120], Loss: 1.3685, Val Loss: 0.7248
Epoch [91/120], Loss: 0.2167, Val Loss: 0.7242
Epoch [92/120], Loss: 0.2574, Val Loss: 0.7271
Epoch [93/120], Loss: 0.2226, Val Loss: 0.7229
Epoch [94/120], Loss: 0.2356, Val Loss: 0.7196
Epoch [95/120], Loss: 0.1709, Val Loss: 0.7210
Epoch [96/120], Loss: 0.8461, Val Loss: 0.7226
Epoch [97/120], Loss: 0.3210, Val Loss: 0.7235
Epoch [98/120], Loss: 0.1401, Val Loss: 0.7215
Epoch [99/120], Loss: 0.2165, Val Loss: 0.7216
Epoch [100/120], Loss: 0.1398, Val Loss: 0.7221
Epoch [101/120], Loss: 0.7783, Val Loss: 0.7228
Epoch [102/120], Loss: 0.2965, Val Loss: 0.7207
Epoch [103/120], Loss: 0.7207, Val Loss: 0.7195
Epoch [104/120], Loss: 0.1846, Val Loss: 0.7197
Epoch [105/120], Loss: 0.2236, Val Loss: 0.7205
Epoch [106/120], Loss: 0.1613, Val Loss: 0.7221
Epoch [107/120], Loss: 0.2529, Val Loss: 0.7214
Epoch [108/120], Loss: 0.5059, Val Loss: 0.7203
Epoch [109/120], Loss: 0.3393, Val Loss: 0.7194
Epoch [110/120], Loss: 0.5632, Val Loss: 0.7211
Epoch [111/120], Loss: 0.1326, Val Loss: 0.7206
Epoch [112/120], Loss: 0.2889, Val Loss: 0.7222
Epoch [113/120], Loss: 0.5401, Val Loss: 0.7199
Epoch [114/120], Loss: 0.4728, Val Loss: 0.7196
Epoch [115/120], Loss: 0.3224, Val Loss: 0.7214
Epoch [116/120], Loss: 0.1546, Val Loss: 0.7210
Epoch [117/120], Loss: 0.2852, Val Loss: 0.7201
Epoch [118/120], Loss: 0.2089, Val Loss: 0.7221
Epoch [119/120], Loss: 0.1692, Val Loss: 0.7228
Epoch [120/120], Loss: 0.1510, Val Loss: 0.7219
Runtime: 0:02:48.680414
R^2 Score: 0.8210
RMSE: 0.9724
MAE: 0.3378
MAPE: 29.39%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 1.0243088581773918e-05
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.5167, Val Loss: 0.8505
Epoch [2/120], Loss: 1.4438, Val Loss: 0.8441
Epoch [3/120], Loss: 0.5723, Val Loss: 0.8370
Epoch [4/120], Loss: 0.2753, Val Loss: 0.8353
Epoch [5/120], Loss: 0.7209, Val Loss: 0.8331
Epoch [6/120], Loss: 1.8299, Val Loss: 0.8281
Epoch [7/120], Loss: 1.8198, Val Loss: 0.8257
Epoch [8/120], Loss: 0.2790, Val Loss: 0.8215
Epoch [9/120], Loss: 0.3053, Val Loss: 0.8189
Epoch [10/120], Loss: 0.5638, Val Loss: 0.8167
Epoch [11/120], Loss: 0.5258, Val Loss: 0.8146
Epoch [12/120], Loss: 0.5782, Val Loss: 0.8121
Epoch [13/120], Loss: 1.5540, Val Loss: 0.8122
Epoch [14/120], Loss: 0.6375, Val Loss: 0.8062
Epoch [15/120], Loss: 1.6537, Val Loss: 0.8045
Epoch [16/120], Loss: 1.1564, Val Loss: 0.8025
Epoch [17/120], Loss: 0.3186, Val Loss: 0.8004
Epoch [18/120], Loss: 0.2309, Val Loss: 0.7965
Epoch [19/120], Loss: 0.3405, Val Loss: 0.7954
Epoch [20/120], Loss: 0.1848, Val Loss: 0.7943
Epoch [21/120], Loss: 1.6023, Val Loss: 0.7922
Epoch [22/120], Loss: 0.6447, Val Loss: 0.7883
Epoch [23/120], Loss: 1.4875, Val Loss: 0.7899
Epoch [24/120], Loss: 0.4712, Val Loss: 0.7859
Epoch [25/120], Loss: 0.5691, Val Loss: 0.7843
Epoch [26/120], Loss: 0.3838, Val Loss: 0.7836
Epoch [27/120], Loss: 0.3058, Val Loss: 0.7860
Epoch [28/120], Loss: 0.3353, Val Loss: 0.7827
Epoch [29/120], Loss: 0.4536, Val Loss: 0.7822
Epoch [30/120], Loss: 0.1486, Val Loss: 0.7801
Epoch [31/120], Loss: 1.5780, Val Loss: 0.7782
Epoch [32/120], Loss: 0.3934, Val Loss: 0.7762
Epoch [33/120], Loss: 0.5409, Val Loss: 0.7748
Epoch [34/120], Loss: 0.6258, Val Loss: 0.7723
Epoch [35/120], Loss: 0.6313, Val Loss: 0.7728
Epoch [36/120], Loss: 0.2333, Val Loss: 0.7713
Epoch [37/120], Loss: 1.4887, Val Loss: 0.7678
Epoch [38/120], Loss: 0.3365, Val Loss: 0.7689
Epoch [39/120], Loss: 0.8385, Val Loss: 0.7667
Epoch [40/120], Loss: 0.7174, Val Loss: 0.7656
Epoch [41/120], Loss: 0.2535, Val Loss: 0.7659
Epoch [42/120], Loss: 0.2859, Val Loss: 0.7639
Epoch [43/120], Loss: 0.4843, Val Loss: 0.7612
Epoch [44/120], Loss: 0.9242, Val Loss: 0.7601
Epoch [45/120], Loss: 0.3400, Val Loss: 0.7579
Epoch [46/120], Loss: 0.6417, Val Loss: 0.7572
Epoch [47/120], Loss: 0.2204, Val Loss: 0.7575
Epoch [48/120], Loss: 0.7514, Val Loss: 0.7548
Epoch [49/120], Loss: 0.5774, Val Loss: 0.7537
Epoch [50/120], Loss: 0.2604, Val Loss: 0.7537
Epoch [51/120], Loss: 0.2035, Val Loss: 0.7539
Epoch [52/120], Loss: 1.4234, Val Loss: 0.7524
Epoch [53/120], Loss: 2.9619, Val Loss: 0.7546
Epoch [54/120], Loss: 0.3239, Val Loss: 0.7514
Epoch [55/120], Loss: 0.2452, Val Loss: 0.7505
Epoch [56/120], Loss: 0.2450, Val Loss: 0.7495
Epoch [57/120], Loss: 0.7462, Val Loss: 0.7497
Epoch [58/120], Loss: 0.1432, Val Loss: 0.7489
Epoch [59/120], Loss: 0.8207, Val Loss: 0.7471
Epoch [60/120], Loss: 0.3920, Val Loss: 0.7494
Epoch [61/120], Loss: 0.3223, Val Loss: 0.7477
Epoch [62/120], Loss: 0.5997, Val Loss: 0.7470
Epoch [63/120], Loss: 0.8500, Val Loss: 0.7457
Epoch [64/120], Loss: 0.3769, Val Loss: 0.7455
Epoch [65/120], Loss: 0.1279, Val Loss: 0.7438
Epoch [66/120], Loss: 1.3598, Val Loss: 0.7442
Epoch [67/120], Loss: 0.6304, Val Loss: 0.7448
Epoch [68/120], Loss: 0.8598, Val Loss: 0.7432
Epoch [69/120], Loss: 0.8071, Val Loss: 0.7449
Epoch [70/120], Loss: 0.2333, Val Loss: 0.7431
Epoch [71/120], Loss: 1.7014, Val Loss: 0.7413
Epoch [72/120], Loss: 0.1578, Val Loss: 0.7398
Epoch [73/120], Loss: 0.4765, Val Loss: 0.7411
Epoch [74/120], Loss: 0.1873, Val Loss: 0.7391
Epoch [75/120], Loss: 0.6185, Val Loss: 0.7397
Epoch [76/120], Loss: 0.1828, Val Loss: 0.7374
Epoch [77/120], Loss: 0.2574, Val Loss: 0.7406
Epoch [78/120], Loss: 0.2729, Val Loss: 0.7393
Epoch [79/120], Loss: 0.4968, Val Loss: 0.7374
Epoch [80/120], Loss: 0.3501, Val Loss: 0.7372
Epoch [81/120], Loss: 0.1736, Val Loss: 0.7372
Epoch [82/120], Loss: 1.2469, Val Loss: 0.7367
Epoch [83/120], Loss: 0.2012, Val Loss: 0.7343
Epoch [84/120], Loss: 0.5228, Val Loss: 0.7367
Epoch [85/120], Loss: 0.1377, Val Loss: 0.7373
Epoch [86/120], Loss: 0.2068, Val Loss: 0.7363
Epoch [87/120], Loss: 0.3066, Val Loss: 0.7347
Epoch [88/120], Loss: 0.5707, Val Loss: 0.7343
Epoch [89/120], Loss: 0.4066, Val Loss: 0.7316
Epoch [90/120], Loss: 1.6376, Val Loss: 0.7342
Epoch [91/120], Loss: 1.8270, Val Loss: 0.7349
Epoch [92/120], Loss: 0.1180, Val Loss: 0.7333
Epoch [93/120], Loss: 1.1559, Val Loss: 0.7324
Epoch [94/120], Loss: 0.3643, Val Loss: 0.7300
Epoch [95/120], Loss: 0.1619, Val Loss: 0.7281
Epoch [96/120], Loss: 0.2827, Val Loss: 0.7305
Epoch [97/120], Loss: 0.2319, Val Loss: 0.7303
Epoch [98/120], Loss: 0.1208, Val Loss: 0.7273
Epoch [99/120], Loss: 0.1470, Val Loss: 0.7301
Epoch [100/120], Loss: 0.3432, Val Loss: 0.7314
Epoch [101/120], Loss: 0.2225, Val Loss: 0.7287
Epoch [102/120], Loss: 0.4338, Val Loss: 0.7279
Epoch [103/120], Loss: 0.6478, Val Loss: 0.7304
Epoch [104/120], Loss: 1.3291, Val Loss: 0.7281
Epoch [105/120], Loss: 0.3581, Val Loss: 0.7303
Epoch [106/120], Loss: 0.1669, Val Loss: 0.7297
Epoch [107/120], Loss: 0.1384, Val Loss: 0.7321
Epoch [108/120], Loss: 0.2692, Val Loss: 0.7271
Epoch [109/120], Loss: 0.3798, Val Loss: 0.7274
Epoch [110/120], Loss: 0.5406, Val Loss: 0.7276
Epoch [111/120], Loss: 0.6090, Val Loss: 0.7323
Epoch [112/120], Loss: 0.6258, Val Loss: 0.7266
Epoch [113/120], Loss: 0.2466, Val Loss: 0.7264
Epoch [114/120], Loss: 0.5445, Val Loss: 0.7251
Epoch [115/120], Loss: 0.3415, Val Loss: 0.7287
Epoch [116/120], Loss: 0.6943, Val Loss: 0.7273
Epoch [117/120], Loss: 0.1694, Val Loss: 0.7268
Epoch [118/120], Loss: 0.1286, Val Loss: 0.7228
Epoch [119/120], Loss: 0.8912, Val Loss: 0.7229
Epoch [120/120], Loss: 1.6846, Val Loss: 0.7237
Runtime: 0:02:57.617720
R^2 Score: 0.8226
RMSE: 0.9680
MAE: 0.3399
MAPE: 29.99%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 1.0243088581773918e-05
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 3.4388, Val Loss: 1.9680
Epoch [2/120], Loss: 0.4247, Val Loss: 1.8662
Epoch [3/120], Loss: 0.8709, Val Loss: 1.7508
Epoch [4/120], Loss: 1.4691, Val Loss: 1.6596
Epoch [5/120], Loss: 0.8844, Val Loss: 1.5993
Epoch [6/120], Loss: 1.8610, Val Loss: 1.5468
Epoch [7/120], Loss: 1.4678, Val Loss: 1.4918
Epoch [8/120], Loss: 1.1768, Val Loss: 1.4319
Epoch [9/120], Loss: 0.6133, Val Loss: 1.3690
Epoch [10/120], Loss: 0.3010, Val Loss: 1.3045
Epoch [11/120], Loss: 0.3579, Val Loss: 1.2437
Epoch [12/120], Loss: 0.4582, Val Loss: 1.1894
Epoch [13/120], Loss: 0.4268, Val Loss: 1.1457
Epoch [14/120], Loss: 0.5554, Val Loss: 1.1112
Epoch [15/120], Loss: 0.8672, Val Loss: 1.0845
Epoch [16/120], Loss: 0.5867, Val Loss: 1.0656
Epoch [17/120], Loss: 0.7974, Val Loss: 1.0525
Epoch [18/120], Loss: 0.3433, Val Loss: 1.0401
Epoch [19/120], Loss: 0.6741, Val Loss: 1.0296
Epoch [20/120], Loss: 0.4361, Val Loss: 1.0196
Epoch [21/120], Loss: 0.2979, Val Loss: 1.0119
Epoch [22/120], Loss: 1.0230, Val Loss: 1.0022
Epoch [23/120], Loss: 0.5533, Val Loss: 0.9948
Epoch [24/120], Loss: 0.2424, Val Loss: 0.9873
Epoch [25/120], Loss: 0.4218, Val Loss: 0.9790
Epoch [26/120], Loss: 1.8604, Val Loss: 0.9703
Epoch [27/120], Loss: 0.3570, Val Loss: 0.9604
Epoch [28/120], Loss: 0.3150, Val Loss: 0.9546
Epoch [29/120], Loss: 0.7201, Val Loss: 0.9510
Epoch [30/120], Loss: 0.6925, Val Loss: 0.9402
Epoch [31/120], Loss: 0.4807, Val Loss: 0.9327
Epoch [32/120], Loss: 0.7347, Val Loss: 0.9264
Epoch [33/120], Loss: 2.6167, Val Loss: 0.9180
Epoch [34/120], Loss: 1.4301, Val Loss: 0.9132
Epoch [35/120], Loss: 0.2739, Val Loss: 0.9058
Epoch [36/120], Loss: 0.5323, Val Loss: 0.8993
Epoch [37/120], Loss: 1.6191, Val Loss: 0.8940
Epoch [38/120], Loss: 0.3515, Val Loss: 0.8863
Epoch [39/120], Loss: 0.2558, Val Loss: 0.8805
Epoch [40/120], Loss: 0.3199, Val Loss: 0.8749
Epoch [41/120], Loss: 0.3667, Val Loss: 0.8696
Epoch [42/120], Loss: 0.3277, Val Loss: 0.8638
Epoch [43/120], Loss: 0.3891, Val Loss: 0.8604
Epoch [44/120], Loss: 0.9810, Val Loss: 0.8515
Epoch [45/120], Loss: 1.6712, Val Loss: 0.8489
Epoch [46/120], Loss: 1.2247, Val Loss: 0.8477
Epoch [47/120], Loss: 0.3763, Val Loss: 0.8410
Epoch [48/120], Loss: 0.2513, Val Loss: 0.8398
Epoch [49/120], Loss: 0.2982, Val Loss: 0.8324
Epoch [50/120], Loss: 0.1059, Val Loss: 0.8303
Epoch [51/120], Loss: 0.2588, Val Loss: 0.8234
Epoch [52/120], Loss: 0.2544, Val Loss: 0.8217
Epoch [53/120], Loss: 0.7722, Val Loss: 0.8184
Epoch [54/120], Loss: 0.4747, Val Loss: 0.8142
Epoch [55/120], Loss: 0.6566, Val Loss: 0.8088
Epoch [56/120], Loss: 0.4166, Val Loss: 0.8069
Epoch [57/120], Loss: 0.6311, Val Loss: 0.8035
Epoch [58/120], Loss: 0.9860, Val Loss: 0.8071
Epoch [59/120], Loss: 0.3305, Val Loss: 0.8045
Epoch [60/120], Loss: 0.3982, Val Loss: 0.7987
Epoch [61/120], Loss: 1.1264, Val Loss: 0.7982
Epoch [62/120], Loss: 0.2348, Val Loss: 0.7937
Epoch [63/120], Loss: 0.3631, Val Loss: 0.7885
Epoch [64/120], Loss: 0.2218, Val Loss: 0.7869
Epoch [65/120], Loss: 0.3171, Val Loss: 0.7840
Epoch [66/120], Loss: 0.4660, Val Loss: 0.7839
Epoch [67/120], Loss: 0.2170, Val Loss: 0.7820
Epoch [68/120], Loss: 0.9882, Val Loss: 0.7807
Epoch [69/120], Loss: 0.3763, Val Loss: 0.7812
Epoch [70/120], Loss: 0.3074, Val Loss: 0.7782
Epoch [71/120], Loss: 0.1401, Val Loss: 0.7766
Epoch [72/120], Loss: 0.2475, Val Loss: 0.7791
Epoch [73/120], Loss: 0.2476, Val Loss: 0.7750
Epoch [74/120], Loss: 0.3114, Val Loss: 0.7743
Epoch [75/120], Loss: 0.2015, Val Loss: 0.7712
Epoch [76/120], Loss: 0.2850, Val Loss: 0.7686
Epoch [77/120], Loss: 0.7215, Val Loss: 0.7663
Epoch [78/120], Loss: 1.2773, Val Loss: 0.7697
Epoch [79/120], Loss: 0.2889, Val Loss: 0.7679
Epoch [80/120], Loss: 0.6309, Val Loss: 0.7607
Epoch [81/120], Loss: 0.5535, Val Loss: 0.7649
Epoch [82/120], Loss: 0.4212, Val Loss: 0.7635
Epoch [83/120], Loss: 0.6046, Val Loss: 0.7620
Epoch [84/120], Loss: 0.0954, Val Loss: 0.7635
Epoch [85/120], Loss: 0.2924, Val Loss: 0.7582
Epoch [86/120], Loss: 0.4370, Val Loss: 0.7552
Epoch [87/120], Loss: 1.6144, Val Loss: 0.7524
Epoch [88/120], Loss: 0.3542, Val Loss: 0.7562
Epoch [89/120], Loss: 0.4357, Val Loss: 0.7544
Epoch [90/120], Loss: 0.3626, Val Loss: 0.7556
Epoch [91/120], Loss: 0.1586, Val Loss: 0.7520
Epoch [92/120], Loss: 0.2144, Val Loss: 0.7495
Epoch [93/120], Loss: 0.4228, Val Loss: 0.7490
Epoch [94/120], Loss: 0.2870, Val Loss: 0.7501
Epoch [95/120], Loss: 0.1434, Val Loss: 0.7452
Epoch [96/120], Loss: 0.7171, Val Loss: 0.7480
Epoch [97/120], Loss: 1.0549, Val Loss: 0.7425
Epoch [98/120], Loss: 1.0095, Val Loss: 0.7452
Epoch [99/120], Loss: 0.2536, Val Loss: 0.7411
Epoch [100/120], Loss: 0.4612, Val Loss: 0.7413
Epoch [101/120], Loss: 0.4118, Val Loss: 0.7412
Epoch [102/120], Loss: 0.3418, Val Loss: 0.7425
Epoch [103/120], Loss: 0.1593, Val Loss: 0.7422
Epoch [104/120], Loss: 0.2253, Val Loss: 0.7408
Epoch [105/120], Loss: 0.2778, Val Loss: 0.7351
Epoch [106/120], Loss: 0.3975, Val Loss: 0.7399
Epoch [107/120], Loss: 0.1657, Val Loss: 0.7344
Epoch [108/120], Loss: 0.1213, Val Loss: 0.7346
Epoch [109/120], Loss: 0.2212, Val Loss: 0.7344
Epoch [110/120], Loss: 0.7525, Val Loss: 0.7352
Epoch [111/120], Loss: 0.1640, Val Loss: 0.7319
Epoch [112/120], Loss: 0.2364, Val Loss: 0.7326
Epoch [113/120], Loss: 0.4064, Val Loss: 0.7299
Epoch [114/120], Loss: 0.6045, Val Loss: 0.7312
Epoch [115/120], Loss: 0.2329, Val Loss: 0.7322
Epoch [116/120], Loss: 0.1722, Val Loss: 0.7282
Epoch [117/120], Loss: 1.6071, Val Loss: 0.7290
Epoch [118/120], Loss: 0.3106, Val Loss: 0.7277
Epoch [119/120], Loss: 0.4619, Val Loss: 0.7275
Epoch [120/120], Loss: 0.0899, Val Loss: 0.7289
Runtime: 0:03:03.867845
R^2 Score: 0.7967
RMSE: 1.0363
MAE: 0.3646
MAPE: 30.42%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.0019515405874699354
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.5154, Val Loss: 0.8728
Epoch [2/120], Loss: 0.1768, Val Loss: 0.8981
Epoch [3/120], Loss: 0.1330, Val Loss: 0.9246
Epoch [4/120], Loss: 0.9154, Val Loss: 1.8960
Epoch [5/120], Loss: 0.3766, Val Loss: 0.8104
Epoch [6/120], Loss: 0.4820, Val Loss: 0.6805
Epoch [7/120], Loss: 0.4347, Val Loss: 0.6993
Epoch [8/120], Loss: 0.1641, Val Loss: 0.7654
Epoch [9/120], Loss: 0.4193, Val Loss: 0.6912
Epoch [10/120], Loss: 0.5919, Val Loss: 1.2249
Epoch [11/120], Loss: 0.2748, Val Loss: 0.9369
Epoch [12/120], Loss: 0.2565, Val Loss: 0.6607
Epoch [13/120], Loss: 0.1438, Val Loss: 0.6133
Epoch [14/120], Loss: 0.2793, Val Loss: 0.8401
Epoch [15/120], Loss: 0.1918, Val Loss: 0.6338
Epoch [16/120], Loss: 0.3188, Val Loss: 0.6806
Epoch [17/120], Loss: 0.0646, Val Loss: 0.6218
Epoch [18/120], Loss: 0.2546, Val Loss: 0.6852
Epoch [19/120], Loss: 0.0359, Val Loss: 0.5782
Epoch [20/120], Loss: 0.0637, Val Loss: 0.6304
Epoch [21/120], Loss: 0.2078, Val Loss: 0.6126
Epoch [22/120], Loss: 0.0758, Val Loss: 0.5877
Epoch [23/120], Loss: 0.2644, Val Loss: 0.6302
Epoch [24/120], Loss: 0.2982, Val Loss: 0.6080
Epoch [25/120], Loss: 0.2353, Val Loss: 0.5828
Epoch [26/120], Loss: 0.2851, Val Loss: 0.6284
Epoch [27/120], Loss: 0.1826, Val Loss: 0.5675
Epoch [28/120], Loss: 0.1362, Val Loss: 0.6541
Epoch [29/120], Loss: 0.1143, Val Loss: 0.6379
Epoch [30/120], Loss: 0.2350, Val Loss: 0.5582
Epoch [31/120], Loss: 0.3719, Val Loss: 0.5774
Epoch [32/120], Loss: 0.0961, Val Loss: 0.6484
Epoch [33/120], Loss: 0.7092, Val Loss: 0.5973
Epoch [34/120], Loss: 0.5192, Val Loss: 0.6078
Epoch [35/120], Loss: 0.1069, Val Loss: 0.6167
Epoch [36/120], Loss: 0.1346, Val Loss: 0.6281
Epoch [37/120], Loss: 0.0998, Val Loss: 0.5776
Epoch [38/120], Loss: 0.1910, Val Loss: 0.6662
Epoch [39/120], Loss: 0.4550, Val Loss: 0.5746
Epoch [40/120], Loss: 1.6103, Val Loss: 0.6327
Epoch [41/120], Loss: 0.1097, Val Loss: 0.9362
Epoch [42/120], Loss: 0.1323, Val Loss: 0.5246
Epoch [43/120], Loss: 0.1555, Val Loss: 0.5497
Epoch [44/120], Loss: 0.0962, Val Loss: 0.5327
Epoch [45/120], Loss: 0.6619, Val Loss: 0.7279
Epoch [46/120], Loss: 0.6616, Val Loss: 0.6254
Epoch [47/120], Loss: 0.1705, Val Loss: 0.5562
Epoch [48/120], Loss: 0.0909, Val Loss: 0.5364
Epoch [49/120], Loss: 0.1338, Val Loss: 0.5495
Epoch [50/120], Loss: 0.4477, Val Loss: 0.6153
Epoch [51/120], Loss: 0.2837, Val Loss: 0.5588
Epoch [52/120], Loss: 0.3947, Val Loss: 0.6922
Epoch [53/120], Loss: 3.0515, Val Loss: 0.9009
Epoch [54/120], Loss: 0.2437, Val Loss: 0.5275
Epoch [55/120], Loss: 0.1255, Val Loss: 0.5794
Epoch [56/120], Loss: 0.1008, Val Loss: 0.5501
Epoch [57/120], Loss: 0.2428, Val Loss: 0.5280
Epoch [58/120], Loss: 0.3255, Val Loss: 0.5274
Epoch [59/120], Loss: 0.3579, Val Loss: 0.5727
Epoch [60/120], Loss: 0.0870, Val Loss: 0.6726
Epoch [61/120], Loss: 0.1298, Val Loss: 0.5587
Epoch [62/120], Loss: 0.0942, Val Loss: 0.5119
Epoch [63/120], Loss: 0.1753, Val Loss: 0.7042
Epoch [64/120], Loss: 0.1174, Val Loss: 0.5529
Epoch [65/120], Loss: 0.3895, Val Loss: 0.5482
Epoch [66/120], Loss: 0.4921, Val Loss: 0.5417
Epoch [67/120], Loss: 0.1295, Val Loss: 0.5253
Epoch [68/120], Loss: 0.0587, Val Loss: 0.7893
Epoch [69/120], Loss: 0.1776, Val Loss: 0.5783
Epoch [70/120], Loss: 0.4700, Val Loss: 0.6450
Epoch [71/120], Loss: 0.1642, Val Loss: 0.7262
Epoch [72/120], Loss: 0.1502, Val Loss: 0.5934
Epoch [73/120], Loss: 0.0954, Val Loss: 0.5477
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.0019515405874699354
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 1.9632, Val Loss: 0.8283
Epoch [2/120], Loss: 0.2374, Val Loss: 0.8651
Epoch [3/120], Loss: 0.1854, Val Loss: 0.7214
Epoch [4/120], Loss: 0.3833, Val Loss: 0.8494
Epoch [5/120], Loss: 0.1408, Val Loss: 0.6497
Epoch [6/120], Loss: 0.2475, Val Loss: 0.7451
Epoch [7/120], Loss: 0.7517, Val Loss: 0.6482
Epoch [8/120], Loss: 0.3283, Val Loss: 0.7973
Epoch [9/120], Loss: 0.3145, Val Loss: 0.7534
Epoch [10/120], Loss: 0.0890, Val Loss: 0.6650
Epoch [11/120], Loss: 0.2423, Val Loss: 0.7255
Epoch [12/120], Loss: 0.3699, Val Loss: 0.6269
Epoch [13/120], Loss: 0.2188, Val Loss: 0.6530
Epoch [14/120], Loss: 0.1827, Val Loss: 0.7273
Epoch [15/120], Loss: 0.1366, Val Loss: 0.6819
Epoch [16/120], Loss: 0.1605, Val Loss: 0.7036
Epoch [17/120], Loss: 0.2706, Val Loss: 0.6068
Epoch [18/120], Loss: 0.1471, Val Loss: 0.6237
Epoch [19/120], Loss: 0.2073, Val Loss: 0.6276
Epoch [20/120], Loss: 0.1114, Val Loss: 0.6291
Epoch [21/120], Loss: 0.1657, Val Loss: 0.6589
Epoch [22/120], Loss: 0.8865, Val Loss: 0.6791
Epoch [23/120], Loss: 0.0999, Val Loss: 0.6767
Epoch [24/120], Loss: 0.0513, Val Loss: 0.8433
Epoch [25/120], Loss: 0.2681, Val Loss: 0.5692
Epoch [26/120], Loss: 0.0778, Val Loss: 0.6296
Epoch [27/120], Loss: 0.0559, Val Loss: 0.6070
Epoch [28/120], Loss: 0.0973, Val Loss: 0.7047
Epoch [29/120], Loss: 0.1616, Val Loss: 0.7325
Epoch [30/120], Loss: 0.2204, Val Loss: 0.6468
Epoch [31/120], Loss: 0.1714, Val Loss: 0.8731
Epoch [32/120], Loss: 0.3270, Val Loss: 0.7096
Epoch [33/120], Loss: 0.1778, Val Loss: 0.6508
Epoch [34/120], Loss: 0.1146, Val Loss: 0.7370
Epoch [35/120], Loss: 0.0693, Val Loss: 0.7905
Epoch [36/120], Loss: 0.9232, Val Loss: 0.6654
Epoch [37/120], Loss: 0.8407, Val Loss: 0.7653
Epoch [38/120], Loss: 0.2026, Val Loss: 0.6785
Epoch [39/120], Loss: 0.1800, Val Loss: 0.7716
Epoch [40/120], Loss: 0.7285, Val Loss: 0.6596
Epoch [41/120], Loss: 0.1628, Val Loss: 0.6122
Epoch [42/120], Loss: 0.1530, Val Loss: 0.6162
Epoch [43/120], Loss: 0.1154, Val Loss: 0.7310
Epoch [44/120], Loss: 0.1648, Val Loss: 0.7191
Epoch [45/120], Loss: 0.0577, Val Loss: 0.5452
Epoch [46/120], Loss: 0.0948, Val Loss: 0.5377
Epoch [47/120], Loss: 0.7519, Val Loss: 0.5390
Epoch [48/120], Loss: 0.3738, Val Loss: 0.5167
Epoch [49/120], Loss: 0.1820, Val Loss: 0.5160
Epoch [50/120], Loss: 0.2972, Val Loss: 0.5272
Epoch [51/120], Loss: 0.7001, Val Loss: 0.5274
Epoch [52/120], Loss: 0.5632, Val Loss: 0.6126
Epoch [53/120], Loss: 1.5266, Val Loss: 0.6832
Epoch [54/120], Loss: 0.1166, Val Loss: 0.5456
Epoch [55/120], Loss: 0.0211, Val Loss: 0.5316
Epoch [56/120], Loss: 1.5288, Val Loss: 0.6214
Epoch [57/120], Loss: 0.0480, Val Loss: 0.5797
Epoch [58/120], Loss: 0.1210, Val Loss: 0.5257
Epoch [59/120], Loss: 0.1249, Val Loss: 0.6568
Epoch [60/120], Loss: 0.1403, Val Loss: 0.6967
Epoch [61/120], Loss: 0.2285, Val Loss: 0.5661
Epoch [62/120], Loss: 0.0895, Val Loss: 0.5740
Epoch [63/120], Loss: 0.2030, Val Loss: 0.5355
Epoch [64/120], Loss: 0.1597, Val Loss: 0.5652
Epoch [65/120], Loss: 0.3239, Val Loss: 0.5585
Epoch [66/120], Loss: 0.0923, Val Loss: 0.5936
Epoch [67/120], Loss: 0.1251, Val Loss: 0.5169
Epoch [68/120], Loss: 0.1057, Val Loss: 0.5544
Epoch [69/120], Loss: 0.1189, Val Loss: 0.5093
Epoch [70/120], Loss: 0.0999, Val Loss: 0.5487
Epoch [71/120], Loss: 0.3025, Val Loss: 0.7210
Epoch [72/120], Loss: 0.1424, Val Loss: 0.5694
Epoch [73/120], Loss: 0.8779, Val Loss: 0.6047
Epoch [74/120], Loss: 0.1539, Val Loss: 0.6166
Epoch [75/120], Loss: 0.1515, Val Loss: 0.8040
Epoch [76/120], Loss: 0.2142, Val Loss: 0.6014
Epoch [77/120], Loss: 0.2388, Val Loss: 0.6371
Epoch [78/120], Loss: 0.1118, Val Loss: 0.7026
Epoch [79/120], Loss: 0.2039, Val Loss: 0.7214
Epoch [80/120], Loss: 0.1914, Val Loss: 0.5204
Epoch [81/120], Loss: 0.4070, Val Loss: 0.7503
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.0006668449495919049
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 1.9917, Val Loss: 0.7715
Epoch [2/120], Loss: 0.3562, Val Loss: 0.9287
Epoch [3/120], Loss: 1.1497, Val Loss: 0.7102
Epoch [4/120], Loss: 0.3000, Val Loss: 0.6740
Epoch [5/120], Loss: 0.1840, Val Loss: 0.7404
Epoch [6/120], Loss: 0.6929, Val Loss: 0.6537
Epoch [7/120], Loss: 0.3066, Val Loss: 0.7949
Epoch [8/120], Loss: 0.1298, Val Loss: 0.6933
Epoch [9/120], Loss: 1.0335, Val Loss: 0.7806
Epoch [10/120], Loss: 0.2948, Val Loss: 0.9116
Epoch [11/120], Loss: 0.0720, Val Loss: 0.6650
Epoch [12/120], Loss: 0.3537, Val Loss: 0.7498
Epoch [13/120], Loss: 0.1431, Val Loss: 0.6485
Epoch [14/120], Loss: 0.0678, Val Loss: 0.7047
Epoch [15/120], Loss: 0.6951, Val Loss: 0.7317
Epoch [16/120], Loss: 0.3160, Val Loss: 0.6495
Epoch [17/120], Loss: 0.2079, Val Loss: 0.6419
Epoch [18/120], Loss: 0.3683, Val Loss: 0.7042
Epoch [19/120], Loss: 0.3441, Val Loss: 0.6415
Epoch [20/120], Loss: 0.0677, Val Loss: 0.6165
Epoch [21/120], Loss: 0.4420, Val Loss: 0.6747
Epoch [22/120], Loss: 0.1125, Val Loss: 0.6790
Epoch [23/120], Loss: 0.4136, Val Loss: 0.7040
Epoch [24/120], Loss: 0.2497, Val Loss: 0.7037
Epoch [25/120], Loss: 0.1416, Val Loss: 0.7054
Epoch [26/120], Loss: 0.1444, Val Loss: 0.8279
Epoch [27/120], Loss: 0.4044, Val Loss: 0.6307
Epoch [28/120], Loss: 0.6750, Val Loss: 0.6830
Epoch [29/120], Loss: 0.0698, Val Loss: 0.6377
Epoch [30/120], Loss: 0.1172, Val Loss: 0.6530
Epoch [31/120], Loss: 0.9319, Val Loss: 0.6327
Epoch [32/120], Loss: 0.1024, Val Loss: 0.6562
Epoch [33/120], Loss: 0.1016, Val Loss: 0.6839
Epoch [34/120], Loss: 0.0865, Val Loss: 0.6405
Epoch [35/120], Loss: 0.2719, Val Loss: 0.7078
Epoch [36/120], Loss: 0.1379, Val Loss: 0.6748
Epoch [37/120], Loss: 0.6709, Val Loss: 0.6187
Epoch [38/120], Loss: 0.1458, Val Loss: 0.6691
Epoch [39/120], Loss: 0.3906, Val Loss: 0.6065
Epoch [40/120], Loss: 0.2257, Val Loss: 0.6643
Epoch [41/120], Loss: 0.0916, Val Loss: 0.6714
Epoch [42/120], Loss: 0.1790, Val Loss: 0.6518
Epoch [43/120], Loss: 0.1592, Val Loss: 0.6404
Epoch [44/120], Loss: 0.1424, Val Loss: 0.7042
Epoch [45/120], Loss: 0.0824, Val Loss: 0.7868
Epoch [46/120], Loss: 0.3125, Val Loss: 0.6481
Epoch [47/120], Loss: 0.1888, Val Loss: 0.7637
Epoch [48/120], Loss: 0.2154, Val Loss: 0.6314
Epoch [49/120], Loss: 0.1648, Val Loss: 0.6882
Epoch [50/120], Loss: 0.1991, Val Loss: 0.6089
Epoch [51/120], Loss: 0.0701, Val Loss: 0.7428
Epoch [52/120], Loss: 0.1958, Val Loss: 0.6430
Epoch [53/120], Loss: 0.2969, Val Loss: 0.6381
Epoch [54/120], Loss: 0.0892, Val Loss: 0.6281
Epoch [55/120], Loss: 0.7138, Val Loss: 0.6639
Epoch [56/120], Loss: 0.0856, Val Loss: 0.7106
Epoch [57/120], Loss: 0.1855, Val Loss: 0.6490
Epoch [58/120], Loss: 0.1665, Val Loss: 0.6348
Epoch [59/120], Loss: 0.0621, Val Loss: 0.6383
Epoch [60/120], Loss: 0.1020, Val Loss: 0.6793
Epoch [61/120], Loss: 0.1041, Val Loss: 0.6319
Epoch [62/120], Loss: 0.1178, Val Loss: 0.6685
Epoch [63/120], Loss: 0.3094, Val Loss: 0.6384
Epoch [64/120], Loss: 0.6847, Val Loss: 0.6285
Epoch [65/120], Loss: 0.1567, Val Loss: 0.6342
Epoch [66/120], Loss: 0.1241, Val Loss: 0.6364
Epoch [67/120], Loss: 0.1041, Val Loss: 0.6489
Epoch [68/120], Loss: 0.1266, Val Loss: 0.6810
Epoch [69/120], Loss: 0.0904, Val Loss: 0.6124
Epoch [70/120], Loss: 0.4136, Val Loss: 0.6334
Epoch [71/120], Loss: 0.4311, Val Loss: 0.6134
Epoch [72/120], Loss: 0.6368, Val Loss: 0.5775
Epoch [73/120], Loss: 0.0705, Val Loss: 0.5861
Epoch [74/120], Loss: 0.2183, Val Loss: 0.6387
Epoch [75/120], Loss: 0.1450, Val Loss: 0.6722
Epoch [76/120], Loss: 0.0633, Val Loss: 0.6630
Epoch [77/120], Loss: 0.2366, Val Loss: 0.6666
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.0006668449495919049
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.2848, Val Loss: 0.7708
Epoch [2/120], Loss: 0.2234, Val Loss: 0.7580
Epoch [3/120], Loss: 0.6825, Val Loss: 0.7462
Epoch [4/120], Loss: 0.2099, Val Loss: 0.8160
Epoch [5/120], Loss: 0.4409, Val Loss: 0.7617
Epoch [6/120], Loss: 0.2035, Val Loss: 0.6942
Epoch [7/120], Loss: 0.1447, Val Loss: 0.8949
Epoch [8/120], Loss: 0.5207, Val Loss: 0.7130
Epoch [9/120], Loss: 0.0701, Val Loss: 0.6847
Epoch [10/120], Loss: 0.1489, Val Loss: 0.7446
Epoch [11/120], Loss: 0.3073, Val Loss: 0.7951
Epoch [12/120], Loss: 0.2296, Val Loss: 0.8150
Epoch [13/120], Loss: 0.0982, Val Loss: 0.6857
Epoch [14/120], Loss: 0.8406, Val Loss: 0.7405
Epoch [15/120], Loss: 0.3217, Val Loss: 0.7069
Epoch [16/120], Loss: 0.6385, Val Loss: 0.6992
Epoch [17/120], Loss: 0.2691, Val Loss: 0.7158
Epoch [18/120], Loss: 0.2272, Val Loss: 0.7160
Epoch [19/120], Loss: 0.2012, Val Loss: 0.7065
Epoch [20/120], Loss: 0.3209, Val Loss: 0.7269
Epoch [21/120], Loss: 0.1614, Val Loss: 0.7096
Epoch [22/120], Loss: 0.1218, Val Loss: 0.6830
Epoch [23/120], Loss: 0.0963, Val Loss: 0.6591
Epoch [24/120], Loss: 0.3261, Val Loss: 0.7081
Epoch [25/120], Loss: 0.1217, Val Loss: 0.6683
Epoch [26/120], Loss: 0.5239, Val Loss: 0.6841
Epoch [27/120], Loss: 0.3014, Val Loss: 0.6212
Epoch [28/120], Loss: 0.2281, Val Loss: 0.6786
Epoch [29/120], Loss: 0.3096, Val Loss: 0.6874
Epoch [30/120], Loss: 0.1078, Val Loss: 0.6771
Epoch [31/120], Loss: 0.0727, Val Loss: 0.6556
Epoch [32/120], Loss: 0.2569, Val Loss: 0.6682
Epoch [33/120], Loss: 0.1566, Val Loss: 0.6553
Epoch [34/120], Loss: 0.3306, Val Loss: 0.6702
Epoch [35/120], Loss: 0.0957, Val Loss: 0.6255
Epoch [36/120], Loss: 0.0527, Val Loss: 0.6547
Epoch [37/120], Loss: 0.1176, Val Loss: 0.6568
Epoch [38/120], Loss: 0.4346, Val Loss: 0.6222
Epoch [39/120], Loss: 0.1610, Val Loss: 0.6240
Epoch [40/120], Loss: 0.0695, Val Loss: 0.6140
Epoch [41/120], Loss: 0.1209, Val Loss: 0.6089
Epoch [42/120], Loss: 0.3087, Val Loss: 0.6699
Epoch [43/120], Loss: 0.3434, Val Loss: 0.6174
Epoch [44/120], Loss: 0.8616, Val Loss: 0.6101
Epoch [45/120], Loss: 0.2633, Val Loss: 0.6268
Epoch [46/120], Loss: 0.8214, Val Loss: 0.6535
Epoch [47/120], Loss: 0.2544, Val Loss: 0.5843
Epoch [48/120], Loss: 0.5780, Val Loss: 0.6027
Epoch [49/120], Loss: 0.5783, Val Loss: 0.5821
Epoch [50/120], Loss: 0.2217, Val Loss: 0.6015
Epoch [51/120], Loss: 0.3219, Val Loss: 0.6123
Epoch [52/120], Loss: 0.4497, Val Loss: 0.5833
Epoch [53/120], Loss: 0.1863, Val Loss: 0.5870
Epoch [54/120], Loss: 0.3508, Val Loss: 0.5923
Epoch [55/120], Loss: 0.3434, Val Loss: 0.5784
Epoch [56/120], Loss: 0.2272, Val Loss: 0.6138
Epoch [57/120], Loss: 0.2004, Val Loss: 0.6074
Epoch [58/120], Loss: 0.0786, Val Loss: 0.5829
Epoch [59/120], Loss: 0.0845, Val Loss: 0.6925
Epoch [60/120], Loss: 0.3253, Val Loss: 0.5684
Epoch [61/120], Loss: 0.5896, Val Loss: 0.5995
Epoch [62/120], Loss: 0.0917, Val Loss: 0.5891
Epoch [63/120], Loss: 0.2862, Val Loss: 0.5726
Epoch [64/120], Loss: 0.1054, Val Loss: 0.6056
Epoch [65/120], Loss: 0.2018, Val Loss: 0.6077
Epoch [66/120], Loss: 0.1243, Val Loss: 0.5999
Epoch [67/120], Loss: 0.1405, Val Loss: 0.6275
Epoch [68/120], Loss: 0.2233, Val Loss: 0.6769
Epoch [69/120], Loss: 0.1762, Val Loss: 0.6030
Epoch [70/120], Loss: 0.2527, Val Loss: 0.5956
Epoch [71/120], Loss: 0.4279, Val Loss: 0.5853
Epoch [72/120], Loss: 0.2584, Val Loss: 0.5880
Epoch [73/120], Loss: 0.2809, Val Loss: 0.7464
Epoch [74/120], Loss: 0.2623, Val Loss: 0.6021
Epoch [75/120], Loss: 0.1855, Val Loss: 0.6279
Epoch [76/120], Loss: 0.1064, Val Loss: 0.5746
Epoch [77/120], Loss: 0.1714, Val Loss: 0.5816
Epoch [78/120], Loss: 0.1589, Val Loss: 0.5935
Epoch [79/120], Loss: 0.1244, Val Loss: 0.6074
Epoch [80/120], Loss: 0.2910, Val Loss: 0.5817
Epoch [81/120], Loss: 0.1144, Val Loss: 0.5622
Epoch [82/120], Loss: 0.1200, Val Loss: 0.6324
Epoch [83/120], Loss: 0.0964, Val Loss: 0.5942
Epoch [84/120], Loss: 0.1257, Val Loss: 0.5902
Epoch [85/120], Loss: 0.0990, Val Loss: 0.5931
Epoch [86/120], Loss: 0.3146, Val Loss: 0.6248
Epoch [87/120], Loss: 0.1481, Val Loss: 0.5904
Epoch [88/120], Loss: 0.1537, Val Loss: 0.6108
Epoch [89/120], Loss: 0.2562, Val Loss: 0.6175
Epoch [90/120], Loss: 0.1063, Val Loss: 0.6237
Epoch [91/120], Loss: 0.1785, Val Loss: 0.5906
Epoch [92/120], Loss: 0.1016, Val Loss: 0.6112
Epoch [93/120], Loss: 0.1275, Val Loss: 0.5983
Epoch [94/120], Loss: 0.2228, Val Loss: 0.5955
Epoch [95/120], Loss: 0.1901, Val Loss: 0.6302
Epoch [96/120], Loss: 0.1092, Val Loss: 0.6291
Epoch [97/120], Loss: 0.1409, Val Loss: 0.6077
Epoch [98/120], Loss: 0.2541, Val Loss: 0.6240
Epoch [99/120], Loss: 0.1901, Val Loss: 0.6123
Epoch [100/120], Loss: 0.3026, Val Loss: 0.5959
Epoch [101/120], Loss: 0.6018, Val Loss: 0.5873
Epoch [102/120], Loss: 0.4414, Val Loss: 0.6233
Epoch [103/120], Loss: 0.1176, Val Loss: 0.6220
Epoch [104/120], Loss: 0.0689, Val Loss: 0.6329
Epoch [105/120], Loss: 0.1138, Val Loss: 0.5896
Epoch [106/120], Loss: 0.4350, Val Loss: 0.6126
Epoch [107/120], Loss: 0.1376, Val Loss: 0.5869
Epoch [108/120], Loss: 0.1139, Val Loss: 0.6061
Epoch [109/120], Loss: 0.0792, Val Loss: 0.6243
Epoch [110/120], Loss: 0.2026, Val Loss: 0.6267
Early stopping at epoch 110
Runtime: 0:02:49.319435
R^2 Score: 0.8963
RMSE: 0.7402
MAE: 0.2441
MAPE: 23.81%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 9.038380812853575e-05
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.3688, Val Loss: 0.8046
Epoch [2/120], Loss: 0.6427, Val Loss: 0.7989
Epoch [3/120], Loss: 1.4084, Val Loss: 0.7802
Epoch [4/120], Loss: 1.8189, Val Loss: 0.7622
Epoch [5/120], Loss: 0.2708, Val Loss: 0.7613
Epoch [6/120], Loss: 0.4055, Val Loss: 0.7457
Epoch [7/120], Loss: 0.2413, Val Loss: 0.7777
Epoch [8/120], Loss: 0.2884, Val Loss: 0.7432
Epoch [9/120], Loss: 0.1686, Val Loss: 0.7297
Epoch [10/120], Loss: 0.8475, Val Loss: 0.7325
Epoch [11/120], Loss: 1.0913, Val Loss: 0.7233
Epoch [12/120], Loss: 0.3368, Val Loss: 0.7454
Epoch [13/120], Loss: 0.4826, Val Loss: 0.7300
Epoch [14/120], Loss: 0.2447, Val Loss: 0.7306
Epoch [15/120], Loss: 0.5369, Val Loss: 0.7113
Epoch [16/120], Loss: 0.3012, Val Loss: 0.7189
Epoch [17/120], Loss: 0.2972, Val Loss: 0.6961
Epoch [18/120], Loss: 0.1469, Val Loss: 0.7057
Epoch [19/120], Loss: 0.1428, Val Loss: 0.7629
Epoch [20/120], Loss: 0.4502, Val Loss: 0.7204
Epoch [21/120], Loss: 0.2127, Val Loss: 0.7132
Epoch [22/120], Loss: 0.3330, Val Loss: 0.7406
Epoch [23/120], Loss: 0.4343, Val Loss: 0.7274
Epoch [24/120], Loss: 2.6556, Val Loss: 0.7342
Epoch [25/120], Loss: 0.2561, Val Loss: 0.7295
Epoch [26/120], Loss: 0.3680, Val Loss: 0.7290
Epoch [27/120], Loss: 0.2139, Val Loss: 0.7402
Epoch [28/120], Loss: 0.3461, Val Loss: 0.7202
Epoch [29/120], Loss: 0.1002, Val Loss: 0.7138
Epoch [30/120], Loss: 0.1740, Val Loss: 0.7121
Epoch [31/120], Loss: 1.2677, Val Loss: 0.7365
Epoch [32/120], Loss: 0.2802, Val Loss: 0.7388
Epoch [33/120], Loss: 0.6846, Val Loss: 0.7051
Epoch [34/120], Loss: 0.4957, Val Loss: 0.6949
Epoch [35/120], Loss: 0.1809, Val Loss: 0.7018
Epoch [36/120], Loss: 0.3015, Val Loss: 0.7495
Epoch [37/120], Loss: 0.4239, Val Loss: 0.7254
Epoch [38/120], Loss: 0.1602, Val Loss: 0.7060
Epoch [39/120], Loss: 0.2645, Val Loss: 0.6956
Epoch [40/120], Loss: 0.3249, Val Loss: 0.6840
Epoch [41/120], Loss: 0.5867, Val Loss: 0.7247
Epoch [42/120], Loss: 0.3268, Val Loss: 0.7064
Epoch [43/120], Loss: 0.1013, Val Loss: 0.7117
Epoch [44/120], Loss: 1.3483, Val Loss: 0.7049
Epoch [45/120], Loss: 0.1420, Val Loss: 0.6880
Epoch [46/120], Loss: 0.9913, Val Loss: 0.7236
Epoch [47/120], Loss: 0.0966, Val Loss: 0.7370
Epoch [48/120], Loss: 0.2135, Val Loss: 0.6719
Epoch [49/120], Loss: 0.1273, Val Loss: 0.7032
Epoch [50/120], Loss: 0.3353, Val Loss: 0.6967
Epoch [51/120], Loss: 0.1785, Val Loss: 0.7004
Epoch [52/120], Loss: 0.1538, Val Loss: 0.6727
Epoch [53/120], Loss: 0.2269, Val Loss: 0.6757
Epoch [54/120], Loss: 0.5331, Val Loss: 0.6921
Epoch [55/120], Loss: 1.2346, Val Loss: 0.6901
Epoch [56/120], Loss: 1.2889, Val Loss: 0.6628
Epoch [57/120], Loss: 0.2153, Val Loss: 0.6700
Epoch [58/120], Loss: 0.1234, Val Loss: 0.6826
Epoch [59/120], Loss: 0.4238, Val Loss: 0.6692
Epoch [60/120], Loss: 0.0587, Val Loss: 0.6956
Epoch [61/120], Loss: 1.4976, Val Loss: 0.6664
Epoch [62/120], Loss: 1.8112, Val Loss: 0.6629
Epoch [63/120], Loss: 0.5868, Val Loss: 0.7002
Epoch [64/120], Loss: 0.2728, Val Loss: 0.6829
Epoch [65/120], Loss: 0.2612, Val Loss: 0.6572
Epoch [66/120], Loss: 0.1990, Val Loss: 0.6952
Epoch [67/120], Loss: 0.2806, Val Loss: 0.7036
Epoch [68/120], Loss: 0.2388, Val Loss: 0.6370
Epoch [69/120], Loss: 0.0724, Val Loss: 0.6893
Epoch [70/120], Loss: 2.0681, Val Loss: 0.7048
Epoch [71/120], Loss: 0.5480, Val Loss: 0.6693
Epoch [72/120], Loss: 0.2651, Val Loss: 0.6723
Epoch [73/120], Loss: 0.1551, Val Loss: 0.6514
Epoch [74/120], Loss: 0.2475, Val Loss: 0.6949
Epoch [75/120], Loss: 0.3906, Val Loss: 0.6736
Epoch [76/120], Loss: 0.2322, Val Loss: 0.6883
Epoch [77/120], Loss: 0.7237, Val Loss: 0.6721
Epoch [78/120], Loss: 0.2958, Val Loss: 0.6791
Epoch [79/120], Loss: 0.2585, Val Loss: 0.6660
Epoch [80/120], Loss: 0.2079, Val Loss: 0.6662
Epoch [81/120], Loss: 0.1590, Val Loss: 0.6741
Epoch [82/120], Loss: 0.5479, Val Loss: 0.6965
Epoch [83/120], Loss: 0.2231, Val Loss: 0.6718
Epoch [84/120], Loss: 0.1430, Val Loss: 0.6265
Epoch [85/120], Loss: 0.2422, Val Loss: 0.6695
Epoch [86/120], Loss: 0.1704, Val Loss: 0.6724
Epoch [87/120], Loss: 0.1688, Val Loss: 0.6701
Epoch [88/120], Loss: 0.1850, Val Loss: 0.6685
Epoch [89/120], Loss: 1.5311, Val Loss: 0.6895
Epoch [90/120], Loss: 0.1134, Val Loss: 0.6601
Epoch [91/120], Loss: 0.3358, Val Loss: 0.6614
Epoch [92/120], Loss: 0.2200, Val Loss: 0.6926
Epoch [93/120], Loss: 1.1112, Val Loss: 0.6749
Epoch [94/120], Loss: 0.2608, Val Loss: 0.6426
Epoch [95/120], Loss: 0.1490, Val Loss: 0.6336
Epoch [96/120], Loss: 0.4638, Val Loss: 0.6804
Epoch [97/120], Loss: 0.3372, Val Loss: 0.6659
Epoch [98/120], Loss: 0.0794, Val Loss: 0.6503
Epoch [99/120], Loss: 0.1241, Val Loss: 0.7027
Epoch [100/120], Loss: 0.3274, Val Loss: 0.6662
Epoch [101/120], Loss: 0.3217, Val Loss: 0.7285
Epoch [102/120], Loss: 0.8957, Val Loss: 0.7130
Epoch [103/120], Loss: 0.1306, Val Loss: 0.6534
Epoch [104/120], Loss: 0.0710, Val Loss: 0.6975
Epoch [105/120], Loss: 0.3237, Val Loss: 0.6592
Epoch [106/120], Loss: 0.3636, Val Loss: 0.6882
Epoch [107/120], Loss: 0.1165, Val Loss: 0.6498
Epoch [108/120], Loss: 0.1331, Val Loss: 0.7210
Epoch [109/120], Loss: 0.2667, Val Loss: 0.6847
Epoch [110/120], Loss: 0.5153, Val Loss: 0.6283
Epoch [111/120], Loss: 0.1356, Val Loss: 0.6693
Epoch [112/120], Loss: 0.1017, Val Loss: 0.6800
Epoch [113/120], Loss: 1.0654, Val Loss: 0.7066
Epoch [114/120], Loss: 0.3354, Val Loss: 0.7098
Epoch [115/120], Loss: 1.1051, Val Loss: 0.6629
Epoch [116/120], Loss: 0.2027, Val Loss: 0.6671
Epoch [117/120], Loss: 0.2844, Val Loss: 0.7129
Epoch [118/120], Loss: 0.1965, Val Loss: 0.6931
Epoch [119/120], Loss: 0.4816, Val Loss: 0.6697
Epoch [120/120], Loss: 0.1145, Val Loss: 0.6559
Runtime: 0:02:56.533924
R^2 Score: 0.8855
RMSE: 0.7779
MAE: 0.2632
MAPE: 24.52%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00035643947194330394
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 1.4748, Val Loss: 0.7576
Epoch [2/120], Loss: 0.2688, Val Loss: 0.7461
Epoch [3/120], Loss: 0.0902, Val Loss: 0.6989
Epoch [4/120], Loss: 0.2668, Val Loss: 0.7458
Epoch [5/120], Loss: 0.2929, Val Loss: 0.8953
Epoch [6/120], Loss: 0.6032, Val Loss: 0.7266
Epoch [7/120], Loss: 0.1244, Val Loss: 0.6750
Epoch [8/120], Loss: 1.2029, Val Loss: 0.6765
Epoch [9/120], Loss: 0.0861, Val Loss: 0.9981
Epoch [10/120], Loss: 0.3258, Val Loss: 0.7131
Epoch [11/120], Loss: 0.4692, Val Loss: 0.7367
Epoch [12/120], Loss: 0.2067, Val Loss: 0.6869
Epoch [13/120], Loss: 0.6443, Val Loss: 0.6993
Epoch [14/120], Loss: 0.4073, Val Loss: 0.6432
Epoch [15/120], Loss: 0.1812, Val Loss: 0.7533
Epoch [16/120], Loss: 0.1395, Val Loss: 0.6591
Epoch [17/120], Loss: 0.2751, Val Loss: 0.6813
Epoch [18/120], Loss: 0.1266, Val Loss: 0.6088
Epoch [19/120], Loss: 0.1119, Val Loss: 0.8095
Epoch [20/120], Loss: 0.9621, Val Loss: 0.6340
Epoch [21/120], Loss: 0.6581, Val Loss: 0.6381
Epoch [22/120], Loss: 0.1500, Val Loss: 0.7076
Epoch [23/120], Loss: 0.0675, Val Loss: 0.6403
Epoch [24/120], Loss: 0.0839, Val Loss: 0.6198
Epoch [25/120], Loss: 0.2564, Val Loss: 0.6495
Epoch [26/120], Loss: 1.5899, Val Loss: 0.6136
Epoch [27/120], Loss: 0.1462, Val Loss: 0.5999
Epoch [28/120], Loss: 0.1892, Val Loss: 0.6651
Epoch [29/120], Loss: 0.2098, Val Loss: 0.6134
Epoch [30/120], Loss: 0.1044, Val Loss: 0.6219
Epoch [31/120], Loss: 0.1839, Val Loss: 0.6117
Epoch [32/120], Loss: 0.3918, Val Loss: 0.6135
Epoch [33/120], Loss: 0.0837, Val Loss: 0.6262
Epoch [34/120], Loss: 0.8292, Val Loss: 0.6132
Epoch [35/120], Loss: 0.6557, Val Loss: 0.6029
Epoch [36/120], Loss: 0.1516, Val Loss: 0.5811
Epoch [37/120], Loss: 0.5779, Val Loss: 0.6313
Epoch [38/120], Loss: 0.2263, Val Loss: 0.5735
Epoch [39/120], Loss: 0.3198, Val Loss: 0.6155
Epoch [40/120], Loss: 0.1646, Val Loss: 0.6258
Epoch [41/120], Loss: 0.2393, Val Loss: 0.5964
Epoch [42/120], Loss: 0.0736, Val Loss: 0.6319
Epoch [43/120], Loss: 0.1421, Val Loss: 0.5896
Epoch [44/120], Loss: 0.2848, Val Loss: 0.5875
Epoch [45/120], Loss: 0.1506, Val Loss: 0.6495
Epoch [46/120], Loss: 0.1405, Val Loss: 0.5854
Epoch [47/120], Loss: 0.3547, Val Loss: 0.6054
Epoch [48/120], Loss: 0.2211, Val Loss: 0.6310
Epoch [49/120], Loss: 0.6358, Val Loss: 0.6058
Epoch [50/120], Loss: 0.1132, Val Loss: 0.7056
Epoch [51/120], Loss: 0.1614, Val Loss: 0.6291
Epoch [52/120], Loss: 0.4169, Val Loss: 0.5975
Epoch [53/120], Loss: 0.4759, Val Loss: 0.6083
Epoch [54/120], Loss: 0.1399, Val Loss: 0.5820
Epoch [55/120], Loss: 0.2247, Val Loss: 0.5646
Epoch [56/120], Loss: 0.0952, Val Loss: 0.5843
Epoch [57/120], Loss: 0.2067, Val Loss: 0.5972
Epoch [58/120], Loss: 0.1554, Val Loss: 0.6339
Epoch [59/120], Loss: 0.1408, Val Loss: 0.5920
Epoch [60/120], Loss: 0.1133, Val Loss: 0.5982
Epoch [61/120], Loss: 0.1245, Val Loss: 0.6186
Epoch [62/120], Loss: 0.0553, Val Loss: 0.6023
Epoch [63/120], Loss: 0.0890, Val Loss: 0.6088
Epoch [64/120], Loss: 0.2715, Val Loss: 0.5723
Epoch [65/120], Loss: 0.0792, Val Loss: 0.5850
Epoch [66/120], Loss: 0.2223, Val Loss: 0.6176
Epoch [67/120], Loss: 0.1973, Val Loss: 0.6145
Epoch [68/120], Loss: 4.3390, Val Loss: 0.6415
Epoch [69/120], Loss: 0.0989, Val Loss: 0.6167
Epoch [70/120], Loss: 0.1216, Val Loss: 0.5798
Epoch [71/120], Loss: 0.2167, Val Loss: 0.6210
Epoch [72/120], Loss: 0.1587, Val Loss: 0.5915
Epoch [73/120], Loss: 0.2509, Val Loss: 0.6085
Epoch [74/120], Loss: 0.1188, Val Loss: 0.5971
Epoch [75/120], Loss: 0.2904, Val Loss: 0.5900
Epoch [76/120], Loss: 0.0883, Val Loss: 0.5699
Epoch [77/120], Loss: 0.0868, Val Loss: 0.5543
Epoch [78/120], Loss: 0.7686, Val Loss: 0.6058
Epoch [79/120], Loss: 0.1680, Val Loss: 0.5790
Epoch [80/120], Loss: 0.0757, Val Loss: 0.5753
Epoch [81/120], Loss: 0.3020, Val Loss: 0.5824
Epoch [82/120], Loss: 0.2027, Val Loss: 0.6050
Epoch [83/120], Loss: 0.1661, Val Loss: 0.5552
Epoch [84/120], Loss: 0.0820, Val Loss: 0.6328
Epoch [85/120], Loss: 0.1184, Val Loss: 0.6046
Epoch [86/120], Loss: 0.1626, Val Loss: 0.5711
Epoch [87/120], Loss: 0.1651, Val Loss: 0.5710
Epoch [88/120], Loss: 0.2474, Val Loss: 0.5556
Epoch [89/120], Loss: 0.1056, Val Loss: 0.5672
Epoch [90/120], Loss: 1.2944, Val Loss: 0.5543
Epoch [91/120], Loss: 0.1463, Val Loss: 0.5801
Epoch [92/120], Loss: 0.1771, Val Loss: 0.5663
Epoch [93/120], Loss: 0.1907, Val Loss: 0.5733
Epoch [94/120], Loss: 0.0996, Val Loss: 0.5752
Epoch [95/120], Loss: 0.2323, Val Loss: 0.5607
Epoch [96/120], Loss: 0.2207, Val Loss: 0.5652
Epoch [97/120], Loss: 0.4183, Val Loss: 0.5588
Epoch [98/120], Loss: 0.1565, Val Loss: 0.6205
Epoch [99/120], Loss: 0.5290, Val Loss: 0.5478
Epoch [100/120], Loss: 0.1039, Val Loss: 0.5930
Epoch [101/120], Loss: 0.1015, Val Loss: 0.5874
Epoch [102/120], Loss: 0.0801, Val Loss: 0.5955
Epoch [103/120], Loss: 0.1232, Val Loss: 0.5773
Epoch [104/120], Loss: 0.0637, Val Loss: 0.5314
Epoch [105/120], Loss: 0.6534, Val Loss: 0.5867
Epoch [106/120], Loss: 0.1318, Val Loss: 0.5965
Epoch [107/120], Loss: 0.1033, Val Loss: 0.5486
Epoch [108/120], Loss: 0.1160, Val Loss: 0.6167
Epoch [109/120], Loss: 0.1665, Val Loss: 0.5720
Epoch [110/120], Loss: 0.2470, Val Loss: 0.6096
Epoch [111/120], Loss: 0.0973, Val Loss: 0.5993
Epoch [112/120], Loss: 0.0751, Val Loss: 0.5603
Epoch [113/120], Loss: 0.5641, Val Loss: 0.5792
Epoch [114/120], Loss: 0.1440, Val Loss: 0.5693
Epoch [115/120], Loss: 0.1140, Val Loss: 0.5619
Epoch [116/120], Loss: 0.3303, Val Loss: 0.6232
Epoch [117/120], Loss: 0.1185, Val Loss: 0.5759
Epoch [118/120], Loss: 0.0635, Val Loss: 0.5702
Epoch [119/120], Loss: 0.0850, Val Loss: 0.5676
Epoch [120/120], Loss: 0.1248, Val Loss: 0.5799
Runtime: 0:02:58.610623
R^2 Score: 0.8967
RMSE: 0.7389
MAE: 0.2257
MAPE: 18.50%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00042629597010090947
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.6515, Val Loss: 0.9033
Epoch [2/120], Loss: 0.2784, Val Loss: 0.8075
Epoch [3/120], Loss: 0.5343, Val Loss: 0.7580
Epoch [4/120], Loss: 0.4721, Val Loss: 0.7447
Epoch [5/120], Loss: 0.1768, Val Loss: 0.8033
Epoch [6/120], Loss: 0.5618, Val Loss: 0.7480
Epoch [7/120], Loss: 0.1605, Val Loss: 0.7649
Epoch [8/120], Loss: 0.6767, Val Loss: 0.6530
Epoch [9/120], Loss: 0.1790, Val Loss: 0.7161
Epoch [10/120], Loss: 0.1543, Val Loss: 0.7735
Epoch [11/120], Loss: 0.1467, Val Loss: 0.7496
Epoch [12/120], Loss: 0.3608, Val Loss: 0.7611
Epoch [13/120], Loss: 0.4110, Val Loss: 0.6565
Epoch [14/120], Loss: 0.8310, Val Loss: 0.8099
Epoch [15/120], Loss: 0.1456, Val Loss: 0.6893
Epoch [16/120], Loss: 0.3279, Val Loss: 0.6415
Epoch [17/120], Loss: 0.2652, Val Loss: 0.7070
Epoch [18/120], Loss: 0.2599, Val Loss: 0.6675
Epoch [19/120], Loss: 0.3827, Val Loss: 0.7201
Epoch [20/120], Loss: 0.2663, Val Loss: 0.6639
Epoch [21/120], Loss: 0.1677, Val Loss: 0.7182
Epoch [22/120], Loss: 0.1425, Val Loss: 0.6650
Epoch [23/120], Loss: 0.1512, Val Loss: 0.6812
Epoch [24/120], Loss: 0.1733, Val Loss: 0.6820
Epoch [25/120], Loss: 0.4929, Val Loss: 0.6076
Epoch [26/120], Loss: 0.0820, Val Loss: 0.6609
Epoch [27/120], Loss: 0.1201, Val Loss: 0.7567
Epoch [28/120], Loss: 0.4974, Val Loss: 0.6646
Epoch [29/120], Loss: 0.2391, Val Loss: 0.6346
Epoch [30/120], Loss: 0.1983, Val Loss: 0.6918
Epoch [31/120], Loss: 0.1225, Val Loss: 0.6014
Epoch [32/120], Loss: 0.1490, Val Loss: 0.6137
Epoch [33/120], Loss: 0.1101, Val Loss: 0.6877
Epoch [34/120], Loss: 0.1782, Val Loss: 0.6135
Epoch [35/120], Loss: 0.0776, Val Loss: 0.6215
Epoch [36/120], Loss: 0.1594, Val Loss: 0.6271
Epoch [37/120], Loss: 0.1464, Val Loss: 0.5927
Epoch [38/120], Loss: 0.3322, Val Loss: 0.6247
Epoch [39/120], Loss: 0.3426, Val Loss: 0.6632
Epoch [40/120], Loss: 0.1981, Val Loss: 0.6350
Epoch [41/120], Loss: 0.0959, Val Loss: 0.6210
Epoch [42/120], Loss: 0.0717, Val Loss: 0.7247
Epoch [43/120], Loss: 0.4765, Val Loss: 0.6195
Epoch [44/120], Loss: 0.0807, Val Loss: 0.6416
Epoch [45/120], Loss: 0.0915, Val Loss: 0.6453
Epoch [46/120], Loss: 0.1560, Val Loss: 0.6083
Epoch [47/120], Loss: 0.1805, Val Loss: 0.6221
Epoch [48/120], Loss: 0.4686, Val Loss: 0.7774
Epoch [49/120], Loss: 0.1789, Val Loss: 0.5994
Epoch [50/120], Loss: 0.2327, Val Loss: 0.6180
Epoch [51/120], Loss: 0.1184, Val Loss: 0.6418
Epoch [52/120], Loss: 0.1428, Val Loss: 0.6156
Epoch [53/120], Loss: 0.5233, Val Loss: 0.6085
Epoch [54/120], Loss: 0.3634, Val Loss: 0.6933
Epoch [55/120], Loss: 0.2184, Val Loss: 0.6439
Epoch [56/120], Loss: 0.4213, Val Loss: 0.6049
Epoch [57/120], Loss: 0.2900, Val Loss: 0.5841
Epoch [58/120], Loss: 0.1207, Val Loss: 0.6029
Epoch [59/120], Loss: 0.0920, Val Loss: 0.6219
Epoch [60/120], Loss: 0.5242, Val Loss: 0.5817
Epoch [61/120], Loss: 0.1419, Val Loss: 0.6441
Epoch [62/120], Loss: 0.1764, Val Loss: 0.7692
Epoch [63/120], Loss: 0.1729, Val Loss: 0.6288
Epoch [64/120], Loss: 0.2690, Val Loss: 0.6728
Epoch [65/120], Loss: 0.2321, Val Loss: 0.6289
Epoch [66/120], Loss: 0.1161, Val Loss: 0.7083
Epoch [67/120], Loss: 0.1543, Val Loss: 0.6707
Epoch [68/120], Loss: 0.2345, Val Loss: 0.5841
Epoch [69/120], Loss: 0.0759, Val Loss: 0.5942
Epoch [70/120], Loss: 0.1435, Val Loss: 0.6226
Epoch [71/120], Loss: 0.2167, Val Loss: 0.6420
Epoch [72/120], Loss: 0.1357, Val Loss: 0.5760
Epoch [73/120], Loss: 0.0934, Val Loss: 0.6533
Epoch [74/120], Loss: 0.3766, Val Loss: 0.6444
Epoch [75/120], Loss: 0.1825, Val Loss: 0.5855
Epoch [76/120], Loss: 0.5877, Val Loss: 0.6301
Epoch [77/120], Loss: 0.2050, Val Loss: 0.5926
Epoch [78/120], Loss: 0.1288, Val Loss: 0.6257
Epoch [79/120], Loss: 0.1386, Val Loss: 0.5998
Epoch [80/120], Loss: 0.1049, Val Loss: 0.6197
Epoch [81/120], Loss: 0.1129, Val Loss: 0.6142
Epoch [82/120], Loss: 0.2952, Val Loss: 0.6200
Epoch [83/120], Loss: 0.0664, Val Loss: 0.6023
Epoch [84/120], Loss: 0.1741, Val Loss: 0.6151
Epoch [85/120], Loss: 0.0948, Val Loss: 0.5973
Epoch [86/120], Loss: 0.1130, Val Loss: 0.6057
Epoch [87/120], Loss: 0.0786, Val Loss: 0.6249
Epoch [88/120], Loss: 0.1461, Val Loss: 0.6519
Epoch [89/120], Loss: 0.2337, Val Loss: 0.6209
Epoch [90/120], Loss: 0.1808, Val Loss: 0.6377
Epoch [91/120], Loss: 0.1052, Val Loss: 0.6205
Epoch [92/120], Loss: 0.0784, Val Loss: 0.6149
Epoch [93/120], Loss: 0.1138, Val Loss: 0.6254
Epoch [94/120], Loss: 0.1879, Val Loss: 0.5949
Epoch [95/120], Loss: 0.3721, Val Loss: 0.6389
Epoch [96/120], Loss: 0.0834, Val Loss: 0.6404
Epoch [97/120], Loss: 0.2150, Val Loss: 0.5978
Epoch [98/120], Loss: 0.1400, Val Loss: 0.6338
Epoch [99/120], Loss: 0.1344, Val Loss: 0.5996
Epoch [100/120], Loss: 0.1543, Val Loss: 0.6340
Epoch [101/120], Loss: 0.1183, Val Loss: 0.6291
Early stopping at epoch 101
Runtime: 0:02:30.344455
R^2 Score: 0.8933
RMSE: 0.7508
MAE: 0.2223
MAPE: 19.61%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00011137053661514074
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.3696, Val Loss: 0.8162
Epoch [2/120], Loss: 1.1443, Val Loss: 0.8040
Epoch [3/120], Loss: 0.1516, Val Loss: 0.8110
Epoch [4/120], Loss: 0.5951, Val Loss: 0.7856
Epoch [5/120], Loss: 0.2046, Val Loss: 0.7398
Epoch [6/120], Loss: 0.2069, Val Loss: 0.7491
Epoch [7/120], Loss: 0.4293, Val Loss: 0.7204
Epoch [8/120], Loss: 0.0761, Val Loss: 0.7270
Epoch [9/120], Loss: 0.2962, Val Loss: 0.7389
Epoch [10/120], Loss: 0.4713, Val Loss: 0.7326
Epoch [11/120], Loss: 1.3870, Val Loss: 0.7047
Epoch [12/120], Loss: 0.5349, Val Loss: 0.7093
Epoch [13/120], Loss: 0.1555, Val Loss: 0.7335
Epoch [14/120], Loss: 0.1330, Val Loss: 0.7181
Epoch [15/120], Loss: 0.1915, Val Loss: 0.6999
Epoch [16/120], Loss: 0.2527, Val Loss: 0.6971
Epoch [17/120], Loss: 1.7880, Val Loss: 0.7270
Epoch [18/120], Loss: 1.1088, Val Loss: 0.7281
Epoch [19/120], Loss: 0.3373, Val Loss: 0.6981
Epoch [20/120], Loss: 0.3270, Val Loss: 0.6872
Epoch [21/120], Loss: 0.7255, Val Loss: 0.7338
Epoch [22/120], Loss: 0.1502, Val Loss: 0.7216
Epoch [23/120], Loss: 0.1077, Val Loss: 0.7244
Epoch [24/120], Loss: 0.1863, Val Loss: 0.6960
Epoch [25/120], Loss: 0.3267, Val Loss: 0.6967
Epoch [26/120], Loss: 0.1498, Val Loss: 0.7417
Epoch [27/120], Loss: 0.3067, Val Loss: 0.7107
Epoch [28/120], Loss: 0.1751, Val Loss: 0.6746
Epoch [29/120], Loss: 0.1634, Val Loss: 0.7072
Epoch [30/120], Loss: 0.1914, Val Loss: 0.7217
Epoch [31/120], Loss: 0.2841, Val Loss: 0.6645
Epoch [32/120], Loss: 0.4779, Val Loss: 0.6554
Epoch [33/120], Loss: 0.1918, Val Loss: 0.6686
Epoch [34/120], Loss: 0.2967, Val Loss: 0.6741
Epoch [35/120], Loss: 0.1228, Val Loss: 0.6585
Epoch [36/120], Loss: 0.1500, Val Loss: 0.6488
Epoch [37/120], Loss: 0.6491, Val Loss: 0.6562
Epoch [38/120], Loss: 0.3371, Val Loss: 0.7165
Epoch [39/120], Loss: 0.3321, Val Loss: 0.6353
Epoch [40/120], Loss: 0.5173, Val Loss: 0.6259
Epoch [41/120], Loss: 0.1658, Val Loss: 0.6746
Epoch [42/120], Loss: 0.7230, Val Loss: 0.6774
Epoch [43/120], Loss: 0.1815, Val Loss: 0.6635
Epoch [44/120], Loss: 0.7536, Val Loss: 0.6443
Epoch [45/120], Loss: 0.3342, Val Loss: 0.6423
Epoch [46/120], Loss: 0.7063, Val Loss: 0.6319
Epoch [47/120], Loss: 0.2917, Val Loss: 0.6363
Epoch [48/120], Loss: 0.0918, Val Loss: 0.6240
Epoch [49/120], Loss: 0.2790, Val Loss: 0.6337
Epoch [50/120], Loss: 0.2132, Val Loss: 0.6802
Epoch [51/120], Loss: 0.2461, Val Loss: 0.6557
Epoch [52/120], Loss: 0.7280, Val Loss: 0.6353
Epoch [53/120], Loss: 0.2196, Val Loss: 0.6495
Epoch [54/120], Loss: 0.1461, Val Loss: 0.6219
Epoch [55/120], Loss: 0.1314, Val Loss: 0.6636
Epoch [56/120], Loss: 0.2440, Val Loss: 0.6444
Epoch [57/120], Loss: 0.4845, Val Loss: 0.6472
Epoch [58/120], Loss: 0.4309, Val Loss: 0.6508
Epoch [59/120], Loss: 0.3231, Val Loss: 0.6518
Epoch [60/120], Loss: 0.9245, Val Loss: 0.6345
Epoch [61/120], Loss: 0.1636, Val Loss: 0.6462
Epoch [62/120], Loss: 0.1165, Val Loss: 0.6572
Epoch [63/120], Loss: 0.3111, Val Loss: 0.6219
Epoch [64/120], Loss: 0.0934, Val Loss: 0.6252
Epoch [65/120], Loss: 0.0790, Val Loss: 0.6360
Epoch [66/120], Loss: 0.2533, Val Loss: 0.6488
Epoch [67/120], Loss: 0.3268, Val Loss: 0.6440
Epoch [68/120], Loss: 0.1836, Val Loss: 0.6087
Epoch [69/120], Loss: 0.4065, Val Loss: 0.6432
Epoch [70/120], Loss: 0.3093, Val Loss: 0.6490
Epoch [71/120], Loss: 0.4981, Val Loss: 0.6168
Epoch [72/120], Loss: 0.2706, Val Loss: 0.6841
Epoch [73/120], Loss: 0.0787, Val Loss: 0.6005
Epoch [74/120], Loss: 0.5426, Val Loss: 0.6112
Epoch [75/120], Loss: 0.1547, Val Loss: 0.6282
Epoch [76/120], Loss: 0.2904, Val Loss: 0.6441
Epoch [77/120], Loss: 1.0641, Val Loss: 0.6064
Epoch [78/120], Loss: 0.4886, Val Loss: 0.6230
Epoch [79/120], Loss: 0.4272, Val Loss: 0.6240
Epoch [80/120], Loss: 0.1313, Val Loss: 0.5995
Epoch [81/120], Loss: 0.1690, Val Loss: 0.6120
Epoch [82/120], Loss: 0.2750, Val Loss: 0.6045
Epoch [83/120], Loss: 0.1956, Val Loss: 0.5975
Epoch [84/120], Loss: 0.3222, Val Loss: 0.6119
Epoch [85/120], Loss: 0.0977, Val Loss: 0.6261
Epoch [86/120], Loss: 0.1538, Val Loss: 0.6048
Epoch [87/120], Loss: 0.1494, Val Loss: 0.6074
Epoch [88/120], Loss: 0.0917, Val Loss: 0.6496
Epoch [89/120], Loss: 0.1194, Val Loss: 0.6203
Epoch [90/120], Loss: 0.1616, Val Loss: 0.6146
Epoch [91/120], Loss: 0.0686, Val Loss: 0.6080
Epoch [92/120], Loss: 0.1188, Val Loss: 0.6320
Epoch [93/120], Loss: 0.8954, Val Loss: 0.6116
Epoch [94/120], Loss: 0.2886, Val Loss: 0.6184
Epoch [95/120], Loss: 0.1648, Val Loss: 0.6181
Epoch [96/120], Loss: 0.2043, Val Loss: 0.6054
Epoch [97/120], Loss: 0.1819, Val Loss: 0.6011
Epoch [98/120], Loss: 0.1377, Val Loss: 0.6119
Epoch [99/120], Loss: 0.2049, Val Loss: 0.6264
Epoch [100/120], Loss: 0.1737, Val Loss: 0.6165
Epoch [101/120], Loss: 0.0556, Val Loss: 0.6211
Epoch [102/120], Loss: 0.5493, Val Loss: 0.6167
Epoch [103/120], Loss: 0.4833, Val Loss: 0.6185
Epoch [104/120], Loss: 0.3486, Val Loss: 0.6006
Epoch [105/120], Loss: 0.1083, Val Loss: 0.6170
Epoch [106/120], Loss: 0.0931, Val Loss: 0.6145
Epoch [107/120], Loss: 0.2908, Val Loss: 0.6145
Epoch [108/120], Loss: 0.5447, Val Loss: 0.6066
Epoch [109/120], Loss: 0.2123, Val Loss: 0.6173
Epoch [110/120], Loss: 4.2512, Val Loss: 0.6130
Epoch [111/120], Loss: 0.2661, Val Loss: 0.6294
Epoch [112/120], Loss: 0.5007, Val Loss: 0.6186
Epoch [113/120], Loss: 0.1191, Val Loss: 0.6156
Epoch [114/120], Loss: 0.2238, Val Loss: 0.6096
Epoch [115/120], Loss: 0.0835, Val Loss: 0.6062
Epoch [116/120], Loss: 0.1013, Val Loss: 0.6256
Epoch [117/120], Loss: 0.2754, Val Loss: 0.6085
Epoch [118/120], Loss: 0.0673, Val Loss: 0.6092
Epoch [119/120], Loss: 0.1524, Val Loss: 0.6206
Epoch [120/120], Loss: 0.9978, Val Loss: 0.5956
Runtime: 0:02:56.953401
R^2 Score: 0.8915
RMSE: 0.7571
MAE: 0.2501
MAPE: 22.68%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00022116575564723462
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.2552, Val Loss: 0.8534
Epoch [2/120], Loss: 0.2517, Val Loss: 0.7469
Epoch [3/120], Loss: 0.2232, Val Loss: 0.7535
Epoch [4/120], Loss: 0.5436, Val Loss: 0.7713
Epoch [5/120], Loss: 0.3630, Val Loss: 0.7413
Epoch [6/120], Loss: 0.2862, Val Loss: 0.7265
Epoch [7/120], Loss: 0.1805, Val Loss: 0.7102
Epoch [8/120], Loss: 0.2219, Val Loss: 0.7429
Epoch [9/120], Loss: 0.4079, Val Loss: 0.7561
Epoch [10/120], Loss: 0.2370, Val Loss: 0.7499
Epoch [11/120], Loss: 1.0878, Val Loss: 0.7530
Epoch [12/120], Loss: 0.0782, Val Loss: 0.7465
Epoch [13/120], Loss: 0.1093, Val Loss: 0.7466
Epoch [14/120], Loss: 0.0706, Val Loss: 0.7479
Epoch [15/120], Loss: 0.1476, Val Loss: 0.7512
Epoch [16/120], Loss: 0.2067, Val Loss: 0.7232
Epoch [17/120], Loss: 1.1518, Val Loss: 0.6959
Epoch [18/120], Loss: 0.2503, Val Loss: 0.7559
Epoch [19/120], Loss: 0.1190, Val Loss: 0.7034
Epoch [20/120], Loss: 0.2359, Val Loss: 0.7099
Epoch [21/120], Loss: 0.2156, Val Loss: 0.7004
Epoch [22/120], Loss: 0.1108, Val Loss: 0.7276
Epoch [23/120], Loss: 0.1822, Val Loss: 0.7750
Epoch [24/120], Loss: 0.2427, Val Loss: 0.6587
Epoch [25/120], Loss: 0.2488, Val Loss: 0.6835
Epoch [26/120], Loss: 0.1294, Val Loss: 0.7689
Epoch [27/120], Loss: 1.1164, Val Loss: 0.7285
Epoch [28/120], Loss: 0.6582, Val Loss: 0.6371
Epoch [29/120], Loss: 0.1506, Val Loss: 0.7555
Epoch [30/120], Loss: 0.7163, Val Loss: 0.7610
Epoch [31/120], Loss: 0.1450, Val Loss: 0.6498
Epoch [32/120], Loss: 0.1417, Val Loss: 0.6412
Epoch [33/120], Loss: 0.1529, Val Loss: 0.6969
Epoch [34/120], Loss: 0.1729, Val Loss: 0.6527
Epoch [35/120], Loss: 0.0938, Val Loss: 0.6464
Epoch [36/120], Loss: 0.2290, Val Loss: 0.6655
Epoch [37/120], Loss: 0.2754, Val Loss: 0.6792
Epoch [38/120], Loss: 0.1310, Val Loss: 0.7231
Epoch [39/120], Loss: 0.2307, Val Loss: 0.6965
Epoch [40/120], Loss: 0.0659, Val Loss: 0.6656
Epoch [41/120], Loss: 0.2021, Val Loss: 0.6312
Epoch [42/120], Loss: 0.2817, Val Loss: 0.6346
Epoch [43/120], Loss: 0.1055, Val Loss: 0.6440
Epoch [44/120], Loss: 0.8518, Val Loss: 0.6498
Epoch [45/120], Loss: 0.2766, Val Loss: 0.7713
Epoch [46/120], Loss: 0.1669, Val Loss: 0.6825
Epoch [47/120], Loss: 0.0663, Val Loss: 0.6277
Epoch [48/120], Loss: 0.3014, Val Loss: 0.6362
Epoch [49/120], Loss: 0.8591, Val Loss: 0.6452
Epoch [50/120], Loss: 0.2732, Val Loss: 0.7554
Epoch [51/120], Loss: 0.2339, Val Loss: 0.6553
Epoch [52/120], Loss: 0.2047, Val Loss: 0.6634
Epoch [53/120], Loss: 0.1769, Val Loss: 0.6173
Epoch [54/120], Loss: 0.2066, Val Loss: 0.6236
Epoch [55/120], Loss: 0.1500, Val Loss: 0.6145
Epoch [56/120], Loss: 0.3842, Val Loss: 0.6456
Epoch [57/120], Loss: 0.3955, Val Loss: 0.6518
Epoch [58/120], Loss: 0.1760, Val Loss: 0.6342
Epoch [59/120], Loss: 0.1201, Val Loss: 0.6310
Epoch [60/120], Loss: 0.4982, Val Loss: 0.6733
Epoch [61/120], Loss: 0.0944, Val Loss: 0.7334
Epoch [62/120], Loss: 0.2748, Val Loss: 0.6443
Epoch [63/120], Loss: 0.6148, Val Loss: 0.6073
Epoch [64/120], Loss: 0.1940, Val Loss: 0.6353
Epoch [65/120], Loss: 0.1232, Val Loss: 0.6508
Epoch [66/120], Loss: 0.3730, Val Loss: 0.6186
Epoch [67/120], Loss: 0.3223, Val Loss: 0.6012
Epoch [68/120], Loss: 0.1262, Val Loss: 0.6324
Epoch [69/120], Loss: 1.4166, Val Loss: 0.6637
Epoch [70/120], Loss: 0.0953, Val Loss: 0.6562
Epoch [71/120], Loss: 0.0693, Val Loss: 0.6084
Epoch [72/120], Loss: 0.0445, Val Loss: 0.6074
Epoch [73/120], Loss: 0.0950, Val Loss: 0.6207
Epoch [74/120], Loss: 0.1487, Val Loss: 0.6234
Epoch [75/120], Loss: 0.0785, Val Loss: 0.6174
Epoch [76/120], Loss: 0.1532, Val Loss: 0.6092
Epoch [77/120], Loss: 0.0764, Val Loss: 0.6691
Epoch [78/120], Loss: 0.1503, Val Loss: 0.6574
Epoch [79/120], Loss: 0.3166, Val Loss: 0.6121
Epoch [80/120], Loss: 0.1782, Val Loss: 0.6358
Epoch [81/120], Loss: 0.1284, Val Loss: 0.6458
Epoch [82/120], Loss: 0.1407, Val Loss: 0.6305
Epoch [83/120], Loss: 0.0698, Val Loss: 0.6145
Epoch [84/120], Loss: 0.3800, Val Loss: 0.6133
Epoch [85/120], Loss: 0.2054, Val Loss: 0.5981
Epoch [86/120], Loss: 0.5118, Val Loss: 0.6020
Epoch [87/120], Loss: 0.5704, Val Loss: 0.5961
Epoch [88/120], Loss: 0.1467, Val Loss: 0.6458
Epoch [89/120], Loss: 0.2818, Val Loss: 0.5868
Epoch [90/120], Loss: 0.1996, Val Loss: 0.5836
Epoch [91/120], Loss: 0.1768, Val Loss: 0.6036
Epoch [92/120], Loss: 0.0952, Val Loss: 0.6114
Epoch [93/120], Loss: 0.0823, Val Loss: 0.6281
Epoch [94/120], Loss: 0.1125, Val Loss: 0.6737
Epoch [95/120], Loss: 0.1556, Val Loss: 0.6446
Epoch [96/120], Loss: 0.1400, Val Loss: 0.6196
Epoch [97/120], Loss: 0.1777, Val Loss: 0.6063
Epoch [98/120], Loss: 0.1159, Val Loss: 0.6265
Epoch [99/120], Loss: 0.1094, Val Loss: 0.6156
Epoch [100/120], Loss: 0.1788, Val Loss: 0.6167
Epoch [101/120], Loss: 0.1433, Val Loss: 0.5989
Epoch [102/120], Loss: 0.2180, Val Loss: 0.5822
Epoch [103/120], Loss: 0.1825, Val Loss: 0.6074
Epoch [104/120], Loss: 0.1008, Val Loss: 0.6088
Epoch [105/120], Loss: 0.0926, Val Loss: 0.6501
Epoch [106/120], Loss: 0.1704, Val Loss: 0.6022
Epoch [107/120], Loss: 0.1114, Val Loss: 0.6255
Epoch [108/120], Loss: 0.0804, Val Loss: 0.5778
Epoch [109/120], Loss: 0.3560, Val Loss: 0.5900
Epoch [110/120], Loss: 0.1705, Val Loss: 0.6686
Epoch [111/120], Loss: 0.3382, Val Loss: 0.6210
Epoch [112/120], Loss: 0.2124, Val Loss: 0.6352
Epoch [113/120], Loss: 0.1542, Val Loss: 0.6172
Epoch [114/120], Loss: 0.1081, Val Loss: 0.6068
Epoch [115/120], Loss: 0.1546, Val Loss: 0.6877
Epoch [116/120], Loss: 0.1810, Val Loss: 0.5969
Epoch [117/120], Loss: 0.2821, Val Loss: 0.6022
Epoch [118/120], Loss: 0.1697, Val Loss: 0.6050
Epoch [119/120], Loss: 0.3671, Val Loss: 0.6030
Epoch [120/120], Loss: 0.8441, Val Loss: 0.6354
Runtime: 0:03:00.048551
R^2 Score: 0.8927
RMSE: 0.7528
MAE: 0.2350
MAPE: 20.04%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00033579737646505237
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1785, Val Loss: 0.7605
Epoch [2/120], Loss: 0.7462, Val Loss: 0.7590
Epoch [3/120], Loss: 0.1828, Val Loss: 0.7090
Epoch [4/120], Loss: 0.7090, Val Loss: 0.8045
Epoch [5/120], Loss: 0.2310, Val Loss: 0.7075
Epoch [6/120], Loss: 0.8711, Val Loss: 0.6659
Epoch [7/120], Loss: 0.8760, Val Loss: 0.8661
Epoch [8/120], Loss: 0.1386, Val Loss: 0.7170
Epoch [9/120], Loss: 0.1696, Val Loss: 0.7393
Epoch [10/120], Loss: 0.4516, Val Loss: 0.6922
Epoch [11/120], Loss: 0.1781, Val Loss: 0.7094
Epoch [12/120], Loss: 0.2827, Val Loss: 0.6899
Epoch [13/120], Loss: 0.2544, Val Loss: 0.6746
Epoch [14/120], Loss: 0.6393, Val Loss: 0.7097
Epoch [15/120], Loss: 0.1592, Val Loss: 0.7547
Epoch [16/120], Loss: 0.9411, Val Loss: 0.6515
Epoch [17/120], Loss: 0.2787, Val Loss: 0.7872
Epoch [18/120], Loss: 0.2909, Val Loss: 0.7015
Epoch [19/120], Loss: 0.1010, Val Loss: 0.6759
Epoch [20/120], Loss: 0.2412, Val Loss: 0.7100
Epoch [21/120], Loss: 0.6760, Val Loss: 0.6756
Epoch [22/120], Loss: 0.3041, Val Loss: 0.6314
Epoch [23/120], Loss: 0.1448, Val Loss: 0.6545
Epoch [24/120], Loss: 0.5890, Val Loss: 0.7040
Epoch [25/120], Loss: 0.2574, Val Loss: 0.6838
Epoch [26/120], Loss: 0.1318, Val Loss: 0.6487
Epoch [27/120], Loss: 0.0939, Val Loss: 0.6914
Epoch [28/120], Loss: 0.0612, Val Loss: 0.6247
Epoch [29/120], Loss: 0.8779, Val Loss: 0.6720
Epoch [30/120], Loss: 0.1319, Val Loss: 0.7221
Epoch [31/120], Loss: 0.1394, Val Loss: 0.7150
Epoch [32/120], Loss: 0.2167, Val Loss: 0.6325
Epoch [33/120], Loss: 0.4592, Val Loss: 0.6192
Epoch [34/120], Loss: 0.3140, Val Loss: 0.6145
Epoch [35/120], Loss: 0.2738, Val Loss: 0.6746
Epoch [36/120], Loss: 0.2116, Val Loss: 0.6393
Epoch [37/120], Loss: 0.1418, Val Loss: 0.6324
Epoch [38/120], Loss: 0.1087, Val Loss: 0.6993
Epoch [39/120], Loss: 0.2077, Val Loss: 0.6576
Epoch [40/120], Loss: 0.3362, Val Loss: 0.6452
Epoch [41/120], Loss: 0.8547, Val Loss: 0.6101
Epoch [42/120], Loss: 0.5166, Val Loss: 0.6258
Epoch [43/120], Loss: 0.1750, Val Loss: 0.6580
Epoch [44/120], Loss: 0.0949, Val Loss: 0.6309
Epoch [45/120], Loss: 0.1774, Val Loss: 0.6342
Epoch [46/120], Loss: 0.2686, Val Loss: 0.6301
Epoch [47/120], Loss: 0.2456, Val Loss: 0.6446
Epoch [48/120], Loss: 0.0722, Val Loss: 0.7199
Epoch [49/120], Loss: 0.2087, Val Loss: 0.6702
Epoch [50/120], Loss: 0.0619, Val Loss: 0.6043
Epoch [51/120], Loss: 0.3732, Val Loss: 0.6192
Epoch [52/120], Loss: 0.1849, Val Loss: 0.6550
Epoch [53/120], Loss: 0.1547, Val Loss: 0.6161
Epoch [54/120], Loss: 0.0992, Val Loss: 0.6435
Epoch [55/120], Loss: 1.6953, Val Loss: 0.5901
Epoch [56/120], Loss: 0.2994, Val Loss: 0.6218
Epoch [57/120], Loss: 0.1675, Val Loss: 0.6025
Epoch [58/120], Loss: 0.1745, Val Loss: 0.6542
Epoch [59/120], Loss: 0.1202, Val Loss: 0.6742
Epoch [60/120], Loss: 0.4869, Val Loss: 0.6310
Epoch [61/120], Loss: 0.1192, Val Loss: 0.6317
Epoch [62/120], Loss: 0.3706, Val Loss: 0.6135
Epoch [63/120], Loss: 0.2643, Val Loss: 0.6286
Epoch [64/120], Loss: 0.0984, Val Loss: 0.6452
Epoch [65/120], Loss: 0.0335, Val Loss: 0.5998
Epoch [66/120], Loss: 0.0443, Val Loss: 0.6429
Epoch [67/120], Loss: 0.2726, Val Loss: 0.6483
Epoch [68/120], Loss: 1.2082, Val Loss: 0.6546
Epoch [69/120], Loss: 0.0757, Val Loss: 0.5951
Epoch [70/120], Loss: 0.4798, Val Loss: 0.6158
Epoch [71/120], Loss: 0.1262, Val Loss: 0.6247
Epoch [72/120], Loss: 0.1469, Val Loss: 0.6041
Epoch [73/120], Loss: 0.1003, Val Loss: 0.5937
Epoch [74/120], Loss: 0.2670, Val Loss: 0.6088
Epoch [75/120], Loss: 0.1199, Val Loss: 0.6180
Epoch [76/120], Loss: 0.0408, Val Loss: 0.6252
Epoch [77/120], Loss: 0.1837, Val Loss: 0.6280
Epoch [78/120], Loss: 0.1938, Val Loss: 0.5960
Epoch [79/120], Loss: 0.1274, Val Loss: 0.6179
Epoch [80/120], Loss: 0.0819, Val Loss: 0.6277
Epoch [81/120], Loss: 0.4569, Val Loss: 0.6125
Epoch [82/120], Loss: 0.4175, Val Loss: 0.6437
Epoch [83/120], Loss: 0.2186, Val Loss: 0.6133
Epoch [84/120], Loss: 0.1310, Val Loss: 0.6141
Epoch [85/120], Loss: 0.0450, Val Loss: 0.6481
Epoch [86/120], Loss: 0.0617, Val Loss: 0.6164
Epoch [87/120], Loss: 0.1295, Val Loss: 0.6717
Epoch [88/120], Loss: 0.3825, Val Loss: 0.6162
Epoch [89/120], Loss: 0.1054, Val Loss: 0.6707
Epoch [90/120], Loss: 0.2239, Val Loss: 0.6794
Epoch [91/120], Loss: 0.2697, Val Loss: 0.6147
Epoch [92/120], Loss: 0.1124, Val Loss: 0.6088
Epoch [93/120], Loss: 0.0645, Val Loss: 0.6329
Epoch [94/120], Loss: 0.0812, Val Loss: 0.6261
Epoch [95/120], Loss: 0.0922, Val Loss: 0.6347
Epoch [96/120], Loss: 0.1135, Val Loss: 0.6468
Epoch [97/120], Loss: 0.3143, Val Loss: 0.6152
Epoch [98/120], Loss: 0.0921, Val Loss: 0.6022
Epoch [99/120], Loss: 0.1793, Val Loss: 0.6139
Epoch [100/120], Loss: 0.1134, Val Loss: 0.6051
Epoch [101/120], Loss: 0.2691, Val Loss: 0.6136
Epoch [102/120], Loss: 0.1280, Val Loss: 0.6383
Early stopping at epoch 102
Runtime: 0:02:31.790579
R^2 Score: 0.8785
RMSE: 0.8011
MAE: 0.2293
MAPE: 18.59%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00035643947194330394
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.1600, Val Loss: 0.8111
Epoch [2/200], Loss: 0.3116, Val Loss: 0.7707
Epoch [3/200], Loss: 0.2796, Val Loss: 0.7552
Epoch [4/200], Loss: 0.3158, Val Loss: 0.7076
Epoch [5/200], Loss: 1.4109, Val Loss: 0.7609
Epoch [6/200], Loss: 0.3537, Val Loss: 0.6907
Epoch [7/200], Loss: 0.6348, Val Loss: 0.7121
Epoch [8/200], Loss: 0.3084, Val Loss: 0.6841
Epoch [9/200], Loss: 2.0081, Val Loss: 0.7033
Epoch [10/200], Loss: 1.0984, Val Loss: 0.7009
Epoch [11/200], Loss: 0.2782, Val Loss: 0.7291
Epoch [12/200], Loss: 0.1387, Val Loss: 0.6741
Epoch [13/200], Loss: 0.1983, Val Loss: 0.7042
Epoch [14/200], Loss: 0.2260, Val Loss: 0.6540
Epoch [15/200], Loss: 0.3511, Val Loss: 0.6249
Epoch [16/200], Loss: 0.1390, Val Loss: 0.6734
Epoch [17/200], Loss: 0.1751, Val Loss: 0.6687
Epoch [18/200], Loss: 0.1559, Val Loss: 0.6760
Epoch [19/200], Loss: 0.1907, Val Loss: 0.7260
Epoch [20/200], Loss: 0.2664, Val Loss: 0.7923
Epoch [21/200], Loss: 0.4138, Val Loss: 0.6637
Epoch [22/200], Loss: 0.2470, Val Loss: 0.6401
Epoch [23/200], Loss: 0.2212, Val Loss: 0.7107
Epoch [24/200], Loss: 0.2465, Val Loss: 0.6598
Epoch [25/200], Loss: 0.3795, Val Loss: 0.6122
Epoch [26/200], Loss: 0.2947, Val Loss: 0.6771
Epoch [27/200], Loss: 0.1457, Val Loss: 0.6576
Epoch [28/200], Loss: 0.2585, Val Loss: 0.6853
Epoch [29/200], Loss: 0.2672, Val Loss: 0.6357
Epoch [30/200], Loss: 0.2970, Val Loss: 0.6316
Epoch [31/200], Loss: 0.1873, Val Loss: 0.6867
Epoch [32/200], Loss: 0.2175, Val Loss: 0.6604
Epoch [33/200], Loss: 0.6721, Val Loss: 0.6116
Epoch [34/200], Loss: 0.4691, Val Loss: 0.6270
Epoch [35/200], Loss: 0.2288, Val Loss: 0.6141
Epoch [36/200], Loss: 0.1720, Val Loss: 0.6235
Epoch [37/200], Loss: 0.0912, Val Loss: 0.6749
Epoch [38/200], Loss: 0.3960, Val Loss: 0.6263
Epoch [39/200], Loss: 0.1123, Val Loss: 0.6553
Epoch [40/200], Loss: 0.0863, Val Loss: 0.6615
Epoch [41/200], Loss: 0.0627, Val Loss: 0.6276
Epoch [42/200], Loss: 0.2514, Val Loss: 0.6510
Epoch [43/200], Loss: 0.6848, Val Loss: 0.6223
Epoch [44/200], Loss: 0.1239, Val Loss: 0.5826
Epoch [45/200], Loss: 2.0577, Val Loss: 0.6079
Epoch [46/200], Loss: 0.1844, Val Loss: 0.6216
Epoch [47/200], Loss: 0.2532, Val Loss: 0.6201
Epoch [48/200], Loss: 0.1341, Val Loss: 0.6642
Epoch [49/200], Loss: 0.1874, Val Loss: 0.6346
Epoch [50/200], Loss: 0.1502, Val Loss: 0.6044
Epoch [51/200], Loss: 0.2731, Val Loss: 0.6186
Epoch [52/200], Loss: 0.3833, Val Loss: 0.6372
Epoch [53/200], Loss: 0.1229, Val Loss: 0.6733
Epoch [54/200], Loss: 0.1610, Val Loss: 0.6045
Epoch [55/200], Loss: 0.1373, Val Loss: 0.6224
Epoch [56/200], Loss: 0.1590, Val Loss: 0.6385
Epoch [57/200], Loss: 0.1490, Val Loss: 0.5926
Epoch [58/200], Loss: 0.7800, Val Loss: 0.6159
Epoch [59/200], Loss: 0.3063, Val Loss: 0.6157
Epoch [60/200], Loss: 0.1722, Val Loss: 0.6005
Epoch [61/200], Loss: 0.2906, Val Loss: 0.6090
Epoch [62/200], Loss: 0.1846, Val Loss: 0.6160
Epoch [63/200], Loss: 0.5536, Val Loss: 0.6481
Epoch [64/200], Loss: 0.1181, Val Loss: 0.6146
Epoch [65/200], Loss: 0.0788, Val Loss: 0.6481
Epoch [66/200], Loss: 0.2167, Val Loss: 0.5987
Epoch [67/200], Loss: 0.2511, Val Loss: 0.6234
Epoch [68/200], Loss: 0.0939, Val Loss: 0.6010
Epoch [69/200], Loss: 0.1006, Val Loss: 0.5800
Epoch [70/200], Loss: 0.1686, Val Loss: 0.6065
Epoch [71/200], Loss: 0.1659, Val Loss: 0.6660
Epoch [72/200], Loss: 0.3391, Val Loss: 0.6189
Epoch [73/200], Loss: 0.0875, Val Loss: 0.6451
Epoch [74/200], Loss: 0.4251, Val Loss: 0.6322
Epoch [75/200], Loss: 0.1199, Val Loss: 0.6537
Epoch [76/200], Loss: 0.2737, Val Loss: 0.6778
Epoch [77/200], Loss: 0.2966, Val Loss: 0.6618
Epoch [78/200], Loss: 0.6668, Val Loss: 0.6477
Epoch [79/200], Loss: 0.1553, Val Loss: 0.6926
Epoch [80/200], Loss: 0.1816, Val Loss: 0.6333
Epoch [81/200], Loss: 0.1709, Val Loss: 0.7093
Epoch [82/200], Loss: 0.0433, Val Loss: 0.6223
Epoch [83/200], Loss: 0.1090, Val Loss: 0.6103
Epoch [84/200], Loss: 0.1897, Val Loss: 0.6347
Epoch [85/200], Loss: 0.1657, Val Loss: 0.6124
Epoch [86/200], Loss: 0.1086, Val Loss: 0.6318
Epoch [87/200], Loss: 0.1805, Val Loss: 0.6526
Epoch [88/200], Loss: 0.1771, Val Loss: 0.6111
Epoch [89/200], Loss: 0.1810, Val Loss: 0.6119
Epoch [90/200], Loss: 0.1354, Val Loss: 0.6099
Epoch [91/200], Loss: 0.1641, Val Loss: 0.6644
Epoch [92/200], Loss: 0.1753, Val Loss: 0.5932
Epoch [93/200], Loss: 0.1365, Val Loss: 0.6204
Epoch [94/200], Loss: 0.5894, Val Loss: 0.6256
Epoch [95/200], Loss: 0.1608, Val Loss: 0.6372
Epoch [96/200], Loss: 0.2941, Val Loss: 0.6048
Epoch [97/200], Loss: 0.0837, Val Loss: 0.6116
Epoch [98/200], Loss: 0.0902, Val Loss: 0.6238
Early stopping at epoch 98
Runtime: 0:02:22.907626
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00033579737646505237
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.1192, Val Loss: 0.7658
Epoch [2/200], Loss: 0.2691, Val Loss: 0.7519
Epoch [3/200], Loss: 0.2875, Val Loss: 0.7274
Epoch [4/200], Loss: 0.2064, Val Loss: 0.7001
Epoch [5/200], Loss: 2.0078, Val Loss: 0.6971
Epoch [6/200], Loss: 0.2888, Val Loss: 0.8017
Epoch [7/200], Loss: 0.1360, Val Loss: 0.6894
Epoch [8/200], Loss: 0.4340, Val Loss: 0.8314
Epoch [9/200], Loss: 0.2260, Val Loss: 0.7787
Epoch [10/200], Loss: 0.7519, Val Loss: 0.6745
Epoch [11/200], Loss: 0.1265, Val Loss: 0.6966
Epoch [12/200], Loss: 0.2967, Val Loss: 0.6687
Epoch [13/200], Loss: 0.1652, Val Loss: 0.6738
Epoch [14/200], Loss: 0.4783, Val Loss: 0.6411
Epoch [15/200], Loss: 0.0735, Val Loss: 0.6640
Epoch [16/200], Loss: 0.4544, Val Loss: 0.6751
Epoch [17/200], Loss: 0.2778, Val Loss: 0.6401
Epoch [18/200], Loss: 0.3541, Val Loss: 0.6680
Epoch [19/200], Loss: 0.1018, Val Loss: 0.6784
Epoch [20/200], Loss: 0.6090, Val Loss: 0.6613
Epoch [21/200], Loss: 0.5194, Val Loss: 0.7024
Epoch [22/200], Loss: 0.1594, Val Loss: 0.6926
Epoch [23/200], Loss: 0.3016, Val Loss: 0.6382
Epoch [24/200], Loss: 0.3039, Val Loss: 0.6474
Epoch [25/200], Loss: 0.1772, Val Loss: 0.6328
Epoch [26/200], Loss: 0.5217, Val Loss: 0.6334
Epoch [27/200], Loss: 0.3693, Val Loss: 0.6670
Epoch [28/200], Loss: 0.8149, Val Loss: 0.7052
Epoch [29/200], Loss: 0.2569, Val Loss: 0.6603
Epoch [30/200], Loss: 0.1562, Val Loss: 0.7393
Epoch [31/200], Loss: 0.7176, Val Loss: 0.6602
Epoch [32/200], Loss: 0.7102, Val Loss: 0.7849
Epoch [33/200], Loss: 0.2514, Val Loss: 0.6071
Epoch [34/200], Loss: 0.1201, Val Loss: 0.6205
Epoch [35/200], Loss: 0.5888, Val Loss: 0.5934
Epoch [36/200], Loss: 0.3270, Val Loss: 0.5992
Epoch [37/200], Loss: 0.1352, Val Loss: 0.6176
Epoch [38/200], Loss: 0.1085, Val Loss: 0.6529
Epoch [39/200], Loss: 0.3330, Val Loss: 0.6526
Epoch [40/200], Loss: 0.1329, Val Loss: 0.6204
Epoch [41/200], Loss: 0.2020, Val Loss: 0.6044
Epoch [42/200], Loss: 0.0649, Val Loss: 0.6064
Epoch [43/200], Loss: 0.2518, Val Loss: 0.6440
Epoch [44/200], Loss: 0.4575, Val Loss: 0.6192
Epoch [45/200], Loss: 0.1786, Val Loss: 0.6271
Epoch [46/200], Loss: 0.6205, Val Loss: 0.6147
Epoch [47/200], Loss: 0.0314, Val Loss: 0.6623
Epoch [48/200], Loss: 0.2131, Val Loss: 0.5927
Epoch [49/200], Loss: 0.1127, Val Loss: 0.5807
Epoch [50/200], Loss: 0.0997, Val Loss: 0.5849
Epoch [51/200], Loss: 0.1170, Val Loss: 0.6126
Epoch [52/200], Loss: 0.1223, Val Loss: 0.6172
Epoch [53/200], Loss: 0.0808, Val Loss: 0.5966
Epoch [54/200], Loss: 0.1638, Val Loss: 0.6443
Epoch [55/200], Loss: 0.1863, Val Loss: 0.5994
Epoch [56/200], Loss: 0.1190, Val Loss: 0.5968
Epoch [57/200], Loss: 0.0888, Val Loss: 0.6106
Epoch [58/200], Loss: 0.1457, Val Loss: 0.6646
Epoch [59/200], Loss: 0.1721, Val Loss: 0.6783
Epoch [60/200], Loss: 0.2010, Val Loss: 0.5853
Epoch [61/200], Loss: 0.3593, Val Loss: 0.7492
Epoch [62/200], Loss: 0.0832, Val Loss: 0.6326
Epoch [63/200], Loss: 0.2120, Val Loss: 0.5830
Epoch [64/200], Loss: 0.2732, Val Loss: 0.6206
Epoch [65/200], Loss: 0.5061, Val Loss: 0.5792
Epoch [66/200], Loss: 0.2534, Val Loss: 0.6733
Epoch [67/200], Loss: 0.4315, Val Loss: 0.6096
Epoch [68/200], Loss: 0.0972, Val Loss: 0.6119
Epoch [69/200], Loss: 0.1571, Val Loss: 0.5810
Epoch [70/200], Loss: 0.0965, Val Loss: 0.5811
Epoch [71/200], Loss: 0.2462, Val Loss: 0.6112
Epoch [72/200], Loss: 0.4026, Val Loss: 0.6200
Epoch [73/200], Loss: 0.3372, Val Loss: 0.6906
Epoch [74/200], Loss: 0.0884, Val Loss: 0.6159
Epoch [75/200], Loss: 0.1858, Val Loss: 0.6164
Epoch [76/200], Loss: 0.2319, Val Loss: 0.6980
Epoch [77/200], Loss: 0.3447, Val Loss: 0.6072
Epoch [78/200], Loss: 0.1465, Val Loss: 0.6110
Epoch [79/200], Loss: 0.2096, Val Loss: 0.6181
Epoch [80/200], Loss: 0.2179, Val Loss: 0.6198
Epoch [81/200], Loss: 0.4913, Val Loss: 0.5989
Epoch [82/200], Loss: 0.0813, Val Loss: 0.6037
Epoch [83/200], Loss: 0.2276, Val Loss: 0.6103
Epoch [84/200], Loss: 0.2737, Val Loss: 0.6474
Epoch [85/200], Loss: 0.1781, Val Loss: 0.6008
Epoch [86/200], Loss: 0.3241, Val Loss: 0.6932
Epoch [87/200], Loss: 0.2393, Val Loss: 0.5992
Epoch [88/200], Loss: 0.6467, Val Loss: 0.6459
Epoch [89/200], Loss: 0.2283, Val Loss: 0.6395
Epoch [90/200], Loss: 0.4028, Val Loss: 0.6165
Epoch [91/200], Loss: 0.0508, Val Loss: 0.6042
Epoch [92/200], Loss: 0.1184, Val Loss: 0.6056
Epoch [93/200], Loss: 2.0454, Val Loss: 0.6168
Epoch [94/200], Loss: 0.2470, Val Loss: 0.6305
Epoch [95/200], Loss: 0.1312, Val Loss: 0.5940
Epoch [96/200], Loss: 0.4263, Val Loss: 0.6028
Epoch [97/200], Loss: 0.0767, Val Loss: 0.6455
Epoch [98/200], Loss: 0.2781, Val Loss: 0.6096
Epoch [99/200], Loss: 0.1170, Val Loss: 0.6202
Early stopping at epoch 99
Runtime: 0:02:26.707097
R^2 Score: 0.8899
RMSE: 0.7626
MAE: 0.2345
MAPE: 21.35%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00033579737646505237
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.2202, Val Loss: 0.6221
Epoch [2/200], Loss: 0.0838, Val Loss: 0.5875
Epoch [3/200], Loss: 0.0872, Val Loss: 0.6335
Epoch [4/200], Loss: 0.0999, Val Loss: 0.6482
Epoch [5/200], Loss: 0.1853, Val Loss: 0.6142
Epoch [6/200], Loss: 0.1323, Val Loss: 0.6683
Epoch [7/200], Loss: 0.7865, Val Loss: 0.6385
Epoch [8/200], Loss: 0.2989, Val Loss: 0.6217
Epoch [9/200], Loss: 0.2467, Val Loss: 0.6035
Epoch [10/200], Loss: 0.0733, Val Loss: 0.6211
Epoch [11/200], Loss: 0.0944, Val Loss: 0.6169
Epoch [12/200], Loss: 0.1142, Val Loss: 0.6533
Epoch [13/200], Loss: 0.0946, Val Loss: 0.6912
Epoch [14/200], Loss: 0.1447, Val Loss: 0.6165
Epoch [15/200], Loss: 0.1068, Val Loss: 0.6018
Epoch [16/200], Loss: 0.1382, Val Loss: 0.5955
Epoch [17/200], Loss: 0.1187, Val Loss: 0.6250
Epoch [18/200], Loss: 0.5514, Val Loss: 0.5832
Epoch [19/200], Loss: 0.0877, Val Loss: 0.6334
Epoch [20/200], Loss: 0.0854, Val Loss: 0.5983
Epoch [21/200], Loss: 0.1792, Val Loss: 0.6231
Epoch [22/200], Loss: 0.2298, Val Loss: 0.6086
Epoch [23/200], Loss: 0.2367, Val Loss: 0.6026
Epoch [24/200], Loss: 0.1361, Val Loss: 0.6089
Epoch [25/200], Loss: 0.1626, Val Loss: 0.6271
Epoch [26/200], Loss: 0.0758, Val Loss: 0.6371
Epoch [27/200], Loss: 0.0878, Val Loss: 0.6102
Epoch [28/200], Loss: 0.1544, Val Loss: 0.6091
Epoch [29/200], Loss: 0.1345, Val Loss: 0.6077
Epoch [30/200], Loss: 0.3966, Val Loss: 0.5960
Epoch [31/200], Loss: 0.3762, Val Loss: 0.6283
Epoch [32/200], Loss: 0.1331, Val Loss: 0.6258
Epoch [33/200], Loss: 0.0815, Val Loss: 0.6301
Epoch [34/200], Loss: 0.1710, Val Loss: 0.6445
Epoch [35/200], Loss: 0.0483, Val Loss: 0.6167
Epoch [36/200], Loss: 0.1611, Val Loss: 0.6201
Epoch [37/200], Loss: 0.1459, Val Loss: 0.6211
Epoch [38/200], Loss: 0.3434, Val Loss: 0.6159
Epoch [39/200], Loss: 0.2128, Val Loss: 0.6153
Epoch [40/200], Loss: 0.6913, Val Loss: 0.6037
Epoch [41/200], Loss: 0.0664, Val Loss: 0.6222
Epoch [42/200], Loss: 0.1400, Val Loss: 0.6141
Epoch [43/200], Loss: 0.0474, Val Loss: 0.6501
Epoch [44/200], Loss: 0.3251, Val Loss: 0.6118
Epoch [45/200], Loss: 0.1893, Val Loss: 0.6020
Epoch [46/200], Loss: 0.1951, Val Loss: 0.6046
Epoch [47/200], Loss: 0.3905, Val Loss: 0.6347
Early stopping at epoch 47
Runtime: 0:01:10.708006
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00033579737646505237
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.1621, Val Loss: 0.6006
Epoch [2/200], Loss: 0.1158, Val Loss: 0.6336
Epoch [3/200], Loss: 0.0766, Val Loss: 0.5970
Epoch [4/200], Loss: 0.0999, Val Loss: 0.6139
Epoch [5/200], Loss: 0.1489, Val Loss: 0.6044
Epoch [6/200], Loss: 0.0793, Val Loss: 0.6358
Epoch [7/200], Loss: 0.1292, Val Loss: 0.6310
Epoch [8/200], Loss: 0.1650, Val Loss: 0.6055
Epoch [9/200], Loss: 0.0804, Val Loss: 0.6244
Epoch [10/200], Loss: 0.1503, Val Loss: 0.6506
Epoch [11/200], Loss: 0.3333, Val Loss: 0.6288
Epoch [12/200], Loss: 0.0669, Val Loss: 0.6106
Epoch [13/200], Loss: 0.1765, Val Loss: 0.6386
Epoch [14/200], Loss: 0.1250, Val Loss: 0.6262
Epoch [15/200], Loss: 0.0739, Val Loss: 0.6230
Epoch [16/200], Loss: 0.6778, Val Loss: 0.6220
Epoch [17/200], Loss: 0.3589, Val Loss: 0.6098
Epoch [18/200], Loss: 0.6764, Val Loss: 0.6055
Epoch [19/200], Loss: 0.4049, Val Loss: 0.6315
Epoch [20/200], Loss: 0.1643, Val Loss: 0.6230
Epoch [21/200], Loss: 0.0698, Val Loss: 0.6279
Epoch [22/200], Loss: 0.1810, Val Loss: 0.6133
Epoch [23/200], Loss: 0.1608, Val Loss: 0.6008
Epoch [24/200], Loss: 0.0492, Val Loss: 0.6611
Epoch [25/200], Loss: 0.1187, Val Loss: 0.6152
Epoch [26/200], Loss: 0.1375, Val Loss: 0.5993
Epoch [27/200], Loss: 0.0486, Val Loss: 0.6202
Epoch [28/200], Loss: 0.0801, Val Loss: 0.6238
Epoch [29/200], Loss: 0.2381, Val Loss: 0.5996
Epoch [30/200], Loss: 0.2265, Val Loss: 0.6200
Epoch [31/200], Loss: 0.3804, Val Loss: 0.5949
Epoch [32/200], Loss: 0.2211, Val Loss: 0.6228
Epoch [33/200], Loss: 0.0941, Val Loss: 0.6105
Epoch [34/200], Loss: 0.0494, Val Loss: 0.6142
Epoch [35/200], Loss: 0.0993, Val Loss: 0.5935
Epoch [36/200], Loss: 0.1580, Val Loss: 0.6087
Epoch [37/200], Loss: 0.1482, Val Loss: 0.6131
Epoch [38/200], Loss: 0.0757, Val Loss: 0.6022
Epoch [39/200], Loss: 0.3542, Val Loss: 0.6213
Epoch [40/200], Loss: 0.1166, Val Loss: 0.6294
Epoch [41/200], Loss: 0.1312, Val Loss: 0.6047
Epoch [42/200], Loss: 0.2530, Val Loss: 0.5997
Epoch [43/200], Loss: 0.4910, Val Loss: 0.6163
Epoch [44/200], Loss: 0.1139, Val Loss: 0.6246
Epoch [45/200], Loss: 0.0966, Val Loss: 0.6127
Epoch [46/200], Loss: 0.4191, Val Loss: 0.5939
Epoch [47/200], Loss: 0.1727, Val Loss: 0.6094
Epoch [48/200], Loss: 0.1838, Val Loss: 0.6063
Epoch [49/200], Loss: 0.2464, Val Loss: 0.6535
Epoch [50/200], Loss: 0.0903, Val Loss: 0.6196
Epoch [51/200], Loss: 0.1112, Val Loss: 0.6089
Epoch [52/200], Loss: 0.0626, Val Loss: 0.6019
Epoch [53/200], Loss: 0.1872, Val Loss: 0.6284
Epoch [54/200], Loss: 0.1207, Val Loss: 0.6036
Epoch [55/200], Loss: 0.2965, Val Loss: 0.6269
Epoch [56/200], Loss: 0.0553, Val Loss: 0.5982
Epoch [57/200], Loss: 0.4450, Val Loss: 0.6033
Epoch [58/200], Loss: 0.1696, Val Loss: 0.6291
Epoch [59/200], Loss: 0.0822, Val Loss: 0.6145
Epoch [60/200], Loss: 0.0337, Val Loss: 0.6195
Epoch [61/200], Loss: 0.1053, Val Loss: 0.6110
Epoch [62/200], Loss: 0.1380, Val Loss: 0.6218
Epoch [63/200], Loss: 0.0940, Val Loss: 0.6049
Epoch [64/200], Loss: 0.2624, Val Loss: 0.6336
Epoch [65/200], Loss: 0.1380, Val Loss: 0.6216
Epoch [66/200], Loss: 0.3295, Val Loss: 0.6075
Epoch [67/200], Loss: 0.1418, Val Loss: 0.5918
Epoch [68/200], Loss: 0.1094, Val Loss: 0.6067
Epoch [69/200], Loss: 0.0774, Val Loss: 0.6365
Epoch [70/200], Loss: 0.0683, Val Loss: 0.6182
Epoch [71/200], Loss: 0.4507, Val Loss: 0.6116
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.3322, Val Loss: 0.7962
Epoch [2/200], Loss: 0.3696, Val Loss: 0.7493
Epoch [3/200], Loss: 0.3252, Val Loss: 0.7368
Epoch [4/200], Loss: 0.4574, Val Loss: 0.7358
Epoch [5/200], Loss: 0.3119, Val Loss: 0.8158
Epoch [6/200], Loss: 0.2655, Val Loss: 0.7182
Epoch [7/200], Loss: 2.0698, Val Loss: 0.8834
Epoch [8/200], Loss: 0.5356, Val Loss: 0.8732
Epoch [9/200], Loss: 0.1267, Val Loss: 0.7327
Epoch [10/200], Loss: 0.8806, Val Loss: 0.7771
Epoch [11/200], Loss: 0.2808, Val Loss: 0.7161
Epoch [12/200], Loss: 0.4509, Val Loss: 0.9447
Epoch [13/200], Loss: 0.7223, Val Loss: 0.7108
Epoch [14/200], Loss: 0.1147, Val Loss: 0.8104
Epoch [15/200], Loss: 0.1079, Val Loss: 0.6900
Epoch [16/200], Loss: 0.2680, Val Loss: 0.7572
Epoch [17/200], Loss: 0.8921, Val Loss: 0.7383
Epoch [18/200], Loss: 0.1163, Val Loss: 0.6977
Epoch [19/200], Loss: 0.1279, Val Loss: 0.6303
Epoch [20/200], Loss: 0.1883, Val Loss: 0.6911
Epoch [21/200], Loss: 0.1341, Val Loss: 0.7298
Epoch [22/200], Loss: 0.1581, Val Loss: 0.6374
Epoch [23/200], Loss: 0.4422, Val Loss: 0.6350
Epoch [24/200], Loss: 0.1481, Val Loss: 0.6917
Epoch [25/200], Loss: 1.0504, Val Loss: 0.6535
Epoch [26/200], Loss: 0.2085, Val Loss: 0.7037
Epoch [27/200], Loss: 1.9926, Val Loss: 0.6401
Epoch [28/200], Loss: 0.1348, Val Loss: 0.6640
Epoch [29/200], Loss: 0.1491, Val Loss: 0.8164
Epoch [30/200], Loss: 0.0798, Val Loss: 0.7119
Epoch [31/200], Loss: 0.1562, Val Loss: 0.6624
Epoch [32/200], Loss: 0.5462, Val Loss: 0.6624
Epoch [33/200], Loss: 0.1774, Val Loss: 0.6257
Epoch [34/200], Loss: 0.0817, Val Loss: 0.6828
Epoch [35/200], Loss: 0.2092, Val Loss: 0.6302
Epoch [36/200], Loss: 0.3848, Val Loss: 0.6734
Epoch [37/200], Loss: 0.1606, Val Loss: 0.6382
Epoch [38/200], Loss: 0.1576, Val Loss: 0.6138
Epoch [39/200], Loss: 0.2906, Val Loss: 0.6318
Epoch [40/200], Loss: 0.1903, Val Loss: 0.6124
Epoch [41/200], Loss: 0.1308, Val Loss: 0.6109
Epoch [42/200], Loss: 0.1514, Val Loss: 0.6352
Epoch [43/200], Loss: 0.1436, Val Loss: 0.6446
Epoch [44/200], Loss: 0.0847, Val Loss: 0.5838
Epoch [45/200], Loss: 0.2688, Val Loss: 0.6561
Epoch [46/200], Loss: 0.1980, Val Loss: 0.6212
Epoch [47/200], Loss: 0.0859, Val Loss: 0.6031
Epoch [48/200], Loss: 0.0348, Val Loss: 0.6166
Epoch [49/200], Loss: 0.1354, Val Loss: 0.6181
Epoch [50/200], Loss: 0.1304, Val Loss: 0.7208
Epoch [51/200], Loss: 0.1038, Val Loss: 0.5821
Epoch [52/200], Loss: 0.5405, Val Loss: 0.6554
Epoch [53/200], Loss: 0.1665, Val Loss: 0.7394
Epoch [54/200], Loss: 0.3643, Val Loss: 0.6382
Epoch [55/200], Loss: 0.5830, Val Loss: 0.5789
Epoch [56/200], Loss: 0.1230, Val Loss: 0.6000
Epoch [57/200], Loss: 0.5259, Val Loss: 0.6528
Epoch [58/200], Loss: 0.0791, Val Loss: 0.6218
Epoch [59/200], Loss: 0.2858, Val Loss: 0.6932
Epoch [60/200], Loss: 0.5504, Val Loss: 0.6174
Epoch [61/200], Loss: 0.0979, Val Loss: 0.5909
Epoch [62/200], Loss: 0.0782, Val Loss: 0.6062
Epoch [63/200], Loss: 0.4460, Val Loss: 0.7161
Epoch [64/200], Loss: 0.1440, Val Loss: 0.5754
Epoch [65/200], Loss: 0.0924, Val Loss: 0.6398
Epoch [66/200], Loss: 0.0818, Val Loss: 0.5980
Epoch [67/200], Loss: 0.7845, Val Loss: 0.6237
Epoch [68/200], Loss: 0.5939, Val Loss: 0.5984
Epoch [69/200], Loss: 0.1956, Val Loss: 0.6302
Epoch [70/200], Loss: 0.1238, Val Loss: 0.6395
Epoch [71/200], Loss: 0.2085, Val Loss: 0.5879
Epoch [72/200], Loss: 0.0870, Val Loss: 0.5764
Epoch [73/200], Loss: 0.0800, Val Loss: 0.5839
Epoch [74/200], Loss: 0.1455, Val Loss: 0.6042
Epoch [75/200], Loss: 0.0529, Val Loss: 0.6276
Epoch [76/200], Loss: 0.1715, Val Loss: 0.6138
Epoch [77/200], Loss: 0.1356, Val Loss: 0.5960
Epoch [78/200], Loss: 0.2303, Val Loss: 0.5688
Epoch [79/200], Loss: 0.2657, Val Loss: 0.5745
Epoch [80/200], Loss: 0.1048, Val Loss: 0.6169
Epoch [81/200], Loss: 0.0553, Val Loss: 0.5825
Epoch [82/200], Loss: 0.5479, Val Loss: 0.6084
Epoch [83/200], Loss: 0.1899, Val Loss: 0.5762
Epoch [84/200], Loss: 0.1175, Val Loss: 0.6048
Epoch [85/200], Loss: 0.2281, Val Loss: 0.5987
Epoch [86/200], Loss: 0.3226, Val Loss: 0.5906
Epoch [87/200], Loss: 0.5337, Val Loss: 0.6146
Epoch [88/200], Loss: 0.3560, Val Loss: 0.5643
Epoch [89/200], Loss: 0.5603, Val Loss: 0.5878
Epoch [90/200], Loss: 0.2928, Val Loss: 0.5960
Epoch [91/200], Loss: 0.1655, Val Loss: 0.5806
Epoch [92/200], Loss: 0.2282, Val Loss: 0.6130
Epoch [93/200], Loss: 0.0868, Val Loss: 0.6199
Epoch [94/200], Loss: 0.1066, Val Loss: 0.5379
Epoch [95/200], Loss: 0.1111, Val Loss: 0.6191
Epoch [96/200], Loss: 0.1144, Val Loss: 0.6136
Epoch [97/200], Loss: 0.0506, Val Loss: 0.6173
Epoch [98/200], Loss: 0.2627, Val Loss: 0.6155
Epoch [99/200], Loss: 0.0739, Val Loss: 0.5723
Epoch [100/200], Loss: 0.0956, Val Loss: 0.5877
Epoch [101/200], Loss: 0.1265, Val Loss: 0.5662
Epoch [102/200], Loss: 0.1785, Val Loss: 0.6101
Epoch [103/200], Loss: 0.3383, Val Loss: 0.5789
Epoch [104/200], Loss: 0.0819, Val Loss: 0.5740
Epoch [105/200], Loss: 0.0675, Val Loss: 0.5757
Epoch [106/200], Loss: 0.2281, Val Loss: 0.6128
Epoch [107/200], Loss: 0.0763, Val Loss: 0.5668
Epoch [108/200], Loss: 0.0784, Val Loss: 0.5950
Epoch [109/200], Loss: 0.0638, Val Loss: 0.6014
Epoch [110/200], Loss: 0.2384, Val Loss: 0.5619
Epoch [111/200], Loss: 0.3505, Val Loss: 0.5696
Epoch [112/200], Loss: 0.1238, Val Loss: 0.5733
Epoch [113/200], Loss: 0.1072, Val Loss: 0.5709
Epoch [114/200], Loss: 0.1418, Val Loss: 0.5759
Epoch [115/200], Loss: 0.2843, Val Loss: 0.6337
Epoch [116/200], Loss: 1.0676, Val Loss: 0.5971
Epoch [117/200], Loss: 0.1667, Val Loss: 0.6025
Epoch [118/200], Loss: 0.1015, Val Loss: 0.5610
Epoch [119/200], Loss: 0.2222, Val Loss: 0.6007
Epoch [120/200], Loss: 0.1946, Val Loss: 0.5587
Epoch [121/200], Loss: 0.0967, Val Loss: 0.5614
Epoch [122/200], Loss: 0.0716, Val Loss: 0.5470
Epoch [123/200], Loss: 0.2202, Val Loss: 0.5504
Early stopping at epoch 123
Runtime: 0:03:03.518968
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.0976, Val Loss: 0.5467
Epoch [2/200], Loss: 0.1013, Val Loss: 0.6011
Epoch [3/200], Loss: 0.2693, Val Loss: 0.5963
Epoch [4/200], Loss: 0.3954, Val Loss: 0.5576
Epoch [5/200], Loss: 0.0839, Val Loss: 0.5901
Epoch [6/200], Loss: 0.1715, Val Loss: 0.5753
Epoch [7/200], Loss: 0.1725, Val Loss: 0.6236
Epoch [8/200], Loss: 1.2202, Val Loss: 0.5910
Epoch [9/200], Loss: 0.0835, Val Loss: 0.5757
Epoch [10/200], Loss: 0.0902, Val Loss: 0.5687
Epoch [11/200], Loss: 0.1406, Val Loss: 0.5789
Epoch [12/200], Loss: 0.2859, Val Loss: 0.5838
Epoch [13/200], Loss: 0.1489, Val Loss: 0.5949
Epoch [14/200], Loss: 0.2361, Val Loss: 0.5684
Epoch [15/200], Loss: 0.6531, Val Loss: 0.5830
Epoch [16/200], Loss: 0.1046, Val Loss: 0.6425
Epoch [17/200], Loss: 0.1858, Val Loss: 0.5662
Epoch [18/200], Loss: 0.1586, Val Loss: 0.5757
Epoch [19/200], Loss: 0.2247, Val Loss: 0.5793
Epoch [20/200], Loss: 0.4652, Val Loss: 0.6013
Epoch [21/200], Loss: 0.1436, Val Loss: 0.5651
Epoch [22/200], Loss: 0.4890, Val Loss: 0.6077
Epoch [23/200], Loss: 0.0582, Val Loss: 0.5694
Epoch [24/200], Loss: 0.3565, Val Loss: 0.5876
Epoch [25/200], Loss: 0.1702, Val Loss: 0.5879
Epoch [26/200], Loss: 0.2614, Val Loss: 0.5718
Epoch [27/200], Loss: 0.2611, Val Loss: 0.6173
Epoch [28/200], Loss: 0.4547, Val Loss: 0.5462
Epoch [29/200], Loss: 0.2995, Val Loss: 0.5561
Epoch [30/200], Loss: 0.1224, Val Loss: 0.5696
Epoch [31/200], Loss: 0.1615, Val Loss: 0.5617
Epoch [32/200], Loss: 0.0805, Val Loss: 0.5656
Epoch [33/200], Loss: 0.1015, Val Loss: 0.5580
Epoch [34/200], Loss: 0.1015, Val Loss: 0.5760
Epoch [35/200], Loss: 0.1421, Val Loss: 0.5595
Epoch [36/200], Loss: 0.0931, Val Loss: 0.5528
Epoch [37/200], Loss: 0.1055, Val Loss: 0.5396
Epoch [38/200], Loss: 0.0555, Val Loss: 0.5555
Epoch [39/200], Loss: 0.0651, Val Loss: 0.5695
Epoch [40/200], Loss: 0.0777, Val Loss: 0.5986
Epoch [41/200], Loss: 0.0983, Val Loss: 0.5886
Epoch [42/200], Loss: 0.1275, Val Loss: 0.5590
Epoch [43/200], Loss: 0.1236, Val Loss: 0.5705
Epoch [44/200], Loss: 0.4590, Val Loss: 0.7313
Epoch [45/200], Loss: 0.1178, Val Loss: 0.5896
Epoch [46/200], Loss: 0.3592, Val Loss: 0.5941
Epoch [47/200], Loss: 0.1012, Val Loss: 0.5598
Epoch [48/200], Loss: 0.1477, Val Loss: 0.5595
Epoch [49/200], Loss: 0.1114, Val Loss: 0.5707
Epoch [50/200], Loss: 0.0579, Val Loss: 0.5447
Epoch [51/200], Loss: 0.1066, Val Loss: 0.5952
Epoch [52/200], Loss: 0.1963, Val Loss: 0.6308
Epoch [53/200], Loss: 0.1069, Val Loss: 0.5473
Epoch [54/200], Loss: 0.0992, Val Loss: 0.5813
Epoch [55/200], Loss: 0.1627, Val Loss: 0.6483
Epoch [56/200], Loss: 0.0965, Val Loss: 0.5971
Epoch [57/200], Loss: 0.1380, Val Loss: 0.5635
Epoch [58/200], Loss: 0.1844, Val Loss: 0.6707
Epoch [59/200], Loss: 0.0596, Val Loss: 0.5649
Epoch [60/200], Loss: 0.0739, Val Loss: 0.5681
Epoch [61/200], Loss: 0.1203, Val Loss: 0.5898
Epoch [62/200], Loss: 0.5559, Val Loss: 0.5618
Epoch [63/200], Loss: 0.0454, Val Loss: 0.5909
Epoch [64/200], Loss: 0.0909, Val Loss: 0.5705
Epoch [65/200], Loss: 0.2966, Val Loss: 0.5796
Epoch [66/200], Loss: 0.1271, Val Loss: 0.6061
Early stopping at epoch 66
Runtime: 0:01:38.835944
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.0740, Val Loss: 0.5491
Epoch [2/200], Loss: 0.9412, Val Loss: 0.5665
Epoch [3/200], Loss: 0.1252, Val Loss: 0.5470
Epoch [4/200], Loss: 0.0744, Val Loss: 0.5671
Epoch [5/200], Loss: 0.0276, Val Loss: 0.5587
Epoch [6/200], Loss: 0.1115, Val Loss: 0.5618
Epoch [7/200], Loss: 0.1687, Val Loss: 0.5881
Epoch [8/200], Loss: 0.2779, Val Loss: 0.5874
Epoch [9/200], Loss: 0.4418, Val Loss: 0.5636
Epoch [10/200], Loss: 0.1756, Val Loss: 0.5637
Epoch [11/200], Loss: 0.3684, Val Loss: 0.5752
Epoch [12/200], Loss: 0.2134, Val Loss: 0.5848
Epoch [13/200], Loss: 0.0761, Val Loss: 0.5981
Epoch [14/200], Loss: 0.0663, Val Loss: 0.5736
Epoch [15/200], Loss: 0.1688, Val Loss: 0.5468
Epoch [16/200], Loss: 0.1618, Val Loss: 0.5704
Epoch [17/200], Loss: 0.2071, Val Loss: 0.6062
Epoch [18/200], Loss: 0.2441, Val Loss: 0.5987
Epoch [19/200], Loss: 0.2572, Val Loss: 0.5968
Epoch [20/200], Loss: 0.0722, Val Loss: 0.5694
Epoch [21/200], Loss: 0.1158, Val Loss: 0.5767
Epoch [22/200], Loss: 0.1799, Val Loss: 0.5976
Epoch [23/200], Loss: 0.1428, Val Loss: 0.5814
Epoch [24/200], Loss: 0.0685, Val Loss: 0.5765
Epoch [25/200], Loss: 0.0904, Val Loss: 0.5744
Epoch [26/200], Loss: 0.2668, Val Loss: 0.5690
Epoch [27/200], Loss: 0.2405, Val Loss: 0.5715
Epoch [28/200], Loss: 0.1198, Val Loss: 0.5611
Epoch [29/200], Loss: 0.0945, Val Loss: 0.5774
Epoch [30/200], Loss: 0.1075, Val Loss: 0.5656
Epoch [31/200], Loss: 0.2740, Val Loss: 0.5911
Epoch [32/200], Loss: 0.0756, Val Loss: 0.6004
Epoch [33/200], Loss: 0.1861, Val Loss: 0.5884
Epoch [34/200], Loss: 0.2295, Val Loss: 0.5852
Epoch [35/200], Loss: 0.1108, Val Loss: 0.5540
Epoch [36/200], Loss: 0.0862, Val Loss: 0.6045
Epoch [37/200], Loss: 0.0606, Val Loss: 0.6042
Epoch [38/200], Loss: 0.1347, Val Loss: 0.5911
Epoch [39/200], Loss: 0.0704, Val Loss: 0.6156
Epoch [40/200], Loss: 0.0707, Val Loss: 0.5671
Epoch [41/200], Loss: 0.0776, Val Loss: 0.5825
Epoch [42/200], Loss: 0.1398, Val Loss: 0.6185
Epoch [43/200], Loss: 0.1049, Val Loss: 0.5673
Epoch [44/200], Loss: 0.0959, Val Loss: 0.6005
Early stopping at epoch 44
Runtime: 0:01:07.413878
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.1584, Val Loss: 0.5749
Epoch [2/200], Loss: 0.0454, Val Loss: 0.6005
Epoch [3/200], Loss: 0.3007, Val Loss: 0.5706
Epoch [4/200], Loss: 0.1017, Val Loss: 0.5873
Epoch [5/200], Loss: 0.1113, Val Loss: 0.5712
Epoch [6/200], Loss: 0.6113, Val Loss: 0.5544
Epoch [7/200], Loss: 0.1109, Val Loss: 0.5842
Epoch [8/200], Loss: 0.0337, Val Loss: 0.5987
Epoch [9/200], Loss: 0.1071, Val Loss: 0.5723
Epoch [10/200], Loss: 0.6467, Val Loss: 0.5918
Epoch [11/200], Loss: 0.0737, Val Loss: 0.5469
Epoch [12/200], Loss: 0.2206, Val Loss: 0.5623
Epoch [13/200], Loss: 0.0983, Val Loss: 0.5787
Epoch [14/200], Loss: 0.2206, Val Loss: 0.6204
Epoch [15/200], Loss: 0.0803, Val Loss: 0.5669
Epoch [16/200], Loss: 0.4116, Val Loss: 0.5689
Epoch [17/200], Loss: 0.1457, Val Loss: 0.5795
Epoch [18/200], Loss: 0.0775, Val Loss: 0.5634
Epoch [19/200], Loss: 0.0820, Val Loss: 0.5618
Epoch [20/200], Loss: 0.0584, Val Loss: 0.5829
Epoch [21/200], Loss: 0.5329, Val Loss: 0.6425
Epoch [22/200], Loss: 0.2731, Val Loss: 0.6128
Epoch [23/200], Loss: 0.1929, Val Loss: 0.5713
Epoch [24/200], Loss: 0.1139, Val Loss: 0.5584
Epoch [25/200], Loss: 0.4420, Val Loss: 0.5889
Epoch [26/200], Loss: 0.1051, Val Loss: 0.6203
Epoch [27/200], Loss: 0.0398, Val Loss: 0.5704
Epoch [28/200], Loss: 0.0879, Val Loss: 0.5826
Epoch [29/200], Loss: 0.1116, Val Loss: 0.5643
Epoch [30/200], Loss: 0.0554, Val Loss: 0.5686
Epoch [31/200], Loss: 0.0693, Val Loss: 0.5630
Epoch [32/200], Loss: 0.2266, Val Loss: 0.5828
Epoch [33/200], Loss: 0.2159, Val Loss: 0.5888
Epoch [34/200], Loss: 0.0803, Val Loss: 0.5793
Epoch [35/200], Loss: 0.0900, Val Loss: 0.5697
Epoch [36/200], Loss: 0.1279, Val Loss: 0.5704
Epoch [37/200], Loss: 0.2806, Val Loss: 0.5626
Epoch [38/200], Loss: 0.0962, Val Loss: 0.5962
Epoch [39/200], Loss: 0.2110, Val Loss: 0.5885
Epoch [40/200], Loss: 0.1818, Val Loss: 0.5896
Epoch [41/200], Loss: 0.4782, Val Loss: 0.5769
Epoch [42/200], Loss: 0.1503, Val Loss: 0.5516
Epoch [43/200], Loss: 0.0464, Val Loss: 0.6080
Epoch [44/200], Loss: 0.1041, Val Loss: 0.5806
Epoch [45/200], Loss: 0.1404, Val Loss: 0.5631
Epoch [46/200], Loss: 0.0744, Val Loss: 0.5511
Epoch [47/200], Loss: 0.4589, Val Loss: 0.5884
Epoch [48/200], Loss: 0.1330, Val Loss: 0.5778
Epoch [49/200], Loss: 0.4141, Val Loss: 0.5883
Epoch [50/200], Loss: 0.0949, Val Loss: 0.5704
Epoch [51/200], Loss: 0.7835, Val Loss: 0.5870
Epoch [52/200], Loss: 0.2162, Val Loss: 0.5636
Epoch [53/200], Loss: 0.0554, Val Loss: 0.5902
Epoch [54/200], Loss: 0.2543, Val Loss: 0.5497
Epoch [55/200], Loss: 0.0942, Val Loss: 0.5712
Epoch [56/200], Loss: 0.0696, Val Loss: 0.5494
Epoch [57/200], Loss: 0.1695, Val Loss: 0.5698
Epoch [58/200], Loss: 0.2274, Val Loss: 0.5698
Epoch [59/200], Loss: 0.3787, Val Loss: 0.5462
Epoch [60/200], Loss: 0.1113, Val Loss: 0.5453
Epoch [61/200], Loss: 0.2239, Val Loss: 0.5516
Epoch [62/200], Loss: 0.1026, Val Loss: 0.5703
Epoch [63/200], Loss: 0.0727, Val Loss: 0.5884
Epoch [64/200], Loss: 0.2827, Val Loss: 0.5440
Epoch [65/200], Loss: 0.1723, Val Loss: 0.5607
Epoch [66/200], Loss: 0.0749, Val Loss: 0.5959
Epoch [67/200], Loss: 0.0412, Val Loss: 0.5592
Epoch [68/200], Loss: 0.0601, Val Loss: 0.6064
Epoch [69/200], Loss: 0.1479, Val Loss: 0.5905
Epoch [70/200], Loss: 0.0915, Val Loss: 0.5987
Epoch [71/200], Loss: 0.1192, Val Loss: 0.5844
Epoch [72/200], Loss: 0.0594, Val Loss: 0.5763
Epoch [73/200], Loss: 0.1227, Val Loss: 0.5883
Epoch [74/200], Loss: 0.1209, Val Loss: 0.5594
Epoch [75/200], Loss: 0.1543, Val Loss: 0.5703
Epoch [76/200], Loss: 0.0750, Val Loss: 0.5634
Epoch [77/200], Loss: 0.0883, Val Loss: 0.5732
Epoch [78/200], Loss: 0.0595, Val Loss: 0.5609
Epoch [79/200], Loss: 0.1186, Val Loss: 0.5660
Epoch [80/200], Loss: 0.2324, Val Loss: 0.5735
Epoch [81/200], Loss: 0.4522, Val Loss: 0.5980
Epoch [82/200], Loss: 0.0657, Val Loss: 0.5658
Epoch [83/200], Loss: 0.3255, Val Loss: 0.5516
Epoch [84/200], Loss: 0.0821, Val Loss: 0.5598
Epoch [85/200], Loss: 0.2480, Val Loss: 0.5612
Epoch [86/200], Loss: 0.0946, Val Loss: 0.5612
Epoch [87/200], Loss: 0.1714, Val Loss: 0.5705
Epoch [88/200], Loss: 0.2861, Val Loss: 0.5535
Epoch [89/200], Loss: 0.2367, Val Loss: 0.5491
Epoch [90/200], Loss: 0.1117, Val Loss: 0.5655
Epoch [91/200], Loss: 0.1843, Val Loss: 0.5788
Epoch [92/200], Loss: 0.2666, Val Loss: 0.5638
Epoch [93/200], Loss: 0.3285, Val Loss: 0.5612
Epoch [94/200], Loss: 0.1060, Val Loss: 0.5694
Epoch [95/200], Loss: 0.2555, Val Loss: 0.5875
Epoch [96/200], Loss: 0.0828, Val Loss: 0.5669
Epoch [97/200], Loss: 0.1567, Val Loss: 0.6140
Epoch [98/200], Loss: 0.1875, Val Loss: 0.5751
Epoch [99/200], Loss: 0.0952, Val Loss: 0.5513
Epoch [100/200], Loss: 0.1552, Val Loss: 0.5672
Epoch [101/200], Loss: 0.1290, Val Loss: 0.6127
Epoch [102/200], Loss: 0.3520, Val Loss: 0.5942
Epoch [103/200], Loss: 0.1766, Val Loss: 0.5608
Early stopping at epoch 103
Runtime: 0:02:33.476486
R^2 Score: 0.8991
RMSE: 0.7300
MAE: 0.2184
MAPE: 18.23%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/200], Loss: 0.2208, Val Loss: 0.5412
Epoch [2/200], Loss: 0.0915, Val Loss: 0.5591
Epoch [3/200], Loss: 0.2591, Val Loss: 0.6088
Epoch [4/200], Loss: 0.1674, Val Loss: 0.5669
Epoch [5/200], Loss: 0.1417, Val Loss: 0.5711
Epoch [6/200], Loss: 0.1699, Val Loss: 0.5674
Epoch [7/200], Loss: 0.0429, Val Loss: 0.5696
Epoch [8/200], Loss: 0.0499, Val Loss: 0.6190
Epoch [9/200], Loss: 0.2424, Val Loss: 0.5511
Epoch [10/200], Loss: 0.0843, Val Loss: 0.5816
Epoch [11/200], Loss: 0.1140, Val Loss: 0.5792
Epoch [12/200], Loss: 0.0668, Val Loss: 0.5502
Epoch [13/200], Loss: 0.0638, Val Loss: 0.5749
Epoch [14/200], Loss: 0.0668, Val Loss: 0.5738
Epoch [15/200], Loss: 0.1190, Val Loss: 0.5607
Epoch [16/200], Loss: 0.1244, Val Loss: 0.5740
Epoch [17/200], Loss: 0.1314, Val Loss: 0.5737
Epoch [18/200], Loss: 0.1998, Val Loss: 0.5484
Epoch [19/200], Loss: 0.0656, Val Loss: 0.5594
Epoch [20/200], Loss: 0.4113, Val Loss: 0.5856
Epoch [21/200], Loss: 0.3046, Val Loss: 0.6077
Epoch [22/200], Loss: 0.1409, Val Loss: 0.5484
Epoch [23/200], Loss: 0.0741, Val Loss: 0.5495
Epoch [24/200], Loss: 0.0978, Val Loss: 0.6109
Epoch [25/200], Loss: 0.1045, Val Loss: 0.5769
Epoch [26/200], Loss: 0.1489, Val Loss: 0.5478
Epoch [27/200], Loss: 0.0968, Val Loss: 0.5624
Epoch [28/200], Loss: 0.0697, Val Loss: 0.5568
Epoch [29/200], Loss: 0.1644, Val Loss: 0.5398
Epoch [30/200], Loss: 0.0611, Val Loss: 0.5648
Epoch [31/200], Loss: 0.1653, Val Loss: 0.5367
Epoch [32/200], Loss: 0.0377, Val Loss: 0.5500
Epoch [33/200], Loss: 0.2906, Val Loss: 0.5445
Epoch [34/200], Loss: 0.1496, Val Loss: 0.5399
Epoch [35/200], Loss: 0.1835, Val Loss: 0.5942
Epoch [36/200], Loss: 0.4168, Val Loss: 0.5630
Epoch [37/200], Loss: 0.0922, Val Loss: 0.5651
Epoch [38/200], Loss: 0.1724, Val Loss: 0.6115
Epoch [39/200], Loss: 0.0954, Val Loss: 0.5607
Epoch [40/200], Loss: 0.1806, Val Loss: 0.6348
Epoch [41/200], Loss: 0.1036, Val Loss: 0.5605
Epoch [42/200], Loss: 0.1363, Val Loss: 0.5437
Epoch [43/200], Loss: 0.2671, Val Loss: 0.5498
Epoch [44/200], Loss: 0.1323, Val Loss: 0.6008
Epoch [45/200], Loss: 0.1343, Val Loss: 0.5841
Epoch [46/200], Loss: 0.1835, Val Loss: 0.5695
Epoch [47/200], Loss: 0.0606, Val Loss: 0.6047
Epoch [48/200], Loss: 0.1161, Val Loss: 0.5770
Epoch [49/200], Loss: 0.0781, Val Loss: 0.6129
Epoch [50/200], Loss: 0.1193, Val Loss: 0.5866
Epoch [51/200], Loss: 0.1447, Val Loss: 0.6010
Epoch [52/200], Loss: 0.0719, Val Loss: 0.5550
Epoch [53/200], Loss: 0.0751, Val Loss: 0.5579
Epoch [54/200], Loss: 0.1401, Val Loss: 0.5639
Epoch [55/200], Loss: 0.2345, Val Loss: 0.5574
Epoch [56/200], Loss: 0.2032, Val Loss: 0.5568
Epoch [57/200], Loss: 0.2365, Val Loss: 0.5624
Epoch [58/200], Loss: 0.2791, Val Loss: 0.5736
Epoch [59/200], Loss: 0.1280, Val Loss: 0.5675
Epoch [60/200], Loss: 0.2314, Val Loss: 0.5839
Epoch [61/200], Loss: 0.0575, Val Loss: 0.5576
Epoch [62/200], Loss: 0.0863, Val Loss: 0.5827
Epoch [63/200], Loss: 0.0713, Val Loss: 0.5684
Epoch [64/200], Loss: 0.0567, Val Loss: 0.5693
Epoch [65/200], Loss: 0.0353, Val Loss: 0.5953
Epoch [66/200], Loss: 0.5117, Val Loss: 0.5768
Epoch [67/200], Loss: 0.2213, Val Loss: 0.5906
Epoch [68/200], Loss: 0.0951, Val Loss: 0.5598
Epoch [69/200], Loss: 0.1590, Val Loss: 0.5668
Epoch [70/200], Loss: 0.0773, Val Loss: 0.5773
Epoch [71/200], Loss: 0.0631, Val Loss: 0.5739
Epoch [72/200], Loss: 0.0910, Val Loss: 0.6135
Epoch [73/200], Loss: 0.1100, Val Loss: 0.5947
Early stopping at epoch 73
Runtime: 0:01:49.774367
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0906, Val Loss: 0.5699
Epoch [2/100], Loss: 0.0688, Val Loss: 0.5588
Epoch [3/100], Loss: 0.1075, Val Loss: 0.5715
Epoch [4/100], Loss: 0.0975, Val Loss: 0.5800
Epoch [5/100], Loss: 0.0831, Val Loss: 0.5819
Epoch [6/100], Loss: 0.0839, Val Loss: 0.5696
Epoch [7/100], Loss: 0.0543, Val Loss: 0.5747
Epoch [8/100], Loss: 0.0393, Val Loss: 0.5643
Epoch [9/100], Loss: 0.1721, Val Loss: 0.5433
Epoch [10/100], Loss: 0.1208, Val Loss: 0.5661
Epoch [11/100], Loss: 0.1776, Val Loss: 0.5581
Epoch [12/100], Loss: 0.1753, Val Loss: 0.5602
Epoch [13/100], Loss: 0.1967, Val Loss: 0.5768
Epoch [14/100], Loss: 0.0868, Val Loss: 0.6899
Epoch [15/100], Loss: 0.1265, Val Loss: 0.5686
Epoch [16/100], Loss: 0.1362, Val Loss: 0.5971
Epoch [17/100], Loss: 0.1702, Val Loss: 0.5740
Epoch [18/100], Loss: 0.1446, Val Loss: 0.5600
Epoch [19/100], Loss: 0.2087, Val Loss: 0.5619
Epoch [20/100], Loss: 0.0368, Val Loss: 0.5648
Epoch [21/100], Loss: 0.1302, Val Loss: 0.5800
Epoch [22/100], Loss: 0.7210, Val Loss: 0.5755
Epoch [23/100], Loss: 0.1280, Val Loss: 0.5574
Epoch [24/100], Loss: 0.2679, Val Loss: 0.5717
Epoch [25/100], Loss: 0.1781, Val Loss: 0.5975
Epoch [26/100], Loss: 0.1018, Val Loss: 0.5821
Epoch [27/100], Loss: 0.1745, Val Loss: 0.6020
Epoch [28/100], Loss: 0.1752, Val Loss: 0.5780
Early stopping at epoch 28
Runtime: 0:00:42.226462
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0885, Val Loss: 0.5763
Epoch [2/100], Loss: 0.0857, Val Loss: 0.5510
Epoch [3/100], Loss: 0.1671, Val Loss: 0.5632
Epoch [4/100], Loss: 0.0447, Val Loss: 0.5717
Epoch [5/100], Loss: 0.0964, Val Loss: 0.5609
Epoch [6/100], Loss: 0.1241, Val Loss: 0.5599
Epoch [7/100], Loss: 0.0783, Val Loss: 0.5847
Epoch [8/100], Loss: 0.1223, Val Loss: 0.5635
Epoch [9/100], Loss: 0.1354, Val Loss: 0.5764
Epoch [10/100], Loss: 0.0491, Val Loss: 0.5866
Epoch [11/100], Loss: 0.0842, Val Loss: 0.5834
Epoch [12/100], Loss: 0.0667, Val Loss: 0.5804
Epoch [13/100], Loss: 0.0965, Val Loss: 0.5929
Epoch [14/100], Loss: 0.0643, Val Loss: 0.6421
Epoch [15/100], Loss: 0.2042, Val Loss: 0.5859
Epoch [16/100], Loss: 0.1267, Val Loss: 0.6138
Epoch [17/100], Loss: 0.0399, Val Loss: 0.5794
Epoch [18/100], Loss: 0.1187, Val Loss: 0.5726
Epoch [19/100], Loss: 0.2400, Val Loss: 0.5913
Epoch [20/100], Loss: 0.1958, Val Loss: 0.5675
Epoch [21/100], Loss: 0.0792, Val Loss: 0.5490
Epoch [22/100], Loss: 0.1229, Val Loss: 0.6044
Epoch [23/100], Loss: 0.0624, Val Loss: 0.5851
Epoch [24/100], Loss: 0.0910, Val Loss: 0.5671
Epoch [25/100], Loss: 0.0803, Val Loss: 0.5718
Epoch [26/100], Loss: 0.0805, Val Loss: 0.5727
Epoch [27/100], Loss: 0.1142, Val Loss: 0.5743
Epoch [28/100], Loss: 0.1177, Val Loss: 0.5554
Epoch [29/100], Loss: 0.0637, Val Loss: 0.5560
Epoch [30/100], Loss: 0.0823, Val Loss: 0.5542
Epoch [31/100], Loss: 0.0866, Val Loss: 0.6006
Epoch [32/100], Loss: 0.1437, Val Loss: 0.5811
Epoch [33/100], Loss: 0.1031, Val Loss: 0.5763
Epoch [34/100], Loss: 0.1092, Val Loss: 0.5867
Epoch [35/100], Loss: 0.0676, Val Loss: 0.5828
Epoch [36/100], Loss: 0.1971, Val Loss: 0.5510
Epoch [37/100], Loss: 0.0953, Val Loss: 0.5933
Epoch [38/100], Loss: 0.0862, Val Loss: 0.5553
Epoch [39/100], Loss: 0.6980, Val Loss: 0.5798
Epoch [40/100], Loss: 0.1896, Val Loss: 0.5674
Epoch [41/100], Loss: 0.2733, Val Loss: 0.5474
Epoch [42/100], Loss: 0.1528, Val Loss: 0.5635
Epoch [43/100], Loss: 0.0947, Val Loss: 0.5545
Epoch [44/100], Loss: 0.1134, Val Loss: 0.5741
Epoch [45/100], Loss: 0.0622, Val Loss: 0.5876
Epoch [46/100], Loss: 0.0587, Val Loss: 0.5561
Epoch [47/100], Loss: 0.1387, Val Loss: 0.5690
Epoch [48/100], Loss: 0.1205, Val Loss: 0.5723
Epoch [49/100], Loss: 0.0751, Val Loss: 0.5822
Epoch [50/100], Loss: 0.1094, Val Loss: 0.5994
Epoch [51/100], Loss: 0.1777, Val Loss: 0.5876
Epoch [52/100], Loss: 0.0891, Val Loss: 0.5689
Epoch [53/100], Loss: 0.1002, Val Loss: 0.5876
Epoch [54/100], Loss: 0.1152, Val Loss: 0.5877
Epoch [55/100], Loss: 0.1514, Val Loss: 0.5736
Epoch [56/100], Loss: 0.0654, Val Loss: 0.5816
Epoch [57/100], Loss: 0.0843, Val Loss: 0.5880
Epoch [58/100], Loss: 0.2267, Val Loss: 0.6066
Epoch [59/100], Loss: 0.0894, Val Loss: 0.5558
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0712, Val Loss: 0.5874
Epoch [2/100], Loss: 0.0907, Val Loss: 0.5832
Epoch [3/100], Loss: 0.0565, Val Loss: 0.5367
Epoch [4/100], Loss: 0.2169, Val Loss: 0.5602
Epoch [5/100], Loss: 0.2054, Val Loss: 0.5592
Epoch [6/100], Loss: 0.1066, Val Loss: 0.6109
Epoch [7/100], Loss: 0.1493, Val Loss: 0.5724
Early stopping at epoch 7
Runtime: 0:00:11.864446
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0726, Val Loss: 0.5883
Epoch [2/100], Loss: 0.1760, Val Loss: 0.5583
Epoch [3/100], Loss: 0.5075, Val Loss: 0.5554
Epoch [4/100], Loss: 0.0655, Val Loss: 0.5459
Epoch [5/100], Loss: 0.0984, Val Loss: 0.5414
Epoch [6/100], Loss: 0.1370, Val Loss: 0.5571
Epoch [7/100], Loss: 0.1036, Val Loss: 0.5846
Epoch [8/100], Loss: 0.1060, Val Loss: 0.5423
Epoch [9/100], Loss: 0.3237, Val Loss: 0.5601
Epoch [10/100], Loss: 0.2201, Val Loss: 0.5729
Epoch [11/100], Loss: 0.1605, Val Loss: 0.5433
Epoch [12/100], Loss: 0.1910, Val Loss: 0.5701
Epoch [13/100], Loss: 0.6519, Val Loss: 0.5693
Epoch [14/100], Loss: 0.1051, Val Loss: 0.5535
Epoch [15/100], Loss: 0.0547, Val Loss: 0.5732
Early stopping at epoch 15
Runtime: 0:00:24.068665
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.2108, Val Loss: 0.5648
Early stopping at epoch 1
Runtime: 0:00:03.009446
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1538, Val Loss: 0.5614
Early stopping at epoch 1
Runtime: 0:00:03.032590
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0520, Val Loss: 0.5705
Epoch [2/100], Loss: 0.0834, Val Loss: 0.5482
Epoch [3/100], Loss: 0.4356, Val Loss: 0.5412
Epoch [4/100], Loss: 0.1474, Val Loss: 0.5693
Early stopping at epoch 4
Runtime: 0:00:07.613728
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0983, Val Loss: 0.5797
Epoch [2/100], Loss: 0.1235, Val Loss: 0.5722
Epoch [3/100], Loss: 0.1948, Val Loss: 0.5785
Epoch [4/100], Loss: 0.1227, Val Loss: 0.5419
Epoch [5/100], Loss: 0.1061, Val Loss: 0.5445
Early stopping at epoch 5
Runtime: 0:00:08.890442
R^2 Score: 0.9025
RMSE: 0.7175
MAE: 0.2052
MAPE: 16.56%
R^2 Score: 0.9025
RMSE: 0.7175
MAE: 0.2052
MAPE: 16.56%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0996, Val Loss: 0.5463
Epoch [2/100], Loss: 0.0537, Val Loss: 0.5527
Early stopping at epoch 2
Runtime: 0:00:04.506348
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1203, Val Loss: 0.5685
Epoch [2/100], Loss: 0.3172, Val Loss: 0.5824
Epoch [3/100], Loss: 0.0662, Val Loss: 0.5628
Epoch [4/100], Loss: 0.0498, Val Loss: 0.5672
Early stopping at epoch 4
Runtime: 0:00:07.573027
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0444, Val Loss: 0.5968
Epoch [2/100], Loss: 0.1789, Val Loss: 0.5974
Epoch [3/100], Loss: 0.0835, Val Loss: 0.5760
Epoch [4/100], Loss: 0.5301, Val Loss: 0.5754
Epoch [5/100], Loss: 0.1249, Val Loss: 0.5376
Epoch [6/100], Loss: 0.0552, Val Loss: 0.5478
Early stopping at epoch 6
Runtime: 0:00:10.827999
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1217, Val Loss: 0.5633
Epoch [2/100], Loss: 0.0691, Val Loss: 0.5937
Early stopping at epoch 2
Runtime: 0:00:04.565694
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0796, Val Loss: 0.5965
Epoch [2/100], Loss: 0.2743, Val Loss: 0.5664
Epoch [3/100], Loss: 0.0452, Val Loss: 0.5767
Early stopping at epoch 3
Runtime: 0:00:05.961186
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1658, Val Loss: 0.5680
Epoch [2/100], Loss: 0.0977, Val Loss: 0.5532
Epoch [3/100], Loss: 0.2876, Val Loss: 0.5817
Early stopping at epoch 3
Runtime: 0:00:05.992699
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1707, Val Loss: 0.5728
Epoch [2/100], Loss: 0.1218, Val Loss: 0.5691
Epoch [3/100], Loss: 0.0478, Val Loss: 0.5745
Early stopping at epoch 3
Runtime: 0:00:05.983893
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.2353, Val Loss: 0.5838
Epoch [2/100], Loss: 0.0491, Val Loss: 0.5845
Epoch [3/100], Loss: 0.0852, Val Loss: 0.5618
Epoch [4/100], Loss: 0.0546, Val Loss: 0.5901
Epoch [5/100], Loss: 0.1798, Val Loss: 0.5412
Epoch [6/100], Loss: 0.0844, Val Loss: 0.5715
Early stopping at epoch 6
Runtime: 0:00:10.603177
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1344, Val Loss: 0.5767
Epoch [2/100], Loss: 0.0771, Val Loss: 0.5793
Epoch [3/100], Loss: 0.1023, Val Loss: 0.5309
Epoch [4/100], Loss: 0.0862, Val Loss: 0.5642
Early stopping at epoch 4
Runtime: 0:00:07.408112
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1212, Val Loss: 0.5829
Epoch [2/100], Loss: 0.0290, Val Loss: 0.5875
Early stopping at epoch 2
Runtime: 0:00:04.462820
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.2192, Val Loss: 0.5689
Epoch [2/100], Loss: 0.1311, Val Loss: 0.5690
Epoch [3/100], Loss: 0.0558, Val Loss: 0.5699
Early stopping at epoch 3
Runtime: 0:00:06.276785
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.8130, Val Loss: 0.5649
Epoch [2/100], Loss: 0.0620, Val Loss: 0.5562
Epoch [3/100], Loss: 0.0763, Val Loss: 0.5776
Early stopping at epoch 3
Runtime: 0:00:06.019006
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0817, Val Loss: 0.5635
Epoch [2/100], Loss: 0.1354, Val Loss: 0.5865
Early stopping at epoch 2
Runtime: 0:00:04.575183
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1925, Val Loss: 0.5695
Epoch [2/100], Loss: 0.2811, Val Loss: 0.5765
Epoch [3/100], Loss: 0.5356, Val Loss: 0.5661
Epoch [4/100], Loss: 0.1312, Val Loss: 0.5459
Epoch [5/100], Loss: 0.0854, Val Loss: 0.5671
Early stopping at epoch 5
Runtime: 0:00:09.075391
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1600, Val Loss: 0.5473
Epoch [2/100], Loss: 1.0995, Val Loss: 0.5547
Epoch [3/100], Loss: 0.1010, Val Loss: 0.5244
Epoch [4/100], Loss: 0.0442, Val Loss: 0.5746
Early stopping at epoch 4
Runtime: 0:00:07.564008
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1171, Val Loss: 0.5663
Epoch [2/100], Loss: 0.1056, Val Loss: 0.5665
Epoch [3/100], Loss: 0.0974, Val Loss: 0.5769
Early stopping at epoch 3
Runtime: 0:00:06.176649
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0591, Val Loss: 0.5513
Epoch [2/100], Loss: 0.1011, Val Loss: 0.5672
Epoch [3/100], Loss: 0.2307, Val Loss: 0.5473
Epoch [4/100], Loss: 0.0636, Val Loss: 0.5489
Early stopping at epoch 4
Runtime: 0:00:07.637641
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1451, Val Loss: 0.5536
Epoch [2/100], Loss: 0.0337, Val Loss: 0.5664
Early stopping at epoch 2
Runtime: 0:00:04.589553
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0895, Val Loss: 0.5948
Epoch [2/100], Loss: 0.2519, Val Loss: 0.5798
Epoch [3/100], Loss: 0.3668, Val Loss: 0.5649
Epoch [4/100], Loss: 0.0636, Val Loss: 0.5533
Epoch [5/100], Loss: 0.0838, Val Loss: 0.5781
Early stopping at epoch 5
Runtime: 0:00:09.322915
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1596, Val Loss: 0.6012
Epoch [2/100], Loss: 0.1682, Val Loss: 0.5537
Early stopping at epoch 2
Runtime: 0:00:04.531388
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.2582, Val Loss: 0.5750
Epoch [2/100], Loss: 0.0597, Val Loss: 0.5614
Epoch [3/100], Loss: 0.0345, Val Loss: 0.5644
Epoch [4/100], Loss: 0.2708, Val Loss: 0.5716
Epoch [5/100], Loss: 0.0628, Val Loss: 0.5574
Epoch [6/100], Loss: 0.1012, Val Loss: 0.5721
Epoch [7/100], Loss: 0.3600, Val Loss: 0.5706
Early stopping at epoch 7
Runtime: 0:00:12.101206
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1164, Val Loss: 0.5834
Epoch [2/100], Loss: 0.0925, Val Loss: 0.5801
Epoch [3/100], Loss: 0.0940, Val Loss: 0.5804
Epoch [4/100], Loss: 0.0385, Val Loss: 0.5733
Epoch [5/100], Loss: 0.0453, Val Loss: 0.5830
Epoch [6/100], Loss: 0.0639, Val Loss: 0.5887
Epoch [7/100], Loss: 0.1456, Val Loss: 0.5893
Epoch [8/100], Loss: 0.4155, Val Loss: 0.5896
Epoch [9/100], Loss: 0.1357, Val Loss: 0.5598
Early stopping at epoch 9
Runtime: 0:00:14.935902
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1252, Val Loss: 0.5906
Epoch [2/100], Loss: 0.0494, Val Loss: 0.5923
Epoch [3/100], Loss: 0.1214, Val Loss: 0.5777
Epoch [4/100], Loss: 0.0545, Val Loss: 0.5849
Epoch [5/100], Loss: 0.1201, Val Loss: 0.5769
Epoch [6/100], Loss: 0.0692, Val Loss: 0.5576
Epoch [7/100], Loss: 0.7282, Val Loss: 0.5656
Epoch [8/100], Loss: 0.0673, Val Loss: 0.5610
Epoch [9/100], Loss: 0.3043, Val Loss: 0.5667
Early stopping at epoch 9
Runtime: 0:00:15.453583
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0926, Val Loss: 0.5677
Epoch [2/100], Loss: 0.1203, Val Loss: 0.5642
Epoch [3/100], Loss: 0.1219, Val Loss: 0.5714
Epoch [4/100], Loss: 0.0777, Val Loss: 0.5777
Epoch [5/100], Loss: 0.0758, Val Loss: 0.5789
Epoch [6/100], Loss: 0.0703, Val Loss: 0.5677
Epoch [7/100], Loss: 0.0835, Val Loss: 0.5673
Early stopping at epoch 7
Runtime: 0:00:12.662744
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1234, Val Loss: 0.5753
Epoch [2/100], Loss: 0.2546, Val Loss: 0.5615
Epoch [3/100], Loss: 0.1630, Val Loss: 0.5581
Early stopping at epoch 3
Runtime: 0:00:06.121523
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1785, Val Loss: 0.5831
Epoch [2/100], Loss: 0.0767, Val Loss: 0.5777
Epoch [3/100], Loss: 0.1044, Val Loss: 0.5718
Early stopping at epoch 3
Runtime: 0:00:06.055818
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1076, Val Loss: 0.5532
Epoch [2/100], Loss: 0.0970, Val Loss: 0.5677
Epoch [3/100], Loss: 0.1062, Val Loss: 0.5485
Early stopping at epoch 3
Runtime: 0:00:06.102506
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0228, Val Loss: 0.5667
Epoch [2/100], Loss: 0.1650, Val Loss: 0.5715
Epoch [3/100], Loss: 0.0657, Val Loss: 0.5711
Epoch [4/100], Loss: 0.1739, Val Loss: 0.5707
Epoch [5/100], Loss: 0.0965, Val Loss: 0.5647
Epoch [6/100], Loss: 0.2007, Val Loss: 0.5507
Epoch [7/100], Loss: 0.1640, Val Loss: 0.5527
Epoch [8/100], Loss: 0.1390, Val Loss: 0.5571
Early stopping at epoch 8
Runtime: 0:00:13.421837
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0609, Val Loss: 0.6088
Epoch [2/100], Loss: 0.0500, Val Loss: 0.5674
Epoch [3/100], Loss: 0.1202, Val Loss: 0.5636
Epoch [4/100], Loss: 0.0567, Val Loss: 0.5744
Epoch [5/100], Loss: 0.0906, Val Loss: 0.5561
Epoch [6/100], Loss: 0.3388, Val Loss: 0.5482
Epoch [7/100], Loss: 0.0838, Val Loss: 0.5500
Epoch [8/100], Loss: 0.0522, Val Loss: 0.5374
Epoch [9/100], Loss: 0.0727, Val Loss: 0.5539
Early stopping at epoch 9
Runtime: 0:00:15.258575
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.0604, Val Loss: 0.5494
Epoch [2/100], Loss: 0.0609, Val Loss: 0.5530
Epoch [3/100], Loss: 0.0948, Val Loss: 0.5368
Early stopping at epoch 3
Runtime: 0:00:05.908866
R^2 Score: 0.9043
RMSE: 0.7111
MAE: 0.2005
MAPE: 16.43%
R^2 Score: 0.9043
RMSE: 0.7111
MAE: 0.2005
MAPE: 16.43%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.1023, Val Loss: 0.5812
Epoch [2/100], Loss: 0.2622, Val Loss: 0.5860
Epoch [3/100], Loss: 0.3672, Val Loss: 0.5918
Epoch [4/100], Loss: 0.0408, Val Loss: 0.5500
Epoch [5/100], Loss: 0.0787, Val Loss: 0.5335
Early stopping at epoch 5
Runtime: 0:00:25.354430
R^2 Score: 0.9046
RMSE: 0.7099
MAE: 0.2014
MAPE: 15.85%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1076, Val Loss: 0.4066
Epoch [2/120], Loss: 0.1335, Val Loss: 0.3792
Epoch [3/120], Loss: 0.0545, Val Loss: 0.3730
Epoch [4/120], Loss: 0.5303, Val Loss: 0.3609
Epoch [5/120], Loss: 0.3743, Val Loss: 0.3658
Epoch [6/120], Loss: 0.4818, Val Loss: 0.3616
Epoch [7/120], Loss: 0.0490, Val Loss: 0.3602
Epoch [8/120], Loss: 0.1278, Val Loss: 0.3698
Epoch [9/120], Loss: 0.3164, Val Loss: 0.3493
Epoch [10/120], Loss: 0.2720, Val Loss: 0.3582
Epoch [11/120], Loss: 0.0809, Val Loss: 0.3606
Epoch [12/120], Loss: 0.1039, Val Loss: 0.3515
Epoch [13/120], Loss: 0.2612, Val Loss: 0.3569
Epoch [14/120], Loss: 0.0683, Val Loss: 0.3412
Epoch [15/120], Loss: 0.0903, Val Loss: 0.3495
Epoch [16/120], Loss: 0.0760, Val Loss: 0.3423
Epoch [17/120], Loss: 0.1483, Val Loss: 0.3546
Epoch [18/120], Loss: 0.1892, Val Loss: 0.3613
Epoch [19/120], Loss: 0.0716, Val Loss: 0.3449
Epoch [20/120], Loss: 0.1419, Val Loss: 0.3637
Epoch [21/120], Loss: 0.1098, Val Loss: 0.3677
Epoch [22/120], Loss: 0.1750, Val Loss: 0.3471
Epoch [23/120], Loss: 0.0542, Val Loss: 0.3476
Epoch [24/120], Loss: 0.1229, Val Loss: 0.3699
Epoch [25/120], Loss: 0.1210, Val Loss: 0.3515
Epoch [26/120], Loss: 0.0656, Val Loss: 0.3576
Epoch [27/120], Loss: 0.1090, Val Loss: 0.3586
Epoch [28/120], Loss: 0.0931, Val Loss: 0.3528
Epoch [29/120], Loss: 0.0605, Val Loss: 0.3509
Epoch [30/120], Loss: 0.1910, Val Loss: 0.3529
Epoch [31/120], Loss: 0.0661, Val Loss: 0.3622
Epoch [32/120], Loss: 0.2909, Val Loss: 0.3841
Epoch [33/120], Loss: 0.1186, Val Loss: 0.3598
Epoch [34/120], Loss: 0.1798, Val Loss: 0.3585
Epoch [35/120], Loss: 0.0693, Val Loss: 0.3533
Epoch [36/120], Loss: 0.0776, Val Loss: 0.3903
Epoch [37/120], Loss: 0.1682, Val Loss: 0.3484
Epoch [38/120], Loss: 0.1523, Val Loss: 0.3474
Epoch [39/120], Loss: 0.0805, Val Loss: 0.3695
Epoch [40/120], Loss: 0.1668, Val Loss: 0.3511
Epoch [41/120], Loss: 0.1187, Val Loss: 0.3828
Epoch [42/120], Loss: 0.0675, Val Loss: 0.3509
Epoch [43/120], Loss: 0.0931, Val Loss: 0.3628
Epoch [44/120], Loss: 0.1034, Val Loss: 0.3671
Epoch [45/120], Loss: 0.1181, Val Loss: 0.3681
Epoch [46/120], Loss: 0.1488, Val Loss: 0.3609
Epoch [47/120], Loss: 0.0588, Val Loss: 0.3529
Epoch [48/120], Loss: 0.0790, Val Loss: 0.3463
Epoch [49/120], Loss: 0.1181, Val Loss: 0.3596
Epoch [50/120], Loss: 0.2003, Val Loss: 0.3494
Epoch [51/120], Loss: 0.1442, Val Loss: 0.3762
Epoch [52/120], Loss: 0.1284, Val Loss: 0.3526
Epoch [53/120], Loss: 0.3529, Val Loss: 0.3621
Epoch [54/120], Loss: 0.0967, Val Loss: 0.3528
Epoch [55/120], Loss: 0.0879, Val Loss: 0.3492
Epoch [56/120], Loss: 0.0449, Val Loss: 0.3678
Epoch [57/120], Loss: 0.1360, Val Loss: 0.3649
Epoch [58/120], Loss: 0.0904, Val Loss: 0.3682
Epoch [59/120], Loss: 0.2515, Val Loss: 0.3582
Epoch [60/120], Loss: 0.0762, Val Loss: 0.3720
Epoch [61/120], Loss: 0.0493, Val Loss: 0.3501
Epoch [62/120], Loss: 0.2739, Val Loss: 0.3562
Epoch [63/120], Loss: 0.1147, Val Loss: 0.3786
Epoch [64/120], Loss: 0.1829, Val Loss: 0.3522
Epoch [65/120], Loss: 0.3844, Val Loss: 0.3595
Epoch [66/120], Loss: 0.3251, Val Loss: 0.3712
Epoch [67/120], Loss: 0.1000, Val Loss: 0.3563
Epoch [68/120], Loss: 0.0704, Val Loss: 0.3565
Epoch [69/120], Loss: 0.0489, Val Loss: 0.3462
Epoch [70/120], Loss: 0.1519, Val Loss: 0.3492
Epoch [71/120], Loss: 0.0718, Val Loss: 0.3607
Epoch [72/120], Loss: 0.0541, Val Loss: 0.3700
Epoch [73/120], Loss: 0.1540, Val Loss: 0.3651
Epoch [74/120], Loss: 0.4839, Val Loss: 0.3620
Epoch [75/120], Loss: 0.1187, Val Loss: 0.3752
Epoch [76/120], Loss: 0.1083, Val Loss: 0.3780
Epoch [77/120], Loss: 0.0638, Val Loss: 0.3781
Epoch [78/120], Loss: 0.1016, Val Loss: 0.3679
Epoch [79/120], Loss: 0.0455, Val Loss: 0.3573
Epoch [80/120], Loss: 0.0431, Val Loss: 0.3660
Epoch [81/120], Loss: 0.0628, Val Loss: 0.3637
Epoch [82/120], Loss: 0.1816, Val Loss: 0.3700
Epoch [83/120], Loss: 0.0445, Val Loss: 0.3588
Epoch [84/120], Loss: 0.1162, Val Loss: 0.3609
Epoch [85/120], Loss: 0.1932, Val Loss: 0.3698
Epoch [86/120], Loss: 0.0817, Val Loss: 0.3655
Epoch [87/120], Loss: 0.0621, Val Loss: 0.3791
Epoch [88/120], Loss: 0.0463, Val Loss: 0.3711
Epoch [89/120], Loss: 0.1892, Val Loss: 0.3657
Epoch [90/120], Loss: 0.0780, Val Loss: 0.3641
Epoch [91/120], Loss: 0.0925, Val Loss: 0.3619
Epoch [92/120], Loss: 0.0468, Val Loss: 0.3681
Epoch [93/120], Loss: 0.2137, Val Loss: 0.3585
Epoch [94/120], Loss: 0.2102, Val Loss: 0.3661
Epoch [95/120], Loss: 0.0436, Val Loss: 0.3664
Epoch [96/120], Loss: 0.1630, Val Loss: 0.3760
Epoch [97/120], Loss: 0.5298, Val Loss: 0.3661
Epoch [98/120], Loss: 0.0521, Val Loss: 0.3683
Early stopping at epoch 98
Runtime: 0:02:05.905113
R^2 Score: 0.9592
RMSE: 0.3958
MAE: 0.1449
MAPE: 13.95%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0880, Val Loss: 0.4005
Epoch [2/120], Loss: 0.1294, Val Loss: 0.3541
Epoch [3/120], Loss: 0.1034, Val Loss: 0.3799
Epoch [4/120], Loss: 0.4382, Val Loss: 0.3741
Epoch [5/120], Loss: 0.1395, Val Loss: 0.3654
Epoch [6/120], Loss: 0.1106, Val Loss: 0.3776
Epoch [7/120], Loss: 0.1201, Val Loss: 0.3860
Epoch [8/120], Loss: 0.1058, Val Loss: 0.3737
Epoch [9/120], Loss: 0.1938, Val Loss: 0.3852
Epoch [10/120], Loss: 0.0958, Val Loss: 0.3770
Epoch [11/120], Loss: 0.0898, Val Loss: 0.3696
Epoch [12/120], Loss: 0.1098, Val Loss: 0.3801
Epoch [13/120], Loss: 0.0567, Val Loss: 0.3755
Epoch [14/120], Loss: 0.2421, Val Loss: 0.3958
Epoch [15/120], Loss: 0.1239, Val Loss: 0.3789
Epoch [16/120], Loss: 0.0934, Val Loss: 0.3720
Epoch [17/120], Loss: 0.0775, Val Loss: 0.3755
Epoch [18/120], Loss: 0.0538, Val Loss: 0.4047
Epoch [19/120], Loss: 0.2849, Val Loss: 0.3710
Epoch [20/120], Loss: 0.0634, Val Loss: 0.3817
Epoch [21/120], Loss: 0.0488, Val Loss: 0.3727
Epoch [22/120], Loss: 0.0635, Val Loss: 0.3703
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0935, Val Loss: 0.3603
Epoch [2/120], Loss: 0.1055, Val Loss: 0.3771
Epoch [3/120], Loss: 0.0510, Val Loss: 0.3772
Epoch [4/120], Loss: 0.0909, Val Loss: 0.3643
Early stopping at epoch 4
Runtime: 0:00:06.681311
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0295, Val Loss: 0.3985
Epoch [2/120], Loss: 0.1130, Val Loss: 0.3988
Epoch [3/120], Loss: 0.0908, Val Loss: 0.4006
Epoch [4/120], Loss: 0.1298, Val Loss: 0.3912
Epoch [5/120], Loss: 0.9558, Val Loss: 0.3719
Epoch [6/120], Loss: 0.0258, Val Loss: 0.3854
Epoch [7/120], Loss: 0.2068, Val Loss: 0.3657
Epoch [8/120], Loss: 0.0410, Val Loss: 0.3768
Epoch [9/120], Loss: 0.0590, Val Loss: 0.3784
Epoch [10/120], Loss: 0.0528, Val Loss: 0.3730
Early stopping at epoch 10
Runtime: 0:00:13.859432
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0747, Val Loss: 0.3973
Epoch [2/120], Loss: 0.0985, Val Loss: 0.4089
Epoch [3/120], Loss: 0.1026, Val Loss: 0.3874
Epoch [4/120], Loss: 0.2006, Val Loss: 0.3822
Epoch [5/120], Loss: 0.0734, Val Loss: 0.3904
Epoch [6/120], Loss: 0.0841, Val Loss: 0.3741
Epoch [7/120], Loss: 0.1285, Val Loss: 0.3849
Epoch [8/120], Loss: 0.0863, Val Loss: 0.3849
Epoch [9/120], Loss: 0.1888, Val Loss: 0.3903
Epoch [10/120], Loss: 0.1835, Val Loss: 0.3770
Epoch [11/120], Loss: 0.0517, Val Loss: 0.3824
Early stopping at epoch 11
Runtime: 0:00:15.208972
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.2322, Val Loss: 0.3876
Epoch [2/120], Loss: 0.1195, Val Loss: 0.3912
Epoch [3/120], Loss: 0.1149, Val Loss: 0.3790
Epoch [4/120], Loss: 0.2155, Val Loss: 0.3847
Epoch [5/120], Loss: 0.1592, Val Loss: 0.3846
Epoch [6/120], Loss: 0.3059, Val Loss: 0.3735
Early stopping at epoch 6
Runtime: 0:00:08.875588
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.3653, Val Loss: 0.3916
Epoch [2/120], Loss: 0.2417, Val Loss: 0.3802
Epoch [3/120], Loss: 0.1211, Val Loss: 0.3936
Early stopping at epoch 3
Runtime: 0:00:05.151910
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1766, Val Loss: 0.3827
Epoch [2/120], Loss: 0.0845, Val Loss: 0.3784
Epoch [3/120], Loss: 0.1066, Val Loss: 0.3855
Epoch [4/120], Loss: 0.0988, Val Loss: 0.3800
Epoch [5/120], Loss: 0.0892, Val Loss: 0.3765
Early stopping at epoch 5
Runtime: 0:00:07.588719
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0795, Val Loss: 0.3711
Epoch [2/120], Loss: 0.1605, Val Loss: 0.3812
Epoch [3/120], Loss: 0.0754, Val Loss: 0.3769
Epoch [4/120], Loss: 0.1176, Val Loss: 0.3778
Epoch [5/120], Loss: 0.1087, Val Loss: 0.3716
Early stopping at epoch 5
Runtime: 0:00:07.589553
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1537, Val Loss: 0.3957
Epoch [2/120], Loss: 0.0944, Val Loss: 0.3633
Early stopping at epoch 2
Runtime: 0:00:03.946113
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0993, Val Loss: 0.3817
Epoch [2/120], Loss: 0.1034, Val Loss: 0.3938
Epoch [3/120], Loss: 0.0668, Val Loss: 0.3789
Epoch [4/120], Loss: 0.0730, Val Loss: 0.3977
Epoch [5/120], Loss: 0.1328, Val Loss: 0.3835
Epoch [6/120], Loss: 0.1088, Val Loss: 0.3803
Epoch [7/120], Loss: 0.1293, Val Loss: 0.3726
Early stopping at epoch 7
Runtime: 0:00:10.135682
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1060, Val Loss: 0.3942
Epoch [2/120], Loss: 0.0677, Val Loss: 0.3767
Epoch [3/120], Loss: 0.0474, Val Loss: 0.3881
Epoch [4/120], Loss: 0.2153, Val Loss: 0.3682
Early stopping at epoch 4
Runtime: 0:00:06.382142
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0410, Val Loss: 0.3812
Epoch [2/120], Loss: 0.0837, Val Loss: 0.3781
Epoch [3/120], Loss: 0.0887, Val Loss: 0.3806
Epoch [4/120], Loss: 0.1665, Val Loss: 0.3873
Epoch [5/120], Loss: 0.3130, Val Loss: 0.3842
Epoch [6/120], Loss: 0.1351, Val Loss: 0.3809
Early stopping at epoch 6
Runtime: 0:00:08.936768
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1930, Val Loss: 0.3798
Epoch [2/120], Loss: 0.0318, Val Loss: 0.3821
Epoch [3/120], Loss: 0.1831, Val Loss: 0.3926
Epoch [4/120], Loss: 0.1165, Val Loss: 0.3784
Early stopping at epoch 4
Runtime: 0:00:06.411292
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1358, Val Loss: 0.3798
Epoch [2/120], Loss: 0.2115, Val Loss: 0.3756
Early stopping at epoch 2
Runtime: 0:00:03.968997
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0953, Val Loss: 0.3853
Early stopping at epoch 1
Runtime: 0:00:02.631106
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0705, Val Loss: 0.3783
Epoch [2/120], Loss: 0.1426, Val Loss: 0.3872
Epoch [3/120], Loss: 0.0852, Val Loss: 0.3820
Early stopping at epoch 3
Runtime: 0:00:05.219466
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0379, Val Loss: 0.3789
Epoch [2/120], Loss: 0.1134, Val Loss: 0.3834
Epoch [3/120], Loss: 0.0315, Val Loss: 0.3913
Epoch [4/120], Loss: 0.3096, Val Loss: 0.3696
Early stopping at epoch 4
Runtime: 0:00:06.335398
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0950, Val Loss: 0.3811
Epoch [2/120], Loss: 0.1197, Val Loss: 0.3822
Early stopping at epoch 2
Runtime: 0:00:03.807395
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0374, Val Loss: 0.3918
Epoch [2/120], Loss: 0.0990, Val Loss: 0.3789
Epoch [3/120], Loss: 0.0396, Val Loss: 0.3843
Early stopping at epoch 3
Runtime: 0:00:05.175048
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.0678, Val Loss: 0.3912
Epoch [2/120], Loss: 0.0797, Val Loss: 0.3769
Early stopping at epoch 2
Runtime: 0:00:03.877946
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.1000, Val Loss: 0.3876
Epoch [2/120], Loss: 0.1135, Val Loss: 0.3888
Epoch [3/120], Loss: 0.1660, Val Loss: 0.3750
Epoch [4/120], Loss: 0.1485, Val Loss: 0.3878
Early stopping at epoch 4
Runtime: 0:00:06.367399
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.3894, Val Loss: 0.4030
Epoch [2/120], Loss: 0.0952, Val Loss: 0.3961
Epoch [3/120], Loss: 0.0490, Val Loss: 0.3958
Epoch [4/120], Loss: 0.0525, Val Loss: 0.3724
Early stopping at epoch 4
Runtime: 0:00:06.304170
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0009340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 1.4224, Val Loss: 1.0757
Epoch [2/120], Loss: 0.5821, Val Loss: 0.9352
Epoch [3/120], Loss: 0.1997, Val Loss: 0.8420
Epoch [4/120], Loss: 0.5372, Val Loss: 0.8029
Epoch [5/120], Loss: 0.4941, Val Loss: 0.8608
Epoch [6/120], Loss: 0.2902, Val Loss: 0.7958
Epoch [7/120], Loss: 0.1926, Val Loss: 0.8138
Epoch [8/120], Loss: 0.6508, Val Loss: 0.7365
Epoch [9/120], Loss: 1.3609, Val Loss: 0.6955
Epoch [10/120], Loss: 1.0176, Val Loss: 0.6789
Epoch [11/120], Loss: 0.3018, Val Loss: 0.6502
Epoch [12/120], Loss: 0.1088, Val Loss: 0.6964
Epoch [13/120], Loss: 0.1030, Val Loss: 0.6653
Epoch [14/120], Loss: 0.1190, Val Loss: 0.6631
Epoch [15/120], Loss: 0.5437, Val Loss: 0.6365
Epoch [16/120], Loss: 0.4107, Val Loss: 0.6325
Epoch [17/120], Loss: 0.1180, Val Loss: 0.5791
Epoch [18/120], Loss: 0.1107, Val Loss: 0.5991
Epoch [19/120], Loss: 0.1696, Val Loss: 0.6250
Epoch [20/120], Loss: 0.5922, Val Loss: 0.6752
Epoch [21/120], Loss: 0.1278, Val Loss: 0.5947
Epoch [22/120], Loss: 0.7194, Val Loss: 0.5976
Epoch [23/120], Loss: 0.3156, Val Loss: 0.5881
Epoch [24/120], Loss: 0.8044, Val Loss: 0.5791
Epoch [25/120], Loss: 0.4063, Val Loss: 0.6280
Epoch [26/120], Loss: 0.8444, Val Loss: 0.5699
Epoch [27/120], Loss: 0.2454, Val Loss: 0.5494
Epoch [28/120], Loss: 0.0703, Val Loss: 0.6260
Epoch [29/120], Loss: 0.4592, Val Loss: 0.5619
Epoch [30/120], Loss: 0.2228, Val Loss: 0.5484
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0009340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.3750, Val Loss: 1.0609
Epoch [2/120], Loss: 0.2972, Val Loss: 0.9064
Epoch [3/120], Loss: 0.4139, Val Loss: 0.8856
Epoch [4/120], Loss: 0.5895, Val Loss: 0.8524
Epoch [5/120], Loss: 0.2067, Val Loss: 0.7883
Epoch [6/120], Loss: 0.3220, Val Loss: 0.7627
Epoch [7/120], Loss: 2.5519, Val Loss: 0.7770
Epoch [8/120], Loss: 0.9048, Val Loss: 0.7053
Epoch [9/120], Loss: 0.2596, Val Loss: 0.7761
Epoch [10/120], Loss: 0.3242, Val Loss: 0.6964
Epoch [11/120], Loss: 0.4983, Val Loss: 0.7006
Epoch [12/120], Loss: 0.0841, Val Loss: 0.6463
Epoch [13/120], Loss: 0.7667, Val Loss: 0.6655
Epoch [14/120], Loss: 0.3088, Val Loss: 0.6708
Epoch [15/120], Loss: 0.1959, Val Loss: 0.6172
Epoch [16/120], Loss: 0.0811, Val Loss: 0.6225
Epoch [17/120], Loss: 0.1687, Val Loss: 0.6248
Epoch [18/120], Loss: 0.1290, Val Loss: 0.6951
Epoch [19/120], Loss: 0.1207, Val Loss: 0.7094
Epoch [20/120], Loss: 0.1198, Val Loss: 0.7039
Epoch [21/120], Loss: 0.1440, Val Loss: 0.6363
Epoch [22/120], Loss: 0.0767, Val Loss: 0.6411
Epoch [23/120], Loss: 0.1278, Val Loss: 0.6030
Epoch [24/120], Loss: 0.0774, Val Loss: 0.5790
Epoch [25/120], Loss: 0.4144, Val Loss: 0.5543
Epoch [26/120], Loss: 0.1304, Val Loss: 0.5452
Epoch [27/120], Loss: 0.1293, Val Loss: 0.5291
Epoch [28/120], Loss: 0.2640, Val Loss: 0.5156
Epoch [29/120], Loss: 0.2340, Val Loss: 0.6154
Epoch [30/120], Loss: 0.4049, Val Loss: 0.5573
Epoch [31/120], Loss: 0.0403, Val Loss: 0.5335
Epoch [32/120], Loss: 0.1237, Val Loss: 0.5891
Epoch [33/120], Loss: 2.4367, Val Loss: 0.5880
Epoch [34/120], Loss: 0.1795, Val Loss: 0.5077
Epoch [35/120], Loss: 0.3138, Val Loss: 0.5133
Epoch [36/120], Loss: 0.5296, Val Loss: 0.6177
Epoch [37/120], Loss: 0.1357, Val Loss: 0.5234
Epoch [38/120], Loss: 0.2130, Val Loss: 0.4992
Epoch [39/120], Loss: 0.0849, Val Loss: 0.5049
Epoch [40/120], Loss: 0.0880, Val Loss: 0.4942
Epoch [41/120], Loss: 0.3088, Val Loss: 0.5150
Epoch [42/120], Loss: 0.2207, Val Loss: 0.5998
Epoch [43/120], Loss: 0.6250, Val Loss: 0.5428
Epoch [44/120], Loss: 0.1682, Val Loss: 0.4829
Epoch [45/120], Loss: 0.1208, Val Loss: 0.4816
Epoch [46/120], Loss: 1.8402, Val Loss: 0.5002
Epoch [47/120], Loss: 0.2424, Val Loss: 0.4964
Epoch [48/120], Loss: 0.1930, Val Loss: 0.4851
Epoch [49/120], Loss: 0.2739, Val Loss: 0.5146
Epoch [50/120], Loss: 0.3124, Val Loss: 0.4838
Epoch [51/120], Loss: 0.1331, Val Loss: 0.4938
Epoch [52/120], Loss: 0.0809, Val Loss: 0.4729
Epoch [53/120], Loss: 0.5504, Val Loss: 0.4976
Epoch [54/120], Loss: 0.1165, Val Loss: 0.5492
Epoch [55/120], Loss: 1.0310, Val Loss: 0.4791
Epoch [56/120], Loss: 0.1805, Val Loss: 0.5810
Epoch [57/120], Loss: 0.0453, Val Loss: 0.5471
Epoch [58/120], Loss: 0.1201, Val Loss: 0.4703
Epoch [59/120], Loss: 0.1334, Val Loss: 0.5239
Epoch [60/120], Loss: 0.2394, Val Loss: 0.5767
Epoch [61/120], Loss: 0.1978, Val Loss: 0.4969
Epoch [62/120], Loss: 0.0360, Val Loss: 0.4954
Epoch [63/120], Loss: 0.2688, Val Loss: 0.6092
Epoch [64/120], Loss: 0.1300, Val Loss: 0.4622
Epoch [65/120], Loss: 0.1641, Val Loss: 0.5084
Epoch [66/120], Loss: 0.2941, Val Loss: 0.4717
Epoch [67/120], Loss: 0.1339, Val Loss: 0.4989
Epoch [68/120], Loss: 0.0954, Val Loss: 0.6090
Epoch [69/120], Loss: 0.6374, Val Loss: 0.4684
Epoch [70/120], Loss: 0.1802, Val Loss: 0.4756
Epoch [71/120], Loss: 0.5335, Val Loss: 0.5006
Epoch [72/120], Loss: 0.1875, Val Loss: 0.4986
Epoch [73/120], Loss: 0.5102, Val Loss: 0.4461
Epoch [74/120], Loss: 0.1678, Val Loss: 0.5101
Epoch [75/120], Loss: 0.1254, Val Loss: 0.4633
Epoch [76/120], Loss: 0.1211, Val Loss: 0.4906
Epoch [77/120], Loss: 0.1882, Val Loss: 0.5944
Epoch [78/120], Loss: 0.0974, Val Loss: 0.5108
Epoch [79/120], Loss: 1.1227, Val Loss: 0.4666
Epoch [80/120], Loss: 0.2224, Val Loss: 0.5315
Epoch [81/120], Loss: 0.2986, Val Loss: 0.4575
Epoch [82/120], Loss: 0.0461, Val Loss: 0.4972
Epoch [83/120], Loss: 0.1158, Val Loss: 0.5204
Epoch [84/120], Loss: 0.4827, Val Loss: 0.4946
Epoch [85/120], Loss: 0.0505, Val Loss: 0.4874
Epoch [86/120], Loss: 0.0916, Val Loss: 0.4748
Epoch [87/120], Loss: 0.0968, Val Loss: 0.4958
Epoch [88/120], Loss: 0.1125, Val Loss: 0.5112
Epoch [89/120], Loss: 0.0666, Val Loss: 0.4588
Epoch [90/120], Loss: 0.0657, Val Loss: 0.4501
Epoch [91/120], Loss: 0.1026, Val Loss: 0.4966
Epoch [92/120], Loss: 0.5470, Val Loss: 0.4984
Epoch [93/120], Loss: 0.1206, Val Loss: 0.4964
Epoch [94/120], Loss: 0.0511, Val Loss: 0.4751
Epoch [95/120], Loss: 0.0702, Val Loss: 0.4914
Epoch [96/120], Loss: 0.1491, Val Loss: 0.5014
Epoch [97/120], Loss: 0.1961, Val Loss: 0.4731
Epoch [98/120], Loss: 0.0477, Val Loss: 0.4601
Epoch [99/120], Loss: 0.0752, Val Loss: 0.4348
Epoch [100/120], Loss: 0.0942, Val Loss: 0.5680
Epoch [101/120], Loss: 0.0904, Val Loss: 0.4449
Epoch [102/120], Loss: 0.1773, Val Loss: 0.4342
Epoch [103/120], Loss: 0.4138, Val Loss: 0.4949
Epoch [104/120], Loss: 0.3801, Val Loss: 0.4536
Epoch [105/120], Loss: 0.1151, Val Loss: 0.4508
Epoch [106/120], Loss: 0.0665, Val Loss: 0.5521
Epoch [107/120], Loss: 0.1433, Val Loss: 0.4584
Epoch [108/120], Loss: 0.2378, Val Loss: 0.4593
Epoch [109/120], Loss: 0.0985, Val Loss: 0.4756
Epoch [110/120], Loss: 0.0597, Val Loss: 0.4632
Epoch [111/120], Loss: 0.1526, Val Loss: 0.4498
Epoch [112/120], Loss: 0.1486, Val Loss: 0.4918
Epoch [113/120], Loss: 0.9756, Val Loss: 0.4905
Epoch [114/120], Loss: 0.5285, Val Loss: 0.4698
Epoch [115/120], Loss: 0.2087, Val Loss: 0.4952
Epoch [116/120], Loss: 0.6424, Val Loss: 0.4268
Epoch [117/120], Loss: 0.1379, Val Loss: 0.4528
Epoch [118/120], Loss: 0.1110, Val Loss: 0.5397
Epoch [119/120], Loss: 0.3990, Val Loss: 0.5146
Epoch [120/120], Loss: 0.1159, Val Loss: 0.4454
Runtime: 0:02:30.860232
R^2 Score: 0.9191
RMSE: 0.5572
MAE: 0.1783
MAPE: 14.81%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0009340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.8938, Val Loss: 1.0778
Epoch [2/120], Loss: 0.1674, Val Loss: 0.9002
Epoch [3/120], Loss: 0.4892, Val Loss: 0.8735
Epoch [4/120], Loss: 0.2128, Val Loss: 0.8082
Epoch [5/120], Loss: 1.0950, Val Loss: 0.7966
Epoch [6/120], Loss: 0.8332, Val Loss: 0.7147
Epoch [7/120], Loss: 1.1899, Val Loss: 0.7070
Epoch [8/120], Loss: 0.3007, Val Loss: 0.8031
Epoch [9/120], Loss: 0.3925, Val Loss: 0.7156
Epoch [10/120], Loss: 1.0675, Val Loss: 0.7918
Epoch [11/120], Loss: 0.2146, Val Loss: 0.6750
Epoch [12/120], Loss: 0.0954, Val Loss: 0.6615
Epoch [13/120], Loss: 0.7199, Val Loss: 0.6223
Epoch [14/120], Loss: 0.1098, Val Loss: 0.6291
Epoch [15/120], Loss: 0.3332, Val Loss: 0.6189
Epoch [16/120], Loss: 0.2251, Val Loss: 0.6665
Epoch [17/120], Loss: 0.0931, Val Loss: 0.5865
Epoch [18/120], Loss: 0.3769, Val Loss: 0.6168
Epoch [19/120], Loss: 0.4237, Val Loss: 0.5725
Epoch [20/120], Loss: 0.1334, Val Loss: 0.5954
Epoch [21/120], Loss: 0.1533, Val Loss: 0.6251
Epoch [22/120], Loss: 0.2646, Val Loss: 0.5727
Epoch [23/120], Loss: 0.2831, Val Loss: 0.6056
Epoch [24/120], Loss: 0.1234, Val Loss: 0.5832
Epoch [25/120], Loss: 0.0985, Val Loss: 0.5464
Epoch [26/120], Loss: 0.3041, Val Loss: 0.5293
Epoch [27/120], Loss: 0.2860, Val Loss: 0.6728
Epoch [28/120], Loss: 0.0734, Val Loss: 0.5915
Epoch [29/120], Loss: 0.4196, Val Loss: 0.5727
Epoch [30/120], Loss: 0.5283, Val Loss: 0.5434
Epoch [31/120], Loss: 1.5242, Val Loss: 0.5662
Epoch [32/120], Loss: 0.3520, Val Loss: 0.5075
Epoch [33/120], Loss: 0.1249, Val Loss: 0.5765
Epoch [34/120], Loss: 0.1210, Val Loss: 0.5582
Epoch [35/120], Loss: 0.0929, Val Loss: 0.5123
Epoch [36/120], Loss: 0.1150, Val Loss: 0.4981
Epoch [37/120], Loss: 0.6057, Val Loss: 0.5228
Epoch [38/120], Loss: 0.2155, Val Loss: 0.5571
Epoch [39/120], Loss: 0.0794, Val Loss: 0.5188
Epoch [40/120], Loss: 0.1632, Val Loss: 0.5644
Epoch [41/120], Loss: 0.3332, Val Loss: 0.5312
Epoch [42/120], Loss: 0.4028, Val Loss: 0.5022
Epoch [43/120], Loss: 0.4046, Val Loss: 0.5148
Epoch [44/120], Loss: 0.2315, Val Loss: 0.5114
Epoch [45/120], Loss: 0.1444, Val Loss: 0.4957
Epoch [46/120], Loss: 0.8702, Val Loss: 0.5268
Epoch [47/120], Loss: 0.1076, Val Loss: 0.5087
Epoch [48/120], Loss: 0.0763, Val Loss: 0.4905
Epoch [49/120], Loss: 0.1118, Val Loss: 0.5239
Epoch [50/120], Loss: 0.1020, Val Loss: 0.5750
Epoch [51/120], Loss: 0.3082, Val Loss: 0.4863
Epoch [52/120], Loss: 0.2871, Val Loss: 0.5113
Epoch [53/120], Loss: 0.2150, Val Loss: 0.5079
Epoch [54/120], Loss: 0.0650, Val Loss: 0.4650
Epoch [55/120], Loss: 0.9917, Val Loss: 0.4764
Epoch [56/120], Loss: 0.2020, Val Loss: 0.5218
Epoch [57/120], Loss: 0.2026, Val Loss: 0.5318
Epoch [58/120], Loss: 0.1669, Val Loss: 0.5160
Epoch [59/120], Loss: 0.0991, Val Loss: 0.5183
Epoch [60/120], Loss: 0.1121, Val Loss: 0.5242
Epoch [61/120], Loss: 0.0559, Val Loss: 0.5255
Epoch [62/120], Loss: 0.2742, Val Loss: 0.4942
Epoch [63/120], Loss: 0.4834, Val Loss: 0.5315
Epoch [64/120], Loss: 0.1513, Val Loss: 0.4838
Epoch [65/120], Loss: 0.1807, Val Loss: 0.4503
Epoch [66/120], Loss: 0.1468, Val Loss: 0.5600
Epoch [67/120], Loss: 0.1531, Val Loss: 0.5673
Epoch [68/120], Loss: 0.4019, Val Loss: 0.5243
Epoch [69/120], Loss: 0.1051, Val Loss: 0.4998
Epoch [70/120], Loss: 0.1818, Val Loss: 0.5618
Epoch [71/120], Loss: 0.0815, Val Loss: 0.4775
Epoch [72/120], Loss: 0.4471, Val Loss: 0.4957
Epoch [73/120], Loss: 0.1796, Val Loss: 0.4896
Epoch [74/120], Loss: 0.1282, Val Loss: 0.4610
Epoch [75/120], Loss: 0.4741, Val Loss: 0.4864
Epoch [76/120], Loss: 0.3366, Val Loss: 0.4692
Epoch [77/120], Loss: 0.0932, Val Loss: 0.4854
Epoch [78/120], Loss: 0.4476, Val Loss: 0.5263
Epoch [79/120], Loss: 0.0878, Val Loss: 0.4889
Epoch [80/120], Loss: 0.0608, Val Loss: 0.5515
Epoch [81/120], Loss: 0.1380, Val Loss: 0.5359
Epoch [82/120], Loss: 0.3547, Val Loss: 0.5036
Epoch [83/120], Loss: 0.2191, Val Loss: 0.4966
Epoch [84/120], Loss: 0.3526, Val Loss: 0.5223
Early stopping at epoch 84
Runtime: 0:01:46.321072
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0009340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2346, Val Loss: 0.5344
Epoch [2/120], Loss: 0.1776, Val Loss: 0.4665
Epoch [3/120], Loss: 0.4927, Val Loss: 0.4961
Epoch [4/120], Loss: 0.2660, Val Loss: 0.5637
Epoch [5/120], Loss: 0.2018, Val Loss: 0.4912
Epoch [6/120], Loss: 0.5315, Val Loss: 0.4777
Epoch [7/120], Loss: 0.3368, Val Loss: 0.4799
Epoch [8/120], Loss: 0.1260, Val Loss: 0.5036
Epoch [9/120], Loss: 0.5075, Val Loss: 0.4693
Epoch [10/120], Loss: 0.1675, Val Loss: 0.4832
Epoch [11/120], Loss: 0.0591, Val Loss: 0.4879
Epoch [12/120], Loss: 0.0999, Val Loss: 0.4976
Epoch [13/120], Loss: 0.1940, Val Loss: 0.5368
Epoch [14/120], Loss: 1.9037, Val Loss: 0.5405
Epoch [15/120], Loss: 0.1775, Val Loss: 0.5710
Epoch [16/120], Loss: 0.1414, Val Loss: 0.4678
Epoch [17/120], Loss: 0.1091, Val Loss: 0.5380
Epoch [18/120], Loss: 0.4046, Val Loss: 0.4980
Epoch [19/120], Loss: 0.6821, Val Loss: 0.5779
Epoch [20/120], Loss: 0.4916, Val Loss: 0.4789
Epoch [21/120], Loss: 0.0953, Val Loss: 0.4731
Epoch [22/120], Loss: 0.0954, Val Loss: 0.4803
Epoch [23/120], Loss: 0.0568, Val Loss: 0.4809
Epoch [24/120], Loss: 0.5748, Val Loss: 0.4718
Epoch [25/120], Loss: 0.1518, Val Loss: 0.4921
Epoch [26/120], Loss: 0.7753, Val Loss: 0.4929
Epoch [27/120], Loss: 0.0757, Val Loss: 0.4672
Epoch [28/120], Loss: 0.2823, Val Loss: 0.4702
Epoch [29/120], Loss: 0.0204, Val Loss: 0.4784
Epoch [30/120], Loss: 0.1014, Val Loss: 0.4808
Epoch [31/120], Loss: 0.2069, Val Loss: 0.5199
Epoch [32/120], Loss: 0.2445, Val Loss: 0.4719
Epoch [33/120], Loss: 0.0650, Val Loss: 0.4910
Epoch [34/120], Loss: 0.1988, Val Loss: 0.4568
Epoch [35/120], Loss: 0.1675, Val Loss: 0.4992
Epoch [36/120], Loss: 0.0806, Val Loss: 0.5017
Epoch [37/120], Loss: 0.1357, Val Loss: 0.4778
Epoch [38/120], Loss: 0.2080, Val Loss: 0.4613
Epoch [39/120], Loss: 0.1202, Val Loss: 0.4798
Epoch [40/120], Loss: 0.1070, Val Loss: 0.4787
Epoch [41/120], Loss: 0.1459, Val Loss: 0.4925
Epoch [42/120], Loss: 0.0871, Val Loss: 0.4721
Epoch [43/120], Loss: 0.2849, Val Loss: 0.4699
Epoch [44/120], Loss: 0.2230, Val Loss: 0.4661
Epoch [45/120], Loss: 0.4894, Val Loss: 0.4715
Epoch [46/120], Loss: 0.2336, Val Loss: 0.4747
Epoch [47/120], Loss: 0.0931, Val Loss: 0.4849
Epoch [48/120], Loss: 0.1049, Val Loss: 0.4808
Epoch [49/120], Loss: 0.3143, Val Loss: 0.4682
Epoch [50/120], Loss: 0.3931, Val Loss: 0.5260
Epoch [51/120], Loss: 0.1575, Val Loss: 0.4978
Epoch [52/120], Loss: 0.1841, Val Loss: 0.5177
Epoch [53/120], Loss: 0.0569, Val Loss: 0.4797
Epoch [54/120], Loss: 0.1516, Val Loss: 0.5315
Epoch [55/120], Loss: 0.0736, Val Loss: 0.4812
Epoch [56/120], Loss: 0.0622, Val Loss: 0.5035
Epoch [57/120], Loss: 0.3043, Val Loss: 0.4425
Epoch [58/120], Loss: 0.1068, Val Loss: 0.4894
Epoch [59/120], Loss: 0.4705, Val Loss: 0.4899
Epoch [60/120], Loss: 0.0735, Val Loss: 0.4845
Epoch [61/120], Loss: 0.0816, Val Loss: 0.4640
Epoch [62/120], Loss: 0.2915, Val Loss: 0.4595
Epoch [63/120], Loss: 0.0647, Val Loss: 0.4324
Epoch [64/120], Loss: 0.1132, Val Loss: 0.4760
Epoch [65/120], Loss: 0.5326, Val Loss: 0.5102
Epoch [66/120], Loss: 0.3108, Val Loss: 0.4638
Epoch [67/120], Loss: 0.1643, Val Loss: 0.4553
Epoch [68/120], Loss: 0.0922, Val Loss: 0.4851
Epoch [69/120], Loss: 0.0595, Val Loss: 0.4654
Epoch [70/120], Loss: 0.0769, Val Loss: 0.5117
Epoch [71/120], Loss: 0.2449, Val Loss: 0.4775
Epoch [72/120], Loss: 0.2079, Val Loss: 0.4646
Epoch [73/120], Loss: 0.2426, Val Loss: 0.4720
Epoch [74/120], Loss: 0.0759, Val Loss: 0.5066
Epoch [75/120], Loss: 0.2247, Val Loss: 0.5900
Epoch [76/120], Loss: 0.0336, Val Loss: 0.5611
Epoch [77/120], Loss: 0.0525, Val Loss: 0.4571
Epoch [78/120], Loss: 0.0941, Val Loss: 0.5196
Epoch [79/120], Loss: 0.5230, Val Loss: 0.4665
Epoch [80/120], Loss: 0.1283, Val Loss: 0.4626
Epoch [81/120], Loss: 0.2440, Val Loss: 0.4747
Epoch [82/120], Loss: 0.0818, Val Loss: 0.4724
Early stopping at epoch 82
Runtime: 0:01:43.605112
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0009340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0445, Val Loss: 0.4596
Epoch [2/120], Loss: 0.0585, Val Loss: 0.5486
Epoch [3/120], Loss: 0.1847, Val Loss: 0.4745
Epoch [4/120], Loss: 0.1097, Val Loss: 0.4914
Epoch [5/120], Loss: 0.2088, Val Loss: 0.4697
Epoch [6/120], Loss: 0.0543, Val Loss: 0.4695
Epoch [7/120], Loss: 0.2986, Val Loss: 0.4619
Epoch [8/120], Loss: 0.3240, Val Loss: 0.4865
Epoch [9/120], Loss: 0.4192, Val Loss: 0.4502
Epoch [10/120], Loss: 0.0798, Val Loss: 0.4763
Epoch [11/120], Loss: 0.1663, Val Loss: 0.4924
Epoch [12/120], Loss: 0.1601, Val Loss: 0.5263
Epoch [13/120], Loss: 0.0945, Val Loss: 0.4757
Epoch [14/120], Loss: 0.0961, Val Loss: 0.4584
Epoch [15/120], Loss: 0.3514, Val Loss: 0.4946
Epoch [16/120], Loss: 0.1851, Val Loss: 0.4739
Epoch [17/120], Loss: 0.1548, Val Loss: 0.4956
Epoch [18/120], Loss: 0.0790, Val Loss: 0.4803
Epoch [19/120], Loss: 0.2713, Val Loss: 0.4616
Epoch [20/120], Loss: 0.6374, Val Loss: 0.4517
Epoch [21/120], Loss: 0.4150, Val Loss: 0.4900
Epoch [22/120], Loss: 0.2040, Val Loss: 0.4531
Epoch [23/120], Loss: 0.0240, Val Loss: 0.4659
Epoch [24/120], Loss: 0.0550, Val Loss: 0.4861
Epoch [25/120], Loss: 0.0525, Val Loss: 0.4628
Epoch [26/120], Loss: 0.0903, Val Loss: 0.4736
Epoch [27/120], Loss: 0.4624, Val Loss: 0.4693
Epoch [28/120], Loss: 0.2286, Val Loss: 0.4522
Epoch [29/120], Loss: 0.0625, Val Loss: 0.4659
Epoch [30/120], Loss: 0.1280, Val Loss: 0.4760
Epoch [31/120], Loss: 0.2049, Val Loss: 0.4622
Epoch [32/120], Loss: 0.0835, Val Loss: 0.4943
Epoch [33/120], Loss: 0.2540, Val Loss: 0.4602
Epoch [34/120], Loss: 0.2600, Val Loss: 0.4725
Epoch [35/120], Loss: 0.0770, Val Loss: 0.4471
Epoch [36/120], Loss: 0.0799, Val Loss: 0.4813
Epoch [37/120], Loss: 0.0602, Val Loss: 0.4478
Epoch [38/120], Loss: 0.1852, Val Loss: 0.4702
Epoch [39/120], Loss: 0.0514, Val Loss: 0.5113
Epoch [40/120], Loss: 0.0410, Val Loss: 0.4638
Epoch [41/120], Loss: 0.0709, Val Loss: 0.4690
Epoch [42/120], Loss: 0.1093, Val Loss: 0.4690
Epoch [43/120], Loss: 0.2046, Val Loss: 0.4747
Epoch [44/120], Loss: 0.0470, Val Loss: 0.4691
Epoch [45/120], Loss: 0.2922, Val Loss: 0.4615
Epoch [46/120], Loss: 0.0499, Val Loss: 0.4532
Epoch [47/120], Loss: 0.0468, Val Loss: 0.4618
Epoch [48/120], Loss: 0.5828, Val Loss: 0.4672
Epoch [49/120], Loss: 0.0984, Val Loss: 0.4685
Epoch [50/120], Loss: 0.4916, Val Loss: 0.4555
Epoch [51/120], Loss: 0.1011, Val Loss: 0.4553
Epoch [52/120], Loss: 0.2065, Val Loss: 0.4868
Epoch [53/120], Loss: 0.1795, Val Loss: 0.4809
Epoch [54/120], Loss: 0.1609, Val Loss: 0.4885
Epoch [55/120], Loss: 0.1555, Val Loss: 0.4897
Epoch [56/120], Loss: 0.3569, Val Loss: 0.4597
Early stopping at epoch 56
Runtime: 0:01:11.387938
R^2 Score: 0.8992
RMSE: 0.6220
MAE: 0.1832
MAPE: 14.48%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.001340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.4030, Val Loss: 1.1314
Epoch [2/120], Loss: 0.2412, Val Loss: 0.8633
Epoch [3/120], Loss: 0.2795, Val Loss: 0.8385
Epoch [4/120], Loss: 0.1711, Val Loss: 0.7900
Epoch [5/120], Loss: 0.3815, Val Loss: 0.7873
Epoch [6/120], Loss: 0.4260, Val Loss: 0.7787
Epoch [7/120], Loss: 0.6011, Val Loss: 0.7289
Epoch [8/120], Loss: 0.5277, Val Loss: 0.6855
Epoch [9/120], Loss: 0.0956, Val Loss: 0.6806
Epoch [10/120], Loss: 0.3152, Val Loss: 0.6834
Epoch [11/120], Loss: 0.1816, Val Loss: 0.6652
Epoch [12/120], Loss: 0.2865, Val Loss: 0.6505
Epoch [13/120], Loss: 1.7943, Val Loss: 0.6542
Epoch [14/120], Loss: 0.3465, Val Loss: 0.6282
Epoch [15/120], Loss: 0.4169, Val Loss: 0.6202
Epoch [16/120], Loss: 1.4805, Val Loss: 0.6227
Epoch [17/120], Loss: 0.1150, Val Loss: 0.5795
Epoch [18/120], Loss: 0.3736, Val Loss: 0.6303
Epoch [19/120], Loss: 0.1767, Val Loss: 0.5587
Epoch [20/120], Loss: 0.3579, Val Loss: 0.6185
Epoch [21/120], Loss: 1.0649, Val Loss: 0.5586
Epoch [22/120], Loss: 1.7854, Val Loss: 0.5897
Epoch [23/120], Loss: 0.1667, Val Loss: 0.5911
Epoch [24/120], Loss: 0.1539, Val Loss: 0.5469
Epoch [25/120], Loss: 0.0930, Val Loss: 0.5138
Epoch [26/120], Loss: 0.1366, Val Loss: 0.4972
Epoch [27/120], Loss: 0.0804, Val Loss: 0.5393
Epoch [28/120], Loss: 0.2613, Val Loss: 0.5584
Epoch [29/120], Loss: 0.2816, Val Loss: 0.4893
Epoch [30/120], Loss: 0.2721, Val Loss: 0.5132
Epoch [31/120], Loss: 0.6773, Val Loss: 0.4886
Epoch [32/120], Loss: 0.0936, Val Loss: 0.5275
Epoch [33/120], Loss: 0.0944, Val Loss: 0.5490
Epoch [34/120], Loss: 0.1239, Val Loss: 0.5011
Epoch [35/120], Loss: 0.2887, Val Loss: 0.5401
Epoch [36/120], Loss: 0.0545, Val Loss: 0.5072
Epoch [37/120], Loss: 0.4177, Val Loss: 0.6291
Epoch [38/120], Loss: 0.0858, Val Loss: 0.5098
Epoch [39/120], Loss: 0.5216, Val Loss: 0.5296
Epoch [40/120], Loss: 0.3079, Val Loss: 0.5103
Epoch [41/120], Loss: 0.1032, Val Loss: 0.5280
Epoch [42/120], Loss: 0.3758, Val Loss: 0.5327
Epoch [43/120], Loss: 0.0934, Val Loss: 0.5321
Epoch [44/120], Loss: 0.0696, Val Loss: 0.4809
Epoch [45/120], Loss: 0.0808, Val Loss: 0.5105
Epoch [46/120], Loss: 0.1623, Val Loss: 0.5214
Epoch [47/120], Loss: 0.5656, Val Loss: 0.5987
Epoch [48/120], Loss: 0.1717, Val Loss: 0.5066
Epoch [49/120], Loss: 0.1422, Val Loss: 0.5299
Epoch [50/120], Loss: 0.1164, Val Loss: 0.5947
Epoch [51/120], Loss: 0.2095, Val Loss: 0.5315
Epoch [52/120], Loss: 0.1276, Val Loss: 0.4680
Epoch [53/120], Loss: 0.0428, Val Loss: 0.5159
Epoch [54/120], Loss: 0.8899, Val Loss: 0.4969
Epoch [55/120], Loss: 0.6786, Val Loss: 0.4954
Epoch [56/120], Loss: 0.5418, Val Loss: 0.4737
Epoch [57/120], Loss: 0.3186, Val Loss: 0.4745
Epoch [58/120], Loss: 0.1692, Val Loss: 0.4870
Epoch [59/120], Loss: 0.1816, Val Loss: 0.4959
Epoch [60/120], Loss: 0.3307, Val Loss: 0.6144
Epoch [61/120], Loss: 0.1092, Val Loss: 0.4933
Epoch [62/120], Loss: 0.5722, Val Loss: 0.4630
Epoch [63/120], Loss: 0.3556, Val Loss: 0.5398
Epoch [64/120], Loss: 0.1726, Val Loss: 0.4673
Epoch [65/120], Loss: 0.3924, Val Loss: 0.5073
Epoch [66/120], Loss: 0.3709, Val Loss: 0.5026
Epoch [67/120], Loss: 0.2542, Val Loss: 0.5031
Epoch [68/120], Loss: 0.2335, Val Loss: 0.4588
Epoch [69/120], Loss: 0.2466, Val Loss: 0.4860
Epoch [70/120], Loss: 0.6118, Val Loss: 0.5610
Epoch [71/120], Loss: 0.2691, Val Loss: 0.4660
Epoch [72/120], Loss: 0.0991, Val Loss: 0.4984
Epoch [73/120], Loss: 0.2798, Val Loss: 0.5158
Epoch [74/120], Loss: 0.1349, Val Loss: 0.5366
Epoch [75/120], Loss: 0.1601, Val Loss: 0.4687
Epoch [76/120], Loss: 0.1305, Val Loss: 0.4892
Epoch [77/120], Loss: 0.0519, Val Loss: 0.4830
Epoch [78/120], Loss: 0.0673, Val Loss: 0.4904
Epoch [79/120], Loss: 0.0802, Val Loss: 0.4353
Epoch [80/120], Loss: 0.0698, Val Loss: 0.4889
Epoch [81/120], Loss: 0.0455, Val Loss: 0.5003
Epoch [82/120], Loss: 0.1652, Val Loss: 0.5048
Epoch [83/120], Loss: 0.8544, Val Loss: 0.5311
Epoch [84/120], Loss: 0.2161, Val Loss: 0.4577
Epoch [85/120], Loss: 0.1543, Val Loss: 0.5812
Epoch [86/120], Loss: 0.1690, Val Loss: 0.4638
Epoch [87/120], Loss: 0.3712, Val Loss: 0.5551
Epoch [88/120], Loss: 0.1578, Val Loss: 0.4739
Epoch [89/120], Loss: 0.1015, Val Loss: 0.4540
Epoch [90/120], Loss: 0.0808, Val Loss: 0.4961
Epoch [91/120], Loss: 0.2357, Val Loss: 0.5247
Epoch [92/120], Loss: 0.2429, Val Loss: 0.5300
Epoch [93/120], Loss: 0.0753, Val Loss: 0.5289
Epoch [94/120], Loss: 0.3003, Val Loss: 0.5561
Epoch [95/120], Loss: 0.3761, Val Loss: 0.4893
Epoch [96/120], Loss: 0.2805, Val Loss: 0.4784
Epoch [97/120], Loss: 0.0781, Val Loss: 0.4302
Epoch [98/120], Loss: 0.1022, Val Loss: 0.4525
Epoch [99/120], Loss: 0.1274, Val Loss: 0.4718
Epoch [100/120], Loss: 0.2509, Val Loss: 0.5045
Epoch [101/120], Loss: 0.1493, Val Loss: 0.4915
Epoch [102/120], Loss: 0.0879, Val Loss: 0.4705
Epoch [103/120], Loss: 0.1244, Val Loss: 0.4523
Epoch [104/120], Loss: 0.3506, Val Loss: 0.4714
Epoch [105/120], Loss: 0.9157, Val Loss: 0.4908
Epoch [106/120], Loss: 0.2300, Val Loss: 0.4910
Epoch [107/120], Loss: 0.0813, Val Loss: 0.4609
Epoch [108/120], Loss: 0.2979, Val Loss: 0.4700
Epoch [109/120], Loss: 0.0979, Val Loss: 0.4606
Epoch [110/120], Loss: 2.1328, Val Loss: 0.4594
Epoch [111/120], Loss: 1.1871, Val Loss: 0.5385
Epoch [112/120], Loss: 0.2993, Val Loss: 0.5712
Epoch [113/120], Loss: 1.8683, Val Loss: 0.5067
Epoch [114/120], Loss: 0.1371, Val Loss: 0.4702
Epoch [115/120], Loss: 0.0354, Val Loss: 0.4826
Epoch [116/120], Loss: 0.2614, Val Loss: 0.4775
Early stopping at epoch 116
Runtime: 0:02:27.394965
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.001340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1903, Val Loss: 0.4716
Epoch [2/120], Loss: 0.1094, Val Loss: 0.4462
Epoch [3/120], Loss: 1.0007, Val Loss: 0.4500
Epoch [4/120], Loss: 0.1407, Val Loss: 0.4937
Epoch [5/120], Loss: 0.1742, Val Loss: 0.4729
Epoch [6/120], Loss: 0.1345, Val Loss: 0.4667
Epoch [7/120], Loss: 0.4360, Val Loss: 0.4818
Epoch [8/120], Loss: 0.0907, Val Loss: 0.4651
Epoch [9/120], Loss: 0.0528, Val Loss: 0.4764
Epoch [10/120], Loss: 0.1567, Val Loss: 0.5035
Epoch [11/120], Loss: 0.1276, Val Loss: 0.4722
Epoch [12/120], Loss: 0.1005, Val Loss: 0.5075
Epoch [13/120], Loss: 0.0950, Val Loss: 0.5015
Epoch [14/120], Loss: 0.1870, Val Loss: 0.5114
Epoch [15/120], Loss: 0.2669, Val Loss: 0.5411
Epoch [16/120], Loss: 0.0879, Val Loss: 0.5161
Epoch [17/120], Loss: 0.0653, Val Loss: 0.4798
Epoch [18/120], Loss: 0.1446, Val Loss: 0.5639
Epoch [19/120], Loss: 0.1232, Val Loss: 0.4487
Epoch [20/120], Loss: 0.2063, Val Loss: 0.4784
Epoch [21/120], Loss: 0.0656, Val Loss: 0.4788
Epoch [22/120], Loss: 0.2019, Val Loss: 0.5270
Epoch [23/120], Loss: 0.0812, Val Loss: 0.4439
Epoch [24/120], Loss: 0.2760, Val Loss: 0.4657
Epoch [25/120], Loss: 0.2890, Val Loss: 0.4719
Epoch [26/120], Loss: 0.2414, Val Loss: 0.5105
Epoch [27/120], Loss: 0.0527, Val Loss: 0.4762
Epoch [28/120], Loss: 0.1988, Val Loss: 0.4659
Epoch [29/120], Loss: 0.1378, Val Loss: 0.4706
Epoch [30/120], Loss: 0.1073, Val Loss: 0.4726
Epoch [31/120], Loss: 0.0831, Val Loss: 0.5328
Epoch [32/120], Loss: 0.0711, Val Loss: 0.4932
Epoch [33/120], Loss: 0.1353, Val Loss: 0.4852
Epoch [34/120], Loss: 0.1295, Val Loss: 0.5300
Epoch [35/120], Loss: 0.6081, Val Loss: 0.4840
Epoch [36/120], Loss: 0.3261, Val Loss: 0.4635
Epoch [37/120], Loss: 0.0721, Val Loss: 0.4677
Epoch [38/120], Loss: 0.1250, Val Loss: 0.4644
Epoch [39/120], Loss: 0.2115, Val Loss: 0.5582
Epoch [40/120], Loss: 0.0640, Val Loss: 0.4840
Epoch [41/120], Loss: 0.1080, Val Loss: 0.5424
Epoch [42/120], Loss: 0.1083, Val Loss: 0.4964
Early stopping at epoch 42
Runtime: 0:00:54.444152
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.001340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1264, Val Loss: 0.4523
Epoch [2/120], Loss: 0.2659, Val Loss: 0.4888
Epoch [3/120], Loss: 0.1669, Val Loss: 0.5191
Epoch [4/120], Loss: 0.3474, Val Loss: 0.4913
Epoch [5/120], Loss: 0.3435, Val Loss: 0.4895
Epoch [6/120], Loss: 0.0716, Val Loss: 0.4752
Epoch [7/120], Loss: 0.0788, Val Loss: 0.4891
Epoch [8/120], Loss: 0.0882, Val Loss: 0.4561
Epoch [9/120], Loss: 0.0585, Val Loss: 0.4525
Epoch [10/120], Loss: 0.2512, Val Loss: 0.4444
Epoch [11/120], Loss: 0.1314, Val Loss: 0.4706
Epoch [12/120], Loss: 0.0628, Val Loss: 0.4512
Epoch [13/120], Loss: 0.1996, Val Loss: 0.4625
Epoch [14/120], Loss: 0.3810, Val Loss: 0.4807
Epoch [15/120], Loss: 0.1046, Val Loss: 0.5016
Epoch [16/120], Loss: 0.1043, Val Loss: 0.5177
Epoch [17/120], Loss: 0.2140, Val Loss: 0.5090
Epoch [18/120], Loss: 0.1964, Val Loss: 0.4631
Epoch [19/120], Loss: 0.2335, Val Loss: 0.4836
Epoch [20/120], Loss: 0.0666, Val Loss: 0.4496
Epoch [21/120], Loss: 0.1289, Val Loss: 0.4441
Epoch [22/120], Loss: 0.2267, Val Loss: 0.4454
Epoch [23/120], Loss: 0.0465, Val Loss: 0.4745
Epoch [24/120], Loss: 0.1364, Val Loss: 0.4624
Epoch [25/120], Loss: 0.1392, Val Loss: 0.4909
Epoch [26/120], Loss: 0.5091, Val Loss: 0.4559
Epoch [27/120], Loss: 0.1465, Val Loss: 0.4533
Epoch [28/120], Loss: 0.0553, Val Loss: 0.4265
Epoch [29/120], Loss: 0.1680, Val Loss: 0.4417
Epoch [30/120], Loss: 0.1020, Val Loss: 0.4774
Epoch [31/120], Loss: 0.2184, Val Loss: 0.4494
Epoch [32/120], Loss: 0.0616, Val Loss: 0.4745
Epoch [33/120], Loss: 0.0331, Val Loss: 0.4450
Epoch [34/120], Loss: 0.1082, Val Loss: 0.5447
Epoch [35/120], Loss: 0.1214, Val Loss: 0.4424
Epoch [36/120], Loss: 0.1315, Val Loss: 0.4458
Epoch [37/120], Loss: 0.0278, Val Loss: 0.4508
Epoch [38/120], Loss: 0.1158, Val Loss: 0.4579
Epoch [39/120], Loss: 0.1178, Val Loss: 0.4658
Epoch [40/120], Loss: 0.0690, Val Loss: 0.4818
Epoch [41/120], Loss: 0.8671, Val Loss: 0.4334
Epoch [42/120], Loss: 0.0607, Val Loss: 0.5538
Epoch [43/120], Loss: 0.2287, Val Loss: 0.4724
Epoch [44/120], Loss: 0.0612, Val Loss: 0.4336
Epoch [45/120], Loss: 0.0839, Val Loss: 0.4701
Epoch [46/120], Loss: 0.0777, Val Loss: 0.4677
Epoch [47/120], Loss: 0.1620, Val Loss: 0.4500
Early stopping at epoch 47
Runtime: 0:00:59.964514
R^2 Score: 0.9194
RMSE: 0.5562
MAE: 0.1756
MAPE: 14.50%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.5209, Val Loss: 0.9644
Epoch [2/120], Loss: 0.2658, Val Loss: 0.8820
Epoch [3/120], Loss: 0.1687, Val Loss: 0.8187
Epoch [4/120], Loss: 0.4343, Val Loss: 0.7503
Epoch [5/120], Loss: 0.3486, Val Loss: 0.8299
Epoch [6/120], Loss: 0.8127, Val Loss: 0.7204
Epoch [7/120], Loss: 0.1780, Val Loss: 0.6877
Epoch [8/120], Loss: 0.0716, Val Loss: 0.7154
Epoch [9/120], Loss: 1.2060, Val Loss: 0.6567
Epoch [10/120], Loss: 0.1477, Val Loss: 0.6986
Epoch [11/120], Loss: 0.3009, Val Loss: 0.7040
Epoch [12/120], Loss: 0.8700, Val Loss: 0.6643
Epoch [13/120], Loss: 0.1705, Val Loss: 0.6656
Epoch [14/120], Loss: 0.2082, Val Loss: 0.6130
Epoch [15/120], Loss: 0.1143, Val Loss: 0.6359
Epoch [16/120], Loss: 0.0980, Val Loss: 0.6333
Epoch [17/120], Loss: 0.6347, Val Loss: 0.6227
Epoch [18/120], Loss: 0.4380, Val Loss: 0.5814
Epoch [19/120], Loss: 0.3319, Val Loss: 0.6931
Epoch [20/120], Loss: 0.3510, Val Loss: 0.5817
Epoch [21/120], Loss: 0.1237, Val Loss: 0.5634
Epoch [22/120], Loss: 0.1232, Val Loss: 0.5280
Epoch [23/120], Loss: 0.2397, Val Loss: 0.6280
Epoch [24/120], Loss: 0.1438, Val Loss: 0.5682
Epoch [25/120], Loss: 0.1520, Val Loss: 0.6866
Epoch [26/120], Loss: 0.2282, Val Loss: 0.5693
Epoch [27/120], Loss: 0.1861, Val Loss: 0.5645
Epoch [28/120], Loss: 0.4022, Val Loss: 0.5416
Epoch [29/120], Loss: 0.4207, Val Loss: 0.5409
Epoch [30/120], Loss: 0.2234, Val Loss: 0.5398
Epoch [31/120], Loss: 0.5223, Val Loss: 0.5444
Epoch [32/120], Loss: 0.1421, Val Loss: 0.5161
Epoch [33/120], Loss: 0.8710, Val Loss: 0.5219
Epoch [34/120], Loss: 0.1136, Val Loss: 0.5746
Epoch [35/120], Loss: 0.1420, Val Loss: 0.4911
Epoch [36/120], Loss: 0.0738, Val Loss: 0.5109
Epoch [37/120], Loss: 0.8117, Val Loss: 0.5191
Epoch [38/120], Loss: 0.1654, Val Loss: 0.5786
Epoch [39/120], Loss: 0.5124, Val Loss: 0.5808
Epoch [40/120], Loss: 0.5662, Val Loss: 0.4786
Epoch [41/120], Loss: 0.2172, Val Loss: 0.9074
Epoch [42/120], Loss: 0.4139, Val Loss: 0.5127
Epoch [43/120], Loss: 0.1657, Val Loss: 0.5613
Epoch [44/120], Loss: 0.5058, Val Loss: 0.4782
Epoch [45/120], Loss: 0.2173, Val Loss: 0.5177
Epoch [46/120], Loss: 0.2558, Val Loss: 0.5266
Epoch [47/120], Loss: 0.0708, Val Loss: 0.5355
Epoch [48/120], Loss: 0.0636, Val Loss: 0.4762
Epoch [49/120], Loss: 0.1149, Val Loss: 0.5376
Epoch [50/120], Loss: 0.1497, Val Loss: 0.4944
Epoch [51/120], Loss: 0.1445, Val Loss: 0.4745
Epoch [52/120], Loss: 0.0725, Val Loss: 0.4968
Epoch [53/120], Loss: 0.1710, Val Loss: 0.5314
Epoch [54/120], Loss: 0.4285, Val Loss: 0.4800
Epoch [55/120], Loss: 0.0764, Val Loss: 0.5183
Epoch [56/120], Loss: 0.0972, Val Loss: 0.5280
Epoch [57/120], Loss: 0.1560, Val Loss: 0.5191
Epoch [58/120], Loss: 0.2739, Val Loss: 0.5002
Epoch [59/120], Loss: 0.6129, Val Loss: 0.4803
Epoch [60/120], Loss: 0.1267, Val Loss: 0.4979
Epoch [61/120], Loss: 0.1979, Val Loss: 0.5237
Epoch [62/120], Loss: 0.0561, Val Loss: 0.4856
Epoch [63/120], Loss: 0.0863, Val Loss: 0.4960
Epoch [64/120], Loss: 0.3595, Val Loss: 0.4859
Epoch [65/120], Loss: 0.2195, Val Loss: 0.5394
Epoch [66/120], Loss: 0.2301, Val Loss: 0.5233
Epoch [67/120], Loss: 0.1381, Val Loss: 0.4921
Epoch [68/120], Loss: 0.4558, Val Loss: 0.4367
Epoch [69/120], Loss: 0.2543, Val Loss: 0.5297
Epoch [70/120], Loss: 0.3674, Val Loss: 0.5309
Epoch [71/120], Loss: 0.1627, Val Loss: 0.4646
Epoch [72/120], Loss: 0.0865, Val Loss: 0.5022
Epoch [73/120], Loss: 0.3028, Val Loss: 0.4708
Epoch [74/120], Loss: 0.1114, Val Loss: 0.4525
Epoch [75/120], Loss: 0.1210, Val Loss: 0.5055
Epoch [76/120], Loss: 0.1158, Val Loss: 0.5140
Epoch [77/120], Loss: 0.3459, Val Loss: 0.4746
Epoch [78/120], Loss: 0.1118, Val Loss: 0.4407
Epoch [79/120], Loss: 0.1415, Val Loss: 0.4795
Epoch [80/120], Loss: 0.2209, Val Loss: 0.5285
Epoch [81/120], Loss: 0.2197, Val Loss: 0.5048
Epoch [82/120], Loss: 0.1046, Val Loss: 0.5420
Epoch [83/120], Loss: 0.1411, Val Loss: 0.4697
Epoch [84/120], Loss: 0.6597, Val Loss: 0.5669
Epoch [85/120], Loss: 1.0526, Val Loss: 0.4527
Epoch [86/120], Loss: 0.2391, Val Loss: 0.4812
Epoch [87/120], Loss: 0.1696, Val Loss: 0.4742
Epoch [88/120], Loss: 0.2192, Val Loss: 0.4624
Epoch [89/120], Loss: 0.1137, Val Loss: 0.5475
Epoch [90/120], Loss: 0.0762, Val Loss: 0.4598
Epoch [91/120], Loss: 0.2784, Val Loss: 0.5519
Epoch [92/120], Loss: 0.0706, Val Loss: 0.4397
Epoch [93/120], Loss: 0.0934, Val Loss: 0.5227
Epoch [94/120], Loss: 0.2517, Val Loss: 0.4762
Epoch [95/120], Loss: 0.1046, Val Loss: 0.5062
Epoch [96/120], Loss: 0.1793, Val Loss: 0.5179
Epoch [97/120], Loss: 0.2081, Val Loss: 0.4819
Epoch [98/120], Loss: 0.2856, Val Loss: 0.4858
Epoch [99/120], Loss: 0.1190, Val Loss: 0.4861
Epoch [100/120], Loss: 0.1050, Val Loss: 0.5450
Epoch [101/120], Loss: 0.3245, Val Loss: 0.4487
Epoch [102/120], Loss: 0.4822, Val Loss: 0.4633
Epoch [103/120], Loss: 0.9926, Val Loss: 0.6236
Epoch [104/120], Loss: 0.0981, Val Loss: 0.4731
Epoch [105/120], Loss: 0.2299, Val Loss: 0.4541
Epoch [106/120], Loss: 0.3305, Val Loss: 0.4824
Epoch [107/120], Loss: 1.5650, Val Loss: 0.4732
Epoch [108/120], Loss: 0.0513, Val Loss: 0.4798
Epoch [109/120], Loss: 0.3916, Val Loss: 0.4640
Epoch [110/120], Loss: 0.2761, Val Loss: 0.5460
Epoch [111/120], Loss: 0.3861, Val Loss: 0.5122
Early stopping at epoch 111
Runtime: 0:02:21.411136
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.3013, Val Loss: 0.5187
Epoch [2/120], Loss: 0.1054, Val Loss: 0.4999
Epoch [3/120], Loss: 0.1314, Val Loss: 0.5143
Epoch [4/120], Loss: 0.1654, Val Loss: 0.4782
Epoch [5/120], Loss: 0.0910, Val Loss: 0.4694
Epoch [6/120], Loss: 0.3485, Val Loss: 0.4667
Epoch [7/120], Loss: 0.2259, Val Loss: 0.4681
Epoch [8/120], Loss: 0.1295, Val Loss: 0.4845
Epoch [9/120], Loss: 0.0811, Val Loss: 0.4609
Epoch [10/120], Loss: 0.2419, Val Loss: 0.4636
Epoch [11/120], Loss: 0.1335, Val Loss: 0.4270
Epoch [12/120], Loss: 0.0576, Val Loss: 0.4963
Epoch [13/120], Loss: 0.1853, Val Loss: 0.4482
Epoch [14/120], Loss: 0.3585, Val Loss: 0.4470
Epoch [15/120], Loss: 0.0640, Val Loss: 0.4615
Epoch [16/120], Loss: 0.1364, Val Loss: 0.4372
Epoch [17/120], Loss: 0.4581, Val Loss: 0.4552
Epoch [18/120], Loss: 0.1242, Val Loss: 0.4962
Epoch [19/120], Loss: 0.0783, Val Loss: 0.5344
Epoch [20/120], Loss: 0.9995, Val Loss: 0.4610
Epoch [21/120], Loss: 0.2403, Val Loss: 0.4584
Epoch [22/120], Loss: 0.0840, Val Loss: 0.4615
Epoch [23/120], Loss: 0.5046, Val Loss: 0.5387
Epoch [24/120], Loss: 0.0728, Val Loss: 0.4609
Epoch [25/120], Loss: 1.0820, Val Loss: 0.5298
Epoch [26/120], Loss: 0.1818, Val Loss: 0.4927
Epoch [27/120], Loss: 0.4256, Val Loss: 0.4624
Epoch [28/120], Loss: 0.0752, Val Loss: 0.4576
Epoch [29/120], Loss: 0.2192, Val Loss: 0.5580
Epoch [30/120], Loss: 0.0703, Val Loss: 0.5023
Early stopping at epoch 30
Runtime: 0:00:41.047177
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0029340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2536, Val Loss: 0.9501
Epoch [2/120], Loss: 1.2236, Val Loss: 0.9217
Epoch [3/120], Loss: 2.5148, Val Loss: 0.7580
Epoch [4/120], Loss: 0.2479, Val Loss: 0.8551
Epoch [5/120], Loss: 0.3655, Val Loss: 0.7724
Epoch [6/120], Loss: 0.1672, Val Loss: 0.7293
Epoch [7/120], Loss: 0.1124, Val Loss: 0.7006
Epoch [8/120], Loss: 0.1164, Val Loss: 0.7165
Epoch [9/120], Loss: 0.1300, Val Loss: 0.7121
Epoch [10/120], Loss: 0.1640, Val Loss: 0.5939
Epoch [11/120], Loss: 0.4792, Val Loss: 0.6630
Epoch [12/120], Loss: 0.4810, Val Loss: 0.7024
Epoch [13/120], Loss: 0.1705, Val Loss: 0.6847
Epoch [14/120], Loss: 0.2150, Val Loss: 0.6492
Epoch [15/120], Loss: 0.5563, Val Loss: 0.6341
Epoch [16/120], Loss: 0.1252, Val Loss: 0.5786
Epoch [17/120], Loss: 0.5959, Val Loss: 0.6210
Epoch [18/120], Loss: 0.1715, Val Loss: 0.6188
Epoch [19/120], Loss: 0.5057, Val Loss: 0.7638
Epoch [20/120], Loss: 0.1735, Val Loss: 0.5231
Epoch [21/120], Loss: 0.5271, Val Loss: 0.5676
Epoch [22/120], Loss: 0.5431, Val Loss: 0.5326
Epoch [23/120], Loss: 1.1020, Val Loss: 0.5821
Epoch [24/120], Loss: 0.2319, Val Loss: 0.5847
Epoch [25/120], Loss: 0.8389, Val Loss: 0.7503
Epoch [26/120], Loss: 0.0737, Val Loss: 0.6205
Epoch [27/120], Loss: 0.0776, Val Loss: 0.5558
Epoch [28/120], Loss: 0.1800, Val Loss: 0.5613
Epoch [29/120], Loss: 0.0989, Val Loss: 0.5834
Epoch [30/120], Loss: 0.3038, Val Loss: 0.5571
Epoch [31/120], Loss: 0.2379, Val Loss: 0.6154
Epoch [32/120], Loss: 0.6338, Val Loss: 0.5648
Epoch [33/120], Loss: 1.7483, Val Loss: 0.5745
Epoch [34/120], Loss: 0.2353, Val Loss: 0.6418
Epoch [35/120], Loss: 0.6644, Val Loss: 0.5817
Epoch [36/120], Loss: 0.1143, Val Loss: 0.6335
Epoch [37/120], Loss: 0.7061, Val Loss: 0.5671
Epoch [38/120], Loss: 0.2148, Val Loss: 0.6505
Epoch [39/120], Loss: 0.0797, Val Loss: 0.5617
Early stopping at epoch 39
Runtime: 0:00:49.609445
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.5166, Val Loss: 1.0179
Epoch [2/120], Loss: 2.9754, Val Loss: 0.9086
Epoch [3/120], Loss: 0.1312, Val Loss: 0.8792
Epoch [4/120], Loss: 0.1706, Val Loss: 0.7766
Epoch [5/120], Loss: 0.0821, Val Loss: 0.7878
Epoch [6/120], Loss: 0.3166, Val Loss: 0.8013
Epoch [7/120], Loss: 0.1736, Val Loss: 0.7224
Epoch [8/120], Loss: 0.4495, Val Loss: 0.7235
Epoch [9/120], Loss: 0.2033, Val Loss: 0.8243
Epoch [10/120], Loss: 0.1608, Val Loss: 0.6348
Epoch [11/120], Loss: 0.2659, Val Loss: 0.7632
Epoch [12/120], Loss: 0.4217, Val Loss: 0.6656
Epoch [13/120], Loss: 0.2233, Val Loss: 0.7198
Epoch [14/120], Loss: 0.6716, Val Loss: 0.6707
Epoch [15/120], Loss: 1.3932, Val Loss: 0.6539
Epoch [16/120], Loss: 0.1016, Val Loss: 0.5795
Epoch [17/120], Loss: 0.1459, Val Loss: 0.5837
Epoch [18/120], Loss: 0.2184, Val Loss: 0.5901
Epoch [19/120], Loss: 0.1281, Val Loss: 0.5885
Epoch [20/120], Loss: 0.0828, Val Loss: 0.6573
Epoch [21/120], Loss: 0.2782, Val Loss: 0.6476
Epoch [22/120], Loss: 0.2515, Val Loss: 0.5301
Epoch [23/120], Loss: 0.4082, Val Loss: 0.5483
Epoch [24/120], Loss: 0.3669, Val Loss: 0.5117
Epoch [25/120], Loss: 0.2340, Val Loss: 0.5006
Epoch [26/120], Loss: 0.1908, Val Loss: 0.5756
Epoch [27/120], Loss: 0.1177, Val Loss: 0.5746
Epoch [28/120], Loss: 0.2410, Val Loss: 0.5634
Epoch [29/120], Loss: 0.0930, Val Loss: 0.5430
Epoch [30/120], Loss: 0.2321, Val Loss: 0.5562
Epoch [31/120], Loss: 0.1168, Val Loss: 0.5282
Epoch [32/120], Loss: 0.1393, Val Loss: 0.5214
Epoch [33/120], Loss: 0.1090, Val Loss: 0.4924
Epoch [34/120], Loss: 0.1433, Val Loss: 0.5710
Epoch [35/120], Loss: 0.2001, Val Loss: 0.5928
Epoch [36/120], Loss: 0.3050, Val Loss: 0.5599
Epoch [37/120], Loss: 0.5351, Val Loss: 0.6226
Epoch [38/120], Loss: 0.3778, Val Loss: 0.5621
Epoch [39/120], Loss: 0.1294, Val Loss: 0.5411
Epoch [40/120], Loss: 0.2927, Val Loss: 0.4942
Epoch [41/120], Loss: 0.1104, Val Loss: 0.5595
Epoch [42/120], Loss: 0.1490, Val Loss: 0.4955
Epoch [43/120], Loss: 0.2206, Val Loss: 0.4884
Epoch [44/120], Loss: 0.1997, Val Loss: 0.4960
Epoch [45/120], Loss: 0.1158, Val Loss: 0.5516
Epoch [46/120], Loss: 0.1481, Val Loss: 0.5800
Epoch [47/120], Loss: 0.2207, Val Loss: 0.5921
Epoch [48/120], Loss: 0.1484, Val Loss: 0.5044
Epoch [49/120], Loss: 0.5620, Val Loss: 0.5003
Epoch [50/120], Loss: 0.0755, Val Loss: 0.5191
Epoch [51/120], Loss: 0.4168, Val Loss: 0.5526
Epoch [52/120], Loss: 0.4291, Val Loss: 0.5228
Epoch [53/120], Loss: 0.4962, Val Loss: 0.4953
Epoch [54/120], Loss: 1.0185, Val Loss: 0.5169
Epoch [55/120], Loss: 0.5205, Val Loss: 0.5809
Epoch [56/120], Loss: 0.1140, Val Loss: 0.5453
Epoch [57/120], Loss: 0.0532, Val Loss: 0.5248
Epoch [58/120], Loss: 0.1496, Val Loss: 0.5338
Epoch [59/120], Loss: 0.0780, Val Loss: 0.4920
Epoch [60/120], Loss: 0.1799, Val Loss: 0.4759
Epoch [61/120], Loss: 0.2313, Val Loss: 0.6733
Epoch [62/120], Loss: 0.6324, Val Loss: 0.5501
Epoch [63/120], Loss: 0.4159, Val Loss: 0.4920
Epoch [64/120], Loss: 0.8903, Val Loss: 0.4992
Epoch [65/120], Loss: 0.0887, Val Loss: 0.4872
Epoch [66/120], Loss: 0.7483, Val Loss: 0.5106
Epoch [67/120], Loss: 0.4866, Val Loss: 0.4944
Epoch [68/120], Loss: 0.1866, Val Loss: 0.4919
Epoch [69/120], Loss: 0.9744, Val Loss: 0.5441
Epoch [70/120], Loss: 0.1005, Val Loss: 0.5535
Epoch [71/120], Loss: 0.0482, Val Loss: 0.4960
Epoch [72/120], Loss: 0.1178, Val Loss: 0.6178
Epoch [73/120], Loss: 0.0871, Val Loss: 0.4920
Epoch [74/120], Loss: 0.2781, Val Loss: 0.5294
Epoch [75/120], Loss: 0.1411, Val Loss: 0.4601
Epoch [76/120], Loss: 0.1320, Val Loss: 0.5381
Epoch [77/120], Loss: 0.0443, Val Loss: 0.4819
Epoch [78/120], Loss: 0.0663, Val Loss: 0.6974
Epoch [79/120], Loss: 0.0542, Val Loss: 0.4601
Epoch [80/120], Loss: 0.4307, Val Loss: 0.4437
Epoch [81/120], Loss: 0.5259, Val Loss: 0.4592
Epoch [82/120], Loss: 0.1027, Val Loss: 0.4900
Epoch [83/120], Loss: 0.1524, Val Loss: 0.5181
Epoch [84/120], Loss: 0.0572, Val Loss: 0.4734
Epoch [85/120], Loss: 0.0991, Val Loss: 0.4791
Epoch [86/120], Loss: 0.2073, Val Loss: 0.4930
Epoch [87/120], Loss: 0.1687, Val Loss: 0.5370
Epoch [88/120], Loss: 0.1135, Val Loss: 0.4938
Epoch [89/120], Loss: 0.5424, Val Loss: 0.5034
Epoch [90/120], Loss: 0.1366, Val Loss: 0.5407
Epoch [91/120], Loss: 0.0502, Val Loss: 0.6394
Epoch [92/120], Loss: 0.4451, Val Loss: 0.4854
Epoch [93/120], Loss: 0.2156, Val Loss: 0.5124
Epoch [94/120], Loss: 0.0432, Val Loss: 0.4931
Epoch [95/120], Loss: 0.0834, Val Loss: 0.4960
Epoch [96/120], Loss: 0.4882, Val Loss: 0.5289
Epoch [97/120], Loss: 0.0846, Val Loss: 0.5235
Epoch [98/120], Loss: 0.0476, Val Loss: 0.4916
Epoch [99/120], Loss: 0.1263, Val Loss: 0.5123
Epoch [100/120], Loss: 0.1903, Val Loss: 0.4925
Epoch [101/120], Loss: 0.2224, Val Loss: 0.4813
Epoch [102/120], Loss: 0.5300, Val Loss: 0.5277
Epoch [103/120], Loss: 0.0653, Val Loss: 0.4948
Epoch [104/120], Loss: 0.1798, Val Loss: 0.4594
Epoch [105/120], Loss: 0.3494, Val Loss: 0.5155
Epoch [106/120], Loss: 0.1594, Val Loss: 0.4900
Epoch [107/120], Loss: 0.0862, Val Loss: 0.4892
Epoch [108/120], Loss: 0.0314, Val Loss: 0.4837
Epoch [109/120], Loss: 0.0951, Val Loss: 0.5839
Early stopping at epoch 109
Runtime: 0:00:51.940859
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2343, Val Loss: 0.4986
Epoch [2/120], Loss: 0.1837, Val Loss: 0.5163
Epoch [3/120], Loss: 0.2556, Val Loss: 0.5130
Epoch [4/120], Loss: 0.1235, Val Loss: 0.4893
Epoch [5/120], Loss: 0.1066, Val Loss: 0.4841
Epoch [6/120], Loss: 0.0964, Val Loss: 0.4848
Epoch [7/120], Loss: 0.0594, Val Loss: 0.5357
Epoch [8/120], Loss: 0.1521, Val Loss: 0.4675
Epoch [9/120], Loss: 0.2244, Val Loss: 0.4564
Epoch [10/120], Loss: 0.2873, Val Loss: 0.5149
Epoch [11/120], Loss: 0.0484, Val Loss: 0.4787
Epoch [12/120], Loss: 0.1020, Val Loss: 0.4624
Epoch [13/120], Loss: 0.1626, Val Loss: 0.4839
Epoch [14/120], Loss: 0.0867, Val Loss: 0.4711
Epoch [15/120], Loss: 0.1692, Val Loss: 0.4813
Epoch [16/120], Loss: 0.0970, Val Loss: 0.5442
Epoch [17/120], Loss: 0.0882, Val Loss: 0.5258
Epoch [18/120], Loss: 0.2857, Val Loss: 0.5095
Epoch [19/120], Loss: 0.1353, Val Loss: 0.5436
Epoch [20/120], Loss: 0.1989, Val Loss: 0.5512
Epoch [21/120], Loss: 0.0582, Val Loss: 0.4512
Epoch [22/120], Loss: 0.2109, Val Loss: 0.4903
Epoch [23/120], Loss: 0.1120, Val Loss: 0.4765
Epoch [24/120], Loss: 0.1068, Val Loss: 0.5032
Epoch [25/120], Loss: 0.1396, Val Loss: 0.4778
Epoch [26/120], Loss: 0.2569, Val Loss: 0.6475
Epoch [27/120], Loss: 0.0882, Val Loss: 0.5065
Epoch [28/120], Loss: 0.1265, Val Loss: 0.4866
Epoch [29/120], Loss: 0.1688, Val Loss: 0.4728
Epoch [30/120], Loss: 0.1309, Val Loss: 0.4453
Epoch [31/120], Loss: 0.0335, Val Loss: 0.5254
Epoch [32/120], Loss: 0.1952, Val Loss: 0.4861
Epoch [33/120], Loss: 0.0642, Val Loss: 0.5090
Epoch [34/120], Loss: 0.0903, Val Loss: 0.5138
Epoch [35/120], Loss: 0.6215, Val Loss: 0.4649
Epoch [36/120], Loss: 0.4691, Val Loss: 0.4627
Epoch [37/120], Loss: 0.1825, Val Loss: 0.5193
Epoch [38/120], Loss: 0.2079, Val Loss: 0.4910
Epoch [39/120], Loss: 0.2507, Val Loss: 0.4621
Epoch [40/120], Loss: 0.0957, Val Loss: 0.5059
Epoch [41/120], Loss: 0.0911, Val Loss: 0.4717
Epoch [42/120], Loss: 0.0413, Val Loss: 0.4298
Epoch [43/120], Loss: 0.0752, Val Loss: 0.5398
Epoch [44/120], Loss: 0.2698, Val Loss: 0.4546
Epoch [45/120], Loss: 0.1058, Val Loss: 0.4769
Epoch [46/120], Loss: 0.3587, Val Loss: 0.4417
Epoch [47/120], Loss: 0.0931, Val Loss: 0.4331
Epoch [48/120], Loss: 0.0533, Val Loss: 0.4741
Epoch [49/120], Loss: 0.6576, Val Loss: 0.4829
Epoch [50/120], Loss: 0.1098, Val Loss: 0.4868
Epoch [51/120], Loss: 0.1486, Val Loss: 0.4857
Epoch [52/120], Loss: 0.1332, Val Loss: 0.4564
Epoch [53/120], Loss: 0.3463, Val Loss: 0.4445
Epoch [54/120], Loss: 0.1791, Val Loss: 0.4423
Epoch [55/120], Loss: 0.2939, Val Loss: 0.4880
Epoch [56/120], Loss: 0.1386, Val Loss: 0.4541
Epoch [57/120], Loss: 0.5210, Val Loss: 0.4415
Epoch [58/120], Loss: 0.1522, Val Loss: 0.4702
Epoch [59/120], Loss: 0.1018, Val Loss: 0.4702
Epoch [60/120], Loss: 0.0715, Val Loss: 0.4624
Epoch [61/120], Loss: 0.2316, Val Loss: 0.4629
Epoch [62/120], Loss: 0.5150, Val Loss: 0.4471
Epoch [63/120], Loss: 0.1656, Val Loss: 0.4512
Epoch [64/120], Loss: 0.1891, Val Loss: 0.4437
Epoch [65/120], Loss: 0.0910, Val Loss: 0.4841
Epoch [66/120], Loss: 0.1282, Val Loss: 0.4930
Epoch [67/120], Loss: 0.0552, Val Loss: 0.4905
Epoch [68/120], Loss: 0.1570, Val Loss: 0.4346
Epoch [69/120], Loss: 0.3016, Val Loss: 0.5358
Epoch [70/120], Loss: 0.1845, Val Loss: 0.4489
Epoch [71/120], Loss: 0.2261, Val Loss: 0.4494
Epoch [72/120], Loss: 0.1218, Val Loss: 0.4686
Epoch [73/120], Loss: 0.4128, Val Loss: 0.5557
Epoch [74/120], Loss: 0.2439, Val Loss: 0.4837
Epoch [75/120], Loss: 0.4445, Val Loss: 0.4285
Epoch [76/120], Loss: 0.0609, Val Loss: 0.4287
Epoch [77/120], Loss: 0.0675, Val Loss: 0.4356
Epoch [78/120], Loss: 0.3531, Val Loss: 0.4354
Epoch [79/120], Loss: 0.1335, Val Loss: 0.4621
Epoch [80/120], Loss: 0.0822, Val Loss: 0.4372
Epoch [81/120], Loss: 0.1513, Val Loss: 0.4972
Epoch [82/120], Loss: 0.3449, Val Loss: 0.4760
Epoch [83/120], Loss: 0.1494, Val Loss: 0.4602
Epoch [84/120], Loss: 0.0339, Val Loss: 0.4407
Epoch [85/120], Loss: 0.8188, Val Loss: 0.4639
Epoch [86/120], Loss: 0.0691, Val Loss: 0.4908
Epoch [87/120], Loss: 0.1265, Val Loss: 0.4471
Epoch [88/120], Loss: 0.0412, Val Loss: 0.4443
Epoch [89/120], Loss: 0.0354, Val Loss: 0.4383
Epoch [90/120], Loss: 0.1445, Val Loss: 0.4917
Epoch [91/120], Loss: 0.0587, Val Loss: 0.4993
Epoch [92/120], Loss: 0.2301, Val Loss: 0.4404
Epoch [93/120], Loss: 0.0621, Val Loss: 0.4519
Epoch [94/120], Loss: 0.1420, Val Loss: 0.4874
Epoch [95/120], Loss: 0.1067, Val Loss: 0.4534
Epoch [96/120], Loss: 0.1394, Val Loss: 0.5219
Epoch [97/120], Loss: 0.3005, Val Loss: 0.4728
Epoch [98/120], Loss: 0.0830, Val Loss: 0.4512
Epoch [99/120], Loss: 0.7072, Val Loss: 0.4780
Epoch [100/120], Loss: 0.1017, Val Loss: 0.4550
Epoch [101/120], Loss: 0.0679, Val Loss: 0.4969
Epoch [102/120], Loss: 0.1508, Val Loss: 0.4633
Epoch [103/120], Loss: 0.6441, Val Loss: 0.4570
Epoch [104/120], Loss: 0.1457, Val Loss: 0.4869
Epoch [105/120], Loss: 0.1119, Val Loss: 0.4763
Early stopping at epoch 105
Runtime: 0:00:48.364075
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 1.2098, Val Loss: 0.9356
Epoch [2/120], Loss: 0.3360, Val Loss: 0.7664
Epoch [3/120], Loss: 0.3361, Val Loss: 0.7672
Epoch [4/120], Loss: 0.3042, Val Loss: 0.8000
Epoch [5/120], Loss: 0.6931, Val Loss: 0.7436
Epoch [6/120], Loss: 0.8957, Val Loss: 0.7458
Epoch [7/120], Loss: 0.4626, Val Loss: 0.8027
Epoch [8/120], Loss: 0.1811, Val Loss: 0.7049
Epoch [9/120], Loss: 0.0790, Val Loss: 0.7356
Epoch [10/120], Loss: 0.2347, Val Loss: 0.6810
Epoch [11/120], Loss: 0.1231, Val Loss: 0.6938
Epoch [12/120], Loss: 0.5497, Val Loss: 0.6646
Epoch [13/120], Loss: 0.3242, Val Loss: 0.6281
Epoch [14/120], Loss: 0.5507, Val Loss: 0.6671
Epoch [15/120], Loss: 0.0874, Val Loss: 0.6098
Epoch [16/120], Loss: 0.0910, Val Loss: 0.6196
Epoch [17/120], Loss: 0.2791, Val Loss: 0.6402
Epoch [18/120], Loss: 0.1113, Val Loss: 0.5771
Epoch [19/120], Loss: 0.5010, Val Loss: 0.7010
Epoch [20/120], Loss: 0.1772, Val Loss: 0.5938
Epoch [21/120], Loss: 0.3176, Val Loss: 0.5522
Epoch [22/120], Loss: 0.1441, Val Loss: 0.5797
Epoch [23/120], Loss: 0.0956, Val Loss: 0.5862
Epoch [24/120], Loss: 0.6977, Val Loss: 0.6767
Epoch [25/120], Loss: 0.3205, Val Loss: 0.5491
Epoch [26/120], Loss: 0.1227, Val Loss: 0.6298
Epoch [27/120], Loss: 0.2804, Val Loss: 0.7141
Epoch [28/120], Loss: 0.1089, Val Loss: 0.5239
Epoch [29/120], Loss: 0.3492, Val Loss: 0.5931
Epoch [30/120], Loss: 0.1456, Val Loss: 0.5218
Epoch [31/120], Loss: 0.8480, Val Loss: 0.5153
Epoch [32/120], Loss: 0.3505, Val Loss: 0.5551
Epoch [33/120], Loss: 6.1355, Val Loss: 0.8082
Epoch [34/120], Loss: 0.5474, Val Loss: 0.6805
Epoch [35/120], Loss: 0.3656, Val Loss: 0.5885
Epoch [36/120], Loss: 0.3034, Val Loss: 0.5336
Epoch [37/120], Loss: 0.1673, Val Loss: 0.5720
Epoch [38/120], Loss: 0.1980, Val Loss: 0.5334
Epoch [39/120], Loss: 0.1199, Val Loss: 0.5601
Epoch [40/120], Loss: 0.5386, Val Loss: 0.5257
Epoch [41/120], Loss: 0.2273, Val Loss: 0.5331
Epoch [42/120], Loss: 0.2477, Val Loss: 0.5208
Epoch [43/120], Loss: 0.1660, Val Loss: 0.4993
Epoch [44/120], Loss: 0.5529, Val Loss: 0.5217
Epoch [45/120], Loss: 0.0679, Val Loss: 0.4975
Epoch [46/120], Loss: 0.3579, Val Loss: 0.4859
Epoch [47/120], Loss: 0.2475, Val Loss: 0.4857
Epoch [48/120], Loss: 0.1052, Val Loss: 0.5038
Epoch [49/120], Loss: 0.1133, Val Loss: 0.4868
Epoch [50/120], Loss: 0.8187, Val Loss: 0.5511
Epoch [51/120], Loss: 0.3296, Val Loss: 0.5307
Epoch [52/120], Loss: 0.2350, Val Loss: 0.5418
Epoch [53/120], Loss: 0.0973, Val Loss: 0.5316
Epoch [54/120], Loss: 0.0528, Val Loss: 0.5459
Epoch [55/120], Loss: 0.3567, Val Loss: 0.5131
Epoch [56/120], Loss: 0.1547, Val Loss: 0.4771
Epoch [57/120], Loss: 0.3840, Val Loss: 0.4650
Epoch [58/120], Loss: 0.1135, Val Loss: 0.4868
Epoch [59/120], Loss: 0.1514, Val Loss: 0.4785
Epoch [60/120], Loss: 0.1322, Val Loss: 0.4947
Epoch [61/120], Loss: 0.0864, Val Loss: 0.4982
Epoch [62/120], Loss: 0.1352, Val Loss: 0.5333
Epoch [63/120], Loss: 0.1667, Val Loss: 0.4942
Epoch [64/120], Loss: 0.2671, Val Loss: 0.4965
Epoch [65/120], Loss: 0.4311, Val Loss: 0.4915
Epoch [66/120], Loss: 0.1214, Val Loss: 0.4895
Epoch [67/120], Loss: 0.2513, Val Loss: 0.5709
Epoch [68/120], Loss: 0.3022, Val Loss: 0.5396
Epoch [69/120], Loss: 0.0849, Val Loss: 0.5091
Epoch [70/120], Loss: 0.3136, Val Loss: 0.6674
Epoch [71/120], Loss: 0.1762, Val Loss: 0.4838
Epoch [72/120], Loss: 0.2174, Val Loss: 0.4977
Epoch [73/120], Loss: 0.3121, Val Loss: 0.4817
Epoch [74/120], Loss: 0.3135, Val Loss: 0.4825
Epoch [75/120], Loss: 0.0866, Val Loss: 0.4816
Epoch [76/120], Loss: 0.1151, Val Loss: 0.5136
Epoch [77/120], Loss: 0.2984, Val Loss: 0.4535
Epoch [78/120], Loss: 0.3488, Val Loss: 0.4883
Epoch [79/120], Loss: 0.1691, Val Loss: 0.5203
Epoch [80/120], Loss: 0.2239, Val Loss: 0.4460
Epoch [81/120], Loss: 0.0666, Val Loss: 0.4775
Epoch [82/120], Loss: 0.1928, Val Loss: 0.5035
Epoch [83/120], Loss: 0.1444, Val Loss: 0.4853
Epoch [84/120], Loss: 0.1399, Val Loss: 0.4692
Epoch [85/120], Loss: 0.0751, Val Loss: 0.4837
Epoch [86/120], Loss: 0.1201, Val Loss: 0.4945
Epoch [87/120], Loss: 0.1599, Val Loss: 0.4742
Epoch [88/120], Loss: 0.4004, Val Loss: 0.5398
Epoch [89/120], Loss: 0.2185, Val Loss: 0.4647
Epoch [90/120], Loss: 0.2049, Val Loss: 0.4958
Epoch [91/120], Loss: 0.1619, Val Loss: 0.4604
Epoch [92/120], Loss: 0.2592, Val Loss: 0.4717
Epoch [93/120], Loss: 1.8746, Val Loss: 0.5030
Epoch [94/120], Loss: 0.1792, Val Loss: 0.5259
Epoch [95/120], Loss: 0.3548, Val Loss: 0.5058
Epoch [96/120], Loss: 0.1590, Val Loss: 0.5155
Epoch [97/120], Loss: 0.0754, Val Loss: 0.4841
Epoch [98/120], Loss: 0.4981, Val Loss: 0.4898
Epoch [99/120], Loss: 0.0678, Val Loss: 0.4426
Epoch [100/120], Loss: 0.2556, Val Loss: 0.4539
Epoch [101/120], Loss: 0.4108, Val Loss: 0.4832
Epoch [102/120], Loss: 0.5103, Val Loss: 0.4892
Epoch [103/120], Loss: 1.1539, Val Loss: 0.5136
Epoch [104/120], Loss: 0.1771, Val Loss: 0.4563
Epoch [105/120], Loss: 0.0780, Val Loss: 0.5475
Epoch [106/120], Loss: 0.1069, Val Loss: 0.4695
Epoch [107/120], Loss: 0.1144, Val Loss: 0.4433
Epoch [108/120], Loss: 0.0963, Val Loss: 0.4712
Epoch [109/120], Loss: 0.1496, Val Loss: 0.4840
Epoch [110/120], Loss: 0.3726, Val Loss: 0.4517
Epoch [111/120], Loss: 0.6723, Val Loss: 0.5180
Epoch [112/120], Loss: 0.2899, Val Loss: 0.4537
Epoch [113/120], Loss: 0.3651, Val Loss: 0.4534
Epoch [114/120], Loss: 0.1380, Val Loss: 0.4749
Epoch [115/120], Loss: 0.3028, Val Loss: 0.4486
Epoch [116/120], Loss: 0.4623, Val Loss: 0.4664
Epoch [117/120], Loss: 0.3378, Val Loss: 0.4639
Epoch [118/120], Loss: 0.3752, Val Loss: 0.4426
Epoch [119/120], Loss: 0.0990, Val Loss: 0.4705
Epoch [120/120], Loss: 0.1189, Val Loss: 0.4897
Runtime: 0:00:58.189805
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1323, Val Loss: 0.4757
Epoch [2/120], Loss: 0.1860, Val Loss: 0.4522
Epoch [3/120], Loss: 0.2108, Val Loss: 0.4740
Epoch [4/120], Loss: 0.0643, Val Loss: 0.4893
Epoch [5/120], Loss: 0.3998, Val Loss: 0.4640
Epoch [6/120], Loss: 0.2991, Val Loss: 0.4746
Epoch [7/120], Loss: 0.1789, Val Loss: 0.4438
Epoch [8/120], Loss: 0.0753, Val Loss: 0.5638
Epoch [9/120], Loss: 0.3083, Val Loss: 0.5303
Epoch [10/120], Loss: 0.7407, Val Loss: 0.5482
Epoch [11/120], Loss: 0.4445, Val Loss: 0.4332
Epoch [12/120], Loss: 0.1792, Val Loss: 0.4530
Epoch [13/120], Loss: 0.0824, Val Loss: 0.4532
Epoch [14/120], Loss: 0.0447, Val Loss: 0.4555
Epoch [15/120], Loss: 0.0591, Val Loss: 0.4871
Epoch [16/120], Loss: 0.1023, Val Loss: 0.5198
Epoch [17/120], Loss: 0.1221, Val Loss: 0.4736
Epoch [18/120], Loss: 0.2807, Val Loss: 0.4384
Epoch [19/120], Loss: 0.2916, Val Loss: 0.4617
Epoch [20/120], Loss: 0.4620, Val Loss: 0.5710
Epoch [21/120], Loss: 0.1668, Val Loss: 0.4995
Epoch [22/120], Loss: 0.1178, Val Loss: 0.4894
Epoch [23/120], Loss: 0.1277, Val Loss: 0.4897
Epoch [24/120], Loss: 0.1544, Val Loss: 0.4306
Epoch [25/120], Loss: 0.1214, Val Loss: 0.5273
Epoch [26/120], Loss: 0.5411, Val Loss: 0.4605
Epoch [27/120], Loss: 0.2660, Val Loss: 0.4865
Epoch [28/120], Loss: 0.1088, Val Loss: 0.4853
Epoch [29/120], Loss: 0.6361, Val Loss: 0.4844
Epoch [30/120], Loss: 0.2586, Val Loss: 0.5165
Epoch [31/120], Loss: 0.1114, Val Loss: 0.4470
Epoch [32/120], Loss: 0.2055, Val Loss: 0.4903
Epoch [33/120], Loss: 0.1347, Val Loss: 0.4472
Epoch [34/120], Loss: 0.0709, Val Loss: 0.5259
Epoch [35/120], Loss: 0.1386, Val Loss: 0.4518
Epoch [36/120], Loss: 0.2337, Val Loss: 0.4441
Epoch [37/120], Loss: 0.3829, Val Loss: 0.4976
Epoch [38/120], Loss: 0.1250, Val Loss: 0.4457
Epoch [39/120], Loss: 0.0725, Val Loss: 0.4927
Epoch [40/120], Loss: 0.2939, Val Loss: 0.4553
Epoch [41/120], Loss: 0.0602, Val Loss: 0.4415
Epoch [42/120], Loss: 0.1387, Val Loss: 0.4432
Epoch [43/120], Loss: 0.2252, Val Loss: 0.4405
Epoch [44/120], Loss: 0.0964, Val Loss: 0.4604
Epoch [45/120], Loss: 0.1399, Val Loss: 0.4934
Epoch [46/120], Loss: 0.3350, Val Loss: 0.4690
Epoch [47/120], Loss: 0.0907, Val Loss: 0.4868
Epoch [48/120], Loss: 0.0495, Val Loss: 0.4543
Epoch [49/120], Loss: 0.8879, Val Loss: 0.4763
Epoch [50/120], Loss: 0.0667, Val Loss: 0.4899
Epoch [51/120], Loss: 0.1576, Val Loss: 0.4656
Epoch [52/120], Loss: 0.7707, Val Loss: 0.4582
Epoch [53/120], Loss: 0.1846, Val Loss: 0.4230
Epoch [54/120], Loss: 0.0480, Val Loss: 0.4326
Epoch [55/120], Loss: 0.0590, Val Loss: 0.5380
Epoch [56/120], Loss: 0.0510, Val Loss: 0.4833
Epoch [57/120], Loss: 0.3658, Val Loss: 0.4340
Epoch [58/120], Loss: 0.0609, Val Loss: 0.4430
Epoch [59/120], Loss: 0.0664, Val Loss: 0.4442
Epoch [60/120], Loss: 0.0901, Val Loss: 0.5069
Epoch [61/120], Loss: 0.0813, Val Loss: 0.4369
Epoch [62/120], Loss: 0.1458, Val Loss: 0.4832
Epoch [63/120], Loss: 0.3375, Val Loss: 0.4315
Epoch [64/120], Loss: 0.1185, Val Loss: 0.4326
Epoch [65/120], Loss: 0.0472, Val Loss: 0.4717
Epoch [66/120], Loss: 0.0749, Val Loss: 0.5183
Epoch [67/120], Loss: 0.1801, Val Loss: 0.4862
Epoch [68/120], Loss: 0.2068, Val Loss: 0.4624
Epoch [69/120], Loss: 0.0495, Val Loss: 0.4722
Epoch [70/120], Loss: 0.4132, Val Loss: 0.4605
Epoch [71/120], Loss: 0.4784, Val Loss: 0.4771
Epoch [72/120], Loss: 0.0380, Val Loss: 0.4776
Epoch [73/120], Loss: 0.0990, Val Loss: 0.4711
Epoch [74/120], Loss: 0.1184, Val Loss: 0.4784
Epoch [75/120], Loss: 0.1087, Val Loss: 0.4453
Epoch [76/120], Loss: 0.0912, Val Loss: 0.4782
Epoch [77/120], Loss: 0.3868, Val Loss: 0.4309
Epoch [78/120], Loss: 0.1960, Val Loss: 0.4188
Epoch [79/120], Loss: 0.2360, Val Loss: 0.4480
Epoch [80/120], Loss: 0.2050, Val Loss: 0.4432
Epoch [81/120], Loss: 0.1001, Val Loss: 0.4392
Epoch [82/120], Loss: 0.1712, Val Loss: 0.4509
Epoch [83/120], Loss: 0.2199, Val Loss: 0.4380
Epoch [84/120], Loss: 0.1245, Val Loss: 0.4584
Epoch [85/120], Loss: 0.1567, Val Loss: 0.4775
Epoch [86/120], Loss: 0.7609, Val Loss: 0.4808
Epoch [87/120], Loss: 0.1748, Val Loss: 0.4991
Epoch [88/120], Loss: 0.0825, Val Loss: 0.4935
Epoch [89/120], Loss: 0.1172, Val Loss: 0.4497
Epoch [90/120], Loss: 0.0571, Val Loss: 0.4534
Epoch [91/120], Loss: 0.1053, Val Loss: 0.4700
Epoch [92/120], Loss: 0.1537, Val Loss: 0.4654
Epoch [93/120], Loss: 0.0624, Val Loss: 0.4667
Epoch [94/120], Loss: 0.0738, Val Loss: 0.4384
Epoch [95/120], Loss: 0.2374, Val Loss: 0.4399
Epoch [96/120], Loss: 0.5220, Val Loss: 0.4524
Epoch [97/120], Loss: 0.1681, Val Loss: 0.4293
Epoch [98/120], Loss: 0.3755, Val Loss: 0.4491
Epoch [99/120], Loss: 0.2172, Val Loss: 0.4478
Epoch [100/120], Loss: 0.1689, Val Loss: 0.4640
Epoch [101/120], Loss: 0.1450, Val Loss: 0.4441
Epoch [102/120], Loss: 0.1508, Val Loss: 0.4454
Epoch [103/120], Loss: 0.2020, Val Loss: 0.4801
Epoch [104/120], Loss: 0.0708, Val Loss: 0.4908
Epoch [105/120], Loss: 0.3561, Val Loss: 0.4467
Epoch [106/120], Loss: 0.1372, Val Loss: 0.4434
Epoch [107/120], Loss: 0.1104, Val Loss: 0.4428
Early stopping at epoch 107
Runtime: 0:00:50.419804
R^2 Score: 0.9121
RMSE: 0.5806
MAE: 0.1796
MAPE: 15.57%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2516, Val Loss: 0.4559
Epoch [2/120], Loss: 0.0756, Val Loss: 0.4498
Epoch [3/120], Loss: 0.0798, Val Loss: 0.4518
Epoch [4/120], Loss: 0.0440, Val Loss: 0.4327
Epoch [5/120], Loss: 0.5583, Val Loss: 0.4548
Epoch [6/120], Loss: 0.1340, Val Loss: 0.4479
Epoch [7/120], Loss: 0.0519, Val Loss: 0.4547
Epoch [8/120], Loss: 0.0363, Val Loss: 0.4064
Epoch [9/120], Loss: 0.0893, Val Loss: 0.4625
Epoch [10/120], Loss: 0.1067, Val Loss: 0.6357
Epoch [11/120], Loss: 0.0732, Val Loss: 0.4562
Epoch [12/120], Loss: 0.3415, Val Loss: 0.4358
Epoch [13/120], Loss: 0.1171, Val Loss: 0.4577
Epoch [14/120], Loss: 0.1449, Val Loss: 0.4632
Epoch [15/120], Loss: 0.1231, Val Loss: 0.4964
Epoch [16/120], Loss: 0.2605, Val Loss: 0.4095
Epoch [17/120], Loss: 0.0977, Val Loss: 0.4245
Epoch [18/120], Loss: 0.0505, Val Loss: 0.4399
Epoch [19/120], Loss: 0.1518, Val Loss: 0.5208
Epoch [20/120], Loss: 0.0615, Val Loss: 0.4880
Epoch [21/120], Loss: 0.1171, Val Loss: 0.4537
Epoch [22/120], Loss: 0.2004, Val Loss: 0.4390
Epoch [23/120], Loss: 0.1056, Val Loss: 0.4342
Epoch [24/120], Loss: 0.0893, Val Loss: 0.4476
Epoch [25/120], Loss: 0.0279, Val Loss: 0.4499
Epoch [26/120], Loss: 0.0522, Val Loss: 0.4277
Epoch [27/120], Loss: 0.1255, Val Loss: 0.4238
Epoch [28/120], Loss: 0.1889, Val Loss: 0.4762
Epoch [29/120], Loss: 0.1092, Val Loss: 0.4671
Epoch [30/120], Loss: 0.1202, Val Loss: 0.4478
Epoch [31/120], Loss: 0.1432, Val Loss: 0.4671
Epoch [32/120], Loss: 0.1214, Val Loss: 0.4375
Epoch [33/120], Loss: 0.1314, Val Loss: 0.5117
Epoch [34/120], Loss: 0.1534, Val Loss: 0.4245
Epoch [35/120], Loss: 0.1100, Val Loss: 0.4572
Epoch [36/120], Loss: 0.0531, Val Loss: 0.4257
Epoch [37/120], Loss: 0.0395, Val Loss: 0.4466
Epoch [38/120], Loss: 0.5002, Val Loss: 0.4514
Epoch [39/120], Loss: 0.2651, Val Loss: 0.4442
Epoch [40/120], Loss: 0.2525, Val Loss: 0.4577
Epoch [41/120], Loss: 0.0892, Val Loss: 0.4591
Epoch [42/120], Loss: 0.2709, Val Loss: 0.4172
Epoch [43/120], Loss: 0.1723, Val Loss: 0.4593
Epoch [44/120], Loss: 0.0651, Val Loss: 0.4195
Epoch [45/120], Loss: 0.2065, Val Loss: 0.4584
Early stopping at epoch 45
Runtime: 0:00:22.215782
R^2 Score: 0.9223
RMSE: 0.5461
MAE: 0.1755
MAPE: 14.76%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.3682, Val Loss: 0.4148
Epoch [2/120], Loss: 0.3919, Val Loss: 0.4309
Epoch [3/120], Loss: 0.1500, Val Loss: 0.4337
Epoch [4/120], Loss: 0.0441, Val Loss: 0.4428
Epoch [5/120], Loss: 0.0401, Val Loss: 0.4404
Epoch [6/120], Loss: 0.0725, Val Loss: 0.4177
Epoch [7/120], Loss: 0.2687, Val Loss: 0.4236
Epoch [8/120], Loss: 0.1381, Val Loss: 0.4484
Epoch [9/120], Loss: 0.1031, Val Loss: 0.4744
Epoch [10/120], Loss: 0.1142, Val Loss: 0.4451
Epoch [11/120], Loss: 0.1005, Val Loss: 0.4679
Epoch [12/120], Loss: 0.1959, Val Loss: 0.4552
Epoch [13/120], Loss: 0.2432, Val Loss: 0.4842
Epoch [14/120], Loss: 0.1952, Val Loss: 0.5047
Epoch [15/120], Loss: 0.1535, Val Loss: 0.4732
Epoch [16/120], Loss: 0.0697, Val Loss: 0.4262
Epoch [17/120], Loss: 0.0913, Val Loss: 0.4338
Epoch [18/120], Loss: 0.1135, Val Loss: 0.4386
Epoch [19/120], Loss: 0.1199, Val Loss: 0.4335
Epoch [20/120], Loss: 0.0821, Val Loss: 0.4930
Epoch [21/120], Loss: 0.0235, Val Loss: 0.4352
Epoch [22/120], Loss: 0.0630, Val Loss: 0.4287
Epoch [23/120], Loss: 0.0369, Val Loss: 0.4453
Epoch [24/120], Loss: 0.2096, Val Loss: 0.4334
Epoch [25/120], Loss: 0.1594, Val Loss: 0.4203
Epoch [26/120], Loss: 0.2815, Val Loss: 0.4138
Epoch [27/120], Loss: 0.2644, Val Loss: 0.4348
Epoch [28/120], Loss: 0.1047, Val Loss: 0.4300
Epoch [29/120], Loss: 0.1701, Val Loss: 0.4552
Epoch [30/120], Loss: 0.3907, Val Loss: 0.4644
Epoch [31/120], Loss: 0.0397, Val Loss: 0.4286
Epoch [32/120], Loss: 0.2530, Val Loss: 0.4377
Epoch [33/120], Loss: 0.2725, Val Loss: 0.4671
Epoch [34/120], Loss: 0.0937, Val Loss: 0.4240
Epoch [35/120], Loss: 0.2637, Val Loss: 0.4623
Epoch [36/120], Loss: 0.0484, Val Loss: 0.4702
Epoch [37/120], Loss: 0.1183, Val Loss: 0.4683
Epoch [38/120], Loss: 0.0538, Val Loss: 0.4513
Epoch [39/120], Loss: 0.2255, Val Loss: 0.4602
Epoch [40/120], Loss: 0.0874, Val Loss: 0.4427
Epoch [41/120], Loss: 0.1813, Val Loss: 0.4404
Epoch [42/120], Loss: 0.0577, Val Loss: 0.4147
Epoch [43/120], Loss: 0.1937, Val Loss: 0.4526
Epoch [44/120], Loss: 0.3411, Val Loss: 0.5184
Epoch [45/120], Loss: 0.0991, Val Loss: 0.4293
Epoch [46/120], Loss: 0.1868, Val Loss: 0.5066
Epoch [47/120], Loss: 0.1182, Val Loss: 0.4309
Epoch [48/120], Loss: 0.0912, Val Loss: 0.4392
Epoch [49/120], Loss: 0.1771, Val Loss: 0.4461
Epoch [50/120], Loss: 0.1207, Val Loss: 0.4385
Epoch [51/120], Loss: 0.2900, Val Loss: 0.4559
Epoch [52/120], Loss: 0.0463, Val Loss: 0.4418
Epoch [53/120], Loss: 0.0735, Val Loss: 0.4259
Epoch [54/120], Loss: 0.0672, Val Loss: 0.4491
Epoch [55/120], Loss: 0.0877, Val Loss: 0.5153
Epoch [56/120], Loss: 0.1350, Val Loss: 0.5018
Epoch [57/120], Loss: 0.1296, Val Loss: 0.4206
Epoch [58/120], Loss: 0.0767, Val Loss: 0.4384
Epoch [59/120], Loss: 0.1842, Val Loss: 0.4453
Epoch [60/120], Loss: 0.0820, Val Loss: 0.4628
Epoch [61/120], Loss: 0.1843, Val Loss: 0.4966
Epoch [62/120], Loss: 0.6322, Val Loss: 0.4731
Epoch [63/120], Loss: 0.1719, Val Loss: 0.4572
Epoch [64/120], Loss: 0.1036, Val Loss: 0.5460
Epoch [65/120], Loss: 0.2574, Val Loss: 0.4250
Epoch [66/120], Loss: 0.1785, Val Loss: 0.4344
Epoch [67/120], Loss: 0.1454, Val Loss: 0.4391
Epoch [68/120], Loss: 0.0382, Val Loss: 0.4322
Epoch [69/120], Loss: 0.0630, Val Loss: 0.4245
Epoch [70/120], Loss: 0.1322, Val Loss: 0.4458
Epoch [71/120], Loss: 0.0699, Val Loss: 0.4384
Early stopping at epoch 71
Runtime: 0:00:35.101944
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.4815, Val Loss: 0.9029
Epoch [2/120], Loss: 0.1729, Val Loss: 0.7373
Epoch [3/120], Loss: 0.3076, Val Loss: 0.7263
Epoch [4/120], Loss: 0.5623, Val Loss: 0.6829
Epoch [5/120], Loss: 0.0963, Val Loss: 0.6536
Epoch [6/120], Loss: 1.2326, Val Loss: 0.7723
Epoch [7/120], Loss: 1.3536, Val Loss: 0.6950
Epoch [8/120], Loss: 0.1607, Val Loss: 0.7461
Epoch [9/120], Loss: 0.1375, Val Loss: 0.6805
Epoch [10/120], Loss: 0.1806, Val Loss: 0.5772
Epoch [11/120], Loss: 0.3885, Val Loss: 0.8813
Epoch [12/120], Loss: 0.2427, Val Loss: 0.6494
Epoch [13/120], Loss: 0.1109, Val Loss: 0.5539
Epoch [14/120], Loss: 0.1294, Val Loss: 0.6516
Epoch [15/120], Loss: 1.0003, Val Loss: 0.6927
Epoch [16/120], Loss: 0.1442, Val Loss: 0.9700
Epoch [17/120], Loss: 0.0640, Val Loss: 0.7726
Epoch [18/120], Loss: 0.3918, Val Loss: 0.7018
Epoch [19/120], Loss: 0.0912, Val Loss: 0.5579
Epoch [20/120], Loss: 0.4580, Val Loss: 0.6507
Epoch [21/120], Loss: 0.2118, Val Loss: 0.5585
Epoch [22/120], Loss: 0.1460, Val Loss: 0.6686
Epoch [23/120], Loss: 0.4363, Val Loss: 0.5603
Epoch [24/120], Loss: 0.1252, Val Loss: 0.6276
Epoch [25/120], Loss: 0.0934, Val Loss: 0.6268
Epoch [26/120], Loss: 0.2208, Val Loss: 0.6353
Epoch [27/120], Loss: 0.0407, Val Loss: 0.5969
Epoch [28/120], Loss: 0.4077, Val Loss: 0.5694
Epoch [29/120], Loss: 0.0783, Val Loss: 0.5717
Epoch [30/120], Loss: 0.1251, Val Loss: 0.5546
Epoch [31/120], Loss: 0.2535, Val Loss: 0.6666
Epoch [32/120], Loss: 0.1352, Val Loss: 0.6503
Epoch [33/120], Loss: 0.0582, Val Loss: 0.5111
Epoch [34/120], Loss: 1.2094, Val Loss: 0.6026
Epoch [35/120], Loss: 0.4892, Val Loss: 0.6180
Epoch [36/120], Loss: 0.3275, Val Loss: 0.5514
Epoch [37/120], Loss: 0.2926, Val Loss: 0.6555
Epoch [38/120], Loss: 0.3593, Val Loss: 0.5884
Epoch [39/120], Loss: 0.6225, Val Loss: 0.6895
Epoch [40/120], Loss: 0.0208, Val Loss: 0.5712
Epoch [41/120], Loss: 0.1800, Val Loss: 0.5606
Epoch [42/120], Loss: 0.4527, Val Loss: 0.5257
Epoch [43/120], Loss: 0.3575, Val Loss: 0.8188
Epoch [44/120], Loss: 1.0856, Val Loss: 0.6088
Epoch [45/120], Loss: 0.1035, Val Loss: 0.5550
Epoch [46/120], Loss: 0.3448, Val Loss: 0.6663
Epoch [47/120], Loss: 0.2334, Val Loss: 0.7448
Epoch [48/120], Loss: 0.1138, Val Loss: 0.5289
Epoch [49/120], Loss: 0.0815, Val Loss: 0.5612
Epoch [50/120], Loss: 0.2140, Val Loss: 0.5522
Epoch [51/120], Loss: 0.1529, Val Loss: 0.7712
Epoch [52/120], Loss: 0.0844, Val Loss: 0.6493
Epoch [53/120], Loss: 0.0468, Val Loss: 0.5260
Epoch [54/120], Loss: 1.4979, Val Loss: 0.6152
Epoch [55/120], Loss: 0.0759, Val Loss: 0.5342
Epoch [56/120], Loss: 0.7390, Val Loss: 0.5514
Epoch [57/120], Loss: 0.1046, Val Loss: 0.5490
Epoch [58/120], Loss: 0.0339, Val Loss: 0.4992
Epoch [59/120], Loss: 1.2611, Val Loss: 0.5979
Epoch [60/120], Loss: 0.1704, Val Loss: 0.5321
Epoch [61/120], Loss: 0.2686, Val Loss: 0.5444
Epoch [62/120], Loss: 0.1182, Val Loss: 0.7515
Epoch [63/120], Loss: 0.1461, Val Loss: 0.5019
Epoch [64/120], Loss: 0.1702, Val Loss: 0.5094
Epoch [65/120], Loss: 0.1592, Val Loss: 0.6172
Epoch [66/120], Loss: 0.1946, Val Loss: 0.5955
Epoch [67/120], Loss: 0.3025, Val Loss: 0.5206
Epoch [68/120], Loss: 0.0529, Val Loss: 0.5742
Epoch [69/120], Loss: 0.0956, Val Loss: 0.5397
Epoch [70/120], Loss: 0.3499, Val Loss: 0.9415
Epoch [71/120], Loss: 0.0520, Val Loss: 0.5237
Epoch [72/120], Loss: 0.2948, Val Loss: 0.5819
Epoch [73/120], Loss: 0.4920, Val Loss: 0.5303
Epoch [74/120], Loss: 0.3450, Val Loss: 0.5248
Epoch [75/120], Loss: 0.1239, Val Loss: 0.5242
Epoch [76/120], Loss: 0.1761, Val Loss: 0.4982
Epoch [77/120], Loss: 0.2465, Val Loss: 0.6034
Epoch [78/120], Loss: 0.0613, Val Loss: 0.7451
Epoch [79/120], Loss: 0.1162, Val Loss: 0.5899
Epoch [80/120], Loss: 0.2579, Val Loss: 0.5261
Epoch [81/120], Loss: 0.2788, Val Loss: 0.5939
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 1.0064, Val Loss: 0.3410
Epoch [2/120], Loss: 0.2966, Val Loss: 0.3396
Epoch [3/120], Loss: 0.0520, Val Loss: 0.3557
Epoch [4/120], Loss: 0.0872, Val Loss: 0.3618
Epoch [5/120], Loss: 0.0357, Val Loss: 0.3303
Epoch [6/120], Loss: 0.3161, Val Loss: 0.3207
Epoch [7/120], Loss: 0.0878, Val Loss: 0.3188
Epoch [8/120], Loss: 0.0963, Val Loss: 0.3593
Epoch [9/120], Loss: 0.1466, Val Loss: 0.3276
Epoch [10/120], Loss: 0.2371, Val Loss: 0.3220
Epoch [11/120], Loss: 0.2574, Val Loss: 0.3252
Epoch [12/120], Loss: 0.0947, Val Loss: 0.3315
Epoch [13/120], Loss: 0.0949, Val Loss: 0.3482
Epoch [14/120], Loss: 0.1387, Val Loss: 0.3383
Epoch [15/120], Loss: 0.0739, Val Loss: 0.3233
Epoch [16/120], Loss: 0.3248, Val Loss: 0.3537
Epoch [17/120], Loss: 0.0613, Val Loss: 0.3503
Epoch [18/120], Loss: 0.1854, Val Loss: 0.3506
Epoch [19/120], Loss: 0.0919, Val Loss: 0.3296
Epoch [20/120], Loss: 0.1663, Val Loss: 0.3349
Epoch [21/120], Loss: 0.1039, Val Loss: 0.3542
Epoch [22/120], Loss: 0.1983, Val Loss: 0.3876
Epoch [23/120], Loss: 0.0848, Val Loss: 0.3582
Epoch [24/120], Loss: 0.0524, Val Loss: 0.3714
Epoch [25/120], Loss: 0.1602, Val Loss: 0.3742
Epoch [26/120], Loss: 0.0673, Val Loss: 0.3677
Epoch [27/120], Loss: 0.6555, Val Loss: 0.3829
Epoch [28/120], Loss: 0.0689, Val Loss: 0.3533
Epoch [29/120], Loss: 0.4430, Val Loss: 0.3667
Epoch [30/120], Loss: 0.1293, Val Loss: 0.3373
Epoch [31/120], Loss: 0.0484, Val Loss: 0.3514
Epoch [32/120], Loss: 0.0928, Val Loss: 0.3467
Epoch [33/120], Loss: 0.1301, Val Loss: 0.3651
Epoch [34/120], Loss: 0.3860, Val Loss: 0.3734
Epoch [35/120], Loss: 0.0857, Val Loss: 0.3767
Epoch [36/120], Loss: 0.1174, Val Loss: 0.3807
Epoch [37/120], Loss: 0.0814, Val Loss: 0.3496
Epoch [38/120], Loss: 0.1107, Val Loss: 0.3600
Epoch [39/120], Loss: 0.3373, Val Loss: 0.3564
Epoch [40/120], Loss: 0.3399, Val Loss: 0.3679
Epoch [41/120], Loss: 0.1343, Val Loss: 0.4016
Epoch [42/120], Loss: 0.5438, Val Loss: 0.3598
Epoch [43/120], Loss: 0.1565, Val Loss: 0.3627
Epoch [44/120], Loss: 0.1833, Val Loss: 0.3581
Early stopping at epoch 44
Runtime: 0:00:21.592129
R^2 Score: 0.9437
RMSE: 0.4648
MAE: 0.1552
MAPE: 14.88%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0616, Val Loss: 0.3439
Epoch [2/120], Loss: 0.0780, Val Loss: 0.3492
Epoch [3/120], Loss: 0.2166, Val Loss: 0.3649
Epoch [4/120], Loss: 0.0600, Val Loss: 0.3547
Epoch [5/120], Loss: 0.9935, Val Loss: 0.3790
Epoch [6/120], Loss: 0.2929, Val Loss: 0.3578
Epoch [7/120], Loss: 0.0933, Val Loss: 0.3641
Epoch [8/120], Loss: 0.1102, Val Loss: 0.3688
Epoch [9/120], Loss: 0.2187, Val Loss: 0.3898
Epoch [10/120], Loss: 0.0526, Val Loss: 0.3653
Epoch [11/120], Loss: 0.0498, Val Loss: 0.3916
Epoch [12/120], Loss: 0.1169, Val Loss: 0.3667
Epoch [13/120], Loss: 0.0790, Val Loss: 0.4080
Epoch [14/120], Loss: 0.0780, Val Loss: 0.3885
Epoch [15/120], Loss: 0.3406, Val Loss: 0.3801
Epoch [16/120], Loss: 0.2496, Val Loss: 0.3995
Epoch [17/120], Loss: 0.1059, Val Loss: 0.3801
Epoch [18/120], Loss: 0.0820, Val Loss: 0.3686
Epoch [19/120], Loss: 0.2908, Val Loss: 0.4014
Epoch [20/120], Loss: 0.0977, Val Loss: 0.3730
Epoch [21/120], Loss: 0.0734, Val Loss: 0.3585
Epoch [22/120], Loss: 0.1241, Val Loss: 0.3643
Epoch [23/120], Loss: 0.5819, Val Loss: 0.3747
Epoch [24/120], Loss: 0.1086, Val Loss: 0.3975
Epoch [25/120], Loss: 0.0557, Val Loss: 0.3928
Epoch [26/120], Loss: 0.1360, Val Loss: 0.3588
Epoch [27/120], Loss: 0.0452, Val Loss: 0.4176
Epoch [28/120], Loss: 0.0634, Val Loss: 0.3958
Epoch [29/120], Loss: 0.4140, Val Loss: 0.3909
Epoch [30/120], Loss: 0.2152, Val Loss: 0.3577
Epoch [31/120], Loss: 0.0547, Val Loss: 0.3952
Early stopping at epoch 31
Runtime: 0:00:15.496306
R^2 Score: 0.9429
RMSE: 0.4683
MAE: 0.1549
MAPE: 14.67%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0043340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2819, Val Loss: 0.9439
Epoch [2/120], Loss: 0.5343, Val Loss: 0.9362
Epoch [3/120], Loss: 0.5310, Val Loss: 0.9699
Epoch [4/120], Loss: 0.2830, Val Loss: 0.8203
Epoch [5/120], Loss: 0.9826, Val Loss: 0.7337
Epoch [6/120], Loss: 0.7113, Val Loss: 0.7920
Epoch [7/120], Loss: 0.0684, Val Loss: 0.7008
Epoch [8/120], Loss: 0.1325, Val Loss: 0.7466
Epoch [9/120], Loss: 0.1642, Val Loss: 0.7709
Epoch [10/120], Loss: 0.4897, Val Loss: 0.7213
Epoch [11/120], Loss: 0.2544, Val Loss: 0.6762
Epoch [12/120], Loss: 0.1163, Val Loss: 0.7024
Epoch [13/120], Loss: 0.1703, Val Loss: 0.6081
Epoch [14/120], Loss: 0.1582, Val Loss: 0.5721
Epoch [15/120], Loss: 0.2362, Val Loss: 0.7167
Epoch [16/120], Loss: 0.1194, Val Loss: 0.5717
Epoch [17/120], Loss: 0.0861, Val Loss: 0.6287
Epoch [18/120], Loss: 0.1721, Val Loss: 0.6863
Epoch [19/120], Loss: 0.3112, Val Loss: 0.5593
Epoch [20/120], Loss: 0.2217, Val Loss: 0.6540
Epoch [21/120], Loss: 0.1115, Val Loss: 0.5895
Epoch [22/120], Loss: 0.2543, Val Loss: 0.5760
Epoch [23/120], Loss: 0.1120, Val Loss: 0.5565
Epoch [24/120], Loss: 0.2544, Val Loss: 0.6216
Epoch [25/120], Loss: 0.1381, Val Loss: 0.6283
Epoch [26/120], Loss: 0.3679, Val Loss: 0.5378
Epoch [27/120], Loss: 0.2077, Val Loss: 0.5535
Epoch [28/120], Loss: 0.1662, Val Loss: 0.5682
Epoch [29/120], Loss: 0.1376, Val Loss: 0.5101
Epoch [30/120], Loss: 0.1641, Val Loss: 0.6246
Epoch [31/120], Loss: 0.1950, Val Loss: 0.5546
Epoch [32/120], Loss: 1.4871, Val Loss: 0.5400
Epoch [33/120], Loss: 0.1545, Val Loss: 0.6647
Epoch [34/120], Loss: 0.0963, Val Loss: 0.5441
Epoch [35/120], Loss: 0.1715, Val Loss: 0.5227
Epoch [36/120], Loss: 0.3776, Val Loss: 0.7365
Epoch [37/120], Loss: 0.1180, Val Loss: 0.5204
Epoch [38/120], Loss: 0.7988, Val Loss: 0.5877
Epoch [39/120], Loss: 0.6596, Val Loss: 0.5971
Epoch [40/120], Loss: 0.0701, Val Loss: 0.5928
Epoch [41/120], Loss: 0.3753, Val Loss: 0.6309
Epoch [42/120], Loss: 0.6047, Val Loss: 0.5477
Epoch [43/120], Loss: 0.1381, Val Loss: 0.5619
Epoch [44/120], Loss: 0.3143, Val Loss: 0.4953
Epoch [45/120], Loss: 0.1101, Val Loss: 0.4918
Epoch [46/120], Loss: 0.1569, Val Loss: 0.5811
Epoch [47/120], Loss: 0.2894, Val Loss: 0.5549
Epoch [48/120], Loss: 0.2063, Val Loss: 0.5123
Epoch [49/120], Loss: 0.1178, Val Loss: 0.5904
Epoch [50/120], Loss: 0.2158, Val Loss: 0.5469
Epoch [51/120], Loss: 0.2660, Val Loss: 0.5554
Epoch [52/120], Loss: 2.2064, Val Loss: 0.5890
Epoch [53/120], Loss: 0.1618, Val Loss: 0.5348
Epoch [54/120], Loss: 0.0888, Val Loss: 0.5451
Epoch [55/120], Loss: 0.0978, Val Loss: 0.5592
Epoch [56/120], Loss: 0.2499, Val Loss: 0.5127
Epoch [57/120], Loss: 0.2268, Val Loss: 0.5706
Epoch [58/120], Loss: 0.2407, Val Loss: 0.7970
Epoch [59/120], Loss: 0.0885, Val Loss: 0.5999
Epoch [60/120], Loss: 0.7829, Val Loss: 0.6124
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0043340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2723, Val Loss: 1.0275
Epoch [2/120], Loss: 0.3129, Val Loss: 1.0877
Epoch [3/120], Loss: 1.1303, Val Loss: 0.8608
Epoch [4/120], Loss: 0.1557, Val Loss: 0.8890
Epoch [5/120], Loss: 0.2064, Val Loss: 0.7837
Epoch [6/120], Loss: 0.3910, Val Loss: 0.8461
Epoch [7/120], Loss: 0.2007, Val Loss: 0.6955
Epoch [8/120], Loss: 0.6350, Val Loss: 0.7796
Epoch [9/120], Loss: 0.0851, Val Loss: 0.7451
Epoch [10/120], Loss: 0.0850, Val Loss: 0.8142
Epoch [11/120], Loss: 0.5045, Val Loss: 0.7126
Epoch [12/120], Loss: 0.3760, Val Loss: 0.8728
Epoch [13/120], Loss: 0.1620, Val Loss: 0.6808
Epoch [14/120], Loss: 0.0952, Val Loss: 0.7247
Epoch [15/120], Loss: 0.1087, Val Loss: 0.5996
Epoch [16/120], Loss: 0.1479, Val Loss: 0.6749
Epoch [17/120], Loss: 0.2382, Val Loss: 0.5902
Epoch [18/120], Loss: 0.4950, Val Loss: 0.7198
Epoch [19/120], Loss: 0.2085, Val Loss: 0.6668
Epoch [20/120], Loss: 1.1089, Val Loss: 0.6043
Epoch [21/120], Loss: 0.2816, Val Loss: 0.6074
Epoch [22/120], Loss: 0.5997, Val Loss: 0.5955
Epoch [23/120], Loss: 0.7103, Val Loss: 0.6340
Epoch [24/120], Loss: 0.7274, Val Loss: 0.5995
Epoch [25/120], Loss: 0.2304, Val Loss: 0.5934
Epoch [26/120], Loss: 0.0698, Val Loss: 0.6159
Epoch [27/120], Loss: 0.2158, Val Loss: 0.5700
Epoch [28/120], Loss: 0.0939, Val Loss: 0.6615
Epoch [29/120], Loss: 0.9334, Val Loss: 0.6724
Epoch [30/120], Loss: 0.3551, Val Loss: 0.5421
Epoch [31/120], Loss: 0.7586, Val Loss: 0.5354
Epoch [32/120], Loss: 0.3417, Val Loss: 0.7553
Epoch [33/120], Loss: 0.2954, Val Loss: 0.6320
Epoch [34/120], Loss: 0.4151, Val Loss: 0.5898
Epoch [35/120], Loss: 1.0034, Val Loss: 0.4961
Epoch [36/120], Loss: 0.6055, Val Loss: 0.4825
Epoch [37/120], Loss: 0.4954, Val Loss: 0.5030
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2092, Val Loss: 0.9846
Epoch [2/120], Loss: 0.1578, Val Loss: 0.9690
Epoch [3/120], Loss: 0.1733, Val Loss: 0.8529
Epoch [4/120], Loss: 0.9376, Val Loss: 0.8120
Epoch [5/120], Loss: 0.1624, Val Loss: 0.8246
Epoch [6/120], Loss: 0.5500, Val Loss: 0.8206
Epoch [7/120], Loss: 0.2946, Val Loss: 0.7254
Epoch [8/120], Loss: 0.2287, Val Loss: 0.6778
Epoch [9/120], Loss: 0.1329, Val Loss: 0.7549
Epoch [10/120], Loss: 0.2084, Val Loss: 0.6107
Epoch [11/120], Loss: 0.1884, Val Loss: 0.6169
Epoch [12/120], Loss: 0.1626, Val Loss: 0.6263
Epoch [13/120], Loss: 0.1930, Val Loss: 0.6487
Epoch [14/120], Loss: 0.4539, Val Loss: 0.6755
Epoch [15/120], Loss: 0.4386, Val Loss: 0.6855
Epoch [16/120], Loss: 0.5156, Val Loss: 0.5546
Epoch [17/120], Loss: 0.2304, Val Loss: 0.6133
Epoch [18/120], Loss: 0.1775, Val Loss: 0.5645
Epoch [19/120], Loss: 0.5637, Val Loss: 0.5683
Epoch [20/120], Loss: 0.1344, Val Loss: 0.6710
Epoch [21/120], Loss: 0.7540, Val Loss: 0.6198
Epoch [22/120], Loss: 0.3965, Val Loss: 0.5564
Epoch [23/120], Loss: 0.2918, Val Loss: 0.5725
Epoch [24/120], Loss: 0.4180, Val Loss: 0.7748
Epoch [25/120], Loss: 0.1422, Val Loss: 0.5389
Epoch [26/120], Loss: 0.0998, Val Loss: 0.5742
Epoch [27/120], Loss: 0.3490, Val Loss: 0.6235
Epoch [28/120], Loss: 0.3102, Val Loss: 0.5650
Epoch [29/120], Loss: 0.1089, Val Loss: 0.5102
Epoch [30/120], Loss: 0.0673, Val Loss: 0.5043
Epoch [31/120], Loss: 0.4020, Val Loss: 0.6550
Epoch [32/120], Loss: 0.1998, Val Loss: 0.5117
Epoch [33/120], Loss: 0.0810, Val Loss: 0.4822
Epoch [34/120], Loss: 0.2160, Val Loss: 0.6260
Epoch [35/120], Loss: 0.2651, Val Loss: 0.5734
Epoch [36/120], Loss: 0.3911, Val Loss: 0.5240
Epoch [37/120], Loss: 0.2188, Val Loss: 0.6460
Epoch [38/120], Loss: 0.1345, Val Loss: 0.5125
Epoch [39/120], Loss: 0.6654, Val Loss: 0.5678
Epoch [40/120], Loss: 0.5944, Val Loss: 0.5878
Epoch [41/120], Loss: 0.1469, Val Loss: 0.5219
Epoch [42/120], Loss: 0.4255, Val Loss: 0.5176
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2696, Val Loss: 0.5631
Epoch [2/120], Loss: 0.3278, Val Loss: 0.5198
Epoch [3/120], Loss: 0.0628, Val Loss: 0.5447
Epoch [4/120], Loss: 0.6980, Val Loss: 0.4794
Epoch [5/120], Loss: 0.3301, Val Loss: 0.6073
Epoch [6/120], Loss: 0.2419, Val Loss: 0.5617
Epoch [7/120], Loss: 0.0856, Val Loss: 0.6248
Epoch [8/120], Loss: 0.1228, Val Loss: 0.5095
Epoch [9/120], Loss: 0.1163, Val Loss: 0.5568
Epoch [10/120], Loss: 0.7091, Val Loss: 0.5007
Epoch [11/120], Loss: 0.1738, Val Loss: 0.5184
Epoch [12/120], Loss: 0.0879, Val Loss: 0.5231
Epoch [13/120], Loss: 0.1253, Val Loss: 0.5274
Epoch [14/120], Loss: 0.0383, Val Loss: 0.5337
Epoch [15/120], Loss: 0.0750, Val Loss: 0.4823
Epoch [16/120], Loss: 0.4384, Val Loss: 0.5152
Epoch [17/120], Loss: 0.6583, Val Loss: 0.4953
Epoch [18/120], Loss: 0.1678, Val Loss: 0.5747
Epoch [19/120], Loss: 0.7504, Val Loss: 0.5149
Epoch [20/120], Loss: 0.5836, Val Loss: 0.5559
Epoch [21/120], Loss: 0.1007, Val Loss: 0.5006
Epoch [22/120], Loss: 0.3929, Val Loss: 0.4698
Epoch [23/120], Loss: 0.0861, Val Loss: 0.5608
Epoch [24/120], Loss: 0.2632, Val Loss: 0.4982
Epoch [25/120], Loss: 0.0528, Val Loss: 0.5852
Epoch [26/120], Loss: 0.2036, Val Loss: 0.5636
Epoch [27/120], Loss: 0.1243, Val Loss: 0.5243
Epoch [28/120], Loss: 0.0902, Val Loss: 0.5353
Epoch [29/120], Loss: 0.1437, Val Loss: 0.5242
Epoch [30/120], Loss: 0.0499, Val Loss: 0.5163
Epoch [31/120], Loss: 0.6445, Val Loss: 0.4942
Epoch [32/120], Loss: 0.2432, Val Loss: 0.5562
Epoch [33/120], Loss: 0.7414, Val Loss: 0.5270
Epoch [34/120], Loss: 0.0821, Val Loss: 0.5291
Epoch [35/120], Loss: 0.2939, Val Loss: 0.6221
Epoch [36/120], Loss: 0.2923, Val Loss: 0.5068
Epoch [37/120], Loss: 0.1209, Val Loss: 0.5440
Epoch [38/120], Loss: 0.1380, Val Loss: 0.5173
Epoch [39/120], Loss: 0.2343, Val Loss: 0.5102
Epoch [40/120], Loss: 0.3007, Val Loss: 0.5956
Epoch [41/120], Loss: 0.1635, Val Loss: 0.4872
Epoch [42/120], Loss: 0.1959, Val Loss: 0.5575
Epoch [43/120], Loss: 0.0533, Val Loss: 0.5085
Epoch [44/120], Loss: 1.5447, Val Loss: 0.6237
Epoch [45/120], Loss: 0.3900, Val Loss: 0.5061
Epoch [46/120], Loss: 0.1258, Val Loss: 0.5437
Epoch [47/120], Loss: 0.0771, Val Loss: 0.5292
Epoch [48/120], Loss: 0.1868, Val Loss: 0.5225
Epoch [49/120], Loss: 0.1820, Val Loss: 0.5218
Epoch [50/120], Loss: 0.0444, Val Loss: 0.5082
Epoch [51/120], Loss: 0.0727, Val Loss: 0.5183
Early stopping at epoch 51
Runtime: 0:00:25.842956
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.3416, Val Loss: 1.0797
Epoch [2/120], Loss: 0.4310, Val Loss: 0.9996
Epoch [3/120], Loss: 2.9934, Val Loss: 0.8163
Epoch [4/120], Loss: 1.3663, Val Loss: 0.8676
Epoch [5/120], Loss: 0.4060, Val Loss: 0.7554
Epoch [6/120], Loss: 1.6244, Val Loss: 0.7919
Epoch [7/120], Loss: 0.7644, Val Loss: 0.7038
Epoch [8/120], Loss: 0.3214, Val Loss: 0.7206
Epoch [9/120], Loss: 0.6861, Val Loss: 0.8096
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0935, Val Loss: 0.7317
Epoch [2/120], Loss: 0.2765, Val Loss: 0.6963
Epoch [3/120], Loss: 0.5592, Val Loss: 0.7141
Epoch [4/120], Loss: 0.2018, Val Loss: 0.6377
Epoch [5/120], Loss: 0.2160, Val Loss: 0.6374
Epoch [6/120], Loss: 0.4342, Val Loss: 0.6235
Epoch [7/120], Loss: 0.4338, Val Loss: 0.6567
Epoch [8/120], Loss: 1.5204, Val Loss: 0.7333
Epoch [9/120], Loss: 0.0788, Val Loss: 0.6500
Epoch [10/120], Loss: 0.7689, Val Loss: 0.6243
Epoch [11/120], Loss: 0.7012, Val Loss: 0.7306
Epoch [12/120], Loss: 0.3219, Val Loss: 0.6251
Epoch [13/120], Loss: 0.4699, Val Loss: 0.5895
Epoch [14/120], Loss: 0.3198, Val Loss: 0.5497
Epoch [15/120], Loss: 0.1271, Val Loss: 0.6889
Epoch [16/120], Loss: 0.4313, Val Loss: 0.6319
Epoch [17/120], Loss: 0.5376, Val Loss: 0.6860
Epoch [18/120], Loss: 0.1123, Val Loss: 0.6486
Epoch [19/120], Loss: 0.0627, Val Loss: 0.5510
Epoch [20/120], Loss: 0.2845, Val Loss: 0.5548
Epoch [21/120], Loss: 0.4602, Val Loss: 0.6345
Epoch [22/120], Loss: 0.2769, Val Loss: 0.5162
Epoch [23/120], Loss: 0.1434, Val Loss: 0.5350
Epoch [24/120], Loss: 0.2448, Val Loss: 0.5909
Epoch [25/120], Loss: 0.1579, Val Loss: 0.6392
Epoch [26/120], Loss: 1.0008, Val Loss: 0.5125
Epoch [27/120], Loss: 0.2620, Val Loss: 0.6177
Epoch [28/120], Loss: 0.1328, Val Loss: 0.6059
Epoch [29/120], Loss: 0.3485, Val Loss: 0.5845
Epoch [30/120], Loss: 0.0825, Val Loss: 0.5591
Epoch [31/120], Loss: 0.0944, Val Loss: 0.6445
Epoch [32/120], Loss: 0.3267, Val Loss: 0.5972
Epoch [33/120], Loss: 0.1911, Val Loss: 0.6211
Epoch [34/120], Loss: 0.3912, Val Loss: 0.5585
Epoch [35/120], Loss: 0.1157, Val Loss: 0.5822
Epoch [36/120], Loss: 0.0530, Val Loss: 0.5555
Epoch [37/120], Loss: 0.2910, Val Loss: 0.5645
Epoch [38/120], Loss: 0.3281, Val Loss: 0.5928
Epoch [39/120], Loss: 0.1014, Val Loss: 0.5387
Epoch [40/120], Loss: 0.5081, Val Loss: 0.6108
Epoch [41/120], Loss: 0.1114, Val Loss: 0.5415
Epoch [42/120], Loss: 0.0761, Val Loss: 0.6244
Epoch [43/120], Loss: 0.2651, Val Loss: 0.5690
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 1.4979, Val Loss: 0.9540
Epoch [2/120], Loss: 0.3428, Val Loss: 0.8359
Epoch [3/120], Loss: 0.1593, Val Loss: 0.7964
Epoch [4/120], Loss: 0.2345, Val Loss: 0.7830
Epoch [5/120], Loss: 0.3800, Val Loss: 0.8097
Epoch [6/120], Loss: 0.2477, Val Loss: 0.7232
Epoch [7/120], Loss: 0.2861, Val Loss: 0.8028
Epoch [8/120], Loss: 0.8573, Val Loss: 0.6888
Epoch [9/120], Loss: 0.2204, Val Loss: 0.6603
Epoch [10/120], Loss: 0.1788, Val Loss: 0.6329
Epoch [11/120], Loss: 0.8192, Val Loss: 0.5901
Epoch [12/120], Loss: 0.3597, Val Loss: 0.6205
Epoch [13/120], Loss: 0.4244, Val Loss: 0.5940
Epoch [14/120], Loss: 0.2118, Val Loss: 0.5688
Epoch [15/120], Loss: 0.8282, Val Loss: 0.7684
Epoch [16/120], Loss: 0.1715, Val Loss: 0.5876
Epoch [17/120], Loss: 0.1490, Val Loss: 0.5807
Epoch [18/120], Loss: 0.1454, Val Loss: 0.5496
Epoch [19/120], Loss: 0.4304, Val Loss: 0.6294
Epoch [20/120], Loss: 0.1236, Val Loss: 0.5453
Epoch [21/120], Loss: 0.1209, Val Loss: 0.5318
Epoch [22/120], Loss: 0.4131, Val Loss: 0.5848
Epoch [23/120], Loss: 0.0880, Val Loss: 0.5432
Epoch [24/120], Loss: 0.3839, Val Loss: 0.5643
Epoch [25/120], Loss: 0.1450, Val Loss: 0.6270
Epoch [26/120], Loss: 0.7118, Val Loss: 0.5288
Epoch [27/120], Loss: 0.1132, Val Loss: 0.5347
Epoch [28/120], Loss: 0.6472, Val Loss: 0.4973
Epoch [29/120], Loss: 0.2070, Val Loss: 0.6471
Epoch [30/120], Loss: 0.1254, Val Loss: 0.5673
Epoch [31/120], Loss: 0.1911, Val Loss: 0.6565
Epoch [32/120], Loss: 0.1209, Val Loss: 0.5498
Epoch [33/120], Loss: 0.0761, Val Loss: 0.5611
Epoch [34/120], Loss: 0.2053, Val Loss: 0.6468
Epoch [35/120], Loss: 0.1579, Val Loss: 0.4884
Epoch [36/120], Loss: 0.4336, Val Loss: 0.5461
Epoch [37/120], Loss: 0.2772, Val Loss: 0.5682
Epoch [38/120], Loss: 0.2198, Val Loss: 0.5160
Epoch [39/120], Loss: 0.0979, Val Loss: 0.5139
Epoch [40/120], Loss: 0.3082, Val Loss: 0.5434
Epoch [41/120], Loss: 0.0921, Val Loss: 0.5039
Epoch [42/120], Loss: 0.2985, Val Loss: 0.5362
Epoch [43/120], Loss: 0.1568, Val Loss: 0.4922
Epoch [44/120], Loss: 0.0861, Val Loss: 0.4924
Epoch [45/120], Loss: 0.1471, Val Loss: 0.5638
Epoch [46/120], Loss: 0.1845, Val Loss: 0.4983
Epoch [47/120], Loss: 0.1205, Val Loss: 0.5185
Epoch [48/120], Loss: 0.1524, Val Loss: 0.6319
Epoch [49/120], Loss: 0.8208, Val Loss: 0.6014
Epoch [50/120], Loss: 0.1941, Val Loss: 0.5028
Epoch [51/120], Loss: 0.2722, Val Loss: 0.5284
Epoch [52/120], Loss: 0.1511, Val Loss: 0.5492
Epoch [53/120], Loss: 0.3385, Val Loss: 0.5539
Epoch [54/120], Loss: 0.1177, Val Loss: 0.5127
Epoch [55/120], Loss: 0.4752, Val Loss: 0.5177
Epoch [56/120], Loss: 0.9915, Val Loss: 0.5974
Epoch [57/120], Loss: 0.2058, Val Loss: 0.5387
Epoch [58/120], Loss: 0.1138, Val Loss: 0.5582
Epoch [59/120], Loss: 0.0629, Val Loss: 0.4998
Epoch [60/120], Loss: 0.2435, Val Loss: 0.5662
Epoch [61/120], Loss: 0.0646, Val Loss: 0.4522
Epoch [62/120], Loss: 0.0825, Val Loss: 0.4526
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.4288, Val Loss: 1.0981
Epoch [2/120], Loss: 0.2610, Val Loss: 0.6614
Epoch [3/120], Loss: 0.0718, Val Loss: 0.4778
Epoch [4/120], Loss: 0.3002, Val Loss: 0.6198
Epoch [5/120], Loss: 0.1159, Val Loss: 0.5216
Epoch [6/120], Loss: 0.0938, Val Loss: 0.5082
Epoch [7/120], Loss: 0.4331, Val Loss: 0.6857
Epoch [8/120], Loss: 0.6192, Val Loss: 0.5703
Epoch [9/120], Loss: 0.1614, Val Loss: 0.5281
Epoch [10/120], Loss: 0.1081, Val Loss: 0.4908
Epoch [11/120], Loss: 0.8237, Val Loss: 0.6202
Epoch [12/120], Loss: 0.1057, Val Loss: 0.4686
Epoch [13/120], Loss: 0.1338, Val Loss: 0.7624
Epoch [14/120], Loss: 0.8552, Val Loss: 0.4709
Epoch [15/120], Loss: 0.1749, Val Loss: 0.4987
Epoch [16/120], Loss: 0.1058, Val Loss: 0.4429
Epoch [17/120], Loss: 0.1689, Val Loss: 0.6078
Epoch [18/120], Loss: 0.0662, Val Loss: 0.4315
Epoch [19/120], Loss: 0.8259, Val Loss: 0.4618
Epoch [20/120], Loss: 0.2651, Val Loss: 0.4796
Epoch [21/120], Loss: 0.2918, Val Loss: 0.5323
Epoch [22/120], Loss: 0.3420, Val Loss: 0.5381
Epoch [23/120], Loss: 0.1118, Val Loss: 0.4767
Epoch [24/120], Loss: 0.0923, Val Loss: 0.5786
Epoch [25/120], Loss: 0.0920, Val Loss: 0.5122
Epoch [26/120], Loss: 0.0779, Val Loss: 0.5217
Epoch [27/120], Loss: 0.0968, Val Loss: 0.5244
Epoch [28/120], Loss: 0.2467, Val Loss: 0.5226
Epoch [29/120], Loss: 0.2987, Val Loss: 0.4572
Epoch [30/120], Loss: 0.7373, Val Loss: 0.4630
Epoch [31/120], Loss: 0.7467, Val Loss: 0.5254
Epoch [32/120], Loss: 0.0962, Val Loss: 0.4843
Epoch [33/120], Loss: 0.0872, Val Loss: 0.5328
Epoch [34/120], Loss: 0.0478, Val Loss: 0.4745
Epoch [35/120], Loss: 0.0601, Val Loss: 0.5038
Epoch [36/120], Loss: 0.1710, Val Loss: 0.4740
Epoch [37/120], Loss: 0.0467, Val Loss: 0.4551
Epoch [38/120], Loss: 0.2911, Val Loss: 0.4676
Epoch [39/120], Loss: 0.4212, Val Loss: 0.4526
Epoch [40/120], Loss: 0.1839, Val Loss: 0.4835
Epoch [41/120], Loss: 0.1548, Val Loss: 0.4790
Epoch [42/120], Loss: 0.0503, Val Loss: 0.4379
Epoch [43/120], Loss: 0.0652, Val Loss: 0.4204
Epoch [44/120], Loss: 0.0521, Val Loss: 0.4682
Epoch [45/120], Loss: 0.1798, Val Loss: 0.4606
Epoch [46/120], Loss: 0.0591, Val Loss: 0.4761
Epoch [47/120], Loss: 0.0565, Val Loss: 0.4608
Epoch [48/120], Loss: 0.1570, Val Loss: 0.4961
Epoch [49/120], Loss: 0.0756, Val Loss: 0.5213
Epoch [50/120], Loss: 0.1283, Val Loss: 0.4855
Epoch [51/120], Loss: 0.5027, Val Loss: 0.4733
Epoch [52/120], Loss: 0.1616, Val Loss: 0.4389
Epoch [53/120], Loss: 0.1394, Val Loss: 0.5577
Epoch [54/120], Loss: 0.1092, Val Loss: 0.4775
Epoch [55/120], Loss: 0.2564, Val Loss: 0.4251
Epoch [56/120], Loss: 0.4106, Val Loss: 0.4676
Epoch [57/120], Loss: 0.1696, Val Loss: 0.4593
Epoch [58/120], Loss: 0.1183, Val Loss: 0.4330
Epoch [59/120], Loss: 0.0613, Val Loss: 0.4777
Epoch [60/120], Loss: 0.2233, Val Loss: 0.4976
Epoch [61/120], Loss: 0.1112, Val Loss: 0.4456
Epoch [62/120], Loss: 0.0636, Val Loss: 0.4734
Epoch [63/120], Loss: 0.4093, Val Loss: 0.5198
Epoch [64/120], Loss: 0.0805, Val Loss: 0.4667
Epoch [65/120], Loss: 0.3895, Val Loss: 0.4763
Epoch [66/120], Loss: 0.1518, Val Loss: 0.4672
Epoch [67/120], Loss: 0.0448, Val Loss: 0.4341
Epoch [68/120], Loss: 0.0985, Val Loss: 0.4538
Epoch [69/120], Loss: 0.1093, Val Loss: 0.4380
Epoch [70/120], Loss: 0.2070, Val Loss: 0.4442
Epoch [71/120], Loss: 0.2458, Val Loss: 0.4537
Epoch [72/120], Loss: 0.2858, Val Loss: 0.4488
Epoch [73/120], Loss: 0.1145, Val Loss: 0.4720
Epoch [74/120], Loss: 0.3180, Val Loss: 0.4575
Epoch [75/120], Loss: 0.2696, Val Loss: 0.4455
Epoch [76/120], Loss: 0.2776, Val Loss: 0.4343
Epoch [77/120], Loss: 0.3676, Val Loss: 0.4488
Epoch [78/120], Loss: 0.1478, Val Loss: 0.4623
Epoch [79/120], Loss: 0.1014, Val Loss: 0.4638
Epoch [80/120], Loss: 0.0737, Val Loss: 0.5019
Epoch [81/120], Loss: 0.1065, Val Loss: 0.4235
Epoch [82/120], Loss: 0.1883, Val Loss: 0.4247
Epoch [83/120], Loss: 0.0628, Val Loss: 0.4452
Epoch [84/120], Loss: 0.1906, Val Loss: 0.4291
Epoch [85/120], Loss: 0.0679, Val Loss: 0.4488
Epoch [86/120], Loss: 0.1208, Val Loss: 0.4332
Epoch [87/120], Loss: 0.3210, Val Loss: 0.4857
Epoch [88/120], Loss: 0.0737, Val Loss: 0.4444
Epoch [89/120], Loss: 0.0873, Val Loss: 0.4121
Epoch [90/120], Loss: 0.4340, Val Loss: 0.4316
Epoch [91/120], Loss: 0.0502, Val Loss: 0.5258
Epoch [92/120], Loss: 0.4072, Val Loss: 0.5200
Epoch [93/120], Loss: 0.1489, Val Loss: 0.4361
Epoch [94/120], Loss: 0.1636, Val Loss: 0.4938
Epoch [95/120], Loss: 0.1017, Val Loss: 0.5594
Epoch [96/120], Loss: 0.0683, Val Loss: 0.4368
Epoch [97/120], Loss: 1.1728, Val Loss: 0.4343
Epoch [98/120], Loss: 0.2902, Val Loss: 0.4570
Epoch [99/120], Loss: 0.0817, Val Loss: 0.4524
Epoch [100/120], Loss: 0.0679, Val Loss: 0.4956
Epoch [101/120], Loss: 0.0912, Val Loss: 0.4249
Epoch [102/120], Loss: 0.1743, Val Loss: 0.4751
Epoch [103/120], Loss: 0.1157, Val Loss: 0.4354
Epoch [104/120], Loss: 0.4427, Val Loss: 0.4280
Epoch [105/120], Loss: 0.0855, Val Loss: 0.4185
Epoch [106/120], Loss: 0.4923, Val Loss: 0.4524
Epoch [107/120], Loss: 0.0826, Val Loss: 0.4378
Epoch [108/120], Loss: 0.1366, Val Loss: 0.4196
Epoch [109/120], Loss: 0.1583, Val Loss: 0.4596
Epoch [110/120], Loss: 0.3279, Val Loss: 0.4425
Epoch [111/120], Loss: 0.1625, Val Loss: 0.4480
Epoch [112/120], Loss: 0.0866, Val Loss: 0.4399
Epoch [113/120], Loss: 0.4763, Val Loss: 0.4541
Epoch [114/120], Loss: 0.0836, Val Loss: 0.4546
Epoch [115/120], Loss: 0.0662, Val Loss: 0.4488
Epoch [116/120], Loss: 0.0653, Val Loss: 0.4392
Epoch [117/120], Loss: 0.2076, Val Loss: 0.4382
Epoch [118/120], Loss: 0.0474, Val Loss: 0.4638
Early stopping at epoch 118
Runtime: 0:03:01.910101
R^2 Score: 0.9283
RMSE: 0.6157
MAE: 0.2100
MAPE: 19.41%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0652, Val Loss: 0.3427
Epoch [2/120], Loss: 0.1120, Val Loss: 0.3438
Epoch [3/120], Loss: 0.0771, Val Loss: 0.3559
Epoch [4/120], Loss: 0.3622, Val Loss: 0.3359
Epoch [5/120], Loss: 0.1791, Val Loss: 0.3300
Epoch [6/120], Loss: 2.2837, Val Loss: 0.3529
Epoch [7/120], Loss: 0.0718, Val Loss: 0.3820
Epoch [8/120], Loss: 0.2833, Val Loss: 0.3618
Epoch [9/120], Loss: 0.1335, Val Loss: 0.3745
Epoch [10/120], Loss: 0.2404, Val Loss: 0.3632
Epoch [11/120], Loss: 0.0614, Val Loss: 0.3390
Epoch [12/120], Loss: 0.1649, Val Loss: 0.3531
Epoch [13/120], Loss: 0.0662, Val Loss: 0.3430
Epoch [14/120], Loss: 0.1417, Val Loss: 0.3496
Epoch [15/120], Loss: 0.0913, Val Loss: 0.3281
Epoch [16/120], Loss: 1.0890, Val Loss: 0.3294
Epoch [17/120], Loss: 0.1344, Val Loss: 0.3480
Epoch [18/120], Loss: 0.0935, Val Loss: 0.3335
Epoch [19/120], Loss: 0.1093, Val Loss: 0.3284
Epoch [20/120], Loss: 0.3639, Val Loss: 0.4015
Epoch [21/120], Loss: 0.0697, Val Loss: 0.3385
Epoch [22/120], Loss: 0.0669, Val Loss: 0.3493
Epoch [23/120], Loss: 0.2234, Val Loss: 0.3563
Epoch [24/120], Loss: 0.1009, Val Loss: 0.3578
Epoch [25/120], Loss: 0.0810, Val Loss: 0.3417
Epoch [26/120], Loss: 0.0792, Val Loss: 0.3705
Epoch [27/120], Loss: 0.0575, Val Loss: 0.3143
Epoch [28/120], Loss: 0.0818, Val Loss: 0.3330
Epoch [29/120], Loss: 0.0643, Val Loss: 0.3358
Epoch [30/120], Loss: 0.1369, Val Loss: 0.3077
Epoch [31/120], Loss: 0.0710, Val Loss: 0.3350
Epoch [32/120], Loss: 0.0904, Val Loss: 0.3342
Epoch [33/120], Loss: 0.1293, Val Loss: 0.3446
Epoch [34/120], Loss: 0.3275, Val Loss: 0.3238
Epoch [35/120], Loss: 0.3430, Val Loss: 0.3372
Epoch [36/120], Loss: 0.6049, Val Loss: 0.3388
Epoch [37/120], Loss: 0.1159, Val Loss: 0.4309
Epoch [38/120], Loss: 0.2813, Val Loss: 0.3455
Epoch [39/120], Loss: 0.1393, Val Loss: 0.3670
Epoch [40/120], Loss: 0.0759, Val Loss: 0.3394
Epoch [41/120], Loss: 0.1393, Val Loss: 0.3384
Epoch [42/120], Loss: 0.1616, Val Loss: 0.3526
Epoch [43/120], Loss: 0.0801, Val Loss: 0.3405
Epoch [44/120], Loss: 0.1531, Val Loss: 0.3135
Epoch [45/120], Loss: 0.2066, Val Loss: 0.3159
Epoch [46/120], Loss: 0.0908, Val Loss: 0.3203
Epoch [47/120], Loss: 0.1021, Val Loss: 0.3245
Epoch [48/120], Loss: 0.2351, Val Loss: 0.3324
Epoch [49/120], Loss: 0.0754, Val Loss: 0.3997
Epoch [50/120], Loss: 0.3455, Val Loss: 0.3252
Epoch [51/120], Loss: 0.1295, Val Loss: 0.3417
Epoch [52/120], Loss: 0.1701, Val Loss: 0.3192
Epoch [53/120], Loss: 0.0508, Val Loss: 0.3516
Epoch [54/120], Loss: 0.0563, Val Loss: 0.3257
Epoch [55/120], Loss: 0.1363, Val Loss: 0.3736
Epoch [56/120], Loss: 0.1663, Val Loss: 0.3393
Epoch [57/120], Loss: 0.0834, Val Loss: 0.3554
Epoch [58/120], Loss: 0.1233, Val Loss: 0.3286
Epoch [59/120], Loss: 0.0426, Val Loss: 0.3698
Epoch [60/120], Loss: 0.1222, Val Loss: 0.3515
Epoch [61/120], Loss: 0.1314, Val Loss: 0.3291
Epoch [62/120], Loss: 0.0984, Val Loss: 0.3426
Epoch [63/120], Loss: 0.1308, Val Loss: 0.3429
Epoch [64/120], Loss: 0.0794, Val Loss: 0.3356
Epoch [65/120], Loss: 0.0946, Val Loss: 0.3541
Epoch [66/120], Loss: 0.4471, Val Loss: 0.3533
Epoch [67/120], Loss: 0.1046, Val Loss: 0.3328
Epoch [68/120], Loss: 0.1771, Val Loss: 0.3679
Epoch [69/120], Loss: 0.2399, Val Loss: 0.3485
Epoch [70/120], Loss: 0.0734, Val Loss: 0.3502
Epoch [71/120], Loss: 0.2430, Val Loss: 0.3333
Epoch [72/120], Loss: 0.1113, Val Loss: 0.3562
Epoch [73/120], Loss: 0.0909, Val Loss: 0.3586
Early stopping at epoch 73
Runtime: 0:00:35.518982
R^2 Score: 0.9637
RMSE: 0.3731
MAE: 0.1473
MAPE: 13.77%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2437, Val Loss: 0.3375
Epoch [2/120], Loss: 0.3585, Val Loss: 0.3560
Epoch [3/120], Loss: 0.3914, Val Loss: 0.3362
Epoch [4/120], Loss: 0.1543, Val Loss: 0.3491
Epoch [5/120], Loss: 0.3479, Val Loss: 0.3615
Epoch [6/120], Loss: 0.1128, Val Loss: 0.3445
Epoch [7/120], Loss: 0.2171, Val Loss: 0.3508
Epoch [8/120], Loss: 0.0585, Val Loss: 0.3339
Epoch [9/120], Loss: 0.1170, Val Loss: 0.3428
Epoch [10/120], Loss: 0.0704, Val Loss: 0.3393
Epoch [11/120], Loss: 0.0614, Val Loss: 0.3512
Epoch [12/120], Loss: 0.0715, Val Loss: 0.3466
Epoch [13/120], Loss: 0.1070, Val Loss: 0.3388
Epoch [14/120], Loss: 0.2131, Val Loss: 0.3588
Epoch [15/120], Loss: 0.1915, Val Loss: 0.3820
Epoch [16/120], Loss: 0.2337, Val Loss: 0.4022
Epoch [17/120], Loss: 0.1798, Val Loss: 0.3668
Epoch [18/120], Loss: 0.1289, Val Loss: 0.3727
Epoch [19/120], Loss: 0.1071, Val Loss: 0.4194
Epoch [20/120], Loss: 0.2150, Val Loss: 0.4262
Epoch [21/120], Loss: 0.3005, Val Loss: 0.4163
Epoch [22/120], Loss: 0.6579, Val Loss: 0.3669
Epoch [23/120], Loss: 0.1716, Val Loss: 0.3787
Epoch [24/120], Loss: 0.3145, Val Loss: 0.3660
Epoch [25/120], Loss: 0.3275, Val Loss: 0.4201
Epoch [26/120], Loss: 0.1383, Val Loss: 0.3720
Epoch [27/120], Loss: 0.1355, Val Loss: 0.3855
Epoch [28/120], Loss: 0.1424, Val Loss: 0.3330
Epoch [29/120], Loss: 0.0512, Val Loss: 0.3551
Epoch [30/120], Loss: 0.1281, Val Loss: 0.3379
Epoch [31/120], Loss: 0.1207, Val Loss: 0.3416
Epoch [32/120], Loss: 0.0373, Val Loss: 0.3452
Epoch [33/120], Loss: 0.1745, Val Loss: 0.3439
Epoch [34/120], Loss: 0.0783, Val Loss: 0.3388
Epoch [35/120], Loss: 0.0949, Val Loss: 0.3249
Epoch [36/120], Loss: 0.1161, Val Loss: 0.3489
Epoch [37/120], Loss: 0.2777, Val Loss: 0.3584
Epoch [38/120], Loss: 0.0795, Val Loss: 0.3602
Epoch [39/120], Loss: 0.1440, Val Loss: 0.3584
Epoch [40/120], Loss: 0.1366, Val Loss: 0.3514
Epoch [41/120], Loss: 0.0821, Val Loss: 0.3493
Epoch [42/120], Loss: 0.0816, Val Loss: 0.3298
Epoch [43/120], Loss: 0.0379, Val Loss: 0.3634
Epoch [44/120], Loss: 0.0750, Val Loss: 0.3551
Epoch [45/120], Loss: 0.0739, Val Loss: 0.3559
Epoch [46/120], Loss: 0.4226, Val Loss: 0.3607
Epoch [47/120], Loss: 0.4042, Val Loss: 0.3676
Epoch [48/120], Loss: 0.0577, Val Loss: 0.3753
Epoch [49/120], Loss: 0.1059, Val Loss: 0.3566
Epoch [50/120], Loss: 0.1865, Val Loss: 0.3757
Epoch [51/120], Loss: 0.2384, Val Loss: 0.3607
Epoch [52/120], Loss: 0.1204, Val Loss: 0.3681
Epoch [53/120], Loss: 0.3322, Val Loss: 0.3560
Epoch [54/120], Loss: 0.0942, Val Loss: 0.3650
Epoch [55/120], Loss: 0.1070, Val Loss: 0.3733
Epoch [56/120], Loss: 0.0729, Val Loss: 0.3571
Epoch [57/120], Loss: 0.1849, Val Loss: 0.3586
Epoch [58/120], Loss: 0.0860, Val Loss: 0.3744
Epoch [59/120], Loss: 0.3085, Val Loss: 0.3418
Epoch [60/120], Loss: 0.0835, Val Loss: 0.3603
Epoch [61/120], Loss: 0.0591, Val Loss: 0.4194
Epoch [62/120], Loss: 0.0722, Val Loss: 0.3781
Epoch [63/120], Loss: 0.1252, Val Loss: 0.3899
Epoch [64/120], Loss: 0.0901, Val Loss: 0.3690
Epoch [65/120], Loss: 0.0507, Val Loss: 0.4090
Epoch [66/120], Loss: 0.2349, Val Loss: 0.3817
Epoch [67/120], Loss: 0.0768, Val Loss: 0.3839
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0646, Val Loss: 0.3676
Epoch [2/120], Loss: 0.0771, Val Loss: 0.3760
Epoch [3/120], Loss: 0.1144, Val Loss: 0.3824
Epoch [4/120], Loss: 0.3965, Val Loss: 0.3620
Epoch [5/120], Loss: 0.3292, Val Loss: 0.4210
Epoch [6/120], Loss: 0.1337, Val Loss: 0.3599
Epoch [7/120], Loss: 0.0598, Val Loss: 0.3666
Epoch [8/120], Loss: 0.0717, Val Loss: 0.3560
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.7506, Val Loss: 1.0429
Epoch [2/120], Loss: 0.3237, Val Loss: 0.8998
Epoch [3/120], Loss: 2.0496, Val Loss: 0.7965
Epoch [4/120], Loss: 0.3423, Val Loss: 0.7426
Epoch [5/120], Loss: 0.8023, Val Loss: 0.7397
Epoch [6/120], Loss: 0.2889, Val Loss: 0.7196
Epoch [7/120], Loss: 0.3380, Val Loss: 0.7018
Epoch [8/120], Loss: 0.3039, Val Loss: 0.7383
Epoch [9/120], Loss: 0.1062, Val Loss: 0.6633
Epoch [10/120], Loss: 0.1003, Val Loss: 0.6484
Epoch [11/120], Loss: 0.0864, Val Loss: 0.6671
Epoch [12/120], Loss: 0.9688, Val Loss: 0.6954
Epoch [13/120], Loss: 1.4562, Val Loss: 0.6898
Epoch [14/120], Loss: 0.1498, Val Loss: 0.6286
Epoch [15/120], Loss: 0.1886, Val Loss: 0.6388
Epoch [16/120], Loss: 0.3950, Val Loss: 0.6401
Epoch [17/120], Loss: 0.4219, Val Loss: 0.6833
Epoch [18/120], Loss: 0.0905, Val Loss: 0.5583
Epoch [19/120], Loss: 0.1524, Val Loss: 0.5791
Epoch [20/120], Loss: 0.1371, Val Loss: 0.5866
Epoch [21/120], Loss: 0.1736, Val Loss: 0.5782
Epoch [22/120], Loss: 0.3488, Val Loss: 0.5382
Epoch [23/120], Loss: 0.2524, Val Loss: 0.5593
Epoch [24/120], Loss: 0.1287, Val Loss: 0.5933
Epoch [25/120], Loss: 0.0965, Val Loss: 0.6412
Epoch [26/120], Loss: 0.1269, Val Loss: 0.6370
Epoch [27/120], Loss: 0.0758, Val Loss: 0.5480
Epoch [28/120], Loss: 0.3284, Val Loss: 0.5394
Epoch [29/120], Loss: 0.0776, Val Loss: 0.5075
Epoch [30/120], Loss: 0.1484, Val Loss: 0.5191
Epoch [31/120], Loss: 0.8016, Val Loss: 0.5223
Epoch [32/120], Loss: 0.3512, Val Loss: 0.5469
Epoch [33/120], Loss: 0.1786, Val Loss: 0.5402
Epoch [34/120], Loss: 0.1835, Val Loss: 0.5329
Epoch [35/120], Loss: 0.1199, Val Loss: 0.5367
Epoch [36/120], Loss: 0.1031, Val Loss: 0.5623
Epoch [37/120], Loss: 0.0684, Val Loss: 0.5683
Epoch [38/120], Loss: 0.5662, Val Loss: 0.6441
Epoch [39/120], Loss: 0.1879, Val Loss: 0.5960
Epoch [40/120], Loss: 0.3771, Val Loss: 0.5349
Epoch [41/120], Loss: 0.2537, Val Loss: 0.4970
Epoch [42/120], Loss: 0.1253, Val Loss: 0.5311
Epoch [43/120], Loss: 0.2253, Val Loss: 0.6244
Epoch [44/120], Loss: 0.2056, Val Loss: 0.5856
Epoch [45/120], Loss: 0.1394, Val Loss: 0.6086
Epoch [46/120], Loss: 0.0767, Val Loss: 0.7266
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1000, Val Loss: 0.4945
Epoch [2/120], Loss: 0.1434, Val Loss: 0.5146
Epoch [3/120], Loss: 0.3957, Val Loss: 0.5761
Epoch [4/120], Loss: 0.1531, Val Loss: 0.5119
Epoch [5/120], Loss: 0.1283, Val Loss: 0.4929
Epoch [6/120], Loss: 0.3803, Val Loss: 0.4971
Epoch [7/120], Loss: 0.7266, Val Loss: 0.5029
Epoch [8/120], Loss: 0.1028, Val Loss: 0.4868
Epoch [9/120], Loss: 0.1088, Val Loss: 0.5031
Epoch [10/120], Loss: 0.0708, Val Loss: 0.4677
Epoch [11/120], Loss: 0.3652, Val Loss: 0.6116
Epoch [12/120], Loss: 0.0797, Val Loss: 0.5200
Epoch [13/120], Loss: 0.0570, Val Loss: 0.5962
Epoch [14/120], Loss: 0.1595, Val Loss: 0.5998
Epoch [15/120], Loss: 0.1232, Val Loss: 0.5475
Epoch [16/120], Loss: 0.2064, Val Loss: 0.4738
Epoch [17/120], Loss: 0.1026, Val Loss: 0.4940
Epoch [18/120], Loss: 0.2206, Val Loss: 0.4901
Epoch [19/120], Loss: 0.2276, Val Loss: 0.5406
Epoch [20/120], Loss: 0.2354, Val Loss: 0.5418
Epoch [21/120], Loss: 1.7474, Val Loss: 0.5484
Epoch [22/120], Loss: 0.0757, Val Loss: 0.5117
Epoch [23/120], Loss: 0.3572, Val Loss: 0.5418
Epoch [24/120], Loss: 0.1348, Val Loss: 0.4981
Epoch [25/120], Loss: 0.0934, Val Loss: 0.6266
Epoch [26/120], Loss: 0.1872, Val Loss: 0.5911
Epoch [27/120], Loss: 0.1601, Val Loss: 0.5164
Epoch [28/120], Loss: 1.6551, Val Loss: 0.5665
Epoch [29/120], Loss: 0.4099, Val Loss: 0.5601
Epoch [30/120], Loss: 0.2184, Val Loss: 0.5206
Epoch [31/120], Loss: 0.2702, Val Loss: 0.5053
Epoch [32/120], Loss: 0.6083, Val Loss: 0.4700
Epoch [33/120], Loss: 0.1777, Val Loss: 0.5377
Epoch [34/120], Loss: 0.1414, Val Loss: 0.4895
Epoch [35/120], Loss: 0.1222, Val Loss: 0.5364
Epoch [36/120], Loss: 0.2305, Val Loss: 0.4892
Epoch [37/120], Loss: 0.1560, Val Loss: 0.5551
Epoch [38/120], Loss: 0.1705, Val Loss: 0.5189
Epoch [39/120], Loss: 0.0806, Val Loss: 0.4843
Epoch [40/120], Loss: 0.0638, Val Loss: 0.5181
Epoch [41/120], Loss: 0.0962, Val Loss: 0.4817
Epoch [42/120], Loss: 0.0807, Val Loss: 0.4829
Epoch [43/120], Loss: 0.1418, Val Loss: 0.5248
Epoch [44/120], Loss: 0.1328, Val Loss: 0.5181
Epoch [45/120], Loss: 0.0756, Val Loss: 0.4583
Epoch [46/120], Loss: 0.2499, Val Loss: 0.4723
Epoch [47/120], Loss: 0.1122, Val Loss: 0.4626
Epoch [48/120], Loss: 0.2167, Val Loss: 0.4760
Epoch [49/120], Loss: 0.0693, Val Loss: 0.4885
Epoch [50/120], Loss: 0.2038, Val Loss: 0.5124
Epoch [51/120], Loss: 0.2117, Val Loss: 0.4522
Epoch [52/120], Loss: 0.1042, Val Loss: 0.5235
Epoch [53/120], Loss: 0.0990, Val Loss: 0.5580
Epoch [54/120], Loss: 0.1342, Val Loss: 0.4763
Epoch [55/120], Loss: 0.1672, Val Loss: 0.4334
Epoch [56/120], Loss: 0.1242, Val Loss: 0.4699
Epoch [57/120], Loss: 0.7920, Val Loss: 0.4725
Epoch [58/120], Loss: 0.0681, Val Loss: 0.4661
Epoch [59/120], Loss: 0.1412, Val Loss: 0.4951
Epoch [60/120], Loss: 0.3163, Val Loss: 0.4665
Epoch [61/120], Loss: 0.1372, Val Loss: 0.4946
Epoch [62/120], Loss: 0.6804, Val Loss: 0.5113
Epoch [63/120], Loss: 0.1089, Val Loss: 0.5267
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1626, Val Loss: 0.4934
Epoch [2/120], Loss: 0.1877, Val Loss: 0.5424
Epoch [3/120], Loss: 0.1198, Val Loss: 0.4570
Epoch [4/120], Loss: 0.8040, Val Loss: 0.5073
Epoch [5/120], Loss: 0.1869, Val Loss: 0.4828
Epoch [6/120], Loss: 0.0845, Val Loss: 0.5615
Epoch [7/120], Loss: 0.0928, Val Loss: 0.4623
Epoch [8/120], Loss: 0.1671, Val Loss: 0.4688
Epoch [9/120], Loss: 0.5095, Val Loss: 0.4493
Epoch [10/120], Loss: 0.0963, Val Loss: 0.5021
Epoch [11/120], Loss: 0.0375, Val Loss: 0.4578
Epoch [12/120], Loss: 0.1031, Val Loss: 0.5134
Epoch [13/120], Loss: 0.2109, Val Loss: 0.5142
Epoch [14/120], Loss: 0.2221, Val Loss: 0.4811
Epoch [15/120], Loss: 0.2035, Val Loss: 0.4825
Epoch [16/120], Loss: 0.2582, Val Loss: 0.4570
Epoch [17/120], Loss: 0.0868, Val Loss: 0.4974
Epoch [18/120], Loss: 0.2964, Val Loss: 0.4585
Epoch [19/120], Loss: 0.0521, Val Loss: 0.4937
Epoch [20/120], Loss: 0.1618, Val Loss: 0.4554
Epoch [21/120], Loss: 0.0731, Val Loss: 0.5048
Epoch [22/120], Loss: 0.2038, Val Loss: 0.4687
Epoch [23/120], Loss: 0.1153, Val Loss: 0.4917
Epoch [24/120], Loss: 0.1067, Val Loss: 0.4741
Epoch [25/120], Loss: 0.3356, Val Loss: 0.4830
Epoch [26/120], Loss: 0.0870, Val Loss: 0.4652
Epoch [27/120], Loss: 0.0565, Val Loss: 0.5946
Epoch [28/120], Loss: 0.0853, Val Loss: 0.4769
Epoch [29/120], Loss: 0.0552, Val Loss: 0.4928
Epoch [30/120], Loss: 0.1072, Val Loss: 0.4836
Epoch [31/120], Loss: 0.3538, Val Loss: 0.5371
Epoch [32/120], Loss: 0.1600, Val Loss: 0.5119
Epoch [33/120], Loss: 0.1082, Val Loss: 0.4823
Epoch [34/120], Loss: 0.1508, Val Loss: 0.4572
Epoch [35/120], Loss: 0.1445, Val Loss: 0.4832
Epoch [36/120], Loss: 0.1799, Val Loss: 0.4879
Epoch [37/120], Loss: 0.1671, Val Loss: 0.5141
Epoch [38/120], Loss: 0.1393, Val Loss: 0.5316
Early stopping at epoch 38
Runtime: 0:00:19.324267
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0862, Val Loss: 0.4738
Epoch [2/120], Loss: 0.1611, Val Loss: 0.4549
Epoch [3/120], Loss: 0.5314, Val Loss: 0.4728
Epoch [4/120], Loss: 0.6102, Val Loss: 0.5745
Epoch [5/120], Loss: 0.1282, Val Loss: 0.4999
Epoch [6/120], Loss: 0.1389, Val Loss: 0.4601
Epoch [7/120], Loss: 0.0601, Val Loss: 0.5175
Epoch [8/120], Loss: 0.0909, Val Loss: 0.5129
Epoch [9/120], Loss: 0.0821, Val Loss: 0.5004
Epoch [10/120], Loss: 0.1709, Val Loss: 0.4911
Epoch [11/120], Loss: 0.1153, Val Loss: 0.4893
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1024, Val Loss: 0.4715
Epoch [2/120], Loss: 0.0698, Val Loss: 0.4922
Epoch [3/120], Loss: 0.1054, Val Loss: 0.4715
Epoch [4/120], Loss: 0.1362, Val Loss: 0.4896
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.3091, Val Loss: 0.4894
Epoch [2/120], Loss: 0.5007, Val Loss: 0.4791
Epoch [3/120], Loss: 0.1316, Val Loss: 0.4620
Epoch [4/120], Loss: 0.2523, Val Loss: 0.5249
Epoch [5/120], Loss: 0.0995, Val Loss: 0.4610
Epoch [6/120], Loss: 0.0779, Val Loss: 0.4643
Epoch [7/120], Loss: 0.1330, Val Loss: 0.4811
Epoch [8/120], Loss: 0.3758, Val Loss: 0.5323
Epoch [9/120], Loss: 0.2627, Val Loss: 0.5552
Epoch [10/120], Loss: 0.0823, Val Loss: 0.4649
Epoch [11/120], Loss: 0.1846, Val Loss: 0.4662
Epoch [12/120], Loss: 0.0723, Val Loss: 0.4496
Epoch [13/120], Loss: 0.1684, Val Loss: 0.4663
Epoch [14/120], Loss: 0.5129, Val Loss: 0.4702
Epoch [15/120], Loss: 0.7115, Val Loss: 0.4953
Epoch [16/120], Loss: 0.1477, Val Loss: 0.5582
Epoch [17/120], Loss: 0.4065, Val Loss: 0.4913
Epoch [18/120], Loss: 0.1351, Val Loss: 0.5126
Epoch [19/120], Loss: 0.1201, Val Loss: 0.4821
Epoch [20/120], Loss: 0.0907, Val Loss: 0.4694
Epoch [21/120], Loss: 0.3139, Val Loss: 0.4825
Epoch [22/120], Loss: 0.0610, Val Loss: 0.4808
Epoch [23/120], Loss: 0.6679, Val Loss: 0.4679
Epoch [24/120], Loss: 0.1235, Val Loss: 0.5029
Epoch [25/120], Loss: 0.4850, Val Loss: 0.4911
Epoch [26/120], Loss: 0.2280, Val Loss: 0.4869
Epoch [27/120], Loss: 0.2810, Val Loss: 0.4625
Epoch [28/120], Loss: 0.2306, Val Loss: 0.4573
Epoch [29/120], Loss: 0.1913, Val Loss: 0.4714
Epoch [30/120], Loss: 0.2139, Val Loss: 0.4792
Epoch [31/120], Loss: 0.1193, Val Loss: 0.4708
Epoch [32/120], Loss: 0.1449, Val Loss: 0.4660
Epoch [33/120], Loss: 0.0564, Val Loss: 0.4621
Epoch [34/120], Loss: 0.1079, Val Loss: 0.5400
Epoch [35/120], Loss: 0.1202, Val Loss: 0.5184
Epoch [36/120], Loss: 0.1003, Val Loss: 0.4672
Epoch [37/120], Loss: 0.1538, Val Loss: 0.4983
Epoch [38/120], Loss: 0.1358, Val Loss: 0.4606
Epoch [39/120], Loss: 0.1655, Val Loss: 0.5379
Epoch [40/120], Loss: 0.2371, Val Loss: 0.4568
Epoch [41/120], Loss: 0.0536, Val Loss: 0.4844
Early stopping at epoch 41
Runtime: 0:00:21.914157
R^2 Score: 0.9063
RMSE: 0.5997
MAE: 0.1826
MAPE: 14.59%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0681, Val Loss: 0.4825
Epoch [2/120], Loss: 0.0809, Val Loss: 0.4949
Epoch [3/120], Loss: 0.1225, Val Loss: 0.5149
Epoch [4/120], Loss: 0.3957, Val Loss: 0.4819
Epoch [5/120], Loss: 0.1794, Val Loss: 0.4945
Epoch [6/120], Loss: 0.0887, Val Loss: 0.4915
Epoch [7/120], Loss: 0.0845, Val Loss: 0.5369
Epoch [8/120], Loss: 0.0558, Val Loss: 0.4889
Epoch [9/120], Loss: 0.0710, Val Loss: 0.4815
Epoch [10/120], Loss: 0.1035, Val Loss: 0.5078
Epoch [11/120], Loss: 0.2519, Val Loss: 0.4831
Epoch [12/120], Loss: 0.1002, Val Loss: 0.4624
Epoch [13/120], Loss: 0.2330, Val Loss: 0.5178
Epoch [14/120], Loss: 0.0720, Val Loss: 0.5088
Epoch [15/120], Loss: 0.2675, Val Loss: 0.4779
Epoch [16/120], Loss: 0.4126, Val Loss: 0.4803
Epoch [17/120], Loss: 0.2534, Val Loss: 0.5383
Epoch [18/120], Loss: 0.3235, Val Loss: 0.4925
Epoch [19/120], Loss: 0.0536, Val Loss: 0.4580
Epoch [20/120], Loss: 0.0757, Val Loss: 0.5081
Epoch [21/120], Loss: 0.2007, Val Loss: 0.4521
Epoch [22/120], Loss: 0.1278, Val Loss: 0.5043
Epoch [23/120], Loss: 0.0672, Val Loss: 0.4649
Epoch [24/120], Loss: 0.1098, Val Loss: 0.5004
Epoch [25/120], Loss: 0.1821, Val Loss: 0.4808
Epoch [26/120], Loss: 0.2007, Val Loss: 0.4689
Epoch [27/120], Loss: 0.1428, Val Loss: 0.4828
Epoch [28/120], Loss: 0.3536, Val Loss: 0.4903
Epoch [29/120], Loss: 0.2054, Val Loss: 0.4716
Epoch [30/120], Loss: 0.0522, Val Loss: 0.4945
Epoch [31/120], Loss: 0.1183, Val Loss: 0.4723
Epoch [32/120], Loss: 0.0863, Val Loss: 0.4803
Epoch [33/120], Loss: 0.1070, Val Loss: 0.4846
Epoch [34/120], Loss: 0.1846, Val Loss: 0.4848
Epoch [35/120], Loss: 0.2117, Val Loss: 0.4876
Epoch [36/120], Loss: 0.5439, Val Loss: 0.4861
Epoch [37/120], Loss: 0.2223, Val Loss: 0.4770
Epoch [38/120], Loss: 1.1642, Val Loss: 0.4896
Epoch [39/120], Loss: 0.0615, Val Loss: 0.5100
Epoch [40/120], Loss: 0.0732, Val Loss: 0.4761
Epoch [41/120], Loss: 0.2834, Val Loss: 0.5296
Epoch [42/120], Loss: 0.3816, Val Loss: 0.4819
Epoch [43/120], Loss: 0.1872, Val Loss: 0.4664
Epoch [44/120], Loss: 0.1585, Val Loss: 0.4616
Epoch [45/120], Loss: 0.1640, Val Loss: 0.4812
Epoch [46/120], Loss: 0.0715, Val Loss: 0.4832
Epoch [47/120], Loss: 0.0900, Val Loss: 0.5017
Epoch [48/120], Loss: 0.1275, Val Loss: 0.4820
Epoch [49/120], Loss: 0.0586, Val Loss: 0.4877
Epoch [50/120], Loss: 0.0939, Val Loss: 0.4644
Early stopping at epoch 50
Runtime: 0:00:24.024747
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.1441, Val Loss: 0.4728
Epoch [2/120], Loss: 0.7614, Val Loss: 0.4921
Epoch [3/120], Loss: 0.0844, Val Loss: 0.4922
Epoch [4/120], Loss: 0.1493, Val Loss: 0.5016
Epoch [5/120], Loss: 0.0837, Val Loss: 0.4632
Epoch [6/120], Loss: 0.1451, Val Loss: 0.4746
Epoch [7/120], Loss: 0.1212, Val Loss: 0.4916
Epoch [8/120], Loss: 0.3346, Val Loss: 0.4816
Epoch [9/120], Loss: 0.0913, Val Loss: 0.4863
Epoch [10/120], Loss: 0.0866, Val Loss: 0.4783
Epoch [11/120], Loss: 0.0907, Val Loss: 0.4652
Epoch [12/120], Loss: 0.0895, Val Loss: 0.4856
Epoch [13/120], Loss: 0.0344, Val Loss: 0.4926
Epoch [14/120], Loss: 1.1128, Val Loss: 0.4730
Epoch [15/120], Loss: 0.0426, Val Loss: 0.4755
Epoch [16/120], Loss: 0.4733, Val Loss: 0.4989
Epoch [17/120], Loss: 0.1062, Val Loss: 0.5258
Epoch [18/120], Loss: 0.3223, Val Loss: 0.5151
Epoch [19/120], Loss: 0.4805, Val Loss: 0.5132
Epoch [20/120], Loss: 0.0800, Val Loss: 0.4952
Epoch [21/120], Loss: 0.2180, Val Loss: 0.5061
Epoch [22/120], Loss: 0.0922, Val Loss: 0.4743
Epoch [23/120], Loss: 0.4156, Val Loss: 0.4916
Epoch [24/120], Loss: 0.0627, Val Loss: 0.5142
Epoch [25/120], Loss: 0.3640, Val Loss: 0.5043
Epoch [26/120], Loss: 0.0863, Val Loss: 0.4792
Epoch [27/120], Loss: 0.0333, Val Loss: 0.4763
Epoch [28/120], Loss: 0.0811, Val Loss: 0.5131
Epoch [29/120], Loss: 0.1931, Val Loss: 0.5270
Epoch [30/120], Loss: 0.4620, Val Loss: 0.4778
Epoch [31/120], Loss: 0.2802, Val Loss: 0.4993
Epoch [32/120], Loss: 0.0911, Val Loss: 0.4555
Epoch [33/120], Loss: 0.2329, Val Loss: 0.5106
Epoch [34/120], Loss: 0.0883, Val Loss: 0.5216
Epoch [35/120], Loss: 0.1963, Val Loss: 0.4899
Epoch [36/120], Loss: 0.0669, Val Loss: 0.4667
Epoch [37/120], Loss: 0.2896, Val Loss: 0.4735
Epoch [38/120], Loss: 0.3356, Val Loss: 0.5039
Epoch [39/120], Loss: 0.0558, Val Loss: 0.5709
Epoch [40/120], Loss: 0.4255, Val Loss: 0.4941
Epoch [41/120], Loss: 0.0749, Val Loss: 0.5411
Epoch [42/120], Loss: 0.2681, Val Loss: 0.5063
Epoch [43/120], Loss: 0.0382, Val Loss: 0.4874
Epoch [44/120], Loss: 0.1269, Val Loss: 0.4922
Epoch [45/120], Loss: 0.0831, Val Loss: 0.4880
Epoch [46/120], Loss: 0.0760, Val Loss: 0.4730
Epoch [47/120], Loss: 0.0609, Val Loss: 0.4924
Epoch [48/120], Loss: 0.5512, Val Loss: 0.4983
Epoch [49/120], Loss: 0.4989, Val Loss: 0.4805
Epoch [50/120], Loss: 0.2322, Val Loss: 0.4867
Epoch [51/120], Loss: 0.0437, Val Loss: 0.4813
Epoch [52/120], Loss: 0.2657, Val Loss: 0.4741
Epoch [53/120], Loss: 0.2457, Val Loss: 0.4722
Epoch [54/120], Loss: 0.1226, Val Loss: 0.4721
Epoch [55/120], Loss: 0.0663, Val Loss: 0.4792
Epoch [56/120], Loss: 0.2874, Val Loss: 0.4767
Epoch [57/120], Loss: 0.2128, Val Loss: 0.4844
Epoch [58/120], Loss: 0.0656, Val Loss: 0.5217
Epoch [59/120], Loss: 0.0614, Val Loss: 0.4807
Epoch [60/120], Loss: 0.0747, Val Loss: 0.5249
Epoch [61/120], Loss: 0.0783, Val Loss: 0.4899
Early stopping at epoch 61
Runtime: 0:00:29.427214
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.4877, Val Loss: 0.9513
Epoch [2/120], Loss: 0.2869, Val Loss: 0.8609
Epoch [3/120], Loss: 0.5715, Val Loss: 0.8856
Epoch [4/120], Loss: 0.3047, Val Loss: 0.7644
Epoch [5/120], Loss: 0.3442, Val Loss: 0.7225
Epoch [6/120], Loss: 1.0332, Val Loss: 0.7277
Epoch [7/120], Loss: 0.4697, Val Loss: 0.9890
Epoch [8/120], Loss: 0.0891, Val Loss: 0.7087
Epoch [9/120], Loss: 0.4812, Val Loss: 0.6607
Epoch [10/120], Loss: 0.4012, Val Loss: 0.6982
Epoch [11/120], Loss: 0.3445, Val Loss: 0.6997
Epoch [12/120], Loss: 0.9817, Val Loss: 0.7073
Epoch [13/120], Loss: 0.3619, Val Loss: 0.6823
Epoch [14/120], Loss: 1.5589, Val Loss: 0.6585
Epoch [15/120], Loss: 0.4860, Val Loss: 0.5942
Epoch [16/120], Loss: 0.0610, Val Loss: 0.6689
Epoch [17/120], Loss: 0.2138, Val Loss: 0.6103
Epoch [18/120], Loss: 0.0902, Val Loss: 0.6391
Epoch [19/120], Loss: 0.1260, Val Loss: 0.5872
Epoch [20/120], Loss: 0.1440, Val Loss: 0.5527
Epoch [21/120], Loss: 0.3740, Val Loss: 0.6201
Epoch [22/120], Loss: 1.1986, Val Loss: 0.6598
Epoch [23/120], Loss: 0.6008, Val Loss: 0.6477
Epoch [24/120], Loss: 0.1589, Val Loss: 0.6024
Epoch [25/120], Loss: 0.1646, Val Loss: 0.5118
Epoch [26/120], Loss: 0.5500, Val Loss: 0.5177
Epoch [27/120], Loss: 0.6697, Val Loss: 0.6018
Epoch [28/120], Loss: 0.2100, Val Loss: 0.5940
Epoch [29/120], Loss: 0.4444, Val Loss: 0.5846
Epoch [30/120], Loss: 0.0744, Val Loss: 0.5604
Epoch [31/120], Loss: 0.1612, Val Loss: 0.5811
Epoch [32/120], Loss: 0.1037, Val Loss: 0.4928
Epoch [33/120], Loss: 0.1757, Val Loss: 0.6094
Epoch [34/120], Loss: 0.5310, Val Loss: 0.6110
Epoch [35/120], Loss: 0.2270, Val Loss: 0.5447
Epoch [36/120], Loss: 0.1334, Val Loss: 0.5685
Epoch [37/120], Loss: 0.4913, Val Loss: 0.5180
Epoch [38/120], Loss: 0.2478, Val Loss: 0.5440
Epoch [39/120], Loss: 0.5779, Val Loss: 0.6161
Epoch [40/120], Loss: 0.3925, Val Loss: 0.5928
Epoch [41/120], Loss: 0.3689, Val Loss: 0.5152
Epoch [42/120], Loss: 0.1367, Val Loss: 0.5350
Epoch [43/120], Loss: 0.0673, Val Loss: 0.4852
Epoch [44/120], Loss: 0.1495, Val Loss: 0.4751
Epoch [45/120], Loss: 0.2694, Val Loss: 0.7693
Epoch [46/120], Loss: 0.1171, Val Loss: 0.5234
Epoch [47/120], Loss: 0.1050, Val Loss: 0.4928
Epoch [48/120], Loss: 0.3901, Val Loss: 0.6007
Epoch [49/120], Loss: 0.1171, Val Loss: 0.4716
Epoch [50/120], Loss: 0.1755, Val Loss: 0.4842
Epoch [51/120], Loss: 0.4924, Val Loss: 0.5421
Epoch [52/120], Loss: 0.1421, Val Loss: 0.5069
Epoch [53/120], Loss: 0.0913, Val Loss: 0.5544
Epoch [54/120], Loss: 0.1175, Val Loss: 0.5061
Epoch [55/120], Loss: 0.1586, Val Loss: 0.5345
Epoch [56/120], Loss: 0.1452, Val Loss: 0.5839
Epoch [57/120], Loss: 0.1109, Val Loss: 0.5372
Epoch [58/120], Loss: 0.0735, Val Loss: 0.5123
Epoch [59/120], Loss: 0.0835, Val Loss: 0.5270
Epoch [60/120], Loss: 0.1350, Val Loss: 0.5677
Epoch [61/120], Loss: 0.0639, Val Loss: 0.5456
Epoch [62/120], Loss: 0.8584, Val Loss: 0.5144
Epoch [63/120], Loss: 0.3134, Val Loss: 0.4826
Epoch [64/120], Loss: 0.1292, Val Loss: 0.5100
Epoch [65/120], Loss: 0.1441, Val Loss: 0.5472
Epoch [66/120], Loss: 0.1326, Val Loss: 0.5407
Epoch [67/120], Loss: 0.0464, Val Loss: 0.5713
Epoch [68/120], Loss: 0.0926, Val Loss: 0.5584
Epoch [69/120], Loss: 0.7818, Val Loss: 0.5328
Epoch [70/120], Loss: 0.1017, Val Loss: 0.5094
Epoch [71/120], Loss: 0.1069, Val Loss: 0.5010
Epoch [72/120], Loss: 0.1206, Val Loss: 0.6854
Epoch [73/120], Loss: 0.6850, Val Loss: 0.5365
Epoch [74/120], Loss: 0.0713, Val Loss: 0.5055
Epoch [75/120], Loss: 0.0607, Val Loss: 0.5318
Epoch [76/120], Loss: 0.1379, Val Loss: 0.4819
Epoch [77/120], Loss: 0.1960, Val Loss: 0.5204
Epoch [78/120], Loss: 0.0966, Val Loss: 0.5430
Early stopping at epoch 78
Runtime: 0:00:37.370929
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 1.3715, Val Loss: 0.9826
Epoch [2/120], Loss: 1.0221, Val Loss: 1.0018
Epoch [3/120], Loss: 0.1671, Val Loss: 0.8371
Epoch [4/120], Loss: 0.4400, Val Loss: 0.8225
Epoch [5/120], Loss: 0.3431, Val Loss: 0.7613
Epoch [6/120], Loss: 0.2209, Val Loss: 0.7286
Epoch [7/120], Loss: 0.2240, Val Loss: 0.6915
Epoch [8/120], Loss: 0.4109, Val Loss: 0.7703
Epoch [9/120], Loss: 0.1755, Val Loss: 0.8198
Epoch [10/120], Loss: 0.1151, Val Loss: 0.7926
Epoch [11/120], Loss: 0.2905, Val Loss: 0.6569
Epoch [12/120], Loss: 0.1125, Val Loss: 0.7457
Epoch [13/120], Loss: 1.8020, Val Loss: 0.6281
Epoch [14/120], Loss: 0.4124, Val Loss: 0.7715
Epoch [15/120], Loss: 1.0934, Val Loss: 0.6751
Epoch [16/120], Loss: 0.1013, Val Loss: 0.6666
Epoch [17/120], Loss: 0.2680, Val Loss: 0.6778
Epoch [18/120], Loss: 0.1066, Val Loss: 0.6291
Epoch [19/120], Loss: 0.1504, Val Loss: 0.6070
Epoch [20/120], Loss: 0.3519, Val Loss: 0.7218
Epoch [21/120], Loss: 0.1886, Val Loss: 0.5832
Epoch [22/120], Loss: 0.0682, Val Loss: 0.6229
Epoch [23/120], Loss: 0.1278, Val Loss: 0.5988
Epoch [24/120], Loss: 0.0901, Val Loss: 0.5736
Epoch [25/120], Loss: 0.1501, Val Loss: 0.5684
Epoch [26/120], Loss: 0.1869, Val Loss: 0.5697
Epoch [27/120], Loss: 0.9785, Val Loss: 0.6750
Epoch [28/120], Loss: 0.1519, Val Loss: 0.5936
Epoch [29/120], Loss: 0.1093, Val Loss: 0.7136
Epoch [30/120], Loss: 0.0837, Val Loss: 0.5631
Epoch [31/120], Loss: 1.1898, Val Loss: 0.5216
Epoch [32/120], Loss: 0.1679, Val Loss: 0.5522
Epoch [33/120], Loss: 0.0571, Val Loss: 0.5813
Epoch [34/120], Loss: 0.1487, Val Loss: 0.5468
Epoch [35/120], Loss: 0.0985, Val Loss: 0.5579
Epoch [36/120], Loss: 0.1630, Val Loss: 0.5035
Epoch [37/120], Loss: 0.1281, Val Loss: 0.5588
Epoch [38/120], Loss: 0.0617, Val Loss: 0.5979
Epoch [39/120], Loss: 0.0707, Val Loss: 0.5125
Epoch [40/120], Loss: 0.0884, Val Loss: 0.5973
Epoch [41/120], Loss: 0.1188, Val Loss: 0.5686
Epoch [42/120], Loss: 0.2510, Val Loss: 0.5813
Epoch [43/120], Loss: 0.3621, Val Loss: 0.5755
Epoch [44/120], Loss: 0.8793, Val Loss: 0.5285
Epoch [45/120], Loss: 0.0526, Val Loss: 0.6300
Epoch [46/120], Loss: 0.0965, Val Loss: 0.5361
Epoch [47/120], Loss: 0.1171, Val Loss: 0.4878
Epoch [48/120], Loss: 0.0889, Val Loss: 0.5669
Epoch [49/120], Loss: 0.1154, Val Loss: 0.5616
Epoch [50/120], Loss: 2.0178, Val Loss: 0.5182
Epoch [51/120], Loss: 0.0830, Val Loss: 0.5363
Epoch [52/120], Loss: 0.3020, Val Loss: 0.5142
Epoch [53/120], Loss: 0.1953, Val Loss: 0.4929
Epoch [54/120], Loss: 0.0742, Val Loss: 0.5540
Epoch [55/120], Loss: 0.1245, Val Loss: 0.5056
Epoch [56/120], Loss: 0.3155, Val Loss: 0.4833
Epoch [57/120], Loss: 0.0753, Val Loss: 0.5311
Epoch [58/120], Loss: 0.1757, Val Loss: 0.4905
Epoch [59/120], Loss: 1.0236, Val Loss: 0.6074
Epoch [60/120], Loss: 0.4806, Val Loss: 0.5566
Epoch [61/120], Loss: 0.0857, Val Loss: 0.5381
Epoch [62/120], Loss: 0.1668, Val Loss: 0.5342
Epoch [63/120], Loss: 0.2039, Val Loss: 0.5326
Epoch [64/120], Loss: 0.0707, Val Loss: 0.5441
Epoch [65/120], Loss: 0.1294, Val Loss: 0.5717
Epoch [66/120], Loss: 0.1311, Val Loss: 0.4613
Epoch [67/120], Loss: 0.2670, Val Loss: 0.4838
Epoch [68/120], Loss: 0.8093, Val Loss: 0.6349
Epoch [69/120], Loss: 1.0083, Val Loss: 0.5460
Epoch [70/120], Loss: 0.7261, Val Loss: 0.4562
Epoch [71/120], Loss: 0.1709, Val Loss: 0.4678
Epoch [72/120], Loss: 0.4169, Val Loss: 0.4950
Epoch [73/120], Loss: 0.5652, Val Loss: 0.4891
Epoch [74/120], Loss: 0.1749, Val Loss: 0.4799
Epoch [75/120], Loss: 0.4035, Val Loss: 0.4682
Epoch [76/120], Loss: 0.2281, Val Loss: 0.4500
Epoch [77/120], Loss: 0.0791, Val Loss: 0.4981
Epoch [78/120], Loss: 0.1925, Val Loss: 0.4848
Epoch [79/120], Loss: 0.2020, Val Loss: 0.4663
Epoch [80/120], Loss: 0.1740, Val Loss: 0.4960
Epoch [81/120], Loss: 0.3556, Val Loss: 0.4897
Epoch [82/120], Loss: 0.1455, Val Loss: 0.6396
Epoch [83/120], Loss: 0.1793, Val Loss: 0.4594
Epoch [84/120], Loss: 0.1507, Val Loss: 0.4687
Epoch [85/120], Loss: 0.1970, Val Loss: 0.5773
Epoch [86/120], Loss: 0.0315, Val Loss: 0.4625
Epoch [87/120], Loss: 0.2907, Val Loss: 0.4776
Epoch [88/120], Loss: 0.1084, Val Loss: 0.5583
Epoch [89/120], Loss: 0.1366, Val Loss: 0.4811
Epoch [90/120], Loss: 0.4789, Val Loss: 0.4745
Epoch [91/120], Loss: 0.1308, Val Loss: 0.4474
Epoch [92/120], Loss: 0.1240, Val Loss: 0.4983
Epoch [93/120], Loss: 0.7029, Val Loss: 0.4745
Epoch [94/120], Loss: 0.1188, Val Loss: 0.4773
Epoch [95/120], Loss: 0.4418, Val Loss: 0.5019
Epoch [96/120], Loss: 0.0664, Val Loss: 0.5455
Epoch [97/120], Loss: 0.3763, Val Loss: 0.4750
Epoch [98/120], Loss: 0.6983, Val Loss: 0.4795
Epoch [99/120], Loss: 0.3243, Val Loss: 0.4726
Epoch [100/120], Loss: 0.3558, Val Loss: 0.5056
Epoch [101/120], Loss: 0.1091, Val Loss: 0.4587
Epoch [102/120], Loss: 0.7104, Val Loss: 0.5159
Epoch [103/120], Loss: 0.2350, Val Loss: 0.5104
Epoch [104/120], Loss: 0.1454, Val Loss: 0.5401
Epoch [105/120], Loss: 1.1454, Val Loss: 0.4693
Epoch [106/120], Loss: 0.3994, Val Loss: 0.4557
Epoch [107/120], Loss: 1.6112, Val Loss: 0.4615
Epoch [108/120], Loss: 0.1105, Val Loss: 0.5093
Epoch [109/120], Loss: 0.2429, Val Loss: 0.4685
Epoch [110/120], Loss: 0.0771, Val Loss: 0.4671
Epoch [111/120], Loss: 0.0712, Val Loss: 0.5147
Epoch [112/120], Loss: 0.0688, Val Loss: 0.4960
Epoch [113/120], Loss: 0.0927, Val Loss: 0.4763
Epoch [114/120], Loss: 0.1589, Val Loss: 0.5134
Epoch [115/120], Loss: 0.0980, Val Loss: 0.5467
Epoch [116/120], Loss: 0.1295, Val Loss: 0.4773
Epoch [117/120], Loss: 0.2761, Val Loss: 0.5079
Epoch [118/120], Loss: 0.1086, Val Loss: 0.5506
Epoch [119/120], Loss: 0.1786, Val Loss: 0.5008
Epoch [120/120], Loss: 0.4929, Val Loss: 0.4926
Runtime: 0:00:56.216818
R^2 Score: 0.9046
RMSE: 0.6051
MAE: 0.1922
MAPE: 16.58%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.4359, Val Loss: 1.2054
Epoch [2/120], Loss: 0.2312, Val Loss: 0.8842
Epoch [3/120], Loss: 0.6836, Val Loss: 0.9400
Epoch [4/120], Loss: 0.5223, Val Loss: 0.7062
Epoch [5/120], Loss: 0.6306, Val Loss: 0.7796
Epoch [6/120], Loss: 0.1079, Val Loss: 0.7750
Epoch [7/120], Loss: 0.3775, Val Loss: 0.7107
Epoch [8/120], Loss: 0.6456, Val Loss: 0.6868
Epoch [9/120], Loss: 0.4023, Val Loss: 0.6411
Epoch [10/120], Loss: 1.1688, Val Loss: 0.8231
Epoch [11/120], Loss: 0.3768, Val Loss: 0.6251
Epoch [12/120], Loss: 1.1330, Val Loss: 0.6393
Epoch [13/120], Loss: 0.2067, Val Loss: 0.6480
Epoch [14/120], Loss: 0.1960, Val Loss: 0.7510
Epoch [15/120], Loss: 0.2508, Val Loss: 0.7049
Epoch [16/120], Loss: 0.3013, Val Loss: 0.6681
Epoch [17/120], Loss: 0.0890, Val Loss: 0.6289
Epoch [18/120], Loss: 0.2190, Val Loss: 0.5568
Epoch [19/120], Loss: 0.9623, Val Loss: 0.5730
Epoch [20/120], Loss: 0.0875, Val Loss: 0.5514
Epoch [21/120], Loss: 0.2209, Val Loss: 0.5571
Epoch [22/120], Loss: 0.2283, Val Loss: 0.5306
Epoch [23/120], Loss: 0.1136, Val Loss: 0.5623
Epoch [24/120], Loss: 0.1823, Val Loss: 0.5147
Epoch [25/120], Loss: 0.2264, Val Loss: 0.5313
Epoch [26/120], Loss: 0.3770, Val Loss: 0.6834
Epoch [27/120], Loss: 2.2497, Val Loss: 0.5409
Epoch [28/120], Loss: 0.1107, Val Loss: 0.6422
Epoch [29/120], Loss: 0.4227, Val Loss: 0.5217
Epoch [30/120], Loss: 0.7183, Val Loss: 0.5525
Epoch [31/120], Loss: 0.1292, Val Loss: 0.7457
Epoch [32/120], Loss: 0.1158, Val Loss: 0.5419
Epoch [33/120], Loss: 0.1318, Val Loss: 0.5184
Epoch [34/120], Loss: 0.1129, Val Loss: 0.5132
Epoch [35/120], Loss: 0.1037, Val Loss: 0.5103
Epoch [36/120], Loss: 0.2542, Val Loss: 0.4930
Epoch [37/120], Loss: 0.1119, Val Loss: 0.4841
Epoch [38/120], Loss: 0.4226, Val Loss: 0.7635
Epoch [39/120], Loss: 0.2770, Val Loss: 0.5564
Epoch [40/120], Loss: 0.4804, Val Loss: 0.5306
Epoch [41/120], Loss: 0.4457, Val Loss: 0.4890
Epoch [42/120], Loss: 0.1330, Val Loss: 0.4913
Epoch [43/120], Loss: 0.6617, Val Loss: 0.4831
Epoch [44/120], Loss: 0.6424, Val Loss: 0.5426
Epoch [45/120], Loss: 0.4564, Val Loss: 0.5144
Epoch [46/120], Loss: 0.1516, Val Loss: 0.5293
Epoch [47/120], Loss: 0.3805, Val Loss: 0.4780
Epoch [48/120], Loss: 0.0912, Val Loss: 0.5048
Epoch [49/120], Loss: 0.2974, Val Loss: 0.6115
Epoch [50/120], Loss: 0.1559, Val Loss: 0.5521
Epoch [51/120], Loss: 0.2418, Val Loss: 0.4980
Epoch [52/120], Loss: 0.1603, Val Loss: 0.4968
Epoch [53/120], Loss: 0.2192, Val Loss: 0.4427
Epoch [54/120], Loss: 0.1293, Val Loss: 0.4994
Epoch [55/120], Loss: 0.9367, Val Loss: 0.5015
Epoch [56/120], Loss: 0.3393, Val Loss: 0.5205
Epoch [57/120], Loss: 0.0701, Val Loss: 0.5207
Epoch [58/120], Loss: 0.2525, Val Loss: 0.4944
Epoch [59/120], Loss: 0.0706, Val Loss: 0.4643
Epoch [60/120], Loss: 0.1216, Val Loss: 0.5007
Epoch [61/120], Loss: 0.0936, Val Loss: 0.6545
Epoch [62/120], Loss: 0.3382, Val Loss: 0.5768
Epoch [63/120], Loss: 0.1706, Val Loss: 0.4634
Epoch [64/120], Loss: 0.1516, Val Loss: 0.5128
Epoch [65/120], Loss: 0.0761, Val Loss: 0.4978
Epoch [66/120], Loss: 0.9124, Val Loss: 0.4683
Epoch [67/120], Loss: 0.1104, Val Loss: 0.5476
Epoch [68/120], Loss: 0.3394, Val Loss: 0.4921
Epoch [69/120], Loss: 0.1552, Val Loss: 0.4524
Epoch [70/120], Loss: 0.0919, Val Loss: 0.5666
Epoch [71/120], Loss: 0.2629, Val Loss: 0.5225
Epoch [72/120], Loss: 0.2455, Val Loss: 0.4645
Epoch [73/120], Loss: 0.0546, Val Loss: 0.4572
Epoch [74/120], Loss: 0.1932, Val Loss: 0.4609
Epoch [75/120], Loss: 0.0735, Val Loss: 0.5227
Epoch [76/120], Loss: 0.4311, Val Loss: 0.4890
Epoch [77/120], Loss: 0.1216, Val Loss: 0.4863
Epoch [78/120], Loss: 0.8237, Val Loss: 0.5773
Epoch [79/120], Loss: 0.3184, Val Loss: 0.4920
Epoch [80/120], Loss: 0.0814, Val Loss: 0.4791
Epoch [81/120], Loss: 0.2040, Val Loss: 0.4871
Epoch [82/120], Loss: 0.1274, Val Loss: 0.7599
Early stopping at epoch 82
Runtime: 0:00:40.252053
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.0875, Val Loss: 1.0074
Epoch [2/120], Loss: 0.2216, Val Loss: 0.8821
Epoch [3/120], Loss: 1.0890, Val Loss: 0.8322
Epoch [4/120], Loss: 0.5376, Val Loss: 0.7501
Epoch [5/120], Loss: 1.4136, Val Loss: 0.8150
Epoch [6/120], Loss: 0.1093, Val Loss: 0.7189
Epoch [7/120], Loss: 0.1097, Val Loss: 0.7102
Epoch [8/120], Loss: 0.7328, Val Loss: 0.9378
Epoch [9/120], Loss: 1.0668, Val Loss: 0.7069
Epoch [10/120], Loss: 0.1415, Val Loss: 0.6586
Epoch [11/120], Loss: 0.2084, Val Loss: 0.8304
Epoch [12/120], Loss: 0.3768, Val Loss: 0.7691
Epoch [13/120], Loss: 0.5408, Val Loss: 0.8386
Epoch [14/120], Loss: 0.0745, Val Loss: 0.6757
Epoch [15/120], Loss: 0.1580, Val Loss: 0.6776
Epoch [16/120], Loss: 0.1528, Val Loss: 0.6013
Epoch [17/120], Loss: 0.1411, Val Loss: 0.7585
Epoch [18/120], Loss: 2.3819, Val Loss: 0.6249
Epoch [19/120], Loss: 0.1721, Val Loss: 0.6329
Epoch [20/120], Loss: 0.2023, Val Loss: 0.5956
Epoch [21/120], Loss: 0.1637, Val Loss: 0.5605
Epoch [22/120], Loss: 0.5134, Val Loss: 0.7132
Epoch [23/120], Loss: 0.1075, Val Loss: 0.5617
Epoch [24/120], Loss: 0.3132, Val Loss: 0.5888
Epoch [25/120], Loss: 0.2589, Val Loss: 0.5707
Epoch [26/120], Loss: 1.0292, Val Loss: 0.6490
Epoch [27/120], Loss: 0.2337, Val Loss: 0.6640
Epoch [28/120], Loss: 0.1626, Val Loss: 0.5661
Epoch [29/120], Loss: 0.3983, Val Loss: 0.5662
Epoch [30/120], Loss: 0.1203, Val Loss: 0.5508
Epoch [31/120], Loss: 0.3070, Val Loss: 0.5792
Epoch [32/120], Loss: 0.2487, Val Loss: 0.5399
Epoch [33/120], Loss: 0.1039, Val Loss: 0.6122
Epoch [34/120], Loss: 0.2022, Val Loss: 0.5118
Epoch [35/120], Loss: 0.1736, Val Loss: 0.5321
Epoch [36/120], Loss: 0.2936, Val Loss: 0.6232
Epoch [37/120], Loss: 1.6465, Val Loss: 0.5960
Epoch [38/120], Loss: 0.8183, Val Loss: 0.5446
Epoch [39/120], Loss: 0.1255, Val Loss: 0.6080
Epoch [40/120], Loss: 0.2297, Val Loss: 0.5353
Epoch [41/120], Loss: 0.1796, Val Loss: 0.5337
Epoch [42/120], Loss: 0.3532, Val Loss: 0.4924
Epoch [43/120], Loss: 0.2155, Val Loss: 0.5214
Epoch [44/120], Loss: 0.8540, Val Loss: 0.5761
Epoch [45/120], Loss: 0.0600, Val Loss: 0.5225
Epoch [46/120], Loss: 0.1016, Val Loss: 0.5018
Epoch [47/120], Loss: 0.1607, Val Loss: 0.5358
Epoch [48/120], Loss: 0.1748, Val Loss: 0.5602
Epoch [49/120], Loss: 0.2557, Val Loss: 0.5509
Epoch [50/120], Loss: 0.1898, Val Loss: 0.5672
Epoch [51/120], Loss: 0.0977, Val Loss: 0.6012
Epoch [52/120], Loss: 0.1726, Val Loss: 0.6373
Epoch [53/120], Loss: 0.2374, Val Loss: 0.5820
Epoch [54/120], Loss: 0.2528, Val Loss: 0.5865
Epoch [55/120], Loss: 0.2973, Val Loss: 0.4975
Epoch [56/120], Loss: 0.1106, Val Loss: 0.6053
Epoch [57/120], Loss: 0.1110, Val Loss: 0.5995
Epoch [58/120], Loss: 0.7832, Val Loss: 0.5306
Epoch [59/120], Loss: 0.1624, Val Loss: 0.5485
Epoch [60/120], Loss: 0.1091, Val Loss: 0.5248
Epoch [61/120], Loss: 0.0999, Val Loss: 0.5126
Epoch [62/120], Loss: 0.5501, Val Loss: 0.5216
Epoch [63/120], Loss: 0.1670, Val Loss: 0.5250
Epoch [64/120], Loss: 0.2353, Val Loss: 0.5147
Epoch [65/120], Loss: 0.0869, Val Loss: 0.4966
Epoch [66/120], Loss: 0.1696, Val Loss: 0.4956
Epoch [67/120], Loss: 0.3346, Val Loss: 0.5177
Epoch [68/120], Loss: 0.2140, Val Loss: 0.5477
Epoch [69/120], Loss: 0.0503, Val Loss: 0.4941
Epoch [70/120], Loss: 0.6516, Val Loss: 0.5953
Epoch [71/120], Loss: 0.1786, Val Loss: 0.5903
Epoch [72/120], Loss: 0.1864, Val Loss: 0.5494
Epoch [73/120], Loss: 0.1905, Val Loss: 0.5783
Epoch [74/120], Loss: 0.3035, Val Loss: 0.5504
Epoch [75/120], Loss: 0.0865, Val Loss: 0.5458
Epoch [76/120], Loss: 0.1481, Val Loss: 0.5057
Epoch [77/120], Loss: 0.1099, Val Loss: 0.5232
Epoch [78/120], Loss: 0.2734, Val Loss: 0.5092
Epoch [79/120], Loss: 0.0870, Val Loss: 0.5024
Epoch [80/120], Loss: 0.1162, Val Loss: 0.6061
Epoch [81/120], Loss: 0.1297, Val Loss: 0.5159
Epoch [82/120], Loss: 0.0980, Val Loss: 0.5636
Epoch [83/120], Loss: 0.1308, Val Loss: 0.4918
Epoch [84/120], Loss: 0.3554, Val Loss: 0.5235
Epoch [85/120], Loss: 0.2036, Val Loss: 0.5406
Epoch [86/120], Loss: 0.2812, Val Loss: 0.4845
Epoch [87/120], Loss: 0.1731, Val Loss: 0.5005
Epoch [88/120], Loss: 0.2166, Val Loss: 0.5206
Epoch [89/120], Loss: 0.7139, Val Loss: 0.4959
Epoch [90/120], Loss: 0.3147, Val Loss: 0.5767
Epoch [91/120], Loss: 0.3299, Val Loss: 0.4997
Epoch [92/120], Loss: 0.0934, Val Loss: 0.5613
Epoch [93/120], Loss: 0.9403, Val Loss: 0.5841
Epoch [94/120], Loss: 0.0698, Val Loss: 0.5443
Epoch [95/120], Loss: 0.0607, Val Loss: 0.5514
Epoch [96/120], Loss: 0.1825, Val Loss: 0.5929
Epoch [97/120], Loss: 0.0970, Val Loss: 0.5760
Epoch [98/120], Loss: 0.1662, Val Loss: 0.4960
Epoch [99/120], Loss: 0.2341, Val Loss: 0.5222
Epoch [100/120], Loss: 0.2756, Val Loss: 0.4898
Epoch [101/120], Loss: 0.1716, Val Loss: 0.5403
Epoch [102/120], Loss: 0.0919, Val Loss: 0.5090
Epoch [103/120], Loss: 0.0558, Val Loss: 0.5557
Epoch [104/120], Loss: 0.1397, Val Loss: 0.4955
Epoch [105/120], Loss: 0.1639, Val Loss: 0.5465
Epoch [106/120], Loss: 0.1138, Val Loss: 0.5239
Epoch [107/120], Loss: 0.0802, Val Loss: 0.4932
Epoch [108/120], Loss: 0.1521, Val Loss: 0.5214
Epoch [109/120], Loss: 0.2307, Val Loss: 0.4872
Epoch [110/120], Loss: 0.0815, Val Loss: 0.4999
Epoch [111/120], Loss: 0.0920, Val Loss: 0.5140
Epoch [112/120], Loss: 0.3047, Val Loss: 0.5816
Epoch [113/120], Loss: 0.0970, Val Loss: 0.5388
Epoch [114/120], Loss: 0.1641, Val Loss: 0.4793
Epoch [115/120], Loss: 0.2532, Val Loss: 0.4959
Epoch [116/120], Loss: 0.0645, Val Loss: 0.4781
Epoch [117/120], Loss: 0.0558, Val Loss: 0.4824
Epoch [118/120], Loss: 0.1000, Val Loss: 0.5098
Epoch [119/120], Loss: 0.0758, Val Loss: 0.5343
Epoch [120/120], Loss: 0.0919, Val Loss: 0.4622
Runtime: 0:00:57.443721
R^2 Score: 0.9053
RMSE: 0.6027
MAE: 0.1919
MAPE: 16.44%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.2395, Val Loss: 1.1414
Epoch [2/120], Loss: 0.0972, Val Loss: 0.8407
Epoch [3/120], Loss: 0.1958, Val Loss: 1.0060
Epoch [4/120], Loss: 0.2435, Val Loss: 0.7292
Epoch [5/120], Loss: 0.2596, Val Loss: 0.7428
Epoch [6/120], Loss: 0.3474, Val Loss: 0.7566
Epoch [7/120], Loss: 0.6455, Val Loss: 0.8819
Epoch [8/120], Loss: 0.0586, Val Loss: 0.7376
Epoch [9/120], Loss: 0.5789, Val Loss: 0.7042
Epoch [10/120], Loss: 0.2949, Val Loss: 0.7085
Epoch [11/120], Loss: 1.6361, Val Loss: 0.7098
Epoch [12/120], Loss: 0.1671, Val Loss: 0.6441
Epoch [13/120], Loss: 0.0985, Val Loss: 0.6137
Epoch [14/120], Loss: 0.3092, Val Loss: 0.8107
Epoch [15/120], Loss: 0.1101, Val Loss: 0.6137
Epoch [16/120], Loss: 0.5431, Val Loss: 0.6051
Epoch [17/120], Loss: 0.1241, Val Loss: 0.5887
Epoch [18/120], Loss: 1.8635, Val Loss: 0.6528
Epoch [19/120], Loss: 0.1603, Val Loss: 0.6228
Epoch [20/120], Loss: 0.1191, Val Loss: 0.6148
Epoch [21/120], Loss: 0.2136, Val Loss: 0.6406
Epoch [22/120], Loss: 0.4272, Val Loss: 0.6082
Epoch [23/120], Loss: 0.2025, Val Loss: 0.5749
Epoch [24/120], Loss: 0.1165, Val Loss: 0.5695
Epoch [25/120], Loss: 0.2006, Val Loss: 0.6051
Epoch [26/120], Loss: 0.4634, Val Loss: 0.5270
Epoch [27/120], Loss: 0.5102, Val Loss: 0.5947
Epoch [28/120], Loss: 0.3373, Val Loss: 0.5424
Epoch [29/120], Loss: 0.3827, Val Loss: 0.5680
Epoch [30/120], Loss: 0.4051, Val Loss: 0.5724
Epoch [31/120], Loss: 0.7935, Val Loss: 0.5780
Epoch [32/120], Loss: 0.1877, Val Loss: 0.6219
Epoch [33/120], Loss: 0.1539, Val Loss: 0.5712
Epoch [34/120], Loss: 0.1203, Val Loss: 0.5635
Epoch [35/120], Loss: 0.1932, Val Loss: 0.6446
Epoch [36/120], Loss: 0.0635, Val Loss: 0.5989
Epoch [37/120], Loss: 0.5861, Val Loss: 0.6811
Epoch [38/120], Loss: 0.0703, Val Loss: 0.5129
Epoch [39/120], Loss: 0.2293, Val Loss: 0.6373
Epoch [40/120], Loss: 0.1102, Val Loss: 0.5310
Epoch [41/120], Loss: 0.3058, Val Loss: 0.5099
Epoch [42/120], Loss: 0.3033, Val Loss: 0.5530
Epoch [43/120], Loss: 0.5450, Val Loss: 0.5927
Epoch [44/120], Loss: 0.3118, Val Loss: 0.6041
Epoch [45/120], Loss: 0.2283, Val Loss: 0.5202
Epoch [46/120], Loss: 0.7214, Val Loss: 0.5402
Epoch [47/120], Loss: 0.2983, Val Loss: 0.5565
Epoch [48/120], Loss: 0.5328, Val Loss: 0.5549
Epoch [49/120], Loss: 0.2884, Val Loss: 0.4834
Epoch [50/120], Loss: 0.0929, Val Loss: 0.5946
Epoch [51/120], Loss: 0.2828, Val Loss: 0.5759
Epoch [52/120], Loss: 0.2977, Val Loss: 0.5240
Epoch [53/120], Loss: 0.1362, Val Loss: 0.5013
Epoch [54/120], Loss: 0.3603, Val Loss: 0.4923
Epoch [55/120], Loss: 0.1143, Val Loss: 0.5518
Epoch [56/120], Loss: 0.0966, Val Loss: 0.5153
Epoch [57/120], Loss: 0.0957, Val Loss: 0.4967
Epoch [58/120], Loss: 0.1137, Val Loss: 0.4988
Epoch [59/120], Loss: 0.7641, Val Loss: 0.5169
Epoch [60/120], Loss: 0.2971, Val Loss: 0.5577
Epoch [61/120], Loss: 0.1895, Val Loss: 0.5784
Epoch [62/120], Loss: 0.1149, Val Loss: 0.5099
Epoch [63/120], Loss: 0.1659, Val Loss: 0.4735
Epoch [64/120], Loss: 0.2711, Val Loss: 0.5204
Epoch [65/120], Loss: 0.2292, Val Loss: 0.4745
Epoch [66/120], Loss: 0.3541, Val Loss: 0.5074
Epoch [67/120], Loss: 0.1292, Val Loss: 0.5628
Epoch [68/120], Loss: 0.2448, Val Loss: 0.4670
Epoch [69/120], Loss: 0.0424, Val Loss: 0.4773
Epoch [70/120], Loss: 0.0521, Val Loss: 0.5388
Epoch [71/120], Loss: 0.1711, Val Loss: 0.4813
Epoch [72/120], Loss: 0.1172, Val Loss: 0.5647
Epoch [73/120], Loss: 0.1232, Val Loss: 0.4670
Epoch [74/120], Loss: 0.2356, Val Loss: 0.4252
Epoch [75/120], Loss: 0.0919, Val Loss: 0.4630
Epoch [76/120], Loss: 0.1231, Val Loss: 0.4450
Epoch [77/120], Loss: 0.7653, Val Loss: 0.4529
Epoch [78/120], Loss: 1.7007, Val Loss: 0.5130
Epoch [79/120], Loss: 0.1309, Val Loss: 0.4389
Epoch [80/120], Loss: 0.2467, Val Loss: 0.4571
Epoch [81/120], Loss: 0.1080, Val Loss: 0.4505
Epoch [82/120], Loss: 0.0887, Val Loss: 0.4323
Epoch [83/120], Loss: 0.3351, Val Loss: 0.4843
Epoch [84/120], Loss: 0.1040, Val Loss: 0.4609
Epoch [85/120], Loss: 0.4198, Val Loss: 0.4703
Epoch [86/120], Loss: 0.1518, Val Loss: 0.4488
Epoch [87/120], Loss: 0.2101, Val Loss: 0.4983
Epoch [88/120], Loss: 0.1616, Val Loss: 0.4667
Epoch [89/120], Loss: 0.2798, Val Loss: 0.4396
Epoch [90/120], Loss: 0.3241, Val Loss: 0.5349
Epoch [91/120], Loss: 0.0440, Val Loss: 0.4289
Epoch [92/120], Loss: 0.2709, Val Loss: 0.4494
Epoch [93/120], Loss: 0.1005, Val Loss: 0.4183
Epoch [94/120], Loss: 0.1098, Val Loss: 0.5803
Epoch [95/120], Loss: 0.0942, Val Loss: 0.4565
Epoch [96/120], Loss: 0.1510, Val Loss: 0.5175
Epoch [97/120], Loss: 0.1515, Val Loss: 0.4963
Epoch [98/120], Loss: 0.0837, Val Loss: 0.4618
Epoch [99/120], Loss: 0.1329, Val Loss: 0.4866
Epoch [100/120], Loss: 0.2635, Val Loss: 0.4901
Epoch [101/120], Loss: 0.0354, Val Loss: 0.4936
Epoch [102/120], Loss: 0.1673, Val Loss: 0.5394
Epoch [103/120], Loss: 0.3710, Val Loss: 0.4372
Epoch [104/120], Loss: 0.0820, Val Loss: 0.4779
Epoch [105/120], Loss: 0.0722, Val Loss: 0.4567
Epoch [106/120], Loss: 0.1279, Val Loss: 0.4551
Epoch [107/120], Loss: 0.3214, Val Loss: 0.5925
Epoch [108/120], Loss: 0.1256, Val Loss: 0.5014
Epoch [109/120], Loss: 0.4746, Val Loss: 0.4985
Epoch [110/120], Loss: 1.0185, Val Loss: 0.4686
Epoch [111/120], Loss: 0.3825, Val Loss: 0.5677
Epoch [112/120], Loss: 0.0772, Val Loss: 0.5206
Epoch [113/120], Loss: 0.1046, Val Loss: 0.4429
Epoch [114/120], Loss: 0.0720, Val Loss: 0.4514
Epoch [115/120], Loss: 0.2808, Val Loss: 0.4327
Epoch [116/120], Loss: 0.1840, Val Loss: 0.4504
Epoch [117/120], Loss: 0.0852, Val Loss: 0.4735
Epoch [118/120], Loss: 0.1294, Val Loss: 0.4493
Epoch [119/120], Loss: 0.1723, Val Loss: 0.5004
Epoch [120/120], Loss: 0.1882, Val Loss: 0.4671
Runtime: 0:00:55.461072
R^2 Score: 0.9002
RMSE: 0.6189
MAE: 0.1970
MAPE: 16.27%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 0.5588, Val Loss: 0.4597
Epoch [2/120], Loss: 0.2022, Val Loss: 0.4888
Epoch [3/120], Loss: 0.0727, Val Loss: 0.4882
Epoch [4/120], Loss: 0.2355, Val Loss: 0.4463
Epoch [5/120], Loss: 0.5784, Val Loss: 0.4963
Epoch [6/120], Loss: 0.2662, Val Loss: 0.5361
Epoch [7/120], Loss: 0.3182, Val Loss: 0.4459
Epoch [8/120], Loss: 0.2410, Val Loss: 0.4446
Epoch [9/120], Loss: 0.0610, Val Loss: 0.4258
Epoch [10/120], Loss: 0.1123, Val Loss: 0.4906
Epoch [11/120], Loss: 0.0681, Val Loss: 0.4476
Epoch [12/120], Loss: 0.0638, Val Loss: 0.4740
Epoch [13/120], Loss: 0.1017, Val Loss: 0.4477
Epoch [14/120], Loss: 0.1207, Val Loss: 0.5212
Epoch [15/120], Loss: 0.0606, Val Loss: 0.4939
Epoch [16/120], Loss: 0.3472, Val Loss: 0.4485
Epoch [17/120], Loss: 0.2519, Val Loss: 0.4315
Epoch [18/120], Loss: 0.0608, Val Loss: 0.4656
Epoch [19/120], Loss: 0.2438, Val Loss: 0.5484
Epoch [20/120], Loss: 0.1190, Val Loss: 0.4480
Epoch [21/120], Loss: 0.2235, Val Loss: 0.4304
Epoch [22/120], Loss: 0.0745, Val Loss: 0.4626
Epoch [23/120], Loss: 0.0211, Val Loss: 0.5376
Epoch [24/120], Loss: 0.2026, Val Loss: 0.4903
Epoch [25/120], Loss: 0.0614, Val Loss: 0.4681
Epoch [26/120], Loss: 0.0853, Val Loss: 0.4943
Epoch [27/120], Loss: 0.3308, Val Loss: 0.5488
Epoch [28/120], Loss: 0.1866, Val Loss: 0.5046
Epoch [29/120], Loss: 0.0798, Val Loss: 0.4621
Epoch [30/120], Loss: 0.1695, Val Loss: 0.5003
Epoch [31/120], Loss: 0.0475, Val Loss: 0.4498
Epoch [32/120], Loss: 0.0601, Val Loss: 0.4139
Epoch [33/120], Loss: 0.0781, Val Loss: 0.4450
Epoch [34/120], Loss: 0.0816, Val Loss: 0.4412
Epoch [35/120], Loss: 0.1387, Val Loss: 0.4666
Epoch [36/120], Loss: 0.1562, Val Loss: 0.4769
Epoch [37/120], Loss: 0.1173, Val Loss: 0.4808
Epoch [38/120], Loss: 0.0905, Val Loss: 0.4997
Epoch [39/120], Loss: 0.0642, Val Loss: 0.5155
Epoch [40/120], Loss: 0.1095, Val Loss: 0.4796
Epoch [41/120], Loss: 0.2361, Val Loss: 0.4597
Epoch [42/120], Loss: 0.1428, Val Loss: 0.4782
Epoch [43/120], Loss: 0.2248, Val Loss: 0.4554
Epoch [44/120], Loss: 0.0542, Val Loss: 0.4212
Epoch [45/120], Loss: 0.1569, Val Loss: 0.4395
Epoch [46/120], Loss: 0.1098, Val Loss: 0.4330
Epoch [47/120], Loss: 0.1351, Val Loss: 0.4614
Epoch [48/120], Loss: 0.1456, Val Loss: 0.4539
Epoch [49/120], Loss: 0.7654, Val Loss: 0.4424
Epoch [50/120], Loss: 0.1443, Val Loss: 0.4616
Epoch [51/120], Loss: 0.1013, Val Loss: 0.4255
Epoch [52/120], Loss: 0.0644, Val Loss: 0.4188
Epoch [53/120], Loss: 0.3175, Val Loss: 0.4417
Epoch [54/120], Loss: 0.3519, Val Loss: 0.4554
Epoch [55/120], Loss: 1.0560, Val Loss: 0.4328
Epoch [56/120], Loss: 0.0579, Val Loss: 0.4298
Epoch [57/120], Loss: 0.0630, Val Loss: 0.4478
Epoch [58/120], Loss: 0.1295, Val Loss: 0.4545
Epoch [59/120], Loss: 0.1305, Val Loss: 0.4326
Epoch [60/120], Loss: 0.0469, Val Loss: 0.4703
Epoch [61/120], Loss: 0.1165, Val Loss: 0.4933
Epoch [62/120], Loss: 0.0703, Val Loss: 0.4169
Epoch [63/120], Loss: 0.1427, Val Loss: 0.4413
Epoch [64/120], Loss: 0.2242, Val Loss: 0.4218
Epoch [65/120], Loss: 0.2172, Val Loss: 0.4271
Epoch [66/120], Loss: 0.1723, Val Loss: 0.4563
Epoch [67/120], Loss: 0.0809, Val Loss: 0.5403
Epoch [68/120], Loss: 0.1016, Val Loss: 0.4480
Epoch [69/120], Loss: 0.2027, Val Loss: 0.4512
Epoch [70/120], Loss: 0.0853, Val Loss: 0.4094
Epoch [71/120], Loss: 0.1426, Val Loss: 0.4369
Epoch [72/120], Loss: 0.1355, Val Loss: 0.4237
Epoch [73/120], Loss: 0.2669, Val Loss: 0.4423
Epoch [74/120], Loss: 0.1704, Val Loss: 0.4606
Epoch [75/120], Loss: 0.2550, Val Loss: 0.4477
Epoch [76/120], Loss: 1.5850, Val Loss: 0.4865
Epoch [77/120], Loss: 0.1939, Val Loss: 0.4837
Epoch [78/120], Loss: 0.1603, Val Loss: 0.4553
Epoch [79/120], Loss: 0.1247, Val Loss: 0.4404
Epoch [80/120], Loss: 0.2136, Val Loss: 0.4644
Epoch [81/120], Loss: 0.0575, Val Loss: 0.4688
Epoch [82/120], Loss: 0.2569, Val Loss: 0.5043
Epoch [83/120], Loss: 0.1060, Val Loss: 0.4536
Epoch [84/120], Loss: 0.3575, Val Loss: 0.4597
Epoch [85/120], Loss: 0.0383, Val Loss: 0.4574
Epoch [86/120], Loss: 0.5030, Val Loss: 0.4868
Epoch [87/120], Loss: 0.1992, Val Loss: 0.4596
Epoch [88/120], Loss: 0.2274, Val Loss: 0.4490
Epoch [89/120], Loss: 0.1363, Val Loss: 0.4668
Epoch [90/120], Loss: 0.0496, Val Loss: 0.4578
Epoch [91/120], Loss: 0.1497, Val Loss: 0.4385
Epoch [92/120], Loss: 0.0424, Val Loss: 0.4854
Epoch [93/120], Loss: 0.1364, Val Loss: 0.4885
Epoch [94/120], Loss: 0.0878, Val Loss: 0.4444
Epoch [95/120], Loss: 0.2574, Val Loss: 0.4731
Epoch [96/120], Loss: 0.3459, Val Loss: 0.4442
Epoch [97/120], Loss: 0.2471, Val Loss: 0.4365
Epoch [98/120], Loss: 0.2264, Val Loss: 0.4589
Epoch [99/120], Loss: 0.1217, Val Loss: 0.4313
Early stopping at epoch 99
Runtime: 0:00:46.449062
R^2 Score: 0.9190
RMSE: 0.5577
MAE: 0.1798
MAPE: 14.26%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [121, 132, 90] - Result:
Epoch [1/120], Loss: 0.5535, Val Loss: 1.0427
Epoch [2/120], Loss: 0.4105, Val Loss: 0.8503
Epoch [3/120], Loss: 0.2093, Val Loss: 0.7751
Epoch [4/120], Loss: 1.1743, Val Loss: 0.7922
Epoch [5/120], Loss: 0.9689, Val Loss: 0.7547
Epoch [6/120], Loss: 0.1049, Val Loss: 0.7738
Epoch [7/120], Loss: 0.2733, Val Loss: 0.8317
Epoch [8/120], Loss: 0.2297, Val Loss: 0.6649
Epoch [9/120], Loss: 0.8234, Val Loss: 0.8263
Epoch [10/120], Loss: 0.5256, Val Loss: 0.7993
Epoch [11/120], Loss: 1.1108, Val Loss: 0.6620
Epoch [12/120], Loss: 1.2145, Val Loss: 0.6414
Epoch [13/120], Loss: 0.2162, Val Loss: 0.7115
Epoch [14/120], Loss: 0.3379, Val Loss: 0.6034
Epoch [15/120], Loss: 1.3091, Val Loss: 0.6342
Epoch [16/120], Loss: 0.2156, Val Loss: 0.7223
Epoch [17/120], Loss: 0.0842, Val Loss: 0.6086
Epoch [18/120], Loss: 0.2111, Val Loss: 0.6700
Epoch [19/120], Loss: 0.4982, Val Loss: 0.6765
Epoch [20/120], Loss: 0.3682, Val Loss: 0.6736
Epoch [21/120], Loss: 0.2557, Val Loss: 0.6026
Epoch [22/120], Loss: 0.0739, Val Loss: 0.6386
Epoch [23/120], Loss: 0.3422, Val Loss: 0.6108
Epoch [24/120], Loss: 0.4530, Val Loss: 0.5674
Epoch [25/120], Loss: 1.1171, Val Loss: 0.5680
Epoch [26/120], Loss: 0.1193, Val Loss: 0.6032
Epoch [27/120], Loss: 0.2741, Val Loss: 0.5497
Epoch [28/120], Loss: 0.0887, Val Loss: 0.5488
Epoch [29/120], Loss: 0.1741, Val Loss: 0.5361
Epoch [30/120], Loss: 0.1098, Val Loss: 0.5824
Epoch [31/120], Loss: 1.5808, Val Loss: 0.5861
Epoch [32/120], Loss: 2.2266, Val Loss: 0.5743
Epoch [33/120], Loss: 0.1111, Val Loss: 0.6289
Epoch [34/120], Loss: 0.0859, Val Loss: 0.5343
Epoch [35/120], Loss: 0.1213, Val Loss: 0.5352
Epoch [36/120], Loss: 0.6880, Val Loss: 0.5663
Epoch [37/120], Loss: 0.1076, Val Loss: 0.5508
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [151, 192, 120] - Result:
Epoch [1/120], Loss: 0.1808, Val Loss: 0.9309
Epoch [2/120], Loss: 1.5730, Val Loss: 0.8665
Epoch [3/120], Loss: 0.3852, Val Loss: 0.8370
Epoch [4/120], Loss: 0.4281, Val Loss: 0.8217
Epoch [5/120], Loss: 0.6047, Val Loss: 0.7636
Epoch [6/120], Loss: 0.3885, Val Loss: 0.7863
Epoch [7/120], Loss: 0.1963, Val Loss: 0.8528
Epoch [8/120], Loss: 0.2326, Val Loss: 0.7004
Epoch [9/120], Loss: 1.7669, Val Loss: 0.7933
Epoch [10/120], Loss: 0.2554, Val Loss: 0.7206
Epoch [11/120], Loss: 0.2253, Val Loss: 0.7287
Epoch [12/120], Loss: 0.2318, Val Loss: 0.6492
Epoch [13/120], Loss: 0.3052, Val Loss: 0.6607
Epoch [14/120], Loss: 0.4691, Val Loss: 0.8135
Epoch [15/120], Loss: 0.2530, Val Loss: 0.6345
Epoch [16/120], Loss: 0.3761, Val Loss: 0.5844
Epoch [17/120], Loss: 0.0498, Val Loss: 0.5525
Epoch [18/120], Loss: 0.1465, Val Loss: 0.6047
Epoch [19/120], Loss: 0.7803, Val Loss: 0.5473
Epoch [20/120], Loss: 0.0726, Val Loss: 0.5328
Epoch [21/120], Loss: 0.2113, Val Loss: 0.5367
Epoch [22/120], Loss: 0.1169, Val Loss: 0.6793
Epoch [23/120], Loss: 0.1392, Val Loss: 0.5840
Epoch [24/120], Loss: 0.5170, Val Loss: 0.5640
Epoch [25/120], Loss: 1.5806, Val Loss: 0.5637
Epoch [26/120], Loss: 0.7574, Val Loss: 0.5902
Epoch [27/120], Loss: 0.2556, Val Loss: 0.5482
Epoch [28/120], Loss: 0.6259, Val Loss: 0.6207
Epoch [29/120], Loss: 0.4329, Val Loss: 0.6103
Epoch [30/120], Loss: 1.6383, Val Loss: 0.5690
Epoch [31/120], Loss: 0.0871, Val Loss: 0.5671
Epoch [32/120], Loss: 0.0865, Val Loss: 0.5069
Epoch [33/120], Loss: 0.3116, Val Loss: 0.4980
Epoch [34/120], Loss: 0.6472, Val Loss: 0.5929
Epoch [35/120], Loss: 0.0752, Val Loss: 0.5366
Epoch [36/120], Loss: 0.1664, Val Loss: 0.5737
Epoch [37/120], Loss: 0.2953, Val Loss: 0.5630
Epoch [38/120], Loss: 0.4641, Val Loss: 0.6265
Epoch [39/120], Loss: 0.0779, Val Loss: 0.5459
Epoch [40/120], Loss: 0.2335, Val Loss: 0.5059
Epoch [41/120], Loss: 0.4444, Val Loss: 0.5608
Epoch [42/120], Loss: 0.3626, Val Loss: 0.7295
Epoch [43/120], Loss: 0.1478, Val Loss: 0.5017
Epoch [44/120], Loss: 0.3079, Val Loss: 0.5235
Epoch [45/120], Loss: 0.0930, Val Loss: 0.5101
Epoch [46/120], Loss: 0.0558, Val Loss: 0.5034
Epoch [47/120], Loss: 0.2360, Val Loss: 0.5122
Epoch [48/120], Loss: 0.0993, Val Loss: 0.5563
Epoch [49/120], Loss: 0.0322, Val Loss: 0.5172
Epoch [50/120], Loss: 0.1209, Val Loss: 0.5418
Epoch [51/120], Loss: 0.3896, Val Loss: 0.5393
Epoch [52/120], Loss: 0.1980, Val Loss: 0.5224
Epoch [53/120], Loss: 0.1529, Val Loss: 0.5228
Epoch [54/120], Loss: 0.1475, Val Loss: 0.5432
Epoch [55/120], Loss: 0.0709, Val Loss: 0.7051
Epoch [56/120], Loss: 0.0794, Val Loss: 0.5413
Epoch [57/120], Loss: 0.4484, Val Loss: 0.6015
Epoch [58/120], Loss: 0.1837, Val Loss: 0.5799
Epoch [59/120], Loss: 0.1781, Val Loss: 0.5422
Epoch [60/120], Loss: 0.0983, Val Loss: 0.5189
Epoch [61/120], Loss: 0.1446, Val Loss: 0.5224
Epoch [62/120], Loss: 0.0786, Val Loss: 0.5292
Epoch [63/120], Loss: 0.2811, Val Loss: 0.5235
Epoch [64/120], Loss: 0.2142, Val Loss: 0.5181
Epoch [65/120], Loss: 0.2551, Val Loss: 0.5672
Epoch [66/120], Loss: 0.4768, Val Loss: 0.5287
Epoch [67/120], Loss: 0.2187, Val Loss: 0.5083
Epoch [68/120], Loss: 0.2014, Val Loss: 0.5422
Epoch [69/120], Loss: 0.0740, Val Loss: 0.5467
Epoch [70/120], Loss: 0.6186, Val Loss: 0.5398
Epoch [71/120], Loss: 0.1589, Val Loss: 0.6473
Epoch [72/120], Loss: 0.2055, Val Loss: 0.5335
Early stopping at epoch 72
Runtime: 0:00:33.993099
R^2 Score: 0.9146
RMSE: 0.5724
MAE: 0.1974
MAPE: 16.69%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.3069, Val Loss: 1.0368
Epoch [2/120], Loss: 1.0197, Val Loss: 1.2496
Epoch [3/120], Loss: 0.2669, Val Loss: 0.9133
Epoch [4/120], Loss: 0.5323, Val Loss: 0.7940
Epoch [5/120], Loss: 0.1096, Val Loss: 0.9236
Epoch [6/120], Loss: 0.3801, Val Loss: 0.6656
Epoch [7/120], Loss: 0.7117, Val Loss: 0.7268
Epoch [8/120], Loss: 1.8038, Val Loss: 0.6633
Epoch [9/120], Loss: 0.4730, Val Loss: 0.7203
Epoch [10/120], Loss: 0.1353, Val Loss: 0.7199
Epoch [11/120], Loss: 1.0711, Val Loss: 0.7030
Epoch [12/120], Loss: 0.5861, Val Loss: 0.6938
Epoch [13/120], Loss: 0.1647, Val Loss: 0.6400
Epoch [14/120], Loss: 0.5859, Val Loss: 0.6591
Epoch [15/120], Loss: 0.1029, Val Loss: 0.6465
Epoch [16/120], Loss: 0.1428, Val Loss: 0.6674
Epoch [17/120], Loss: 0.3267, Val Loss: 0.6060
Epoch [18/120], Loss: 0.5097, Val Loss: 0.6263
Epoch [19/120], Loss: 0.1193, Val Loss: 0.6899
Epoch [20/120], Loss: 0.2580, Val Loss: 0.6212
Epoch [21/120], Loss: 0.2588, Val Loss: 0.5691
Epoch [22/120], Loss: 0.9279, Val Loss: 0.5303
Epoch [23/120], Loss: 0.9367, Val Loss: 0.5842
Epoch [24/120], Loss: 0.0918, Val Loss: 0.5555
Epoch [25/120], Loss: 0.2376, Val Loss: 0.5897
Epoch [26/120], Loss: 0.1043, Val Loss: 0.6144
Epoch [27/120], Loss: 0.1747, Val Loss: 0.6374
Epoch [28/120], Loss: 0.0889, Val Loss: 0.6141
Epoch [29/120], Loss: 0.2083, Val Loss: 0.6526
Epoch [30/120], Loss: 0.6028, Val Loss: 0.5477
Epoch [31/120], Loss: 0.0542, Val Loss: 0.6482
Epoch [32/120], Loss: 0.1464, Val Loss: 0.5919
Epoch [33/120], Loss: 0.5274, Val Loss: 0.5667
Epoch [34/120], Loss: 0.1983, Val Loss: 0.6071
Epoch [35/120], Loss: 0.1600, Val Loss: 0.5281
Epoch [36/120], Loss: 0.6662, Val Loss: 0.5528
Epoch [37/120], Loss: 0.1229, Val Loss: 0.5530
Epoch [38/120], Loss: 0.1878, Val Loss: 0.5804
Epoch [39/120], Loss: 0.5268, Val Loss: 0.5016
Epoch [40/120], Loss: 0.0627, Val Loss: 0.5599
Epoch [41/120], Loss: 0.6978, Val Loss: 0.6356
Epoch [42/120], Loss: 0.1742, Val Loss: 0.6517
Epoch [43/120], Loss: 1.0758, Val Loss: 0.5622
Epoch [44/120], Loss: 0.1101, Val Loss: 0.5280
Epoch [45/120], Loss: 0.1808, Val Loss: 0.5866
Epoch [46/120], Loss: 0.9490, Val Loss: 0.6142
Epoch [47/120], Loss: 0.6617, Val Loss: 0.5699
Epoch [48/120], Loss: 0.0859, Val Loss: 0.5516
Epoch [49/120], Loss: 0.2850, Val Loss: 0.4999
Epoch [50/120], Loss: 0.1055, Val Loss: 0.5353
Epoch [51/120], Loss: 0.1546, Val Loss: 0.5109
Epoch [52/120], Loss: 0.0737, Val Loss: 0.4971
Epoch [53/120], Loss: 0.0498, Val Loss: 0.5088
Epoch [54/120], Loss: 0.3993, Val Loss: 0.5847
Epoch [55/120], Loss: 0.3950, Val Loss: 0.5019
Epoch [56/120], Loss: 0.0513, Val Loss: 0.5005
Epoch [57/120], Loss: 0.1776, Val Loss: 0.5956
Epoch [58/120], Loss: 0.2409, Val Loss: 0.5272
Epoch [59/120], Loss: 0.1224, Val Loss: 0.4733
Epoch [60/120], Loss: 0.1047, Val Loss: 0.6414
Epoch [61/120], Loss: 0.3520, Val Loss: 0.5370
Epoch [62/120], Loss: 0.0666, Val Loss: 0.5128
Epoch [63/120], Loss: 0.2929, Val Loss: 0.5231
Epoch [64/120], Loss: 0.0707, Val Loss: 0.5338
Epoch [65/120], Loss: 0.1710, Val Loss: 0.5594
Epoch [66/120], Loss: 0.4889, Val Loss: 0.4908
Epoch [67/120], Loss: 0.3175, Val Loss: 0.5168
Epoch [68/120], Loss: 0.1040, Val Loss: 0.5610
Epoch [69/120], Loss: 0.0951, Val Loss: 0.4911
Epoch [70/120], Loss: 0.1766, Val Loss: 0.5619
Epoch [71/120], Loss: 0.6423, Val Loss: 0.4846
Epoch [72/120], Loss: 0.1490, Val Loss: 0.4988
Epoch [73/120], Loss: 0.7405, Val Loss: 0.5774
Epoch [74/120], Loss: 0.0751, Val Loss: 0.5686
Epoch [75/120], Loss: 0.2950, Val Loss: 0.5080
Epoch [76/120], Loss: 1.2141, Val Loss: 0.6338
Epoch [77/120], Loss: 0.7282, Val Loss: 0.5402
Epoch [78/120], Loss: 0.0819, Val Loss: 0.4715
Epoch [79/120], Loss: 0.3216, Val Loss: 0.6050
Epoch [80/120], Loss: 0.4381, Val Loss: 0.4875
Epoch [81/120], Loss: 0.2918, Val Loss: 0.5012
Epoch [82/120], Loss: 0.1396, Val Loss: 0.6522
Epoch [83/120], Loss: 0.1380, Val Loss: 0.6361
Epoch [84/120], Loss: 0.2181, Val Loss: 0.5188
Epoch [85/120], Loss: 0.2761, Val Loss: 0.5388
Epoch [86/120], Loss: 0.4619, Val Loss: 0.5145
Epoch [87/120], Loss: 0.1043, Val Loss: 0.5113
Epoch [88/120], Loss: 0.0731, Val Loss: 0.5450
Epoch [89/120], Loss: 0.0643, Val Loss: 0.5006
Epoch [90/120], Loss: 0.0664, Val Loss: 0.5080
Epoch [91/120], Loss: 0.1339, Val Loss: 0.5233
Epoch [92/120], Loss: 0.1196, Val Loss: 0.5060
Epoch [93/120], Loss: 0.2468, Val Loss: 0.5029
Epoch [94/120], Loss: 0.5404, Val Loss: 0.4881
Epoch [95/120], Loss: 0.1353, Val Loss: 0.4894
Epoch [96/120], Loss: 0.1408, Val Loss: 0.4944
Epoch [97/120], Loss: 0.0630, Val Loss: 0.5112
Epoch [98/120], Loss: 0.2945, Val Loss: 0.5526
Epoch [99/120], Loss: 0.1705, Val Loss: 0.5096
Epoch [100/120], Loss: 0.2192, Val Loss: 0.5691
Epoch [101/120], Loss: 0.3496, Val Loss: 0.4890
Epoch [102/120], Loss: 0.2064, Val Loss: 0.4975
Epoch [103/120], Loss: 0.1470, Val Loss: 0.5585
Epoch [104/120], Loss: 0.7681, Val Loss: 0.4924
Epoch [105/120], Loss: 0.3075, Val Loss: 0.4913
Epoch [106/120], Loss: 0.1304, Val Loss: 0.4980
Epoch [107/120], Loss: 0.1136, Val Loss: 0.5749
Early stopping at epoch 107
Runtime: 0:00:56.582786
R^2 Score: 0.9106
RMSE: 0.5858
MAE: 0.2015
MAPE: 16.53%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 1.2162, Val Loss: 1.0213
Epoch [2/120], Loss: 0.1970, Val Loss: 1.0446
Epoch [3/120], Loss: 0.2628, Val Loss: 0.8182
Epoch [4/120], Loss: 0.3684, Val Loss: 0.7752
Epoch [5/120], Loss: 0.6250, Val Loss: 0.8402
Epoch [6/120], Loss: 0.1889, Val Loss: 0.8457
Epoch [7/120], Loss: 0.4548, Val Loss: 0.8285
Epoch [8/120], Loss: 7.1220, Val Loss: 1.4170
Epoch [9/120], Loss: 0.3899, Val Loss: 0.8431
Epoch [10/120], Loss: 0.6992, Val Loss: 0.7442
Epoch [11/120], Loss: 0.2450, Val Loss: 0.7564
Epoch [12/120], Loss: 0.4469, Val Loss: 0.6706
Epoch [13/120], Loss: 0.1539, Val Loss: 0.8798
Epoch [14/120], Loss: 0.4485, Val Loss: 0.6648
Epoch [15/120], Loss: 0.3362, Val Loss: 0.7346
Epoch [16/120], Loss: 0.1689, Val Loss: 0.7375
Epoch [17/120], Loss: 0.0813, Val Loss: 0.6830
Epoch [18/120], Loss: 0.0977, Val Loss: 0.6695
Epoch [19/120], Loss: 0.1080, Val Loss: 0.6195
Epoch [20/120], Loss: 1.0371, Val Loss: 0.6931
Epoch [21/120], Loss: 0.2195, Val Loss: 0.6637
Epoch [22/120], Loss: 0.2206, Val Loss: 0.6083
Epoch [23/120], Loss: 0.2456, Val Loss: 0.5791
Epoch [24/120], Loss: 0.0825, Val Loss: 0.6342
Epoch [25/120], Loss: 0.3012, Val Loss: 0.6308
Epoch [26/120], Loss: 0.6149, Val Loss: 0.6116
Epoch [27/120], Loss: 0.3387, Val Loss: 0.7445
Epoch [28/120], Loss: 1.7236, Val Loss: 0.6188
Epoch [29/120], Loss: 0.3938, Val Loss: 0.6346
Epoch [30/120], Loss: 0.1077, Val Loss: 0.5901
Epoch [31/120], Loss: 0.1544, Val Loss: 0.6065
Epoch [32/120], Loss: 0.1235, Val Loss: 0.6485
Epoch [33/120], Loss: 0.9550, Val Loss: 0.6245
Epoch [34/120], Loss: 0.4894, Val Loss: 0.5625
Epoch [35/120], Loss: 0.1789, Val Loss: 0.6031
Epoch [36/120], Loss: 2.0810, Val Loss: 0.6046
Epoch [37/120], Loss: 0.3445, Val Loss: 0.6448
Epoch [38/120], Loss: 0.5306, Val Loss: 0.6838
Epoch [39/120], Loss: 0.3906, Val Loss: 0.7451
Epoch [40/120], Loss: 0.3523, Val Loss: 0.6375
Epoch [41/120], Loss: 0.1360, Val Loss: 0.6527
Epoch [42/120], Loss: 1.3495, Val Loss: 0.6387
Epoch [43/120], Loss: 0.1858, Val Loss: 0.6492
Epoch [44/120], Loss: 0.1783, Val Loss: 0.5884
Epoch [45/120], Loss: 0.3100, Val Loss: 0.5707
Epoch [46/120], Loss: 0.2770, Val Loss: 0.5692
Epoch [47/120], Loss: 0.2553, Val Loss: 0.6421
Epoch [48/120], Loss: 0.2643, Val Loss: 0.6726
Epoch [49/120], Loss: 0.3268, Val Loss: 0.6105
Epoch [50/120], Loss: 0.1361, Val Loss: 0.5629
Epoch [51/120], Loss: 0.5267, Val Loss: 0.6328
Epoch [52/120], Loss: 0.2403, Val Loss: 0.6343
Epoch [53/120], Loss: 0.6190, Val Loss: 0.6120
Epoch [54/120], Loss: 0.1608, Val Loss: 0.6162
Epoch [55/120], Loss: 0.2442, Val Loss: 0.5932
Epoch [56/120], Loss: 0.3574, Val Loss: 0.7023
Epoch [57/120], Loss: 0.2027, Val Loss: 0.5747
Epoch [58/120], Loss: 0.0892, Val Loss: 0.5555
Epoch [59/120], Loss: 0.9363, Val Loss: 0.6405
Epoch [60/120], Loss: 0.4159, Val Loss: 0.5995
Epoch [61/120], Loss: 0.2140, Val Loss: 0.6283
Epoch [62/120], Loss: 0.1163, Val Loss: 0.5631
Epoch [63/120], Loss: 0.0795, Val Loss: 0.7618
Epoch [64/120], Loss: 0.1795, Val Loss: 0.6490
Epoch [65/120], Loss: 0.1032, Val Loss: 0.6809
Epoch [66/120], Loss: 0.1378, Val Loss: 0.5891
Epoch [67/120], Loss: 0.5344, Val Loss: 0.5747
Epoch [68/120], Loss: 0.2050, Val Loss: 0.5679
Epoch [69/120], Loss: 0.5980, Val Loss: 0.6809
Epoch [70/120], Loss: 0.1325, Val Loss: 0.9363
Epoch [71/120], Loss: 0.1279, Val Loss: 0.6232
Epoch [72/120], Loss: 0.1145, Val Loss: 0.7001
Epoch [73/120], Loss: 0.4621, Val Loss: 0.5972
Epoch [74/120], Loss: 0.0582, Val Loss: 0.5823
Epoch [75/120], Loss: 0.1642, Val Loss: 0.5906
Epoch [76/120], Loss: 0.3882, Val Loss: 0.5588
Epoch [77/120], Loss: 0.2007, Val Loss: 0.5707
Epoch [78/120], Loss: 0.0950, Val Loss: 0.6072
Epoch [79/120], Loss: 0.1358, Val Loss: 0.5891
Epoch [80/120], Loss: 0.1869, Val Loss: 0.6018
Epoch [81/120], Loss: 0.6631, Val Loss: 0.5721
Epoch [82/120], Loss: 0.1967, Val Loss: 0.5813
Epoch [83/120], Loss: 0.3551, Val Loss: 0.5935
Epoch [84/120], Loss: 0.2304, Val Loss: 0.6458
Epoch [85/120], Loss: 0.1342, Val Loss: 0.5405
Epoch [86/120], Loss: 0.2033, Val Loss: 0.6412
Epoch [87/120], Loss: 0.1283, Val Loss: 0.6119
Epoch [88/120], Loss: 0.2949, Val Loss: 0.5802
Epoch [89/120], Loss: 0.5981, Val Loss: 0.6144
Epoch [90/120], Loss: 0.1647, Val Loss: 0.6094
Epoch [91/120], Loss: 0.1277, Val Loss: 0.6088
Epoch [92/120], Loss: 0.1399, Val Loss: 0.5929
Epoch [93/120], Loss: 0.5993, Val Loss: 0.5991
Epoch [94/120], Loss: 0.1545, Val Loss: 0.5616
Epoch [95/120], Loss: 0.4705, Val Loss: 0.6184
Epoch [96/120], Loss: 0.3285, Val Loss: 0.5507
Epoch [97/120], Loss: 0.2024, Val Loss: 0.5754
Epoch [98/120], Loss: 0.0723, Val Loss: 0.5276
Epoch [99/120], Loss: 0.2957, Val Loss: 0.5556
Epoch [100/120], Loss: 0.1409, Val Loss: 0.6374
Epoch [101/120], Loss: 0.2062, Val Loss: 0.6048
Epoch [102/120], Loss: 0.1845, Val Loss: 0.5915
Epoch [103/120], Loss: 0.0794, Val Loss: 0.5363
Epoch [104/120], Loss: 0.4370, Val Loss: 0.5575
Epoch [105/120], Loss: 0.2556, Val Loss: 0.6181
Epoch [106/120], Loss: 0.2799, Val Loss: 0.6011
Epoch [107/120], Loss: 0.4284, Val Loss: 0.5514
Epoch [108/120], Loss: 0.1558, Val Loss: 0.7032
Epoch [109/120], Loss: 0.1230, Val Loss: 0.5881
Epoch [110/120], Loss: 0.1326, Val Loss: 0.5267
Epoch [111/120], Loss: 0.3000, Val Loss: 0.5347
Epoch [112/120], Loss: 0.0832, Val Loss: 0.5368
Epoch [113/120], Loss: 0.0902, Val Loss: 0.6061
Epoch [114/120], Loss: 0.1251, Val Loss: 0.5616
Epoch [115/120], Loss: 0.2272, Val Loss: 0.6732
Epoch [116/120], Loss: 0.5227, Val Loss: 0.6558
Epoch [117/120], Loss: 1.0756, Val Loss: 0.6261
Epoch [118/120], Loss: 0.4931, Val Loss: 0.6367
Epoch [119/120], Loss: 0.1139, Val Loss: 0.5600
Epoch [120/120], Loss: 0.2427, Val Loss: 0.6183
Runtime: 0:01:07.715951
R^2 Score: 0.9008
RMSE: 0.6171
MAE: 0.2298
MAPE: 19.71%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.8814, Val Loss: 1.0087
Epoch [2/120], Loss: 0.4845, Val Loss: 0.9701
Epoch [3/120], Loss: 0.5858, Val Loss: 0.9136
Epoch [4/120], Loss: 0.3205, Val Loss: 0.7292
Epoch [5/120], Loss: 0.2713, Val Loss: 0.7619
Epoch [6/120], Loss: 0.1739, Val Loss: 0.7568
Epoch [7/120], Loss: 0.1276, Val Loss: 0.8025
Epoch [8/120], Loss: 0.6191, Val Loss: 0.8581
Epoch [9/120], Loss: 0.2668, Val Loss: 0.8606
Epoch [10/120], Loss: 0.5027, Val Loss: 0.6931
Epoch [11/120], Loss: 0.9366, Val Loss: 0.7972
Epoch [12/120], Loss: 0.9485, Val Loss: 0.6541
Epoch [13/120], Loss: 0.2156, Val Loss: 0.6404
Epoch [14/120], Loss: 0.1867, Val Loss: 0.6752
Epoch [15/120], Loss: 0.7904, Val Loss: 0.6253
Epoch [16/120], Loss: 0.1148, Val Loss: 0.6463
Epoch [17/120], Loss: 0.3954, Val Loss: 0.6054
Epoch [18/120], Loss: 0.1664, Val Loss: 0.6333
Epoch [19/120], Loss: 0.3551, Val Loss: 0.7764
Epoch [20/120], Loss: 0.2126, Val Loss: 0.8099
Epoch [21/120], Loss: 0.3109, Val Loss: 0.7397
Epoch [22/120], Loss: 0.3742, Val Loss: 0.6334
Epoch [23/120], Loss: 0.1468, Val Loss: 0.8412
Epoch [24/120], Loss: 0.2212, Val Loss: 0.5847
Epoch [25/120], Loss: 0.7872, Val Loss: 0.5613
Epoch [26/120], Loss: 0.2748, Val Loss: 0.5397
Epoch [27/120], Loss: 0.1443, Val Loss: 0.6182
Epoch [28/120], Loss: 0.1993, Val Loss: 0.5261
Epoch [29/120], Loss: 0.3269, Val Loss: 0.5839
Epoch [30/120], Loss: 0.2518, Val Loss: 0.6191
Epoch [31/120], Loss: 0.5965, Val Loss: 0.5604
Epoch [32/120], Loss: 0.0799, Val Loss: 0.5413
Epoch [33/120], Loss: 0.2997, Val Loss: 0.5200
Epoch [34/120], Loss: 0.1026, Val Loss: 0.5414
Epoch [35/120], Loss: 0.2589, Val Loss: 0.5541
Epoch [36/120], Loss: 0.1113, Val Loss: 0.6124
Epoch [37/120], Loss: 0.3536, Val Loss: 0.4905
Epoch [38/120], Loss: 0.2777, Val Loss: 0.5044
Epoch [39/120], Loss: 0.1593, Val Loss: 0.5659
Epoch [40/120], Loss: 0.2999, Val Loss: 0.5294
Epoch [41/120], Loss: 0.2949, Val Loss: 0.5601
Epoch [42/120], Loss: 0.1643, Val Loss: 0.5120
Epoch [43/120], Loss: 0.3048, Val Loss: 0.4957
Epoch [44/120], Loss: 0.4390, Val Loss: 0.5820
Epoch [45/120], Loss: 0.4925, Val Loss: 0.6706
Epoch [46/120], Loss: 0.0991, Val Loss: 0.5683
Epoch [47/120], Loss: 0.1861, Val Loss: 0.5325
Epoch [48/120], Loss: 0.1624, Val Loss: 0.7835
Epoch [49/120], Loss: 0.1794, Val Loss: 0.5300
Epoch [50/120], Loss: 0.1108, Val Loss: 0.5575
Epoch [51/120], Loss: 0.0998, Val Loss: 0.5024
Epoch [52/120], Loss: 0.0882, Val Loss: 0.5443
Epoch [53/120], Loss: 0.4969, Val Loss: 0.6728
Epoch [54/120], Loss: 0.2656, Val Loss: 0.6509
Epoch [55/120], Loss: 0.3438, Val Loss: 0.5907
Epoch [56/120], Loss: 0.2296, Val Loss: 0.6080
Epoch [57/120], Loss: 0.4433, Val Loss: 0.6101
Epoch [58/120], Loss: 0.6431, Val Loss: 0.5447
Epoch [59/120], Loss: 0.2669, Val Loss: 0.6374
Epoch [60/120], Loss: 0.0635, Val Loss: 0.6460
Epoch [61/120], Loss: 0.1326, Val Loss: 0.7952
Epoch [62/120], Loss: 0.4078, Val Loss: 0.5591
Epoch [63/120], Loss: 0.2559, Val Loss: 0.5081
Epoch [64/120], Loss: 0.1328, Val Loss: 0.6082
Epoch [65/120], Loss: 0.4304, Val Loss: 0.5185
Epoch [66/120], Loss: 0.3533, Val Loss: 0.5522
Early stopping at epoch 66
Runtime: 0:00:37.806093
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.4620, Val Loss: 0.5123
Epoch [2/120], Loss: 0.2369, Val Loss: 0.5504
Epoch [3/120], Loss: 0.0564, Val Loss: 0.5597
Epoch [4/120], Loss: 0.2851, Val Loss: 0.5471
Epoch [5/120], Loss: 0.0942, Val Loss: 0.5397
Epoch [6/120], Loss: 0.2910, Val Loss: 0.6026
Epoch [7/120], Loss: 0.2849, Val Loss: 0.5419
Epoch [8/120], Loss: 0.2807, Val Loss: 0.5419
Epoch [9/120], Loss: 0.4531, Val Loss: 0.6232
Epoch [10/120], Loss: 0.1866, Val Loss: 0.6400
Epoch [11/120], Loss: 1.2599, Val Loss: 0.5740
Epoch [12/120], Loss: 0.0831, Val Loss: 0.6411
Epoch [13/120], Loss: 0.1010, Val Loss: 0.5559
Epoch [14/120], Loss: 0.2585, Val Loss: 0.5669
Epoch [15/120], Loss: 0.1651, Val Loss: 0.6130
Epoch [16/120], Loss: 0.0841, Val Loss: 0.5604
Epoch [17/120], Loss: 0.1541, Val Loss: 0.5581
Epoch [18/120], Loss: 0.3438, Val Loss: 0.5444
Epoch [19/120], Loss: 0.1579, Val Loss: 0.5909
Epoch [20/120], Loss: 0.1076, Val Loss: 0.5548
Epoch [21/120], Loss: 0.0864, Val Loss: 0.5377
Epoch [22/120], Loss: 0.2667, Val Loss: 0.5128
Epoch [23/120], Loss: 0.2816, Val Loss: 0.6165
Epoch [24/120], Loss: 0.1659, Val Loss: 0.5264
Epoch [25/120], Loss: 0.4243, Val Loss: 0.6241
Epoch [26/120], Loss: 0.1683, Val Loss: 0.5406
Epoch [27/120], Loss: 0.3805, Val Loss: 0.5667
Epoch [28/120], Loss: 0.1486, Val Loss: 0.5464
Epoch [29/120], Loss: 0.2031, Val Loss: 0.5520
Epoch [30/120], Loss: 0.1560, Val Loss: 0.5658
Epoch [31/120], Loss: 0.1009, Val Loss: 0.5563
Epoch [32/120], Loss: 0.1094, Val Loss: 0.5037
Epoch [33/120], Loss: 0.6024, Val Loss: 0.5180
Epoch [34/120], Loss: 0.5022, Val Loss: 0.5661
Epoch [35/120], Loss: 0.1900, Val Loss: 0.5796
Epoch [36/120], Loss: 0.0889, Val Loss: 0.5206
Epoch [37/120], Loss: 0.0816, Val Loss: 0.5238
Epoch [38/120], Loss: 0.2816, Val Loss: 0.5075
Epoch [39/120], Loss: 0.4214, Val Loss: 0.5349
Epoch [40/120], Loss: 0.1583, Val Loss: 0.5136
Epoch [41/120], Loss: 0.2609, Val Loss: 0.6377
Epoch [42/120], Loss: 0.1180, Val Loss: 0.5055
Epoch [43/120], Loss: 0.4180, Val Loss: 0.5201
Epoch [44/120], Loss: 0.3456, Val Loss: 0.5141
Epoch [45/120], Loss: 0.1222, Val Loss: 0.5887
Epoch [46/120], Loss: 0.1275, Val Loss: 0.5229
Epoch [47/120], Loss: 0.1726, Val Loss: 0.5330
Epoch [48/120], Loss: 0.0913, Val Loss: 0.5272
Epoch [49/120], Loss: 0.3917, Val Loss: 0.5086
Epoch [50/120], Loss: 0.2510, Val Loss: 0.5537
Epoch [51/120], Loss: 0.9288, Val Loss: 0.6507
Epoch [52/120], Loss: 0.4380, Val Loss: 0.5572
Epoch [53/120], Loss: 0.2422, Val Loss: 0.5143
Epoch [54/120], Loss: 0.1135, Val Loss: 0.5716
Epoch [55/120], Loss: 0.0974, Val Loss: 0.5200
Epoch [56/120], Loss: 0.0993, Val Loss: 0.4935
Epoch [57/120], Loss: 0.1662, Val Loss: 0.5798
Epoch [58/120], Loss: 0.0953, Val Loss: 0.4890
Epoch [59/120], Loss: 0.1642, Val Loss: 0.5099
Epoch [60/120], Loss: 0.2611, Val Loss: 0.5180
Epoch [61/120], Loss: 0.8072, Val Loss: 0.5135
Epoch [62/120], Loss: 0.0589, Val Loss: 0.5747
Epoch [63/120], Loss: 0.2434, Val Loss: 0.5671
Epoch [64/120], Loss: 0.2281, Val Loss: 0.5413
Epoch [65/120], Loss: 0.1507, Val Loss: 0.6040
Epoch [66/120], Loss: 0.4610, Val Loss: 0.5137
Epoch [67/120], Loss: 0.0823, Val Loss: 0.5519
Epoch [68/120], Loss: 0.1768, Val Loss: 0.5012
Epoch [69/120], Loss: 0.2056, Val Loss: 0.4924
Epoch [70/120], Loss: 0.0787, Val Loss: 0.5151
Epoch [71/120], Loss: 1.0634, Val Loss: 0.7055
Epoch [72/120], Loss: 0.1481, Val Loss: 0.5577
Epoch [73/120], Loss: 0.1062, Val Loss: 0.5237
Epoch [74/120], Loss: 0.1293, Val Loss: 0.5312
Epoch [75/120], Loss: 0.1959, Val Loss: 0.5834
Epoch [76/120], Loss: 0.2033, Val Loss: 0.5529
Epoch [77/120], Loss: 0.0832, Val Loss: 0.5300
Epoch [78/120], Loss: 0.2101, Val Loss: 0.5075
Epoch [79/120], Loss: 0.2717, Val Loss: 0.5246
Epoch [80/120], Loss: 0.0958, Val Loss: 0.5679
Epoch [81/120], Loss: 0.3089, Val Loss: 0.5144
Epoch [82/120], Loss: 0.2179, Val Loss: 0.5444
Epoch [83/120], Loss: 0.2137, Val Loss: 0.5039
Epoch [84/120], Loss: 0.3593, Val Loss: 0.5608
Epoch [85/120], Loss: 0.4826, Val Loss: 0.5599
Epoch [86/120], Loss: 0.2590, Val Loss: 0.5025
Epoch [87/120], Loss: 0.3302, Val Loss: 0.6012
Epoch [88/120], Loss: 0.2727, Val Loss: 0.5373
Epoch [89/120], Loss: 0.2964, Val Loss: 0.6051
Epoch [90/120], Loss: 0.1707, Val Loss: 0.5043
Epoch [91/120], Loss: 0.0827, Val Loss: 0.5224
Epoch [92/120], Loss: 0.4036, Val Loss: 0.6910
Epoch [93/120], Loss: 0.6291, Val Loss: 0.5121
Epoch [94/120], Loss: 0.1250, Val Loss: 0.5409
Epoch [95/120], Loss: 0.2089, Val Loss: 0.5458
Epoch [96/120], Loss: 0.3583, Val Loss: 0.5680
Epoch [97/120], Loss: 0.0761, Val Loss: 0.4982
Epoch [98/120], Loss: 0.0460, Val Loss: 0.5005
Epoch [99/120], Loss: 0.1135, Val Loss: 0.4895
Epoch [100/120], Loss: 0.9203, Val Loss: 0.5119
Epoch [101/120], Loss: 0.4578, Val Loss: 0.5118
Epoch [102/120], Loss: 0.4300, Val Loss: 0.4960
Epoch [103/120], Loss: 0.1577, Val Loss: 0.5584
Epoch [104/120], Loss: 0.1404, Val Loss: 0.5013
Epoch [105/120], Loss: 0.3792, Val Loss: 0.5190
Epoch [106/120], Loss: 0.5792, Val Loss: 0.6230
Epoch [107/120], Loss: 0.1962, Val Loss: 0.4750
Epoch [108/120], Loss: 0.0818, Val Loss: 0.4929
Epoch [109/120], Loss: 0.5258, Val Loss: 0.5229
Epoch [110/120], Loss: 0.9143, Val Loss: 0.5432
Epoch [111/120], Loss: 0.3660, Val Loss: 0.5674
Epoch [112/120], Loss: 0.2244, Val Loss: 0.5571
Epoch [113/120], Loss: 0.0749, Val Loss: 0.5313
Epoch [114/120], Loss: 0.2162, Val Loss: 0.5221
Epoch [115/120], Loss: 0.1955, Val Loss: 0.5334
Epoch [116/120], Loss: 0.1560, Val Loss: 0.5379
Epoch [117/120], Loss: 0.0865, Val Loss: 0.5834
Epoch [118/120], Loss: 0.2161, Val Loss: 0.5342
Epoch [119/120], Loss: 0.1596, Val Loss: 0.6016
Epoch [120/120], Loss: 0.4274, Val Loss: 0.5149
Runtime: 0:01:09.264033
R^2 Score: 0.9121
RMSE: 0.5808
MAE: 0.1987
MAPE: 18.22%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.4148, Val Loss: 1.1676
Epoch [2/120], Loss: 0.9416, Val Loss: 0.9063
Epoch [3/120], Loss: 0.1942, Val Loss: 0.8561
Epoch [4/120], Loss: 1.3964, Val Loss: 0.8915
Epoch [5/120], Loss: 0.4936, Val Loss: 0.8030
Epoch [6/120], Loss: 0.2162, Val Loss: 0.8639
Epoch [7/120], Loss: 0.2306, Val Loss: 0.7212
Epoch [8/120], Loss: 1.1510, Val Loss: 0.7338
Epoch [9/120], Loss: 0.3017, Val Loss: 0.7724
Epoch [10/120], Loss: 0.2028, Val Loss: 0.7923
Epoch [11/120], Loss: 0.3036, Val Loss: 0.8683
Epoch [12/120], Loss: 0.1059, Val Loss: 0.8762
Epoch [13/120], Loss: 0.1318, Val Loss: 0.7774
Epoch [14/120], Loss: 0.1646, Val Loss: 0.7413
Epoch [15/120], Loss: 0.1418, Val Loss: 0.7914
Epoch [16/120], Loss: 0.1767, Val Loss: 0.9223
Epoch [17/120], Loss: 0.4299, Val Loss: 0.7521
Epoch [18/120], Loss: 0.1631, Val Loss: 0.7440
Epoch [19/120], Loss: 0.7650, Val Loss: 0.6751
Epoch [20/120], Loss: 0.2828, Val Loss: 0.8057
Epoch [21/120], Loss: 0.2247, Val Loss: 0.6830
Epoch [22/120], Loss: 1.0055, Val Loss: 0.8160
Epoch [23/120], Loss: 0.7881, Val Loss: 0.7296
Epoch [24/120], Loss: 0.4975, Val Loss: 0.7780
Epoch [25/120], Loss: 0.2351, Val Loss: 0.7189
Epoch [26/120], Loss: 0.5600, Val Loss: 0.7770
Epoch [27/120], Loss: 0.2075, Val Loss: 0.6673
Epoch [28/120], Loss: 0.7303, Val Loss: 0.6337
Epoch [29/120], Loss: 0.1219, Val Loss: 0.6314
Epoch [30/120], Loss: 0.2200, Val Loss: 0.6288
Epoch [31/120], Loss: 1.5883, Val Loss: 0.6306
Epoch [32/120], Loss: 0.3549, Val Loss: 0.6881
Epoch [33/120], Loss: 0.1718, Val Loss: 0.6524
Epoch [34/120], Loss: 0.1794, Val Loss: 0.7006
Epoch [35/120], Loss: 0.3848, Val Loss: 0.7194
Epoch [36/120], Loss: 0.1315, Val Loss: 0.6450
Epoch [37/120], Loss: 0.0415, Val Loss: 0.6288
Epoch [38/120], Loss: 0.1389, Val Loss: 0.6359
Epoch [39/120], Loss: 0.4651, Val Loss: 0.8909
Epoch [40/120], Loss: 0.8308, Val Loss: 0.6030
Epoch [41/120], Loss: 2.1446, Val Loss: 0.6383
Epoch [42/120], Loss: 0.1147, Val Loss: 0.6695
Epoch [43/120], Loss: 0.3341, Val Loss: 0.7632
Epoch [44/120], Loss: 0.2347, Val Loss: 0.7163
Epoch [45/120], Loss: 1.1436, Val Loss: 0.8386
Epoch [46/120], Loss: 0.8627, Val Loss: 0.7050
Epoch [47/120], Loss: 0.5930, Val Loss: 0.6117
Epoch [48/120], Loss: 0.0824, Val Loss: 0.6084
Epoch [49/120], Loss: 0.3037, Val Loss: 0.5959
Epoch [50/120], Loss: 0.2206, Val Loss: 0.6609
Epoch [51/120], Loss: 0.5059, Val Loss: 0.5922
Epoch [52/120], Loss: 0.1052, Val Loss: 0.6415
Epoch [53/120], Loss: 0.5335, Val Loss: 0.7172
Epoch [54/120], Loss: 0.3104, Val Loss: 0.6597
Epoch [55/120], Loss: 0.0775, Val Loss: 0.5738
Epoch [56/120], Loss: 0.0566, Val Loss: 0.6068
Epoch [57/120], Loss: 0.2724, Val Loss: 0.6015
Epoch [58/120], Loss: 0.2769, Val Loss: 0.6000
Epoch [59/120], Loss: 1.4839, Val Loss: 0.6263
Epoch [60/120], Loss: 0.5763, Val Loss: 0.7088
Epoch [61/120], Loss: 0.1542, Val Loss: 0.6307
Epoch [62/120], Loss: 0.7347, Val Loss: 0.6345
Epoch [63/120], Loss: 0.6706, Val Loss: 0.6087
Epoch [64/120], Loss: 0.1066, Val Loss: 0.6134
Epoch [65/120], Loss: 0.3060, Val Loss: 0.6220
Epoch [66/120], Loss: 0.1013, Val Loss: 0.7444
Epoch [67/120], Loss: 3.9381, Val Loss: 0.8533
Epoch [68/120], Loss: 0.2635, Val Loss: 0.5941
Epoch [69/120], Loss: 0.1168, Val Loss: 0.5810
Epoch [70/120], Loss: 0.4194, Val Loss: 0.6503
Epoch [71/120], Loss: 1.0245, Val Loss: 0.6057
Epoch [72/120], Loss: 0.3120, Val Loss: 0.6188
Epoch [73/120], Loss: 0.3096, Val Loss: 0.7277
Epoch [74/120], Loss: 0.0896, Val Loss: 0.6134
Epoch [75/120], Loss: 0.3772, Val Loss: 0.6296
Epoch [76/120], Loss: 0.4620, Val Loss: 0.6272
Epoch [77/120], Loss: 0.1333, Val Loss: 0.6409
Epoch [78/120], Loss: 0.2987, Val Loss: 0.7167
Epoch [79/120], Loss: 0.3040, Val Loss: 0.6169
Epoch [80/120], Loss: 0.3108, Val Loss: 0.6273
Epoch [81/120], Loss: 0.2228, Val Loss: 0.6611
Epoch [82/120], Loss: 0.1302, Val Loss: 0.6176
Epoch [83/120], Loss: 0.1427, Val Loss: 0.6823
Epoch [84/120], Loss: 0.1408, Val Loss: 0.5920
Early stopping at epoch 84
Runtime: 0:00:48.901038
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.1604, Val Loss: 0.6366
Epoch [2/120], Loss: 0.2002, Val Loss: 0.6512
Epoch [3/120], Loss: 0.7160, Val Loss: 0.6370
Epoch [4/120], Loss: 1.1275, Val Loss: 0.5943
Epoch [5/120], Loss: 0.2199, Val Loss: 0.6187
Epoch [6/120], Loss: 0.4243, Val Loss: 0.7249
Epoch [7/120], Loss: 7.0569, Val Loss: 1.0541
Epoch [8/120], Loss: 0.2863, Val Loss: 0.7781
Epoch [9/120], Loss: 0.6255, Val Loss: 0.6534
Epoch [10/120], Loss: 0.3091, Val Loss: 0.6690
Epoch [11/120], Loss: 0.3306, Val Loss: 0.6108
Epoch [12/120], Loss: 0.1209, Val Loss: 0.6238
Epoch [13/120], Loss: 0.1378, Val Loss: 0.5759
Epoch [14/120], Loss: 0.0709, Val Loss: 0.5771
Epoch [15/120], Loss: 0.3199, Val Loss: 0.6010
Epoch [16/120], Loss: 0.1345, Val Loss: 0.5542
Epoch [17/120], Loss: 0.1598, Val Loss: 0.6636
Epoch [18/120], Loss: 0.6465, Val Loss: 0.5660
Epoch [19/120], Loss: 0.4847, Val Loss: 0.6644
Epoch [20/120], Loss: 0.3237, Val Loss: 0.6199
Epoch [21/120], Loss: 0.6081, Val Loss: 0.6345
Epoch [22/120], Loss: 0.2383, Val Loss: 0.5905
Epoch [23/120], Loss: 0.1742, Val Loss: 0.6106
Epoch [24/120], Loss: 0.4665, Val Loss: 0.6479
Epoch [25/120], Loss: 0.1198, Val Loss: 0.6161
Epoch [26/120], Loss: 0.7874, Val Loss: 0.5756
Epoch [27/120], Loss: 0.3809, Val Loss: 0.6771
Epoch [28/120], Loss: 0.6596, Val Loss: 0.6490
Epoch [29/120], Loss: 0.3374, Val Loss: 0.6222
Epoch [30/120], Loss: 0.1469, Val Loss: 0.5936
Epoch [31/120], Loss: 0.8461, Val Loss: 0.6685
Epoch [32/120], Loss: 0.1170, Val Loss: 0.5831
Epoch [33/120], Loss: 0.2425, Val Loss: 0.6034
Epoch [34/120], Loss: 0.1820, Val Loss: 0.5693
Epoch [35/120], Loss: 0.3312, Val Loss: 0.5511
Epoch [36/120], Loss: 0.2507, Val Loss: 0.5824
Epoch [37/120], Loss: 0.1900, Val Loss: 0.6381
Epoch [38/120], Loss: 0.1777, Val Loss: 0.5998
Epoch [39/120], Loss: 0.1717, Val Loss: 0.5733
Epoch [40/120], Loss: 0.2529, Val Loss: 0.6049
Epoch [41/120], Loss: 0.6472, Val Loss: 0.5653
Epoch [42/120], Loss: 0.4822, Val Loss: 0.5800
Epoch [43/120], Loss: 0.1452, Val Loss: 0.6990
Epoch [44/120], Loss: 0.4100, Val Loss: 0.5374
Epoch [45/120], Loss: 0.3037, Val Loss: 0.5950
Epoch [46/120], Loss: 0.7439, Val Loss: 0.5831
Epoch [47/120], Loss: 0.6778, Val Loss: 0.7213
Epoch [48/120], Loss: 0.2305, Val Loss: 0.7680
Epoch [49/120], Loss: 0.1668, Val Loss: 0.5658
Epoch [50/120], Loss: 0.5266, Val Loss: 0.5980
Epoch [51/120], Loss: 0.1651, Val Loss: 0.5752
Epoch [52/120], Loss: 0.0953, Val Loss: 0.6070
Epoch [53/120], Loss: 0.3577, Val Loss: 0.5921
Epoch [54/120], Loss: 0.6873, Val Loss: 0.7584
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.1789, Val Loss: 0.9098
Epoch [2/120], Loss: 0.6211, Val Loss: 0.8913
Epoch [3/120], Loss: 0.1203, Val Loss: 0.7762
Epoch [4/120], Loss: 0.1608, Val Loss: 0.7927
Epoch [5/120], Loss: 0.0747, Val Loss: 0.7991
Epoch [6/120], Loss: 1.1661, Val Loss: 0.7840
Epoch [7/120], Loss: 0.7830, Val Loss: 0.7353
Epoch [8/120], Loss: 0.3246, Val Loss: 0.6859
Epoch [9/120], Loss: 0.8079, Val Loss: 0.6991
Epoch [10/120], Loss: 0.1160, Val Loss: 0.7349
Epoch [11/120], Loss: 0.6172, Val Loss: 0.6902
Epoch [12/120], Loss: 0.6335, Val Loss: 0.6960
Epoch [13/120], Loss: 0.3113, Val Loss: 0.7456
Epoch [14/120], Loss: 0.2923, Val Loss: 0.5873
Epoch [15/120], Loss: 0.4637, Val Loss: 0.5764
Epoch [16/120], Loss: 0.3500, Val Loss: 0.7348
Epoch [17/120], Loss: 1.1333, Val Loss: 0.6138
Epoch [18/120], Loss: 0.0886, Val Loss: 0.6721
Epoch [19/120], Loss: 0.2208, Val Loss: 0.5982
Epoch [20/120], Loss: 0.0836, Val Loss: 0.6179
Epoch [21/120], Loss: 0.1350, Val Loss: 0.5825
Epoch [22/120], Loss: 0.7061, Val Loss: 0.5992
Epoch [23/120], Loss: 0.1330, Val Loss: 0.6069
Epoch [24/120], Loss: 0.2812, Val Loss: 0.6250
Epoch [25/120], Loss: 0.1297, Val Loss: 0.5458
Epoch [26/120], Loss: 0.0741, Val Loss: 0.6816
Epoch [27/120], Loss: 0.3230, Val Loss: 0.5191
Epoch [28/120], Loss: 0.0875, Val Loss: 0.5636
Epoch [29/120], Loss: 0.1068, Val Loss: 0.5763
Epoch [30/120], Loss: 0.2952, Val Loss: 0.6263
Epoch [31/120], Loss: 0.2719, Val Loss: 0.5422
Epoch [32/120], Loss: 0.2673, Val Loss: 0.5972
Epoch [33/120], Loss: 0.4131, Val Loss: 0.6401
Epoch [34/120], Loss: 0.2012, Val Loss: 1.1767
Epoch [35/120], Loss: 0.1492, Val Loss: 0.5741
Epoch [36/120], Loss: 1.1457, Val Loss: 0.5972
Epoch [37/120], Loss: 0.1664, Val Loss: 0.5134
Epoch [38/120], Loss: 0.7052, Val Loss: 0.6588
Epoch [39/120], Loss: 1.1023, Val Loss: 0.5452
Epoch [40/120], Loss: 0.2190, Val Loss: 0.4927
Epoch [41/120], Loss: 0.0570, Val Loss: 0.5422
Epoch [42/120], Loss: 0.0719, Val Loss: 0.5656
Epoch [43/120], Loss: 0.2506, Val Loss: 0.6094
Epoch [44/120], Loss: 0.6880, Val Loss: 0.8667
Epoch [45/120], Loss: 0.0697, Val Loss: 0.5711
Epoch [46/120], Loss: 0.5101, Val Loss: 0.5518
Epoch [47/120], Loss: 0.0688, Val Loss: 0.5130
Epoch [48/120], Loss: 0.1360, Val Loss: 0.5165
Epoch [49/120], Loss: 0.4221, Val Loss: 0.5904
Epoch [50/120], Loss: 0.2001, Val Loss: 0.5569
Epoch [51/120], Loss: 0.2100, Val Loss: 0.5877
Epoch [52/120], Loss: 0.0880, Val Loss: 0.5766
Epoch [53/120], Loss: 0.1285, Val Loss: 0.4953
Epoch [54/120], Loss: 0.0500, Val Loss: 0.5428
Epoch [55/120], Loss: 0.1639, Val Loss: 0.5310
Epoch [56/120], Loss: 0.1317, Val Loss: 0.5794
Epoch [57/120], Loss: 0.0982, Val Loss: 0.6050
Epoch [58/120], Loss: 0.1419, Val Loss: 0.5535
Epoch [59/120], Loss: 0.0948, Val Loss: 0.5106
Epoch [60/120], Loss: 0.3226, Val Loss: 0.4930
Epoch [61/120], Loss: 0.0720, Val Loss: 0.4896
Epoch [62/120], Loss: 0.1810, Val Loss: 0.5045
Epoch [63/120], Loss: 0.1263, Val Loss: 0.5369
Epoch [64/120], Loss: 0.2286, Val Loss: 0.5752
Epoch [65/120], Loss: 0.2957, Val Loss: 0.5431
Epoch [66/120], Loss: 0.3499, Val Loss: 0.6755
Epoch [67/120], Loss: 0.4704, Val Loss: 0.4918
Epoch [68/120], Loss: 0.0892, Val Loss: 0.5130
Epoch [69/120], Loss: 0.2449, Val Loss: 0.5608
Epoch [70/120], Loss: 0.0537, Val Loss: 0.4990
Epoch [71/120], Loss: 0.2740, Val Loss: 0.4984
Epoch [72/120], Loss: 0.1038, Val Loss: 0.5310
Epoch [73/120], Loss: 0.0980, Val Loss: 0.5783
Epoch [74/120], Loss: 0.6376, Val Loss: 0.5030
Epoch [75/120], Loss: 0.1099, Val Loss: 0.4924
Epoch [76/120], Loss: 0.2625, Val Loss: 0.5069
Epoch [77/120], Loss: 0.3627, Val Loss: 0.4860
Epoch [78/120], Loss: 0.0867, Val Loss: 0.5093
Epoch [79/120], Loss: 0.2787, Val Loss: 0.5630
Epoch [80/120], Loss: 0.1279, Val Loss: 0.5108
Epoch [81/120], Loss: 0.1326, Val Loss: 0.5376
Epoch [82/120], Loss: 0.4206, Val Loss: 0.5257
Epoch [83/120], Loss: 0.0821, Val Loss: 0.5859
Epoch [84/120], Loss: 0.1132, Val Loss: 0.5302
Epoch [85/120], Loss: 0.2006, Val Loss: 0.5303
Epoch [86/120], Loss: 0.2270, Val Loss: 0.5629
Epoch [87/120], Loss: 0.6694, Val Loss: 0.5832
Epoch [88/120], Loss: 0.1997, Val Loss: 0.5414
Epoch [89/120], Loss: 0.2902, Val Loss: 0.5716
Epoch [90/120], Loss: 0.1976, Val Loss: 0.6370
Epoch [91/120], Loss: 0.1192, Val Loss: 0.5649
Epoch [92/120], Loss: 0.1634, Val Loss: 0.5573
Epoch [93/120], Loss: 0.1920, Val Loss: 0.5264
Epoch [94/120], Loss: 0.1117, Val Loss: 0.5311
Epoch [95/120], Loss: 0.1200, Val Loss: 0.4841
Epoch [96/120], Loss: 0.1191, Val Loss: 0.5125
Epoch [97/120], Loss: 0.3583, Val Loss: 0.5450
Epoch [98/120], Loss: 0.1555, Val Loss: 0.6235
Epoch [99/120], Loss: 0.2510, Val Loss: 0.5962
Epoch [100/120], Loss: 0.3152, Val Loss: 0.5893
Epoch [101/120], Loss: 0.0802, Val Loss: 0.5443
Epoch [102/120], Loss: 0.7731, Val Loss: 0.5288
Epoch [103/120], Loss: 0.1224, Val Loss: 0.5859
Epoch [104/120], Loss: 0.4239, Val Loss: 0.5343
Epoch [105/120], Loss: 0.4593, Val Loss: 0.5027
Epoch [106/120], Loss: 0.0749, Val Loss: 0.5396
Epoch [107/120], Loss: 0.2164, Val Loss: 0.5448
Epoch [108/120], Loss: 0.3681, Val Loss: 0.5940
Epoch [109/120], Loss: 0.1186, Val Loss: 0.5154
Epoch [110/120], Loss: 0.4479, Val Loss: 0.5477
Epoch [111/120], Loss: 0.3147, Val Loss: 0.6328
Epoch [112/120], Loss: 0.1508, Val Loss: 0.5546
Epoch [113/120], Loss: 0.0976, Val Loss: 0.5225
Epoch [114/120], Loss: 0.1693, Val Loss: 0.5277
Epoch [115/120], Loss: 0.1772, Val Loss: 0.5358
Epoch [116/120], Loss: 0.5307, Val Loss: 0.5828
Epoch [117/120], Loss: 0.1403, Val Loss: 0.5390
Epoch [118/120], Loss: 0.2689, Val Loss: 0.5567
Epoch [119/120], Loss: 0.0563, Val Loss: 0.5549
Epoch [120/120], Loss: 0.1709, Val Loss: 0.5174
Runtime: 0:01:09.586990
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.2463, Val Loss: 0.5276
Epoch [2/120], Loss: 0.0483, Val Loss: 0.5334
Epoch [3/120], Loss: 0.0471, Val Loss: 0.5216
Epoch [4/120], Loss: 0.1531, Val Loss: 0.6834
Epoch [5/120], Loss: 0.2164, Val Loss: 0.5182
Epoch [6/120], Loss: 0.1062, Val Loss: 0.5106
Epoch [7/120], Loss: 0.1600, Val Loss: 0.5291
Epoch [8/120], Loss: 0.1979, Val Loss: 0.5081
Epoch [9/120], Loss: 0.0670, Val Loss: 0.5103
Epoch [10/120], Loss: 0.1817, Val Loss: 0.5546
Epoch [11/120], Loss: 0.5369, Val Loss: 0.5581
Epoch [12/120], Loss: 0.5507, Val Loss: 0.6041
Epoch [13/120], Loss: 0.0852, Val Loss: 0.5193
Epoch [14/120], Loss: 0.0852, Val Loss: 0.5139
Epoch [15/120], Loss: 0.0960, Val Loss: 0.5364
Epoch [16/120], Loss: 0.3004, Val Loss: 0.5817
Epoch [17/120], Loss: 1.1322, Val Loss: 0.5495
Epoch [18/120], Loss: 0.3571, Val Loss: 0.5961
Epoch [19/120], Loss: 0.1224, Val Loss: 0.6315
Epoch [20/120], Loss: 0.1832, Val Loss: 0.5964
Epoch [21/120], Loss: 0.0648, Val Loss: 0.5039
Epoch [22/120], Loss: 0.0462, Val Loss: 0.5124
Epoch [23/120], Loss: 0.7109, Val Loss: 0.5439
Epoch [24/120], Loss: 0.1591, Val Loss: 0.5117
Epoch [25/120], Loss: 0.2197, Val Loss: 0.4908
Epoch [26/120], Loss: 0.0875, Val Loss: 0.5509
Epoch [27/120], Loss: 0.5501, Val Loss: 0.5707
Epoch [28/120], Loss: 0.4835, Val Loss: 0.5065
Epoch [29/120], Loss: 0.0750, Val Loss: 0.5546
Epoch [30/120], Loss: 0.2395, Val Loss: 0.4921
Epoch [31/120], Loss: 0.1856, Val Loss: 0.4976
Epoch [32/120], Loss: 0.0697, Val Loss: 0.6132
Epoch [33/120], Loss: 0.9199, Val Loss: 0.5892
Epoch [34/120], Loss: 0.2678, Val Loss: 0.5176
Epoch [35/120], Loss: 0.0747, Val Loss: 0.5128
Epoch [36/120], Loss: 0.0971, Val Loss: 0.5933
Epoch [37/120], Loss: 0.1050, Val Loss: 0.5478
Epoch [38/120], Loss: 0.2308, Val Loss: 0.5649
Epoch [39/120], Loss: 0.0890, Val Loss: 0.5131
Epoch [40/120], Loss: 0.4367, Val Loss: 0.6350
Epoch [41/120], Loss: 0.1433, Val Loss: 0.6742
Epoch [42/120], Loss: 0.5336, Val Loss: 0.5378
Epoch [43/120], Loss: 0.1653, Val Loss: 0.5445
Epoch [44/120], Loss: 0.3309, Val Loss: 0.5071
Epoch [45/120], Loss: 0.1700, Val Loss: 0.5766
Epoch [46/120], Loss: 0.2198, Val Loss: 0.5637
Epoch [47/120], Loss: 0.2413, Val Loss: 0.5324
Epoch [48/120], Loss: 0.0846, Val Loss: 0.5557
Epoch [49/120], Loss: 0.1757, Val Loss: 0.5799
Epoch [50/120], Loss: 0.0560, Val Loss: 0.5463
Epoch [51/120], Loss: 0.0843, Val Loss: 0.5146
Epoch [52/120], Loss: 0.1590, Val Loss: 0.5480
Epoch [53/120], Loss: 0.0587, Val Loss: 0.5232
Epoch [54/120], Loss: 0.2853, Val Loss: 0.5537
Epoch [55/120], Loss: 0.0798, Val Loss: 0.6078
Epoch [56/120], Loss: 0.1584, Val Loss: 0.5741
Epoch [57/120], Loss: 0.2977, Val Loss: 0.5270
Epoch [58/120], Loss: 0.3028, Val Loss: 0.5429
Epoch [59/120], Loss: 0.2712, Val Loss: 0.5770
Early stopping at epoch 59
Runtime: 0:00:35.419185
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.0797, Val Loss: 0.5605
Epoch [2/120], Loss: 0.9353, Val Loss: 0.5388
Epoch [3/120], Loss: 0.1150, Val Loss: 0.5237
Epoch [4/120], Loss: 0.7090, Val Loss: 0.7415
Epoch [5/120], Loss: 0.2986, Val Loss: 0.5571
Epoch [6/120], Loss: 0.1928, Val Loss: 0.5460
Epoch [7/120], Loss: 0.1188, Val Loss: 0.5090
Epoch [8/120], Loss: 0.1334, Val Loss: 0.4852
Epoch [9/120], Loss: 0.3155, Val Loss: 0.6556
Epoch [10/120], Loss: 0.2085, Val Loss: 0.5053
Epoch [11/120], Loss: 0.3110, Val Loss: 0.5598
Epoch [12/120], Loss: 0.0786, Val Loss: 0.5450
Epoch [13/120], Loss: 0.2101, Val Loss: 0.5567
Epoch [14/120], Loss: 0.1075, Val Loss: 0.5465
Epoch [15/120], Loss: 0.1850, Val Loss: 0.5063
Epoch [16/120], Loss: 0.4648, Val Loss: 0.5623
Epoch [17/120], Loss: 0.4474, Val Loss: 0.5375
Epoch [18/120], Loss: 0.3894, Val Loss: 0.5265
Epoch [19/120], Loss: 0.0877, Val Loss: 0.5930
Epoch [20/120], Loss: 0.3501, Val Loss: 0.5346
Epoch [21/120], Loss: 1.3449, Val Loss: 0.6641
Epoch [22/120], Loss: 0.1100, Val Loss: 0.5211
Epoch [23/120], Loss: 0.2073, Val Loss: 0.5880
Epoch [24/120], Loss: 0.3289, Val Loss: 0.6143
Epoch [25/120], Loss: 0.2751, Val Loss: 0.5226
Epoch [26/120], Loss: 0.1183, Val Loss: 0.5074
Epoch [27/120], Loss: 0.6813, Val Loss: 0.5140
Epoch [28/120], Loss: 0.2338, Val Loss: 0.5229
Epoch [29/120], Loss: 0.0742, Val Loss: 0.5251
Epoch [30/120], Loss: 0.1142, Val Loss: 0.5309
Epoch [31/120], Loss: 0.1098, Val Loss: 0.5606
Epoch [32/120], Loss: 0.2128, Val Loss: 0.5593
Epoch [33/120], Loss: 0.1260, Val Loss: 0.5245
Epoch [34/120], Loss: 0.1753, Val Loss: 0.5246
Epoch [35/120], Loss: 0.1593, Val Loss: 0.5856
Epoch [36/120], Loss: 0.1449, Val Loss: 0.5023
Epoch [37/120], Loss: 0.3538, Val Loss: 0.5458
Early stopping at epoch 37
Runtime: 0:00:23.174338
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.8687, Val Loss: 0.4971
Epoch [2/120], Loss: 0.2348, Val Loss: 0.5655
Epoch [3/120], Loss: 0.0742, Val Loss: 0.5628
Epoch [4/120], Loss: 0.3197, Val Loss: 0.5564
Epoch [5/120], Loss: 0.2076, Val Loss: 0.5547
Epoch [6/120], Loss: 0.1128, Val Loss: 0.5413
Epoch [7/120], Loss: 0.1256, Val Loss: 0.5213
Epoch [8/120], Loss: 0.1866, Val Loss: 0.5368
Epoch [9/120], Loss: 0.1027, Val Loss: 0.5254
Epoch [10/120], Loss: 0.4718, Val Loss: 0.5278
Epoch [11/120], Loss: 0.2269, Val Loss: 0.4997
Epoch [12/120], Loss: 0.1223, Val Loss: 0.5147
Epoch [13/120], Loss: 0.1251, Val Loss: 0.5430
Epoch [14/120], Loss: 0.2008, Val Loss: 0.5506
Epoch [15/120], Loss: 0.1291, Val Loss: 0.5316
Epoch [16/120], Loss: 0.2060, Val Loss: 0.5659
Epoch [17/120], Loss: 0.1133, Val Loss: 0.4800
Epoch [18/120], Loss: 0.1155, Val Loss: 0.5543
Epoch [19/120], Loss: 0.1069, Val Loss: 0.5102
Epoch [20/120], Loss: 0.1166, Val Loss: 0.5520
Epoch [21/120], Loss: 0.2717, Val Loss: 0.5669
Epoch [22/120], Loss: 0.0909, Val Loss: 0.5410
Epoch [23/120], Loss: 0.1480, Val Loss: 0.5863
Epoch [24/120], Loss: 0.0953, Val Loss: 0.5740
Epoch [25/120], Loss: 0.2314, Val Loss: 0.5367
Epoch [26/120], Loss: 0.1045, Val Loss: 0.5069
Epoch [27/120], Loss: 0.3625, Val Loss: 0.5229
Epoch [28/120], Loss: 0.0602, Val Loss: 0.5123
Epoch [29/120], Loss: 0.0981, Val Loss: 0.5469
Epoch [30/120], Loss: 0.1110, Val Loss: 0.5372
Epoch [31/120], Loss: 0.2336, Val Loss: 0.5312
Epoch [32/120], Loss: 0.3048, Val Loss: 0.5329
Epoch [33/120], Loss: 0.0821, Val Loss: 0.5275
Epoch [34/120], Loss: 0.8445, Val Loss: 0.5191
Epoch [35/120], Loss: 0.2554, Val Loss: 0.5275
Epoch [36/120], Loss: 0.5655, Val Loss: 0.5395
Epoch [37/120], Loss: 0.0667, Val Loss: 0.5185
Epoch [38/120], Loss: 0.3136, Val Loss: 0.5294
Epoch [39/120], Loss: 0.3277, Val Loss: 0.5239
Epoch [40/120], Loss: 0.4562, Val Loss: 0.5409
Epoch [41/120], Loss: 0.1483, Val Loss: 0.5283
Epoch [42/120], Loss: 0.0331, Val Loss: 0.5172
Epoch [43/120], Loss: 0.4117, Val Loss: 0.5102
Epoch [44/120], Loss: 0.1637, Val Loss: 0.5321
Epoch [45/120], Loss: 0.0860, Val Loss: 0.5416
Epoch [46/120], Loss: 0.2240, Val Loss: 0.5042
Early stopping at epoch 46
Runtime: 0:00:27.658655
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.2135, Val Loss: 0.5142
Epoch [2/120], Loss: 0.0517, Val Loss: 0.5008
Epoch [3/120], Loss: 0.0863, Val Loss: 0.5201
Epoch [4/120], Loss: 0.0786, Val Loss: 0.5698
Epoch [5/120], Loss: 0.2725, Val Loss: 0.6478
Epoch [6/120], Loss: 0.0769, Val Loss: 0.5315
Epoch [7/120], Loss: 0.1189, Val Loss: 0.5359
Epoch [8/120], Loss: 0.1278, Val Loss: 0.5490
Epoch [9/120], Loss: 0.1347, Val Loss: 0.5712
Epoch [10/120], Loss: 0.0942, Val Loss: 0.4814
Epoch [11/120], Loss: 0.0949, Val Loss: 0.5617
Epoch [12/120], Loss: 0.4844, Val Loss: 0.5598
Epoch [13/120], Loss: 0.2410, Val Loss: 0.5116
Epoch [14/120], Loss: 0.1098, Val Loss: 0.5363
Epoch [15/120], Loss: 0.2347, Val Loss: 0.5718
Epoch [16/120], Loss: 0.3432, Val Loss: 0.5265
Epoch [17/120], Loss: 0.0562, Val Loss: 0.4916
Epoch [18/120], Loss: 0.1970, Val Loss: 0.5997
Epoch [19/120], Loss: 0.3094, Val Loss: 0.5323
Epoch [20/120], Loss: 0.1438, Val Loss: 0.5350
Epoch [21/120], Loss: 0.2102, Val Loss: 0.5628
Epoch [22/120], Loss: 0.0572, Val Loss: 0.5346
Epoch [23/120], Loss: 0.3103, Val Loss: 0.5420
Epoch [24/120], Loss: 0.1695, Val Loss: 0.5011
Epoch [25/120], Loss: 0.1086, Val Loss: 0.5212
Epoch [26/120], Loss: 0.1884, Val Loss: 0.5210
Epoch [27/120], Loss: 0.0400, Val Loss: 0.6543
Epoch [28/120], Loss: 0.1224, Val Loss: 0.5570
Epoch [29/120], Loss: 0.1627, Val Loss: 0.5245
Epoch [30/120], Loss: 0.1227, Val Loss: 0.5120
Epoch [31/120], Loss: 0.2789, Val Loss: 0.5469
Epoch [32/120], Loss: 0.1130, Val Loss: 0.4741
Epoch [33/120], Loss: 0.1924, Val Loss: 0.4750
Epoch [34/120], Loss: 0.1246, Val Loss: 0.4977
Epoch [35/120], Loss: 0.1933, Val Loss: 0.5285
Epoch [36/120], Loss: 0.2825, Val Loss: 0.5224
Epoch [37/120], Loss: 0.0669, Val Loss: 0.5021
Epoch [38/120], Loss: 0.1853, Val Loss: 0.5660
Epoch [39/120], Loss: 0.0930, Val Loss: 0.5424
Epoch [40/120], Loss: 0.0799, Val Loss: 0.5254
Epoch [41/120], Loss: 0.0708, Val Loss: 0.4947
Epoch [42/120], Loss: 0.2435, Val Loss: 0.5659
Epoch [43/120], Loss: 0.2925, Val Loss: 0.5254
Epoch [44/120], Loss: 0.2760, Val Loss: 0.5014
Epoch [45/120], Loss: 0.1992, Val Loss: 0.4869
Epoch [46/120], Loss: 0.1035, Val Loss: 0.5509
Epoch [47/120], Loss: 0.2891, Val Loss: 0.5250
Epoch [48/120], Loss: 0.0759, Val Loss: 0.5500
Epoch [49/120], Loss: 0.1590, Val Loss: 0.5491
Epoch [50/120], Loss: 0.2043, Val Loss: 0.5489
Epoch [51/120], Loss: 0.1581, Val Loss: 0.5268
Epoch [52/120], Loss: 0.0624, Val Loss: 0.5746
Epoch [53/120], Loss: 0.1452, Val Loss: 0.5541
Epoch [54/120], Loss: 0.0928, Val Loss: 0.5494
Epoch [55/120], Loss: 0.2848, Val Loss: 0.6247
Epoch [56/120], Loss: 0.2305, Val Loss: 0.5511
Epoch [57/120], Loss: 0.3321, Val Loss: 0.5290
Epoch [58/120], Loss: 0.0644, Val Loss: 0.5368
Epoch [59/120], Loss: 0.1153, Val Loss: 0.5579
Epoch [60/120], Loss: 0.0893, Val Loss: 0.5721
Epoch [61/120], Loss: 0.3027, Val Loss: 0.5241
Epoch [62/120], Loss: 0.1074, Val Loss: 0.5148
Early stopping at epoch 62
Runtime: 0:00:37.708051
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.5123, Val Loss: 0.5335
Epoch [2/120], Loss: 0.3030, Val Loss: 0.5578
Epoch [3/120], Loss: 0.1478, Val Loss: 0.6220
Epoch [4/120], Loss: 0.1313, Val Loss: 0.5374
Epoch [5/120], Loss: 0.1573, Val Loss: 0.5344
Epoch [6/120], Loss: 0.1082, Val Loss: 0.5634
Epoch [7/120], Loss: 0.3426, Val Loss: 0.5076
Epoch [8/120], Loss: 0.0811, Val Loss: 0.5386
Epoch [9/120], Loss: 0.1925, Val Loss: 0.5430
Epoch [10/120], Loss: 0.0820, Val Loss: 0.5358
Epoch [11/120], Loss: 0.0643, Val Loss: 0.5774
Epoch [12/120], Loss: 0.1201, Val Loss: 0.5096
Epoch [13/120], Loss: 0.0582, Val Loss: 0.5166
Epoch [14/120], Loss: 0.1914, Val Loss: 0.5121
Epoch [15/120], Loss: 0.4346, Val Loss: 0.4901
Epoch [16/120], Loss: 0.1780, Val Loss: 0.5114
Epoch [17/120], Loss: 0.0957, Val Loss: 0.5633
Epoch [18/120], Loss: 0.1956, Val Loss: 0.5259
Epoch [19/120], Loss: 0.1920, Val Loss: 0.5344
Epoch [20/120], Loss: 0.1412, Val Loss: 0.5236
Epoch [21/120], Loss: 0.1357, Val Loss: 0.5090
Epoch [22/120], Loss: 0.0863, Val Loss: 0.5605
Epoch [23/120], Loss: 0.1244, Val Loss: 0.5347
Epoch [24/120], Loss: 0.1910, Val Loss: 0.5103
Epoch [25/120], Loss: 0.0559, Val Loss: 0.4984
Epoch [26/120], Loss: 0.1736, Val Loss: 0.5564
Epoch [27/120], Loss: 0.1901, Val Loss: 0.5178
Epoch [28/120], Loss: 0.1258, Val Loss: 0.5253
Epoch [29/120], Loss: 0.3276, Val Loss: 0.5065
Epoch [30/120], Loss: 0.4445, Val Loss: 0.5120
Epoch [31/120], Loss: 0.1516, Val Loss: 0.5377
Epoch [32/120], Loss: 0.1563, Val Loss: 0.5248
Epoch [33/120], Loss: 0.2875, Val Loss: 0.5204
Epoch [34/120], Loss: 0.0718, Val Loss: 0.6059
Epoch [35/120], Loss: 0.2248, Val Loss: 0.5272
Epoch [36/120], Loss: 0.1480, Val Loss: 0.5500
Epoch [37/120], Loss: 0.0618, Val Loss: 0.5126
Epoch [38/120], Loss: 0.0901, Val Loss: 0.5062
Epoch [39/120], Loss: 0.0963, Val Loss: 0.4898
Epoch [40/120], Loss: 0.3562, Val Loss: 0.5218
Epoch [41/120], Loss: 0.1322, Val Loss: 0.5562
Epoch [42/120], Loss: 0.1159, Val Loss: 0.5380
Epoch [43/120], Loss: 0.2560, Val Loss: 0.4766
Epoch [44/120], Loss: 0.1317, Val Loss: 0.4949
Epoch [45/120], Loss: 0.3378, Val Loss: 0.4962
Epoch [46/120], Loss: 0.0922, Val Loss: 0.4877
Epoch [47/120], Loss: 0.1082, Val Loss: 0.5374
Epoch [48/120], Loss: 0.1048, Val Loss: 0.5340
Epoch [49/120], Loss: 0.2154, Val Loss: 0.4663
Epoch [50/120], Loss: 0.0836, Val Loss: 0.5552
Epoch [51/120], Loss: 0.2942, Val Loss: 0.5260
Epoch [52/120], Loss: 0.2524, Val Loss: 0.5078
Epoch [53/120], Loss: 0.9528, Val Loss: 0.4914
Epoch [54/120], Loss: 0.1829, Val Loss: 0.4945
Epoch [55/120], Loss: 0.1442, Val Loss: 0.4766
Epoch [56/120], Loss: 0.1294, Val Loss: 0.5498
Epoch [57/120], Loss: 0.0957, Val Loss: 0.5227
Epoch [58/120], Loss: 0.0399, Val Loss: 0.5408
Epoch [59/120], Loss: 0.0783, Val Loss: 0.5370
Epoch [60/120], Loss: 0.1701, Val Loss: 0.5018
Epoch [61/120], Loss: 0.1001, Val Loss: 0.5176
Epoch [62/120], Loss: 0.0973, Val Loss: 0.5216
Epoch [63/120], Loss: 0.1225, Val Loss: 0.5315
Epoch [64/120], Loss: 0.3260, Val Loss: 0.5051
Epoch [65/120], Loss: 0.2102, Val Loss: 0.5136
Epoch [66/120], Loss: 0.2419, Val Loss: 0.4904
Epoch [67/120], Loss: 0.1850, Val Loss: 0.5315
Epoch [68/120], Loss: 0.3240, Val Loss: 0.5255
Epoch [69/120], Loss: 0.0741, Val Loss: 0.5078
Epoch [70/120], Loss: 0.2299, Val Loss: 0.5523
Epoch [71/120], Loss: 0.1655, Val Loss: 0.5058
Epoch [72/120], Loss: 0.0772, Val Loss: 0.5760
Epoch [73/120], Loss: 0.1508, Val Loss: 0.5116
Epoch [74/120], Loss: 0.1576, Val Loss: 0.5268
Epoch [75/120], Loss: 0.0495, Val Loss: 0.5437
Epoch [76/120], Loss: 0.1109, Val Loss: 0.5225
Epoch [77/120], Loss: 0.0869, Val Loss: 0.5746
Epoch [78/120], Loss: 0.1890, Val Loss: 0.5941
Early stopping at epoch 78
Runtime: 0:00:46.026597
R^2 Score: 0.9245
RMSE: 0.5381
MAE: 0.1992
MAPE: 18.82%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.3050, Val Loss: 0.4153
Epoch [2/120], Loss: 0.1059, Val Loss: 0.3696
Epoch [3/120], Loss: 0.0614, Val Loss: 0.3768
Epoch [4/120], Loss: 0.0415, Val Loss: 0.3621
Epoch [5/120], Loss: 0.0541, Val Loss: 0.3923
Epoch [6/120], Loss: 0.0648, Val Loss: 0.3924
Epoch [7/120], Loss: 0.3126, Val Loss: 0.3713
Epoch [8/120], Loss: 0.0804, Val Loss: 0.4101
Epoch [9/120], Loss: 0.1431, Val Loss: 0.3742
Epoch [10/120], Loss: 0.4727, Val Loss: 0.4269
Epoch [11/120], Loss: 0.1113, Val Loss: 0.3923
Epoch [12/120], Loss: 0.1957, Val Loss: 0.4344
Epoch [13/120], Loss: 0.2242, Val Loss: 0.4312
Epoch [14/120], Loss: 0.0851, Val Loss: 0.4179
Epoch [15/120], Loss: 0.0648, Val Loss: 0.3904
Epoch [16/120], Loss: 0.3010, Val Loss: 0.3708
Epoch [17/120], Loss: 0.3315, Val Loss: 0.3869
Epoch [18/120], Loss: 0.1812, Val Loss: 0.3932
Epoch [19/120], Loss: 0.1709, Val Loss: 0.4138
Epoch [20/120], Loss: 0.0784, Val Loss: 0.4066
Epoch [21/120], Loss: 0.1016, Val Loss: 0.4041
Epoch [22/120], Loss: 0.1462, Val Loss: 0.4209
Epoch [23/120], Loss: 0.9827, Val Loss: 0.4548
Epoch [24/120], Loss: 0.1226, Val Loss: 0.4665
Epoch [25/120], Loss: 0.0977, Val Loss: 0.4834
Epoch [26/120], Loss: 0.1097, Val Loss: 0.4058
Epoch [27/120], Loss: 0.1189, Val Loss: 0.3820
Epoch [28/120], Loss: 0.0762, Val Loss: 0.4738
Epoch [29/120], Loss: 0.4406, Val Loss: 0.4020
Epoch [30/120], Loss: 0.1086, Val Loss: 0.4253
Epoch [31/120], Loss: 0.3097, Val Loss: 0.4371
Epoch [32/120], Loss: 0.1488, Val Loss: 0.4376
Epoch [33/120], Loss: 0.1112, Val Loss: 0.4648
Early stopping at epoch 33
Runtime: 0:00:20.956613
R^2 Score: 0.9333
RMSE: 0.5847
MAE: 0.1961
MAPE: 15.82%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.3936, Val Loss: 0.9145
Epoch [2/120], Loss: 0.2885, Val Loss: 1.2877
Epoch [3/120], Loss: 0.3508, Val Loss: 0.8551
Epoch [4/120], Loss: 0.3943, Val Loss: 1.0045
Epoch [5/120], Loss: 0.4380, Val Loss: 1.3216
Epoch [6/120], Loss: 0.1310, Val Loss: 0.7353
Epoch [7/120], Loss: 0.2813, Val Loss: 0.7006
Epoch [8/120], Loss: 0.4438, Val Loss: 0.7739
Epoch [9/120], Loss: 0.3758, Val Loss: 0.7343
Epoch [10/120], Loss: 0.2519, Val Loss: 0.8107
Epoch [11/120], Loss: 0.1795, Val Loss: 1.1412
Epoch [12/120], Loss: 0.7027, Val Loss: 0.7462
Epoch [13/120], Loss: 0.2598, Val Loss: 0.8241
Epoch [14/120], Loss: 0.1797, Val Loss: 0.8352
Epoch [15/120], Loss: 0.1124, Val Loss: 0.8340
Epoch [16/120], Loss: 0.4165, Val Loss: 0.7472
Epoch [17/120], Loss: 0.8821, Val Loss: 0.6709
Epoch [18/120], Loss: 0.1751, Val Loss: 0.6323
Epoch [19/120], Loss: 0.1654, Val Loss: 0.6829
Epoch [20/120], Loss: 0.1612, Val Loss: 0.7482
Epoch [21/120], Loss: 0.9413, Val Loss: 0.7149
Epoch [22/120], Loss: 0.6506, Val Loss: 0.6887
Epoch [23/120], Loss: 0.9001, Val Loss: 0.5726
Epoch [24/120], Loss: 0.0898, Val Loss: 0.5747
Epoch [25/120], Loss: 0.1371, Val Loss: 0.6951
Epoch [26/120], Loss: 0.0916, Val Loss: 0.6278
Epoch [27/120], Loss: 0.1123, Val Loss: 0.6492
Epoch [28/120], Loss: 0.1119, Val Loss: 0.5821
Epoch [29/120], Loss: 0.4373, Val Loss: 0.6541
Epoch [30/120], Loss: 0.1039, Val Loss: 0.6423
Epoch [31/120], Loss: 0.2226, Val Loss: 0.6144
Epoch [32/120], Loss: 0.9834, Val Loss: 0.5792
Epoch [33/120], Loss: 0.3541, Val Loss: 0.6624
Epoch [34/120], Loss: 0.3770, Val Loss: 0.5871
Epoch [35/120], Loss: 0.5065, Val Loss: 0.6557
Epoch [36/120], Loss: 0.4414, Val Loss: 0.7142
Epoch [37/120], Loss: 0.1659, Val Loss: 0.6662
Epoch [38/120], Loss: 0.0953, Val Loss: 0.6039
Epoch [39/120], Loss: 0.2374, Val Loss: 0.6240
Epoch [40/120], Loss: 0.0717, Val Loss: 0.5882
Epoch [41/120], Loss: 0.3670, Val Loss: 0.7633
Epoch [42/120], Loss: 0.0296, Val Loss: 0.6265
Epoch [43/120], Loss: 0.5151, Val Loss: 0.6280
Epoch [44/120], Loss: 0.2547, Val Loss: 0.5741
Epoch [45/120], Loss: 0.5277, Val Loss: 0.6146
Epoch [46/120], Loss: 0.6596, Val Loss: 0.5613
Epoch [47/120], Loss: 3.0955, Val Loss: 0.6215
Epoch [48/120], Loss: 0.6798, Val Loss: 0.6152
Epoch [49/120], Loss: 0.2421, Val Loss: 0.5595
Epoch [50/120], Loss: 0.7271, Val Loss: 0.5950
Epoch [51/120], Loss: 0.0411, Val Loss: 0.5931
Epoch [52/120], Loss: 0.3607, Val Loss: 0.6466
Epoch [53/120], Loss: 0.1778, Val Loss: 0.5640
Epoch [54/120], Loss: 0.3576, Val Loss: 0.6525
Epoch [55/120], Loss: 0.2927, Val Loss: 0.5455
Epoch [56/120], Loss: 0.1327, Val Loss: 0.5816
Epoch [57/120], Loss: 0.2094, Val Loss: 0.5677
Epoch [58/120], Loss: 0.1210, Val Loss: 0.5744
Epoch [59/120], Loss: 0.1771, Val Loss: 0.6269
Epoch [60/120], Loss: 0.2512, Val Loss: 0.5606
Epoch [61/120], Loss: 0.1336, Val Loss: 0.5689
Epoch [62/120], Loss: 0.3702, Val Loss: 0.5651
Epoch [63/120], Loss: 0.3310, Val Loss: 0.6258
Epoch [64/120], Loss: 0.4780, Val Loss: 0.6051
Epoch [65/120], Loss: 0.1739, Val Loss: 0.5333
Epoch [66/120], Loss: 0.1703, Val Loss: 0.5568
Epoch [67/120], Loss: 0.6575, Val Loss: 0.5998
Epoch [68/120], Loss: 0.1107, Val Loss: 0.5346
Epoch [69/120], Loss: 0.9068, Val Loss: 0.5656
Epoch [70/120], Loss: 0.1380, Val Loss: 0.5989
Epoch [71/120], Loss: 0.6137, Val Loss: 0.5354
Epoch [72/120], Loss: 0.1236, Val Loss: 0.6043
Epoch [73/120], Loss: 0.3885, Val Loss: 0.5686
Epoch [74/120], Loss: 0.5443, Val Loss: 0.6486
Epoch [75/120], Loss: 0.1173, Val Loss: 0.5389
Epoch [76/120], Loss: 0.3686, Val Loss: 0.5538
Epoch [77/120], Loss: 0.4622, Val Loss: 0.7589
Epoch [78/120], Loss: 0.3567, Val Loss: 0.5934
Epoch [79/120], Loss: 0.0900, Val Loss: 0.7470
Epoch [80/120], Loss: 0.0701, Val Loss: 0.5523
Epoch [81/120], Loss: 0.1942, Val Loss: 0.5496
Epoch [82/120], Loss: 0.2107, Val Loss: 0.5567
Epoch [83/120], Loss: 0.1409, Val Loss: 0.5783
Epoch [84/120], Loss: 0.1448, Val Loss: 0.5663
Epoch [85/120], Loss: 0.0616, Val Loss: 0.5579
Epoch [86/120], Loss: 0.0790, Val Loss: 0.5463
Epoch [87/120], Loss: 0.1940, Val Loss: 0.5832
Epoch [88/120], Loss: 0.3698, Val Loss: 0.5288
Epoch [89/120], Loss: 0.0637, Val Loss: 0.5333
Epoch [90/120], Loss: 0.2917, Val Loss: 0.5578
Epoch [91/120], Loss: 0.1137, Val Loss: 0.5610
Epoch [92/120], Loss: 0.3072, Val Loss: 0.5536
Epoch [93/120], Loss: 0.1076, Val Loss: 0.6343
Epoch [94/120], Loss: 0.1220, Val Loss: 0.5579
Epoch [95/120], Loss: 0.2109, Val Loss: 0.6131
Epoch [96/120], Loss: 0.1169, Val Loss: 0.5671
Epoch [97/120], Loss: 0.0725, Val Loss: 0.7182
Epoch [98/120], Loss: 0.3682, Val Loss: 0.5653
Epoch [99/120], Loss: 0.1208, Val Loss: 0.5463
Epoch [100/120], Loss: 0.7577, Val Loss: 0.5627
Epoch [101/120], Loss: 0.2803, Val Loss: 0.6679
Epoch [102/120], Loss: 0.0899, Val Loss: 0.6247
Epoch [103/120], Loss: 0.1502, Val Loss: 0.6676
Epoch [104/120], Loss: 3.4556, Val Loss: 0.5931
Epoch [105/120], Loss: 0.3092, Val Loss: 0.6338
Epoch [106/120], Loss: 0.1921, Val Loss: 0.6483
Epoch [107/120], Loss: 0.2164, Val Loss: 0.5644
Epoch [108/120], Loss: 0.4358, Val Loss: 0.5998
Epoch [109/120], Loss: 0.3073, Val Loss: 0.5940
Epoch [110/120], Loss: 0.0813, Val Loss: 0.5652
Epoch [111/120], Loss: 0.6158, Val Loss: 0.5532
Epoch [112/120], Loss: 0.2224, Val Loss: 0.6643
Epoch [113/120], Loss: 0.2621, Val Loss: 0.5473
Epoch [114/120], Loss: 0.0668, Val Loss: 0.5465
Epoch [115/120], Loss: 0.1066, Val Loss: 0.5511
Epoch [116/120], Loss: 0.4376, Val Loss: 0.5820
Epoch [117/120], Loss: 0.2051, Val Loss: 0.5677
Epoch [118/120], Loss: 0.0403, Val Loss: 0.5316
Epoch [119/120], Loss: 0.0746, Val Loss: 0.5230
Epoch [120/120], Loss: 0.4247, Val Loss: 0.5520
Runtime: 0:01:10.092656
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.0996, Val Loss: 0.5490
Epoch [2/120], Loss: 0.1795, Val Loss: 0.6113
Epoch [3/120], Loss: 0.6404, Val Loss: 0.5801
Epoch [4/120], Loss: 0.2315, Val Loss: 0.5340
Epoch [5/120], Loss: 0.1555, Val Loss: 0.5462
Epoch [6/120], Loss: 0.0931, Val Loss: 0.5500
Epoch [7/120], Loss: 0.1292, Val Loss: 0.6157
Epoch [8/120], Loss: 0.3048, Val Loss: 0.6418
Epoch [9/120], Loss: 0.7137, Val Loss: 0.5818
Epoch [10/120], Loss: 0.1627, Val Loss: 0.6030
Epoch [11/120], Loss: 0.4085, Val Loss: 0.5997
Epoch [12/120], Loss: 0.0917, Val Loss: 0.5559
Epoch [13/120], Loss: 0.2368, Val Loss: 0.5100
Epoch [14/120], Loss: 0.0822, Val Loss: 0.6768
Epoch [15/120], Loss: 0.5572, Val Loss: 0.7547
Epoch [16/120], Loss: 0.0738, Val Loss: 0.5461
Epoch [17/120], Loss: 0.2375, Val Loss: 0.6181
Epoch [18/120], Loss: 0.2816, Val Loss: 0.5967
Epoch [19/120], Loss: 0.2717, Val Loss: 0.5678
Epoch [20/120], Loss: 0.2769, Val Loss: 0.5648
Epoch [21/120], Loss: 0.0910, Val Loss: 0.5525
Epoch [22/120], Loss: 0.5735, Val Loss: 0.5598
Epoch [23/120], Loss: 0.0603, Val Loss: 0.6075
Epoch [24/120], Loss: 0.5164, Val Loss: 0.5262
Epoch [25/120], Loss: 0.1133, Val Loss: 0.6246
Epoch [26/120], Loss: 0.2538, Val Loss: 0.5455
Epoch [27/120], Loss: 0.1954, Val Loss: 0.5544
Epoch [28/120], Loss: 0.1060, Val Loss: 0.5639
Epoch [29/120], Loss: 0.1369, Val Loss: 0.5702
Epoch [30/120], Loss: 0.1421, Val Loss: 0.5103
Epoch [31/120], Loss: 0.3044, Val Loss: 0.5390
Epoch [32/120], Loss: 0.0734, Val Loss: 0.5713
Epoch [33/120], Loss: 0.1188, Val Loss: 0.5928
Epoch [34/120], Loss: 0.2025, Val Loss: 0.5623
Epoch [35/120], Loss: 0.5172, Val Loss: 0.5559
Epoch [36/120], Loss: 1.0681, Val Loss: 0.5535
Epoch [37/120], Loss: 0.0940, Val Loss: 0.6707
Epoch [38/120], Loss: 0.5850, Val Loss: 0.5688
Epoch [39/120], Loss: 0.1464, Val Loss: 0.5448
Epoch [40/120], Loss: 0.0504, Val Loss: 0.6249
Epoch [41/120], Loss: 0.2161, Val Loss: 0.5482
Epoch [42/120], Loss: 0.2109, Val Loss: 0.5854
Epoch [43/120], Loss: 0.1762, Val Loss: 0.5355
Epoch [44/120], Loss: 0.2159, Val Loss: 0.6132
Epoch [45/120], Loss: 0.2284, Val Loss: 0.5605
Epoch [46/120], Loss: 0.1176, Val Loss: 0.6178
Epoch [47/120], Loss: 0.0640, Val Loss: 0.5534
Epoch [48/120], Loss: 0.5921, Val Loss: 0.5268
Epoch [49/120], Loss: 0.2045, Val Loss: 0.6399
Epoch [50/120], Loss: 0.1441, Val Loss: 0.5340
Epoch [51/120], Loss: 0.4195, Val Loss: 0.5337
Epoch [52/120], Loss: 0.1244, Val Loss: 0.5800
Epoch [53/120], Loss: 0.3392, Val Loss: 0.5656
Epoch [54/120], Loss: 0.1435, Val Loss: 0.5787
Epoch [55/120], Loss: 0.0853, Val Loss: 0.6125
Epoch [56/120], Loss: 0.2700, Val Loss: 0.5582
Epoch [57/120], Loss: 0.1776, Val Loss: 0.5691
Epoch [58/120], Loss: 0.0809, Val Loss: 0.5947
Epoch [59/120], Loss: 0.2565, Val Loss: 0.6228
Early stopping at epoch 59
Runtime: 0:00:35.555646
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.2324, Val Loss: 0.5633
Epoch [2/120], Loss: 0.1436, Val Loss: 0.5786
Epoch [3/120], Loss: 0.1444, Val Loss: 0.5495
Epoch [4/120], Loss: 0.1395, Val Loss: 0.5784
Epoch [5/120], Loss: 0.1019, Val Loss: 0.5580
Epoch [6/120], Loss: 0.5377, Val Loss: 0.5561
Epoch [7/120], Loss: 0.0446, Val Loss: 0.5469
Epoch [8/120], Loss: 0.0558, Val Loss: 0.5879
Epoch [9/120], Loss: 0.9623, Val Loss: 0.5534
Epoch [10/120], Loss: 0.4468, Val Loss: 0.6411
Epoch [11/120], Loss: 0.2124, Val Loss: 0.5878
Epoch [12/120], Loss: 0.2093, Val Loss: 0.5811
Epoch [13/120], Loss: 0.1149, Val Loss: 0.5893
Epoch [14/120], Loss: 0.0692, Val Loss: 0.5635
Epoch [15/120], Loss: 0.0640, Val Loss: 0.6098
Epoch [16/120], Loss: 0.2543, Val Loss: 0.5742
Epoch [17/120], Loss: 0.2117, Val Loss: 0.5690
Epoch [18/120], Loss: 0.2767, Val Loss: 0.5699
Epoch [19/120], Loss: 0.1336, Val Loss: 0.5826
Epoch [20/120], Loss: 0.4684, Val Loss: 0.6630
Epoch [21/120], Loss: 0.5436, Val Loss: 0.5608
Epoch [22/120], Loss: 0.2199, Val Loss: 0.5550
Epoch [23/120], Loss: 0.9040, Val Loss: 0.6572
Epoch [24/120], Loss: 0.0812, Val Loss: 0.5275
Epoch [25/120], Loss: 0.4051, Val Loss: 0.6062
Epoch [26/120], Loss: 0.0695, Val Loss: 0.5750
Epoch [27/120], Loss: 0.1151, Val Loss: 0.5402
Epoch [28/120], Loss: 0.1763, Val Loss: 0.6005
Epoch [29/120], Loss: 0.1419, Val Loss: 0.5277
Epoch [30/120], Loss: 0.4421, Val Loss: 0.5687
Epoch [31/120], Loss: 0.1271, Val Loss: 0.5422
Epoch [32/120], Loss: 0.1095, Val Loss: 0.5331
Epoch [33/120], Loss: 0.1470, Val Loss: 0.5396
Epoch [34/120], Loss: 0.0605, Val Loss: 0.5244
Epoch [35/120], Loss: 0.1454, Val Loss: 0.5229
Epoch [36/120], Loss: 0.0898, Val Loss: 0.5651
Epoch [37/120], Loss: 0.1309, Val Loss: 0.5551
Epoch [38/120], Loss: 0.1643, Val Loss: 0.6262
Epoch [39/120], Loss: 0.2683, Val Loss: 0.5647
Epoch [40/120], Loss: 0.7083, Val Loss: 0.5552
Epoch [41/120], Loss: 0.0791, Val Loss: 0.5474
Epoch [42/120], Loss: 0.1286, Val Loss: 0.6024
Epoch [43/120], Loss: 0.4814, Val Loss: 0.5769
Epoch [44/120], Loss: 0.3258, Val Loss: 0.6927
Epoch [45/120], Loss: 0.3257, Val Loss: 0.6013
Epoch [46/120], Loss: 0.0856, Val Loss: 0.5177
Epoch [47/120], Loss: 0.1423, Val Loss: 0.5258
Epoch [48/120], Loss: 0.1654, Val Loss: 0.5405
Epoch [49/120], Loss: 0.0674, Val Loss: 0.5687
Epoch [50/120], Loss: 0.2477, Val Loss: 0.5640
Epoch [51/120], Loss: 0.2557, Val Loss: 0.5452
Epoch [52/120], Loss: 0.3256, Val Loss: 0.5351
Epoch [53/120], Loss: 0.8823, Val Loss: 0.5717
Epoch [54/120], Loss: 0.0735, Val Loss: 0.6011
Epoch [55/120], Loss: 0.1063, Val Loss: 0.5373
Epoch [56/120], Loss: 0.0852, Val Loss: 0.5151
Epoch [57/120], Loss: 0.1650, Val Loss: 0.5543
Epoch [58/120], Loss: 0.2675, Val Loss: 0.5835
Epoch [59/120], Loss: 0.9317, Val Loss: 0.5795
Epoch [60/120], Loss: 0.1841, Val Loss: 0.5775
Epoch [61/120], Loss: 0.1399, Val Loss: 0.5817
Epoch [62/120], Loss: 0.1360, Val Loss: 0.6290
Epoch [63/120], Loss: 0.2179, Val Loss: 0.5846
Epoch [64/120], Loss: 1.5063, Val Loss: 0.6209
Epoch [65/120], Loss: 0.1792, Val Loss: 0.5707
Epoch [66/120], Loss: 0.1008, Val Loss: 0.6063
Epoch [67/120], Loss: 0.4892, Val Loss: 0.5473
Epoch [68/120], Loss: 0.1425, Val Loss: 0.5321
Epoch [69/120], Loss: 0.0838, Val Loss: 0.5426
Epoch [70/120], Loss: 0.1686, Val Loss: 0.5879
Epoch [71/120], Loss: 0.0652, Val Loss: 0.5712
Epoch [72/120], Loss: 0.0811, Val Loss: 0.5258
Epoch [73/120], Loss: 0.0508, Val Loss: 0.5573
Epoch [74/120], Loss: 0.0601, Val Loss: 0.5760
Epoch [75/120], Loss: 0.1667, Val Loss: 0.5610
Epoch [76/120], Loss: 0.2024, Val Loss: 0.5420
Epoch [77/120], Loss: 0.1164, Val Loss: 0.5702
Epoch [78/120], Loss: 1.3231, Val Loss: 0.6077
Epoch [79/120], Loss: 0.3459, Val Loss: 0.5739
Epoch [80/120], Loss: 0.6446, Val Loss: 0.5813
Epoch [81/120], Loss: 0.6684, Val Loss: 0.5279
Epoch [82/120], Loss: 0.2533, Val Loss: 0.5631
Epoch [83/120], Loss: 0.1540, Val Loss: 0.5795
Epoch [84/120], Loss: 0.7472, Val Loss: 0.5476
Epoch [85/120], Loss: 0.3972, Val Loss: 0.5439
Early stopping at epoch 85
Runtime: 0:00:49.654286
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.1363, Val Loss: 0.5298
Epoch [2/120], Loss: 0.3081, Val Loss: 0.5415
Epoch [3/120], Loss: 0.2299, Val Loss: 0.5556
Epoch [4/120], Loss: 0.0583, Val Loss: 0.5458
Epoch [5/120], Loss: 0.1639, Val Loss: 0.5428
Epoch [6/120], Loss: 0.0735, Val Loss: 0.5867
Epoch [7/120], Loss: 0.1896, Val Loss: 0.5946
Epoch [8/120], Loss: 0.9531, Val Loss: 0.5303
Epoch [9/120], Loss: 0.1802, Val Loss: 0.5715
Epoch [10/120], Loss: 0.1611, Val Loss: 0.5620
Epoch [11/120], Loss: 0.0804, Val Loss: 0.5314
Epoch [12/120], Loss: 0.2559, Val Loss: 0.5397
Epoch [13/120], Loss: 0.3261, Val Loss: 0.5580
Epoch [14/120], Loss: 0.0802, Val Loss: 0.5557
Epoch [15/120], Loss: 0.1669, Val Loss: 0.5559
Epoch [16/120], Loss: 1.0262, Val Loss: 0.5429
Epoch [17/120], Loss: 0.3843, Val Loss: 0.5385
Epoch [18/120], Loss: 0.2590, Val Loss: 0.5553
Epoch [19/120], Loss: 0.2142, Val Loss: 0.5103
Epoch [20/120], Loss: 0.3584, Val Loss: 0.5579
Epoch [21/120], Loss: 0.2164, Val Loss: 0.5139
Epoch [22/120], Loss: 0.0887, Val Loss: 0.5854
Epoch [23/120], Loss: 0.1879, Val Loss: 0.5939
Epoch [24/120], Loss: 0.1182, Val Loss: 0.6014
Epoch [25/120], Loss: 0.4865, Val Loss: 0.5743
Epoch [26/120], Loss: 0.1026, Val Loss: 0.5813
Epoch [27/120], Loss: 0.0773, Val Loss: 0.5229
Epoch [28/120], Loss: 0.2897, Val Loss: 0.5505
Epoch [29/120], Loss: 0.0956, Val Loss: 0.6069
Epoch [30/120], Loss: 0.4843, Val Loss: 0.6027
Epoch [31/120], Loss: 0.1664, Val Loss: 0.6255
Epoch [32/120], Loss: 0.1248, Val Loss: 0.5340
Epoch [33/120], Loss: 0.3577, Val Loss: 0.5327
Epoch [34/120], Loss: 0.1422, Val Loss: 0.5821
Epoch [35/120], Loss: 0.1894, Val Loss: 0.5559
Epoch [36/120], Loss: 0.0732, Val Loss: 0.5627
Epoch [37/120], Loss: 0.4106, Val Loss: 0.5693
Epoch [38/120], Loss: 0.1252, Val Loss: 0.6289
Epoch [39/120], Loss: 0.1016, Val Loss: 0.5571
Epoch [40/120], Loss: 0.1745, Val Loss: 0.5416
Epoch [41/120], Loss: 0.3644, Val Loss: 0.6275
Epoch [42/120], Loss: 0.2674, Val Loss: 0.5777
Epoch [43/120], Loss: 0.6064, Val Loss: 0.6370
Epoch [44/120], Loss: 0.1931, Val Loss: 0.5692
Epoch [45/120], Loss: 0.1753, Val Loss: 0.5609
Epoch [46/120], Loss: 0.1149, Val Loss: 0.5594
Epoch [47/120], Loss: 0.1151, Val Loss: 0.5498
Epoch [48/120], Loss: 0.1069, Val Loss: 0.6040
Epoch [49/120], Loss: 0.0610, Val Loss: 0.6402
Epoch [50/120], Loss: 0.2923, Val Loss: 0.5977
Early stopping at epoch 50
Runtime: 0:00:29.986809
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.0683, Val Loss: 0.5427
Epoch [2/120], Loss: 0.3425, Val Loss: 0.5648
Epoch [3/120], Loss: 0.1764, Val Loss: 0.5617
Epoch [4/120], Loss: 0.7759, Val Loss: 0.5419
Epoch [5/120], Loss: 0.0872, Val Loss: 0.5441
Epoch [6/120], Loss: 0.1878, Val Loss: 0.5456
Epoch [7/120], Loss: 0.1057, Val Loss: 0.5629
Epoch [8/120], Loss: 0.0507, Val Loss: 0.5398
Epoch [9/120], Loss: 0.0746, Val Loss: 0.6092
Epoch [10/120], Loss: 0.2246, Val Loss: 0.5974
Epoch [11/120], Loss: 0.1648, Val Loss: 0.6007
Epoch [12/120], Loss: 0.0723, Val Loss: 0.5694
Epoch [13/120], Loss: 0.0922, Val Loss: 0.5746
Epoch [14/120], Loss: 0.2047, Val Loss: 0.8311
Epoch [15/120], Loss: 0.0457, Val Loss: 0.6394
Epoch [16/120], Loss: 0.1803, Val Loss: 0.5765
Epoch [17/120], Loss: 0.0646, Val Loss: 0.5318
Epoch [18/120], Loss: 0.0650, Val Loss: 0.5534
Epoch [19/120], Loss: 0.4163, Val Loss: 0.5528
Epoch [20/120], Loss: 0.5254, Val Loss: 0.5612
Epoch [21/120], Loss: 0.4781, Val Loss: 0.6277
Epoch [22/120], Loss: 0.0745, Val Loss: 0.5194
Epoch [23/120], Loss: 0.4691, Val Loss: 0.5326
Epoch [24/120], Loss: 0.0611, Val Loss: 0.5757
Epoch [25/120], Loss: 0.0797, Val Loss: 0.5301
Epoch [26/120], Loss: 0.1474, Val Loss: 0.5532
Epoch [27/120], Loss: 0.6890, Val Loss: 0.5764
Epoch [28/120], Loss: 0.4202, Val Loss: 0.5480
Epoch [29/120], Loss: 0.4189, Val Loss: 0.5618
Epoch [30/120], Loss: 0.0425, Val Loss: 0.5250
Epoch [31/120], Loss: 0.0926, Val Loss: 0.5343
Epoch [32/120], Loss: 0.0697, Val Loss: 0.5369
Epoch [33/120], Loss: 0.3279, Val Loss: 0.6105
Epoch [34/120], Loss: 0.0819, Val Loss: 0.5327
Epoch [35/120], Loss: 0.1789, Val Loss: 0.5430
Epoch [36/120], Loss: 0.3342, Val Loss: 0.5791
Epoch [37/120], Loss: 0.1809, Val Loss: 0.5026
Epoch [38/120], Loss: 0.2473, Val Loss: 0.5637
Epoch [39/120], Loss: 0.6256, Val Loss: 0.5012
Epoch [40/120], Loss: 0.1214, Val Loss: 0.5278
Epoch [41/120], Loss: 0.1981, Val Loss: 0.5259
Epoch [42/120], Loss: 0.0950, Val Loss: 0.5596
Epoch [43/120], Loss: 0.0861, Val Loss: 0.5971
Epoch [44/120], Loss: 0.1370, Val Loss: 0.5257
Epoch [45/120], Loss: 0.1070, Val Loss: 0.4935
Epoch [46/120], Loss: 0.2011, Val Loss: 0.5247
Epoch [47/120], Loss: 0.5812, Val Loss: 0.5079
Epoch [48/120], Loss: 0.1934, Val Loss: 0.5410
Epoch [49/120], Loss: 0.2729, Val Loss: 0.5183
Epoch [50/120], Loss: 0.0924, Val Loss: 0.5673
Epoch [51/120], Loss: 0.2735, Val Loss: 0.5353
Epoch [52/120], Loss: 0.0819, Val Loss: 0.5244
Epoch [53/120], Loss: 0.0776, Val Loss: 0.5359
Epoch [54/120], Loss: 0.1566, Val Loss: 0.5642
Epoch [55/120], Loss: 0.1110, Val Loss: 0.6611
Epoch [56/120], Loss: 0.1633, Val Loss: 0.5425
Epoch [57/120], Loss: 0.1039, Val Loss: 0.5442
Epoch [58/120], Loss: 0.2313, Val Loss: 0.5148
Epoch [59/120], Loss: 0.1251, Val Loss: 0.5379
Epoch [60/120], Loss: 1.2181, Val Loss: 0.5522
Epoch [61/120], Loss: 0.1218, Val Loss: 0.5449
Epoch [62/120], Loss: 0.1068, Val Loss: 0.5385
Epoch [63/120], Loss: 0.1187, Val Loss: 0.5133
Epoch [64/120], Loss: 0.0752, Val Loss: 0.5590
Epoch [65/120], Loss: 0.2370, Val Loss: 0.6009
Epoch [66/120], Loss: 0.0885, Val Loss: 0.5647
Epoch [67/120], Loss: 0.2863, Val Loss: 0.5440
Epoch [68/120], Loss: 0.1034, Val Loss: 0.6057
Epoch [69/120], Loss: 0.1999, Val Loss: 0.6352
Epoch [70/120], Loss: 0.1225, Val Loss: 0.5648
Epoch [71/120], Loss: 0.2445, Val Loss: 0.5609
Epoch [72/120], Loss: 0.1787, Val Loss: 0.6168
Epoch [73/120], Loss: 0.1940, Val Loss: 0.5515
Epoch [74/120], Loss: 0.3224, Val Loss: 0.6141
Early stopping at epoch 74
Runtime: 0:00:43.580547
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/120], Loss: 0.2191, Val Loss: 0.5667
Epoch [2/120], Loss: 0.1030, Val Loss: 0.5490
Epoch [3/120], Loss: 0.1217, Val Loss: 0.6101
Epoch [4/120], Loss: 0.1168, Val Loss: 0.6126
Epoch [5/120], Loss: 0.1546, Val Loss: 0.5775
Epoch [6/120], Loss: 0.2929, Val Loss: 0.5933
Epoch [7/120], Loss: 0.0677, Val Loss: 0.5791
Epoch [8/120], Loss: 2.0126, Val Loss: 0.5969
Epoch [9/120], Loss: 0.6510, Val Loss: 0.6395
Epoch [10/120], Loss: 0.3094, Val Loss: 0.5780
Epoch [11/120], Loss: 0.1264, Val Loss: 0.5759
Epoch [12/120], Loss: 0.0886, Val Loss: 0.5559
Epoch [13/120], Loss: 0.2919, Val Loss: 0.5461
Epoch [14/120], Loss: 0.1473, Val Loss: 0.5503
Epoch [15/120], Loss: 0.0911, Val Loss: 0.5256
Epoch [16/120], Loss: 0.0701, Val Loss: 0.5446
Epoch [17/120], Loss: 0.1380, Val Loss: 0.5184
Epoch [18/120], Loss: 0.3099, Val Loss: 0.6825
Epoch [19/120], Loss: 0.0641, Val Loss: 0.5387
Epoch [20/120], Loss: 0.1488, Val Loss: 0.5427
Epoch [21/120], Loss: 0.2152, Val Loss: 0.5288
Epoch [22/120], Loss: 0.2261, Val Loss: 0.5475
Epoch [23/120], Loss: 0.1824, Val Loss: 0.7223
Epoch [24/120], Loss: 0.2767, Val Loss: 0.5448
Epoch [25/120], Loss: 0.6858, Val Loss: 0.5473
Epoch [26/120], Loss: 0.1126, Val Loss: 0.6249
Epoch [27/120], Loss: 0.2221, Val Loss: 0.5442
Epoch [28/120], Loss: 0.3798, Val Loss: 0.5461
Epoch [29/120], Loss: 0.2651, Val Loss: 0.5210
Epoch [30/120], Loss: 0.3141, Val Loss: 0.6633
Epoch [31/120], Loss: 0.1818, Val Loss: 0.6089
Epoch [32/120], Loss: 0.2979, Val Loss: 0.5675
Epoch [33/120], Loss: 0.0690, Val Loss: 0.5915
Epoch [34/120], Loss: 0.1918, Val Loss: 0.5495
Epoch [35/120], Loss: 0.1564, Val Loss: 0.6306
Epoch [36/120], Loss: 0.0859, Val Loss: 0.5600
Epoch [37/120], Loss: 0.1956, Val Loss: 0.5442
Epoch [38/120], Loss: 0.3900, Val Loss: 0.5546
Epoch [39/120], Loss: 0.1892, Val Loss: 0.5687
Epoch [40/120], Loss: 0.1041, Val Loss: 0.5538
Epoch [41/120], Loss: 0.1304, Val Loss: 0.5310
Epoch [42/120], Loss: 0.1059, Val Loss: 0.5178
Epoch [43/120], Loss: 0.4292, Val Loss: 0.5328
Epoch [44/120], Loss: 0.0907, Val Loss: 0.5229
Epoch [45/120], Loss: 0.2697, Val Loss: 0.5198
Epoch [46/120], Loss: 0.0666, Val Loss: 0.5533
Epoch [47/120], Loss: 0.1808, Val Loss: 0.5694
Epoch [48/120], Loss: 0.0935, Val Loss: 0.5386
Epoch [49/120], Loss: 0.2992, Val Loss: 0.5629
Epoch [50/120], Loss: 0.7783, Val Loss: 0.5272
Epoch [51/120], Loss: 0.0541, Val Loss: 0.6514
Epoch [52/120], Loss: 0.2202, Val Loss: 0.5361
Epoch [53/120], Loss: 0.3689, Val Loss: 0.5766
Epoch [54/120], Loss: 0.0407, Val Loss: 0.5545
Epoch [55/120], Loss: 0.0299, Val Loss: 0.5841
Epoch [56/120], Loss: 0.1642, Val Loss: 0.5601
Epoch [57/120], Loss: 0.2987, Val Loss: 0.5579
Epoch [58/120], Loss: 0.0797, Val Loss: 0.5723
Epoch [59/120], Loss: 0.1284, Val Loss: 0.5590
Epoch [60/120], Loss: 0.1490, Val Loss: 0.6532
Epoch [61/120], Loss: 0.2077, Val Loss: 0.5100
Epoch [62/120], Loss: 0.1718, Val Loss: 0.5850
Epoch [63/120], Loss: 0.1899, Val Loss: 0.5910
Epoch [64/120], Loss: 0.2087, Val Loss: 0.5420
Epoch [65/120], Loss: 0.2238, Val Loss: 0.5390
Epoch [66/120], Loss: 0.3969, Val Loss: 0.6384
Epoch [67/120], Loss: 0.0745, Val Loss: 0.5405
Epoch [68/120], Loss: 0.0647, Val Loss: 0.5392
Epoch [69/120], Loss: 0.0695, Val Loss: 0.5298
Epoch [70/120], Loss: 0.2709, Val Loss: 0.6077
Epoch [71/120], Loss: 0.0550, Val Loss: 0.5352
Epoch [72/120], Loss: 0.0799, Val Loss: 0.6315
Epoch [73/120], Loss: 0.0585, Val Loss: 0.6248
Epoch [74/120], Loss: 0.3556, Val Loss: 0.5603
Epoch [75/120], Loss: 0.3686, Val Loss: 0.5599
Epoch [76/120], Loss: 0.3205, Val Loss: 0.5557
Epoch [77/120], Loss: 0.0525, Val Loss: 0.5677
Epoch [78/120], Loss: 0.3802, Val Loss: 0.5947
Epoch [79/120], Loss: 0.1053, Val Loss: 0.5692
Epoch [80/120], Loss: 1.6383, Val Loss: 0.6580
Epoch [81/120], Loss: 0.0675, Val Loss: 0.5822
Epoch [82/120], Loss: 0.1886, Val Loss: 0.5674
Epoch [83/120], Loss: 0.0978, Val Loss: 0.5696
Epoch [84/120], Loss: 0.2287, Val Loss: 0.5745
Epoch [85/120], Loss: 0.0934, Val Loss: 0.5933
Epoch [86/120], Loss: 0.1575, Val Loss: 0.5404
Epoch [87/120], Loss: 0.0776, Val Loss: 0.5459
Epoch [88/120], Loss: 0.0879, Val Loss: 0.5251
Epoch [89/120], Loss: 1.1861, Val Loss: 0.5269
Epoch [90/120], Loss: 0.6371, Val Loss: 0.5824
Early stopping at epoch 90
Runtime: 0:00:52.572988
R^2 Score: 0.9047
RMSE: 0.6989
MAE: 0.1966
MAPE: 17.62%
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/120], Loss: 2.5145, Val Loss: 0.9777
Epoch [2/120], Loss: 5.9375, Val Loss: 1.0312
Epoch [3/120], Loss: 0.3959, Val Loss: 0.7920
Epoch [4/120], Loss: 0.9268, Val Loss: 0.7636
Epoch [5/120], Loss: 0.1723, Val Loss: 0.7559
Epoch [6/120], Loss: 0.8949, Val Loss: 0.7482
Epoch [7/120], Loss: 0.6974, Val Loss: 0.7617
Epoch [8/120], Loss: 0.3384, Val Loss: 0.7652
Epoch [9/120], Loss: 0.6652, Val Loss: 0.6740
Epoch [10/120], Loss: 0.1187, Val Loss: 0.7717
Epoch [11/120], Loss: 0.1286, Val Loss: 0.6655
Epoch [12/120], Loss: 0.4667, Val Loss: 0.6722
Epoch [13/120], Loss: 0.0830, Val Loss: 0.6730
Epoch [14/120], Loss: 0.2581, Val Loss: 0.7058
Epoch [15/120], Loss: 5.5352, Val Loss: 0.7335
Epoch [16/120], Loss: 2.9402, Val Loss: 0.7565
Epoch [17/120], Loss: 0.6474, Val Loss: 0.6124
Epoch [18/120], Loss: 0.0898, Val Loss: 0.6522
Epoch [19/120], Loss: 0.9677, Val Loss: 0.6186
Epoch [20/120], Loss: 0.1681, Val Loss: 0.5877
Epoch [21/120], Loss: 0.9015, Val Loss: 0.6679
Epoch [22/120], Loss: 0.1380, Val Loss: 0.6898
Epoch [23/120], Loss: 0.2393, Val Loss: 0.6466
Epoch [24/120], Loss: 0.1409, Val Loss: 0.5485
Epoch [25/120], Loss: 0.0973, Val Loss: 0.5845
Epoch [26/120], Loss: 0.3806, Val Loss: 0.5112
Epoch [27/120], Loss: 0.1111, Val Loss: 0.5408
Epoch [28/120], Loss: 0.1081, Val Loss: 0.5476
Epoch [29/120], Loss: 0.4669, Val Loss: 0.5740
Epoch [30/120], Loss: 0.1790, Val Loss: 0.5489
Epoch [31/120], Loss: 0.0905, Val Loss: 0.5020
Epoch [32/120], Loss: 0.3268, Val Loss: 0.4958
Epoch [33/120], Loss: 0.1514, Val Loss: 0.5929
Epoch [34/120], Loss: 0.1230, Val Loss: 0.6078
Epoch [35/120], Loss: 0.1262, Val Loss: 0.4944
Epoch [36/120], Loss: 0.0988, Val Loss: 0.6135
Epoch [37/120], Loss: 0.8623, Val Loss: 0.6372
Epoch [38/120], Loss: 0.1038, Val Loss: 0.6190
Epoch [39/120], Loss: 0.4897, Val Loss: 0.7197
Epoch [40/120], Loss: 0.2057, Val Loss: 0.7025
Epoch [41/120], Loss: 0.1012, Val Loss: 0.5004
Epoch [42/120], Loss: 0.1785, Val Loss: 0.5045
Epoch [43/120], Loss: 0.2594, Val Loss: 0.4938
Epoch [44/120], Loss: 0.2602, Val Loss: 0.5689
Epoch [45/120], Loss: 0.0970, Val Loss: 0.5969
Epoch [46/120], Loss: 0.1051, Val Loss: 0.5443
Epoch [47/120], Loss: 0.2924, Val Loss: 0.5248
Epoch [48/120], Loss: 0.3482, Val Loss: 0.5551
Epoch [49/120], Loss: 0.0701, Val Loss: 0.6224
Epoch [50/120], Loss: 0.9368, Val Loss: 0.5159
Epoch [51/120], Loss: 0.1514, Val Loss: 0.4969
Epoch [52/120], Loss: 0.1590, Val Loss: 0.6146
Epoch [53/120], Loss: 0.1769, Val Loss: 0.4579
Epoch [54/120], Loss: 0.3637, Val Loss: 0.7084
Epoch [55/120], Loss: 0.4384, Val Loss: 0.5758
Epoch [56/120], Loss: 0.1747, Val Loss: 0.5856
Epoch [57/120], Loss: 0.3836, Val Loss: 0.5049
Epoch [58/120], Loss: 0.1059, Val Loss: 0.5388
Epoch [59/120], Loss: 0.3092, Val Loss: 0.5016
Epoch [60/120], Loss: 0.1031, Val Loss: 0.4832
Epoch [61/120], Loss: 0.1793, Val Loss: 0.4537
Epoch [62/120], Loss: 0.2310, Val Loss: 0.5260
Epoch [63/120], Loss: 0.3525, Val Loss: 0.6992
Epoch [64/120], Loss: 0.1495, Val Loss: 0.5135
Epoch [65/120], Loss: 0.2374, Val Loss: 0.4534
Epoch [66/120], Loss: 0.0911, Val Loss: 0.5192
Epoch [67/120], Loss: 0.1775, Val Loss: 0.4795
Epoch [68/120], Loss: 0.1729, Val Loss: 0.5647
Epoch [69/120], Loss: 0.0981, Val Loss: 0.4913
Epoch [70/120], Loss: 0.1674, Val Loss: 0.7107
Epoch [71/120], Loss: 0.3718, Val Loss: 0.4600
Epoch [72/120], Loss: 0.0717, Val Loss: 0.6807
Epoch [73/120], Loss: 0.1287, Val Loss: 0.5290
Epoch [74/120], Loss: 0.0359, Val Loss: 0.4810
Epoch [75/120], Loss: 0.3669, Val Loss: 0.5762
Epoch [76/120], Loss: 3.2105, Val Loss: 0.5554
Epoch [77/120], Loss: 0.2484, Val Loss: 0.5205
Epoch [78/120], Loss: 0.8204, Val Loss: 0.5238
Epoch [79/120], Loss: 0.1306, Val Loss: 0.4761
Epoch [80/120], Loss: 0.1046, Val Loss: 0.5078
Epoch [81/120], Loss: 0.2482, Val Loss: 0.4631
Epoch [82/120], Loss: 0.0873, Val Loss: 0.4988
Epoch [83/120], Loss: 0.2005, Val Loss: 0.4609
Epoch [84/120], Loss: 0.1213, Val Loss: 0.4986
Epoch [85/120], Loss: 0.0642, Val Loss: 0.4604
Epoch [86/120], Loss: 0.0693, Val Loss: 0.4947
Epoch [87/120], Loss: 0.1822, Val Loss: 0.4902
Epoch [88/120], Loss: 0.1163, Val Loss: 0.4614
Epoch [89/120], Loss: 0.1505, Val Loss: 0.4884
Epoch [90/120], Loss: 0.1655, Val Loss: 0.4962
Epoch [91/120], Loss: 0.1131, Val Loss: 0.4391
Epoch [92/120], Loss: 0.3173, Val Loss: 0.5322
Epoch [93/120], Loss: 0.0703, Val Loss: 0.5187
Epoch [94/120], Loss: 0.1183, Val Loss: 0.4843
Epoch [95/120], Loss: 0.3427, Val Loss: 0.6155
Epoch [96/120], Loss: 0.1568, Val Loss: 0.5179
Epoch [97/120], Loss: 0.4784, Val Loss: 0.5058
Epoch [98/120], Loss: 0.2440, Val Loss: 0.5019
Epoch [99/120], Loss: 0.1028, Val Loss: 0.4848
Epoch [100/120], Loss: 0.0495, Val Loss: 0.5065
Epoch [101/120], Loss: 0.0675, Val Loss: 0.4917
Epoch [102/120], Loss: 0.1100, Val Loss: 0.4563
Epoch [103/120], Loss: 0.1629, Val Loss: 0.4889
Epoch [104/120], Loss: 0.0903, Val Loss: 0.5050
Epoch [105/120], Loss: 0.1498, Val Loss: 0.4808
Epoch [106/120], Loss: 0.1047, Val Loss: 0.4684
Epoch [107/120], Loss: 0.2803, Val Loss: 0.4823
Epoch [108/120], Loss: 0.2559, Val Loss: 0.4965
Epoch [109/120], Loss: 0.2303, Val Loss: 0.5899
Epoch [110/120], Loss: 0.5557, Val Loss: 0.5080
Epoch [111/120], Loss: 0.1762, Val Loss: 0.5040
Epoch [112/120], Loss: 1.9716, Val Loss: 0.5259
Epoch [113/120], Loss: 0.3041, Val Loss: 0.5443
Epoch [114/120], Loss: 0.1148, Val Loss: 0.5439
Epoch [115/120], Loss: 0.0696, Val Loss: 0.4770
Epoch [116/120], Loss: 0.2161, Val Loss: 0.5097
Epoch [117/120], Loss: 0.1187, Val Loss: 0.4955
Epoch [118/120], Loss: 0.1117, Val Loss: 0.5283
Epoch [119/120], Loss: 0.2541, Val Loss: 0.4870
Epoch [120/120], Loss: 0.1367, Val Loss: 0.4930
Runtime: 0:00:56.686285
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/200], Loss: 0.6612, Val Loss: 0.9070
Epoch [2/200], Loss: 0.2304, Val Loss: 0.9238
Epoch [3/200], Loss: 2.1035, Val Loss: 0.8392
Epoch [4/200], Loss: 0.7484, Val Loss: 0.7529
Epoch [5/200], Loss: 0.1272, Val Loss: 1.0058
Epoch [6/200], Loss: 0.6594, Val Loss: 0.7648
Epoch [7/200], Loss: 0.2628, Val Loss: 0.7814
Epoch [8/200], Loss: 0.3094, Val Loss: 0.6653
Epoch [9/200], Loss: 0.8213, Val Loss: 0.7719
Epoch [10/200], Loss: 0.9014, Val Loss: 0.6979
Epoch [11/200], Loss: 0.2549, Val Loss: 0.6188
Epoch [12/200], Loss: 0.6230, Val Loss: 0.6579
Epoch [13/200], Loss: 0.1257, Val Loss: 0.5991
Epoch [14/200], Loss: 1.7060, Val Loss: 0.6943
Epoch [15/200], Loss: 0.1474, Val Loss: 0.5947
Epoch [16/200], Loss: 0.3585, Val Loss: 0.6418
Epoch [17/200], Loss: 0.1080, Val Loss: 0.5692
Epoch [18/200], Loss: 0.6448, Val Loss: 0.6238
Epoch [19/200], Loss: 1.1830, Val Loss: 0.7170
Epoch [20/200], Loss: 0.0770, Val Loss: 0.5923
Epoch [21/200], Loss: 0.2409, Val Loss: 0.5817
Epoch [22/200], Loss: 0.1494, Val Loss: 0.5620
Epoch [23/200], Loss: 0.0601, Val Loss: 0.5872
Epoch [24/200], Loss: 0.4619, Val Loss: 0.5919
Epoch [25/200], Loss: 0.0734, Val Loss: 0.5223
Epoch [26/200], Loss: 0.2945, Val Loss: 0.5604
Epoch [27/200], Loss: 0.0804, Val Loss: 0.6238
Epoch [28/200], Loss: 0.1677, Val Loss: 0.5267
Epoch [29/200], Loss: 0.2300, Val Loss: 0.5361
Epoch [30/200], Loss: 0.2124, Val Loss: 0.5909
Epoch [31/200], Loss: 0.6264, Val Loss: 0.5046
Epoch [32/200], Loss: 0.1586, Val Loss: 0.5646
Epoch [33/200], Loss: 0.2561, Val Loss: 0.5316
Epoch [34/200], Loss: 0.4741, Val Loss: 0.5520
Epoch [35/200], Loss: 0.0902, Val Loss: 0.5530
Epoch [36/200], Loss: 0.0680, Val Loss: 0.6442
Epoch [37/200], Loss: 0.1752, Val Loss: 0.4848
Epoch [38/200], Loss: 0.1885, Val Loss: 0.5179
Epoch [39/200], Loss: 0.3690, Val Loss: 0.5521
Epoch [40/200], Loss: 0.0974, Val Loss: 0.4768
Epoch [41/200], Loss: 0.0596, Val Loss: 0.5001
Epoch [42/200], Loss: 0.1806, Val Loss: 0.4990
Epoch [43/200], Loss: 0.4058, Val Loss: 0.4969
Epoch [44/200], Loss: 0.2137, Val Loss: 0.5114
Epoch [45/200], Loss: 0.1939, Val Loss: 0.4808
Epoch [46/200], Loss: 0.2394, Val Loss: 0.5193
Epoch [47/200], Loss: 0.1290, Val Loss: 0.6142
Epoch [48/200], Loss: 0.5588, Val Loss: 0.4791
Epoch [49/200], Loss: 0.0799, Val Loss: 0.5330
Epoch [50/200], Loss: 0.0682, Val Loss: 0.4832
Epoch [51/200], Loss: 0.2765, Val Loss: 0.4629
Epoch [52/200], Loss: 0.3472, Val Loss: 0.5621
Epoch [53/200], Loss: 0.1319, Val Loss: 0.5231
Epoch [54/200], Loss: 0.1184, Val Loss: 0.7107
Epoch [55/200], Loss: 0.1947, Val Loss: 0.5442
Epoch [56/200], Loss: 0.1418, Val Loss: 0.5553
Epoch [57/200], Loss: 0.3120, Val Loss: 0.5298
Epoch [58/200], Loss: 0.1366, Val Loss: 0.4547
Epoch [59/200], Loss: 0.1760, Val Loss: 0.4421
Epoch [60/200], Loss: 0.0776, Val Loss: 0.5565
Epoch [61/200], Loss: 0.2377, Val Loss: 0.4623
Epoch [62/200], Loss: 0.0453, Val Loss: 0.5411
Epoch [63/200], Loss: 0.1872, Val Loss: 0.4889
Epoch [64/200], Loss: 0.2071, Val Loss: 0.4953
Epoch [65/200], Loss: 0.0586, Val Loss: 0.4970
Epoch [66/200], Loss: 0.4282, Val Loss: 0.4837
Epoch [67/200], Loss: 0.6651, Val Loss: 0.4596
Epoch [68/200], Loss: 0.0873, Val Loss: 0.4560
Epoch [69/200], Loss: 0.1856, Val Loss: 0.5264
Epoch [70/200], Loss: 0.1420, Val Loss: 0.4363
Epoch [71/200], Loss: 0.1671, Val Loss: 0.4620
Epoch [72/200], Loss: 0.1221, Val Loss: 0.4683
Epoch [73/200], Loss: 0.0747, Val Loss: 0.5147
Epoch [74/200], Loss: 0.1433, Val Loss: 0.4753
Epoch [75/200], Loss: 0.4442, Val Loss: 0.5016
Epoch [76/200], Loss: 1.0309, Val Loss: 0.4434
Epoch [77/200], Loss: 0.2349, Val Loss: 0.4871
Epoch [78/200], Loss: 0.7421, Val Loss: 0.4534
Epoch [79/200], Loss: 0.1896, Val Loss: 0.4418
Epoch [80/200], Loss: 0.1023, Val Loss: 0.4572
Epoch [81/200], Loss: 0.4104, Val Loss: 0.4708
Epoch [82/200], Loss: 0.0947, Val Loss: 0.5534
Epoch [83/200], Loss: 0.0790, Val Loss: 0.4389
Epoch [84/200], Loss: 0.1144, Val Loss: 0.4859
Epoch [85/200], Loss: 0.3099, Val Loss: 0.4335
Epoch [86/200], Loss: 0.5223, Val Loss: 0.4704
Epoch [87/200], Loss: 0.0920, Val Loss: 0.4675
Epoch [88/200], Loss: 0.2548, Val Loss: 0.4266
Epoch [89/200], Loss: 0.1450, Val Loss: 0.4913
Epoch [90/200], Loss: 0.1224, Val Loss: 0.4806
Epoch [91/200], Loss: 0.2660, Val Loss: 0.5117
Epoch [92/200], Loss: 0.0747, Val Loss: 0.4595
Epoch [93/200], Loss: 0.2016, Val Loss: 0.5174
Epoch [94/200], Loss: 0.0883, Val Loss: 0.4472
Epoch [95/200], Loss: 0.1005, Val Loss: 0.4528
Epoch [96/200], Loss: 0.1611, Val Loss: 0.4964
Epoch [97/200], Loss: 0.0739, Val Loss: 0.4289
Epoch [98/200], Loss: 0.0840, Val Loss: 0.4574
Epoch [99/200], Loss: 0.1918, Val Loss: 0.4624
Epoch [100/200], Loss: 0.0871, Val Loss: 0.4464
Epoch [101/200], Loss: 0.1828, Val Loss: 0.5098
Epoch [102/200], Loss: 0.0907, Val Loss: 0.4401
Epoch [103/200], Loss: 0.2853, Val Loss: 0.4441
Epoch [104/200], Loss: 0.1158, Val Loss: 0.4599
Epoch [105/200], Loss: 0.2324, Val Loss: 0.4589
Epoch [106/200], Loss: 0.2653, Val Loss: 0.4694
Epoch [107/200], Loss: 0.0896, Val Loss: 0.5109
Epoch [108/200], Loss: 0.2133, Val Loss: 0.5019
Epoch [109/200], Loss: 0.2032, Val Loss: 0.4814
Epoch [110/200], Loss: 0.2127, Val Loss: 0.5179
Epoch [111/200], Loss: 0.3242, Val Loss: 0.5311
Epoch [112/200], Loss: 0.9759, Val Loss: 0.4992
Epoch [113/200], Loss: 0.1744, Val Loss: 0.5605
Epoch [114/200], Loss: 0.1395, Val Loss: 0.4959
Epoch [115/200], Loss: 0.1241, Val Loss: 0.4910
Epoch [116/200], Loss: 0.1282, Val Loss: 0.4734
Epoch [117/200], Loss: 0.0408, Val Loss: 0.4623
Epoch [118/200], Loss: 0.1589, Val Loss: 0.5239
Epoch [119/200], Loss: 0.8933, Val Loss: 0.5416
Epoch [120/200], Loss: 0.3543, Val Loss: 0.4703
Epoch [121/200], Loss: 0.3930, Val Loss: 0.5138
Epoch [122/200], Loss: 0.1582, Val Loss: 0.4613
Epoch [123/200], Loss: 0.2268, Val Loss: 0.5145
Epoch [124/200], Loss: 0.3737, Val Loss: 0.5028
Epoch [125/200], Loss: 0.2754, Val Loss: 0.4601
Epoch [126/200], Loss: 0.3631, Val Loss: 0.5150
Epoch [127/200], Loss: 0.1318, Val Loss: 0.4924
Epoch [128/200], Loss: 0.0793, Val Loss: 0.4500
Epoch [129/200], Loss: 0.3177, Val Loss: 0.4803
Epoch [130/200], Loss: 0.1323, Val Loss: 0.4705
Epoch [131/200], Loss: 0.2598, Val Loss: 0.4895
Epoch [132/200], Loss: 0.2956, Val Loss: 0.4949
Epoch [133/200], Loss: 0.2903, Val Loss: 0.4771
Epoch [134/200], Loss: 0.3125, Val Loss: 0.5005
Epoch [135/200], Loss: 0.4444, Val Loss: 0.4591
Epoch [136/200], Loss: 0.1956, Val Loss: 0.4716
Epoch [137/200], Loss: 0.3194, Val Loss: 0.4690
Epoch [138/200], Loss: 0.3257, Val Loss: 0.5004
Epoch [139/200], Loss: 0.0933, Val Loss: 0.5453
Epoch [140/200], Loss: 0.3857, Val Loss: 0.4618
Epoch [141/200], Loss: 0.1224, Val Loss: 0.5047
Epoch [142/200], Loss: 0.5467, Val Loss: 0.4533
Epoch [143/200], Loss: 0.1393, Val Loss: 0.4614
Epoch [144/200], Loss: 0.3309, Val Loss: 0.4759
Epoch [145/200], Loss: 0.1100, Val Loss: 0.4981
Epoch [146/200], Loss: 0.3268, Val Loss: 0.5165
Early stopping at epoch 146
Runtime: 0:01:11.924699
Using optimizer: Adam
Standard data
Optimized hyperparameter at Trial 299 finished with value: 0.2546721821831119             and parameters: {'weight_decay': 6.818751742897769e-05, 'batch_size': 128, 'n_units_l1': 111, 'n_units_l2': 122, 'n_units_l3': 80}.            Suggested LR = 0.0023340117186307907
TruncatedSVD_50
MLP with layer size: [111, 122, 80] - Result:
Epoch [1/200], Loss: 0.5064, Val Loss: 0.9625
Epoch [2/200], Loss: 1.2800, Val Loss: 0.8433
Epoch [3/200], Loss: 0.2627, Val Loss: 0.7963
Epoch [4/200], Loss: 0.3663, Val Loss: 0.8137
Epoch [5/200], Loss: 0.3164, Val Loss: 0.8792
Epoch [6/200], Loss: 1.2186, Val Loss: 0.8183
Epoch [7/200], Loss: 0.1459, Val Loss: 0.6833
Epoch [8/200], Loss: 0.5811, Val Loss: 0.8773
Epoch [9/200], Loss: 0.1709, Val Loss: 0.7097
Epoch [10/200], Loss: 0.1037, Val Loss: 0.7094
Epoch [11/200], Loss: 2.0524, Val Loss: 0.7446
Epoch [12/200], Loss: 0.2566, Val Loss: 0.7770
Epoch [13/200], Loss: 0.1721, Val Loss: 0.6808
Epoch [14/200], Loss: 0.0632, Val Loss: 0.6457
Epoch [15/200], Loss: 0.5287, Val Loss: 0.7931
Epoch [16/200], Loss: 0.0624, Val Loss: 0.6438
Epoch [17/200], Loss: 0.2684, Val Loss: 0.6645
Epoch [18/200], Loss: 0.4475, Val Loss: 0.6224
Epoch [19/200], Loss: 0.2586, Val Loss: 0.6822
Epoch [20/200], Loss: 0.1123, Val Loss: 0.5757
Epoch [21/200], Loss: 0.2035, Val Loss: 0.6361
Epoch [22/200], Loss: 0.8447, Val Loss: 0.5727
Epoch [23/200], Loss: 0.6383, Val Loss: 0.5420
Epoch [24/200], Loss: 0.2744, Val Loss: 0.5775
Epoch [25/200], Loss: 4.7006, Val Loss: 0.6345
Epoch [26/200], Loss: 0.1829, Val Loss: 0.6086
Epoch [27/200], Loss: 0.2742, Val Loss: 0.5538
Epoch [28/200], Loss: 0.6787, Val Loss: 0.5901
Epoch [29/200], Loss: 0.2404, Val Loss: 0.5175
Epoch [30/200], Loss: 0.1174, Val Loss: 0.5932
Epoch [31/200], Loss: 0.1806, Val Loss: 0.5181
Epoch [32/200], Loss: 0.1724, Val Loss: 0.5089
Epoch [33/200], Loss: 0.1422, Val Loss: 0.6198
Epoch [34/200], Loss: 0.2130, Val Loss: 0.5088
Epoch [35/200], Loss: 0.1221, Val Loss: 0.6033
Epoch [36/200], Loss: 0.5423, Val Loss: 0.4978
Epoch [37/200], Loss: 0.1606, Val Loss: 0.4973
Epoch [38/200], Loss: 0.1598, Val Loss: 0.5234
Epoch [39/200], Loss: 0.0891, Val Loss: 0.5240
Epoch [40/200], Loss: 0.1637, Val Loss: 0.5825
Epoch [41/200], Loss: 0.2215, Val Loss: 0.5999
Epoch [42/200], Loss: 0.2081, Val Loss: 0.5135
Epoch [43/200], Loss: 0.1040, Val Loss: 0.5232
Epoch [44/200], Loss: 1.1829, Val Loss: 0.5327
Epoch [45/200], Loss: 0.2267, Val Loss: 0.5953
Epoch [46/200], Loss: 0.5135, Val Loss: 0.5505
Epoch [47/200], Loss: 0.1210, Val Loss: 0.5353
Epoch [48/200], Loss: 0.1111, Val Loss: 0.5055
Epoch [49/200], Loss: 0.0973, Val Loss: 0.5764
Epoch [50/200], Loss: 0.1327, Val Loss: 0.5350
Epoch [51/200], Loss: 0.0711, Val Loss: 0.5422
Epoch [52/200], Loss: 0.1257, Val Loss: 0.4946
Epoch [53/200], Loss: 0.0963, Val Loss: 0.4832
Epoch [54/200], Loss: 0.1155, Val Loss: 0.5141
Epoch [55/200], Loss: 0.0930, Val Loss: 0.5436
Epoch [56/200], Loss: 0.4840, Val Loss: 0.4882
Epoch [57/200], Loss: 0.4539, Val Loss: 0.5821
Epoch [58/200], Loss: 0.1200, Val Loss: 0.5126
Epoch [59/200], Loss: 0.7023, Val Loss: 0.5897
Epoch [60/200], Loss: 0.1645, Val Loss: 0.5232
Epoch [61/200], Loss: 0.1296, Val Loss: 0.5074
Epoch [62/200], Loss: 0.0959, Val Loss: 0.5354
Epoch [63/200], Loss: 0.0492, Val Loss: 0.5261
Epoch [64/200], Loss: 0.0969, Val Loss: 0.5142
Epoch [65/200], Loss: 0.0683, Val Loss: 0.4963
Epoch [66/200], Loss: 0.2146, Val Loss: 0.4904
Epoch [67/200], Loss: 0.1640, Val Loss: 0.5366
Epoch [68/200], Loss: 0.1196, Val Loss: 0.5204
Epoch [69/200], Loss: 0.0803, Val Loss: 0.5053
Epoch [70/200], Loss: 0.1947, Val Loss: 0.4749
Epoch [71/200], Loss: 0.5871, Val Loss: 0.5441
Epoch [72/200], Loss: 0.7323, Val Loss: 0.5100
Epoch [73/200], Loss: 0.1195, Val Loss: 0.5575
Epoch [74/200], Loss: 0.1017, Val Loss: 0.4930
Epoch [75/200], Loss: 0.1654, Val Loss: 0.5265
Epoch [76/200], Loss: 0.2198, Val Loss: 0.4886
Epoch [77/200], Loss: 0.1043, Val Loss: 0.4829
Epoch [78/200], Loss: 0.1590, Val Loss: 0.5167
Epoch [79/200], Loss: 0.1999, Val Loss: 0.5037
Epoch [80/200], Loss: 1.1629, Val Loss: 0.5399
Epoch [81/200], Loss: 0.0834, Val Loss: 0.5676
Epoch [82/200], Loss: 0.0904, Val Loss: 0.5057
Epoch [83/200], Loss: 0.0830, Val Loss: 0.4878
Epoch [84/200], Loss: 0.1934, Val Loss: 0.5312
Epoch [85/200], Loss: 0.1305, Val Loss: 0.5458
Epoch [86/200], Loss: 0.1018, Val Loss: 0.4778
Epoch [87/200], Loss: 0.0345, Val Loss: 0.4776
Epoch [88/200], Loss: 0.4340, Val Loss: 0.4783
Epoch [89/200], Loss: 0.0783, Val Loss: 0.5220
Epoch [90/200], Loss: 0.1884, Val Loss: 0.5220
Epoch [91/200], Loss: 0.4864, Val Loss: 0.5724
Epoch [92/200], Loss: 0.0633, Val Loss: 0.5730
Epoch [93/200], Loss: 0.0814, Val Loss: 0.4606
Epoch [94/200], Loss: 0.7079, Val Loss: 0.4838
Epoch [95/200], Loss: 0.1629, Val Loss: 0.4861
Epoch [96/200], Loss: 0.0654, Val Loss: 0.4666
Epoch [97/200], Loss: 0.1199, Val Loss: 0.5181
Epoch [98/200], Loss: 0.0428, Val Loss: 0.4832
Epoch [99/200], Loss: 0.0372, Val Loss: 0.5620
Epoch [100/200], Loss: 0.1320, Val Loss: 0.5096
Epoch [101/200], Loss: 0.1211, Val Loss: 0.5006
Epoch [102/200], Loss: 0.1371, Val Loss: 0.4762
Epoch [103/200], Loss: 0.1347, Val Loss: 0.5527
Epoch [104/200], Loss: 0.1359, Val Loss: 0.5225
Epoch [105/200], Loss: 0.1023, Val Loss: 0.5676
Epoch [106/200], Loss: 0.2149, Val Loss: 0.4665
Epoch [107/200], Loss: 0.1766, Val Loss: 0.4612
Epoch [108/200], Loss: 0.3344, Val Loss: 0.4791
Epoch [109/200], Loss: 0.1357, Val Loss: 0.4808
Epoch [110/200], Loss: 0.1453, Val Loss: 0.5478
Epoch [111/200], Loss: 0.3051, Val Loss: 0.4935
Epoch [112/200], Loss: 0.1776, Val Loss: 0.5182
Epoch [113/200], Loss: 0.1070, Val Loss: 0.4899
Epoch [114/200], Loss: 0.0616, Val Loss: 0.4849
Epoch [115/200], Loss: 0.1748, Val Loss: 0.4646
Epoch [116/200], Loss: 0.3388, Val Loss: 0.4948
Epoch [117/200], Loss: 0.2752, Val Loss: 0.4920
Epoch [118/200], Loss: 0.3434, Val Loss: 0.4783
Epoch [119/200], Loss: 0.1055, Val Loss: 0.6781
Epoch [120/200], Loss: 0.1043, Val Loss: 0.4953
Epoch [121/200], Loss: 0.2436, Val Loss: 0.5708
Epoch [122/200], Loss: 0.1194, Val Loss: 0.4922
Epoch [123/200], Loss: 0.2188, Val Loss: 0.4885
Epoch [124/200], Loss: 0.0678, Val Loss: 0.5049
Epoch [125/200], Loss: 0.3150, Val Loss: 0.4856
Epoch [126/200], Loss: 0.2028, Val Loss: 0.5334
Epoch [127/200], Loss: 0.7195, Val Loss: 0.4713
Epoch [128/200], Loss: 0.1533, Val Loss: 0.5111
Epoch [129/200], Loss: 0.1850, Val Loss: 0.5007
Epoch [130/200], Loss: 0.3239, Val Loss: 0.4940
Epoch [131/200], Loss: 0.1219, Val Loss: 0.5537
Epoch [132/200], Loss: 0.0881, Val Loss: 0.5066
Epoch [133/200], Loss: 0.4971, Val Loss: 0.4778
Epoch [134/200], Loss: 0.2679, Val Loss: 0.4987
Epoch [135/200], Loss: 0.0839, Val Loss: 0.5142
Epoch [136/200], Loss: 0.7042, Val Loss: 0.4699
Epoch [137/200], Loss: 0.1382, Val Loss: 0.4931
Epoch [138/200], Loss: 0.1917, Val Loss: 0.4811
Epoch [139/200], Loss: 0.1331, Val Loss: 0.4998
Epoch [140/200], Loss: 0.2001, Val Loss: 0.4871
Epoch [141/200], Loss: 0.1124, Val Loss: 0.5730
Epoch [142/200], Loss: 0.3219, Val Loss: 0.5236
Epoch [143/200], Loss: 0.1105, Val Loss: 0.5030
Epoch [144/200], Loss: 0.0911, Val Loss: 0.4902
Epoch [145/200], Loss: 0.1118, Val Loss: 0.5365
Epoch [146/200], Loss: 0.0492, Val Loss: 0.5652
Epoch [147/200], Loss: 0.1393, Val Loss: 0.5242
Epoch [148/200], Loss: 0.3618, Val Loss: 0.5497
Epoch [149/200], Loss: 0.6912, Val Loss: 0.5226
Epoch [150/200], Loss: 0.0580, Val Loss: 0.5723
Epoch [151/200], Loss: 0.2679, Val Loss: 0.5685
Epoch [152/200], Loss: 0.0944, Val Loss: 0.4912
Epoch [153/200], Loss: 0.1278, Val Loss: 0.5286
Epoch [154/200], Loss: 0.1741, Val Loss: 0.5253
Epoch [155/200], Loss: 0.0591, Val Loss: 0.5850
Epoch [156/200], Loss: 1.2961, Val Loss: 0.5373
Epoch [157/200], Loss: 0.1319, Val Loss: 0.4968
Epoch [158/200], Loss: 0.2631, Val Loss: 0.5130
Epoch [159/200], Loss: 0.2822, Val Loss: 0.5034
Epoch [160/200], Loss: 0.0636, Val Loss: 0.5260
Epoch [161/200], Loss: 0.1678, Val Loss: 0.4825
Epoch [162/200], Loss: 0.0562, Val Loss: 0.4780
Epoch [163/200], Loss: 0.1233, Val Loss: 0.5051
Epoch [164/200], Loss: 0.1770, Val Loss: 0.5182
Epoch [165/200], Loss: 0.3105, Val Loss: 0.5486
Epoch [166/200], Loss: 0.2050, Val Loss: 0.4838
Epoch [167/200], Loss: 0.8182, Val Loss: 0.4801
Epoch [168/200], Loss: 0.2816, Val Loss: 0.5234
Epoch [169/200], Loss: 0.2695, Val Loss: 0.5562
Epoch [170/200], Loss: 0.0714, Val Loss: 0.5741
Epoch [171/200], Loss: 0.1676, Val Loss: 0.5214
Epoch [172/200], Loss: 0.1444, Val Loss: 0.5120
Epoch [173/200], Loss: 0.0618, Val Loss: 0.4783
Epoch [174/200], Loss: 0.4742, Val Loss: 0.4839
Epoch [175/200], Loss: 0.1718, Val Loss: 0.4990
Epoch [176/200], Loss: 0.1964, Val Loss: 0.4891
Epoch [177/200], Loss: 0.0649, Val Loss: 0.5317
Epoch [178/200], Loss: 0.0550, Val Loss: 0.5284
Epoch [179/200], Loss: 0.0843, Val Loss: 0.5170
Epoch [180/200], Loss: 0.0563, Val Loss: 0.5732
Epoch [181/200], Loss: 0.1187, Val Loss: 0.5682
Epoch [182/200], Loss: 0.0979, Val Loss: 0.4781
Epoch [183/200], Loss: 0.2343, Val Loss: 0.5123
Epoch [184/200], Loss: 0.2491, Val Loss: 0.5140
Epoch [185/200], Loss: 0.1391, Val Loss: 0.5222
Epoch [186/200], Loss: 0.2347, Val Loss: 0.4913
Epoch [187/200], Loss: 0.0811, Val Loss: 0.5041
Epoch [188/200], Loss: 0.0942, Val Loss: 0.5473
Epoch [189/200], Loss: 0.1842, Val Loss: 0.4863
Epoch [190/200], Loss: 0.2372, Val Loss: 0.4999
Epoch [191/200], Loss: 0.3511, Val Loss: 0.4985
Epoch [192/200], Loss: 0.1322, Val Loss: 0.6125
Epoch [193/200], Loss: 0.1007, Val Loss: 0.5689
Epoch [194/200], Loss: 0.0484, Val Loss: 0.5394
Early stopping at epoch 194
Runtime: 0:01:33.013503
R^2 Score: 0.9087
RMSE: 0.5919
MAE: 0.1852
MAPE: 15.09%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 251, 392, 200, 80] - Result:
Epoch [1/250], Loss: 0.7853, Val Loss: 0.9119
Epoch [2/250], Loss: 0.6929, Val Loss: 0.8533
Epoch [3/250], Loss: 1.2785, Val Loss: 0.9435
Epoch [4/250], Loss: 0.6772, Val Loss: 0.8963
Epoch [5/250], Loss: 1.5967, Val Loss: 0.8827
Epoch [6/250], Loss: 0.5658, Val Loss: 0.7098
Epoch [7/250], Loss: 1.0489, Val Loss: 1.0701
Epoch [8/250], Loss: 0.7508, Val Loss: 0.7667
Epoch [9/250], Loss: 1.2774, Val Loss: 1.0247
Epoch [10/250], Loss: 0.3190, Val Loss: 0.7509
Epoch [11/250], Loss: 0.4317, Val Loss: 0.7987
Epoch [12/250], Loss: 0.5822, Val Loss: 0.6550
Epoch [13/250], Loss: 0.5348, Val Loss: 0.7416
Epoch [14/250], Loss: 0.5213, Val Loss: 0.6971
Epoch [15/250], Loss: 0.3033, Val Loss: 0.6758
Epoch [16/250], Loss: 0.6195, Val Loss: 0.5971
Epoch [17/250], Loss: 1.1631, Val Loss: 0.6627
Epoch [18/250], Loss: 0.4500, Val Loss: 0.7076
Epoch [19/250], Loss: 0.6327, Val Loss: 0.6036
Epoch [20/250], Loss: 0.3455, Val Loss: 0.5984
Epoch [21/250], Loss: 0.7414, Val Loss: 0.6179
Epoch [22/250], Loss: 0.3780, Val Loss: 0.5701
Epoch [23/250], Loss: 0.3184, Val Loss: 0.6010
Epoch [24/250], Loss: 0.4201, Val Loss: 0.6727
Epoch [25/250], Loss: 0.3976, Val Loss: 0.5713
Epoch [26/250], Loss: 0.6187, Val Loss: 0.5917
Epoch [27/250], Loss: 0.5358, Val Loss: 0.6299
Epoch [28/250], Loss: 0.3480, Val Loss: 0.5601
Epoch [29/250], Loss: 0.2025, Val Loss: 0.5917
Epoch [30/250], Loss: 0.5362, Val Loss: 0.5928
Epoch [31/250], Loss: 0.2999, Val Loss: 0.6567
Epoch [32/250], Loss: 0.4628, Val Loss: 0.5690
Epoch [33/250], Loss: 0.2384, Val Loss: 0.5441
Epoch [34/250], Loss: 0.2882, Val Loss: 0.5495
Epoch [35/250], Loss: 0.4221, Val Loss: 0.7113
Epoch [36/250], Loss: 0.4135, Val Loss: 0.5478
Epoch [37/250], Loss: 0.3071, Val Loss: 0.5531
Epoch [38/250], Loss: 0.6883, Val Loss: 0.5272
Epoch [39/250], Loss: 0.2574, Val Loss: 0.5287
Epoch [40/250], Loss: 0.4574, Val Loss: 0.6659
Epoch [41/250], Loss: 0.2527, Val Loss: 0.6358
Epoch [42/250], Loss: 0.3909, Val Loss: 0.5288
Epoch [43/250], Loss: 0.2914, Val Loss: 0.6537
Epoch [44/250], Loss: 0.2793, Val Loss: 0.5628
Epoch [45/250], Loss: 0.2619, Val Loss: 0.5655
Epoch [46/250], Loss: 0.3158, Val Loss: 0.6058
Epoch [47/250], Loss: 0.2412, Val Loss: 0.5036
Epoch [48/250], Loss: 0.4289, Val Loss: 0.6168
Epoch [49/250], Loss: 0.4259, Val Loss: 0.5497
Epoch [50/250], Loss: 0.2718, Val Loss: 0.4947
Epoch [51/250], Loss: 0.3802, Val Loss: 0.5032
Epoch [52/250], Loss: 0.2460, Val Loss: 0.5276
Epoch [53/250], Loss: 0.3952, Val Loss: 0.5348
Epoch [54/250], Loss: 0.7680, Val Loss: 0.5274
Epoch [55/250], Loss: 0.4108, Val Loss: 0.5791
Epoch [56/250], Loss: 0.3306, Val Loss: 0.7745
Epoch [57/250], Loss: 0.3322, Val Loss: 0.5432
Epoch [58/250], Loss: 0.3502, Val Loss: 0.5386
Epoch [59/250], Loss: 0.4315, Val Loss: 0.5992
Epoch [60/250], Loss: 1.3064, Val Loss: 0.5395
Epoch [61/250], Loss: 0.7567, Val Loss: 0.7266
Epoch [62/250], Loss: 0.3005, Val Loss: 0.5341
Epoch [63/250], Loss: 0.3953, Val Loss: 0.5281
Epoch [64/250], Loss: 0.4109, Val Loss: 0.5210
Epoch [65/250], Loss: 0.4626, Val Loss: 0.6532
Epoch [66/250], Loss: 0.2137, Val Loss: 0.5175
Epoch [67/250], Loss: 0.8766, Val Loss: 0.6217
Epoch [68/250], Loss: 0.5674, Val Loss: 0.5209
Epoch [69/250], Loss: 0.2792, Val Loss: 0.5021
Epoch [70/250], Loss: 1.0002, Val Loss: 0.5587
Epoch [71/250], Loss: 0.2256, Val Loss: 0.5109
Epoch [72/250], Loss: 0.8711, Val Loss: 0.5289
Epoch [73/250], Loss: 0.2621, Val Loss: 0.5390
Epoch [74/250], Loss: 0.2548, Val Loss: 0.5789
Epoch [75/250], Loss: 0.2518, Val Loss: 0.5283
Epoch [76/250], Loss: 0.1916, Val Loss: 0.6191
Epoch [77/250], Loss: 0.2194, Val Loss: 0.5183
Epoch [78/250], Loss: 0.2058, Val Loss: 0.5137
Epoch [79/250], Loss: 0.4589, Val Loss: 0.5657
Epoch [80/250], Loss: 0.3459, Val Loss: 0.5346
Epoch [81/250], Loss: 0.2310, Val Loss: 0.5629
Epoch [82/250], Loss: 0.3292, Val Loss: 0.5269
Epoch [83/250], Loss: 0.1906, Val Loss: 0.5194
Epoch [84/250], Loss: 0.1861, Val Loss: 0.5046
Epoch [85/250], Loss: 0.2093, Val Loss: 0.5335
Epoch [86/250], Loss: 0.2909, Val Loss: 0.4971
Epoch [87/250], Loss: 0.2750, Val Loss: 0.5082
Epoch [88/250], Loss: 0.3313, Val Loss: 0.5102
Epoch [89/250], Loss: 0.3391, Val Loss: 0.4943
Epoch [90/250], Loss: 0.1771, Val Loss: 0.5395
Epoch [91/250], Loss: 0.4654, Val Loss: 0.5994
Epoch [92/250], Loss: 0.1972, Val Loss: 0.6143
Epoch [93/250], Loss: 0.4653, Val Loss: 0.5255
Epoch [94/250], Loss: 0.3869, Val Loss: 0.5646
Epoch [95/250], Loss: 0.2649, Val Loss: 0.5341
Epoch [96/250], Loss: 0.2230, Val Loss: 0.5043
Epoch [97/250], Loss: 0.1769, Val Loss: 0.5235
Epoch [98/250], Loss: 0.6889, Val Loss: 0.5000
Epoch [99/250], Loss: 0.2005, Val Loss: 0.5178
Epoch [100/250], Loss: 0.2816, Val Loss: 0.5099
Epoch [101/250], Loss: 0.3503, Val Loss: 0.5384
Epoch [102/250], Loss: 0.3464, Val Loss: 0.5806
Epoch [103/250], Loss: 0.2795, Val Loss: 0.5589
Epoch [104/250], Loss: 0.1948, Val Loss: 0.5027
Epoch [105/250], Loss: 0.4038, Val Loss: 0.5623
Epoch [106/250], Loss: 0.2333, Val Loss: 0.4778
Epoch [107/250], Loss: 0.3816, Val Loss: 0.5156
Epoch [108/250], Loss: 0.1897, Val Loss: 0.5323
Epoch [109/250], Loss: 0.2108, Val Loss: 0.5034
Epoch [110/250], Loss: 0.4144, Val Loss: 0.5588
Epoch [111/250], Loss: 0.2349, Val Loss: 0.5099
Epoch [112/250], Loss: 0.2160, Val Loss: 0.5070
Epoch [113/250], Loss: 0.3185, Val Loss: 0.5413
Epoch [114/250], Loss: 0.1441, Val Loss: 0.4810
Epoch [115/250], Loss: 0.1723, Val Loss: 0.5049
Epoch [116/250], Loss: 0.3647, Val Loss: 0.6056
Epoch [117/250], Loss: 0.2520, Val Loss: 0.5042
Epoch [118/250], Loss: 0.4463, Val Loss: 0.5706
Epoch [119/250], Loss: 0.4397, Val Loss: 0.5688
Epoch [120/250], Loss: 0.1960, Val Loss: 0.5244
Epoch [121/250], Loss: 0.4087, Val Loss: 0.6227
Epoch [122/250], Loss: 0.1795, Val Loss: 0.5065
Epoch [123/250], Loss: 0.2276, Val Loss: 0.4782
Epoch [124/250], Loss: 0.6594, Val Loss: 0.5182
Epoch [125/250], Loss: 0.2470, Val Loss: 0.5152
Epoch [126/250], Loss: 0.3031, Val Loss: 0.5567
Epoch [127/250], Loss: 0.1576, Val Loss: 0.5069
Epoch [128/250], Loss: 0.3248, Val Loss: 0.5215
Epoch [129/250], Loss: 0.2006, Val Loss: 0.5594
Epoch [130/250], Loss: 0.4823, Val Loss: 0.5390
Epoch [131/250], Loss: 0.2557, Val Loss: 0.5025
Epoch [132/250], Loss: 0.2941, Val Loss: 0.5179
Epoch [133/250], Loss: 0.3069, Val Loss: 0.5131
Epoch [134/250], Loss: 0.3204, Val Loss: 0.4878
Epoch [135/250], Loss: 0.4160, Val Loss: 0.5614
Epoch [136/250], Loss: 0.3298, Val Loss: 0.5530
Epoch [137/250], Loss: 0.3641, Val Loss: 0.5932
Epoch [138/250], Loss: 0.2762, Val Loss: 0.4983
Epoch [139/250], Loss: 0.3571, Val Loss: 0.5105
Epoch [140/250], Loss: 0.2003, Val Loss: 0.4974
Epoch [141/250], Loss: 0.3159, Val Loss: 0.5339
Epoch [142/250], Loss: 0.3077, Val Loss: 0.5437
Epoch [143/250], Loss: 0.2537, Val Loss: 0.4904
Epoch [144/250], Loss: 0.1687, Val Loss: 0.6048
Epoch [145/250], Loss: 0.3800, Val Loss: 0.5584
Epoch [146/250], Loss: 0.3708, Val Loss: 0.4860
Epoch [147/250], Loss: 0.2037, Val Loss: 0.6682
Epoch [148/250], Loss: 0.2476, Val Loss: 0.5377
Epoch [149/250], Loss: 0.2042, Val Loss: 0.5143
Epoch [150/250], Loss: 0.1437, Val Loss: 0.5304
Epoch [151/250], Loss: 0.2868, Val Loss: 0.5301
Epoch [152/250], Loss: 0.4572, Val Loss: 0.5661
Epoch [153/250], Loss: 0.2805, Val Loss: 0.5349
Epoch [154/250], Loss: 0.1763, Val Loss: 0.5439
Epoch [155/250], Loss: 0.2192, Val Loss: 0.5099
Epoch [156/250], Loss: 0.4588, Val Loss: 0.5900
Epoch [157/250], Loss: 0.4356, Val Loss: 0.5584
Epoch [158/250], Loss: 0.1607, Val Loss: 0.5092
Epoch [159/250], Loss: 0.2462, Val Loss: 0.4946
Epoch [160/250], Loss: 0.1857, Val Loss: 0.5169
Epoch [161/250], Loss: 0.3669, Val Loss: 0.5610
Epoch [162/250], Loss: 0.4707, Val Loss: 0.5055
Epoch [163/250], Loss: 0.3281, Val Loss: 0.5373
Epoch [164/250], Loss: 0.3791, Val Loss: 0.5327
Epoch [165/250], Loss: 0.2753, Val Loss: 0.5093
Epoch [166/250], Loss: 0.3030, Val Loss: 0.4935
Epoch [167/250], Loss: 0.1825, Val Loss: 0.5528
Epoch [168/250], Loss: 0.2112, Val Loss: 0.5230
Epoch [169/250], Loss: 0.4116, Val Loss: 0.5492
Epoch [170/250], Loss: 0.2918, Val Loss: 0.5294
Epoch [171/250], Loss: 0.4200, Val Loss: 0.5488
Epoch [172/250], Loss: 0.2031, Val Loss: 0.5055
Epoch [173/250], Loss: 0.4139, Val Loss: 0.5100
Epoch [174/250], Loss: 0.3135, Val Loss: 0.5393
Epoch [175/250], Loss: 0.2499, Val Loss: 0.5448
Epoch [176/250], Loss: 0.3324, Val Loss: 0.5164
Epoch [177/250], Loss: 0.6349, Val Loss: 0.5410
Epoch [178/250], Loss: 0.2247, Val Loss: 0.6058
Epoch [179/250], Loss: 0.2573, Val Loss: 0.5380
Epoch [180/250], Loss: 0.2187, Val Loss: 0.5105
Epoch [181/250], Loss: 0.2506, Val Loss: 0.5307
Epoch [182/250], Loss: 0.3492, Val Loss: 0.5016
Epoch [183/250], Loss: 0.1669, Val Loss: 0.5341
Epoch [184/250], Loss: 0.4739, Val Loss: 0.5203
Epoch [185/250], Loss: 0.3216, Val Loss: 0.5403
Epoch [186/250], Loss: 0.4131, Val Loss: 0.5291
Epoch [187/250], Loss: 0.3178, Val Loss: 0.5222
Epoch [188/250], Loss: 0.2386, Val Loss: 0.5063
Epoch [189/250], Loss: 0.4447, Val Loss: 0.5516
Epoch [190/250], Loss: 0.5419, Val Loss: 0.5423
Epoch [191/250], Loss: 0.3558, Val Loss: 0.5176
Epoch [192/250], Loss: 0.4086, Val Loss: 0.5490
Epoch [193/250], Loss: 0.4591, Val Loss: 0.5499
Epoch [194/250], Loss: 0.2141, Val Loss: 0.5289
Epoch [195/250], Loss: 0.3326, Val Loss: 0.5086
Epoch [196/250], Loss: 0.2713, Val Loss: 0.5307
Epoch [197/250], Loss: 0.2297, Val Loss: 0.4996
Epoch [198/250], Loss: 0.4088, Val Loss: 0.5925
Epoch [199/250], Loss: 0.1687, Val Loss: 0.5087
Epoch [200/250], Loss: 0.2995, Val Loss: 0.4853
Epoch [201/250], Loss: 0.2332, Val Loss: 0.5098
Epoch [202/250], Loss: 0.3753, Val Loss: 0.5261
Epoch [203/250], Loss: 1.1207, Val Loss: 0.5544
Epoch [204/250], Loss: 0.2777, Val Loss: 0.5104
Epoch [205/250], Loss: 0.1664, Val Loss: 0.5040
Epoch [206/250], Loss: 0.2006, Val Loss: 0.5303
Epoch [207/250], Loss: 0.1880, Val Loss: 0.5260
Epoch [208/250], Loss: 0.3614, Val Loss: 0.5238
Epoch [209/250], Loss: 0.6615, Val Loss: 0.5672
Epoch [210/250], Loss: 0.3031, Val Loss: 0.5285
Epoch [211/250], Loss: 0.3407, Val Loss: 0.5484
Epoch [212/250], Loss: 0.1601, Val Loss: 0.5160
Epoch [213/250], Loss: 0.3005, Val Loss: 0.5581
Epoch [214/250], Loss: 0.3575, Val Loss: 0.5621
Epoch [215/250], Loss: 0.3066, Val Loss: 0.5343
Epoch [216/250], Loss: 0.3181, Val Loss: 0.5033
Epoch [217/250], Loss: 0.1871, Val Loss: 0.5089
Epoch [218/250], Loss: 0.2334, Val Loss: 0.5120
Epoch [219/250], Loss: 0.2449, Val Loss: 0.5556
Epoch [220/250], Loss: 0.2074, Val Loss: 0.5149
Epoch [221/250], Loss: 0.2746, Val Loss: 0.4929
Epoch [222/250], Loss: 0.2753, Val Loss: 0.5294
Early stopping at epoch 222
Runtime: 0:01:20.018015
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 0.6703, Val Loss: 1.0578
Epoch [2/250], Loss: 0.6849, Val Loss: 0.9753
Epoch [3/250], Loss: 0.5454, Val Loss: 0.9692
Epoch [4/250], Loss: 2.7295, Val Loss: 0.8303
Epoch [5/250], Loss: 0.5391, Val Loss: 0.8216
Epoch [6/250], Loss: 0.6280, Val Loss: 0.7921
Epoch [7/250], Loss: 0.7945, Val Loss: 0.6945
Epoch [8/250], Loss: 0.9362, Val Loss: 0.7987
Epoch [9/250], Loss: 0.4803, Val Loss: 0.7084
Epoch [10/250], Loss: 0.6651, Val Loss: 1.0831
Epoch [11/250], Loss: 0.8478, Val Loss: 0.7975
Epoch [12/250], Loss: 0.5402, Val Loss: 0.8573
Epoch [13/250], Loss: 0.3642, Val Loss: 0.6920
Epoch [14/250], Loss: 0.3877, Val Loss: 0.6935
Epoch [15/250], Loss: 0.4298, Val Loss: 0.6327
Epoch [16/250], Loss: 0.5025, Val Loss: 0.7588
Epoch [17/250], Loss: 0.9967, Val Loss: 0.6627
Epoch [18/250], Loss: 0.3629, Val Loss: 0.6025
Epoch [19/250], Loss: 0.5206, Val Loss: 0.6790
Epoch [20/250], Loss: 0.5300, Val Loss: 0.5993
Epoch [21/250], Loss: 0.4378, Val Loss: 0.5923
Epoch [22/250], Loss: 0.8019, Val Loss: 0.8890
Epoch [23/250], Loss: 0.4055, Val Loss: 0.5702
Epoch [24/250], Loss: 0.2878, Val Loss: 0.6184
Epoch [25/250], Loss: 0.5875, Val Loss: 0.5879
Epoch [26/250], Loss: 0.9606, Val Loss: 0.7905
Epoch [27/250], Loss: 0.7107, Val Loss: 0.7540
Epoch [28/250], Loss: 0.2228, Val Loss: 0.6176
Epoch [29/250], Loss: 0.2350, Val Loss: 0.6094
Epoch [30/250], Loss: 0.2565, Val Loss: 0.5847
Epoch [31/250], Loss: 0.2491, Val Loss: 0.5685
Epoch [32/250], Loss: 0.4071, Val Loss: 0.6488
Epoch [33/250], Loss: 0.3505, Val Loss: 0.5389
Epoch [34/250], Loss: 0.3429, Val Loss: 0.5515
Epoch [35/250], Loss: 0.3792, Val Loss: 0.5609
Epoch [36/250], Loss: 0.3923, Val Loss: 0.6205
Epoch [37/250], Loss: 0.4294, Val Loss: 0.5340
Epoch [38/250], Loss: 0.2686, Val Loss: 0.5669
Epoch [39/250], Loss: 0.3140, Val Loss: 0.5359
Epoch [40/250], Loss: 0.2001, Val Loss: 0.5228
Epoch [41/250], Loss: 0.2657, Val Loss: 0.6060
Epoch [42/250], Loss: 0.4029, Val Loss: 0.5856
Epoch [43/250], Loss: 0.2723, Val Loss: 0.5392
Epoch [44/250], Loss: 0.4042, Val Loss: 0.5680
Epoch [45/250], Loss: 0.3770, Val Loss: 0.5443
Epoch [46/250], Loss: 0.2496, Val Loss: 0.6319
Epoch [47/250], Loss: 0.3511, Val Loss: 0.5700
Epoch [48/250], Loss: 0.7002, Val Loss: 0.5486
Epoch [49/250], Loss: 0.1972, Val Loss: 0.6854
Epoch [50/250], Loss: 0.7337, Val Loss: 0.6259
Epoch [51/250], Loss: 0.4582, Val Loss: 0.5610
Epoch [52/250], Loss: 0.3246, Val Loss: 0.5380
Epoch [53/250], Loss: 0.7946, Val Loss: 0.5207
Epoch [54/250], Loss: 0.8147, Val Loss: 0.5328
Epoch [55/250], Loss: 0.3616, Val Loss: 0.5368
Epoch [56/250], Loss: 0.2653, Val Loss: 0.5270
Epoch [57/250], Loss: 0.3240, Val Loss: 0.6114
Epoch [58/250], Loss: 0.2836, Val Loss: 0.5549
Epoch [59/250], Loss: 0.5141, Val Loss: 0.6655
Epoch [60/250], Loss: 0.6832, Val Loss: 0.5904
Epoch [61/250], Loss: 0.3119, Val Loss: 0.5756
Epoch [62/250], Loss: 0.4070, Val Loss: 0.5670
Epoch [63/250], Loss: 0.2414, Val Loss: 0.5831
Epoch [64/250], Loss: 0.2941, Val Loss: 0.6188
Epoch [65/250], Loss: 0.2323, Val Loss: 0.5750
Epoch [66/250], Loss: 0.3647, Val Loss: 0.5371
Epoch [67/250], Loss: 0.3137, Val Loss: 0.5389
Epoch [68/250], Loss: 0.7910, Val Loss: 0.6305
Epoch [69/250], Loss: 0.5663, Val Loss: 0.5483
Epoch [70/250], Loss: 0.1860, Val Loss: 0.5206
Epoch [71/250], Loss: 0.3792, Val Loss: 0.5506
Epoch [72/250], Loss: 0.3832, Val Loss: 0.5341
Epoch [73/250], Loss: 0.3222, Val Loss: 0.5500
Epoch [74/250], Loss: 0.5884, Val Loss: 0.5168
Epoch [75/250], Loss: 0.2707, Val Loss: 0.5456
Epoch [76/250], Loss: 0.5249, Val Loss: 0.5093
Epoch [77/250], Loss: 0.2029, Val Loss: 0.7637
Epoch [78/250], Loss: 0.1901, Val Loss: 0.5159
Epoch [79/250], Loss: 0.3162, Val Loss: 0.5472
Epoch [80/250], Loss: 0.2667, Val Loss: 0.5495
Epoch [81/250], Loss: 0.2982, Val Loss: 0.5632
Epoch [82/250], Loss: 1.0850, Val Loss: 0.5566
Epoch [83/250], Loss: 0.5890, Val Loss: 0.6240
Epoch [84/250], Loss: 0.2280, Val Loss: 0.4985
Epoch [85/250], Loss: 0.2236, Val Loss: 0.5807
Epoch [86/250], Loss: 0.3467, Val Loss: 0.5217
Epoch [87/250], Loss: 0.2009, Val Loss: 0.5594
Epoch [88/250], Loss: 0.2645, Val Loss: 0.5300
Epoch [89/250], Loss: 0.2468, Val Loss: 0.5274
Epoch [90/250], Loss: 0.2584, Val Loss: 0.6269
Epoch [91/250], Loss: 0.3589, Val Loss: 0.5527
Epoch [92/250], Loss: 0.4730, Val Loss: 0.5836
Epoch [93/250], Loss: 0.3002, Val Loss: 0.5631
Epoch [94/250], Loss: 0.2384, Val Loss: 0.5166
Epoch [95/250], Loss: 0.2362, Val Loss: 0.5079
Epoch [96/250], Loss: 0.2976, Val Loss: 0.5262
Epoch [97/250], Loss: 0.4057, Val Loss: 0.5274
Epoch [98/250], Loss: 0.2903, Val Loss: 0.5516
Epoch [99/250], Loss: 0.1833, Val Loss: 0.5056
Epoch [100/250], Loss: 0.3305, Val Loss: 0.6923
Epoch [101/250], Loss: 0.3247, Val Loss: 0.5346
Epoch [102/250], Loss: 0.2777, Val Loss: 0.5409
Epoch [103/250], Loss: 0.2098, Val Loss: 0.5019
Epoch [104/250], Loss: 0.3536, Val Loss: 0.5339
Epoch [105/250], Loss: 0.5658, Val Loss: 0.5389
Epoch [106/250], Loss: 0.3380, Val Loss: 0.5526
Epoch [107/250], Loss: 0.3023, Val Loss: 0.5479
Epoch [108/250], Loss: 0.2371, Val Loss: 0.5305
Epoch [109/250], Loss: 0.4459, Val Loss: 0.5971
Epoch [110/250], Loss: 0.3900, Val Loss: 0.5411
Epoch [111/250], Loss: 0.2667, Val Loss: 0.5916
Epoch [112/250], Loss: 0.2104, Val Loss: 0.5174
Epoch [113/250], Loss: 0.8244, Val Loss: 0.5386
Epoch [114/250], Loss: 0.1666, Val Loss: 0.4987
Epoch [115/250], Loss: 0.2745, Val Loss: 0.6949
Epoch [116/250], Loss: 0.1862, Val Loss: 0.5412
Epoch [117/250], Loss: 0.2144, Val Loss: 0.5741
Epoch [118/250], Loss: 0.3129, Val Loss: 0.5267
Epoch [119/250], Loss: 0.2040, Val Loss: 0.6567
Epoch [120/250], Loss: 0.4249, Val Loss: 0.5520
Epoch [121/250], Loss: 0.2975, Val Loss: 0.4923
Epoch [122/250], Loss: 0.2402, Val Loss: 0.5161
Epoch [123/250], Loss: 0.3846, Val Loss: 0.5235
Epoch [124/250], Loss: 0.2180, Val Loss: 0.5660
Epoch [125/250], Loss: 0.3489, Val Loss: 0.5047
Epoch [126/250], Loss: 0.4401, Val Loss: 0.5781
Epoch [127/250], Loss: 0.2076, Val Loss: 0.5066
Epoch [128/250], Loss: 0.4757, Val Loss: 0.5895
Epoch [129/250], Loss: 0.2626, Val Loss: 0.5497
Epoch [130/250], Loss: 0.3569, Val Loss: 0.5287
Epoch [131/250], Loss: 0.2129, Val Loss: 0.5242
Epoch [132/250], Loss: 0.1841, Val Loss: 0.4932
Epoch [133/250], Loss: 0.2059, Val Loss: 0.5609
Epoch [134/250], Loss: 0.2742, Val Loss: 0.5254
Epoch [135/250], Loss: 1.2281, Val Loss: 0.5241
Epoch [136/250], Loss: 0.7251, Val Loss: 0.4979
Epoch [137/250], Loss: 0.7867, Val Loss: 0.5316
Epoch [138/250], Loss: 0.3348, Val Loss: 0.5834
Epoch [139/250], Loss: 0.2965, Val Loss: 0.4956
Epoch [140/250], Loss: 0.1883, Val Loss: 0.5016
Epoch [141/250], Loss: 0.2512, Val Loss: 0.5505
Epoch [142/250], Loss: 0.2098, Val Loss: 0.5096
Epoch [143/250], Loss: 0.1816, Val Loss: 0.5253
Epoch [144/250], Loss: 0.1469, Val Loss: 0.5141
Epoch [145/250], Loss: 0.2977, Val Loss: 0.4785
Epoch [146/250], Loss: 0.3437, Val Loss: 0.5562
Epoch [147/250], Loss: 0.2560, Val Loss: 0.5534
Epoch [148/250], Loss: 0.2346, Val Loss: 0.4934
Epoch [149/250], Loss: 0.4567, Val Loss: 0.6050
Epoch [150/250], Loss: 0.2691, Val Loss: 0.5270
Epoch [151/250], Loss: 0.3477, Val Loss: 0.6637
Epoch [152/250], Loss: 0.2046, Val Loss: 0.5163
Epoch [153/250], Loss: 0.2058, Val Loss: 0.5004
Epoch [154/250], Loss: 0.2069, Val Loss: 0.4873
Epoch [155/250], Loss: 0.1998, Val Loss: 0.5025
Epoch [156/250], Loss: 0.1364, Val Loss: 0.4981
Epoch [157/250], Loss: 0.1874, Val Loss: 0.4922
Epoch [158/250], Loss: 0.2758, Val Loss: 0.5202
Epoch [159/250], Loss: 1.1402, Val Loss: 0.5575
Epoch [160/250], Loss: 0.2286, Val Loss: 0.5129
Epoch [161/250], Loss: 0.1934, Val Loss: 0.5024
Epoch [162/250], Loss: 0.3024, Val Loss: 0.5208
Epoch [163/250], Loss: 0.1373, Val Loss: 0.4956
Epoch [164/250], Loss: 0.1977, Val Loss: 0.5205
Epoch [165/250], Loss: 0.2797, Val Loss: 0.5325
Epoch [166/250], Loss: 0.1829, Val Loss: 0.4840
Epoch [167/250], Loss: 0.2231, Val Loss: 0.5017
Epoch [168/250], Loss: 0.9245, Val Loss: 0.5295
Epoch [169/250], Loss: 0.3645, Val Loss: 0.5059
Epoch [170/250], Loss: 0.2795, Val Loss: 0.4914
Epoch [171/250], Loss: 0.2965, Val Loss: 0.5232
Epoch [172/250], Loss: 0.2628, Val Loss: 0.5129
Epoch [173/250], Loss: 0.2075, Val Loss: 0.5275
Epoch [174/250], Loss: 0.3878, Val Loss: 0.5131
Epoch [175/250], Loss: 0.5166, Val Loss: 0.5379
Epoch [176/250], Loss: 0.3441, Val Loss: 0.6091
Epoch [177/250], Loss: 0.2637, Val Loss: 0.5320
Epoch [178/250], Loss: 0.2296, Val Loss: 0.5564
Epoch [179/250], Loss: 0.3020, Val Loss: 0.4862
Epoch [180/250], Loss: 0.1975, Val Loss: 0.5117
Epoch [181/250], Loss: 0.2762, Val Loss: 0.5338
Epoch [182/250], Loss: 0.6581, Val Loss: 0.5149
Epoch [183/250], Loss: 0.2404, Val Loss: 0.5123
Epoch [184/250], Loss: 0.2247, Val Loss: 0.5871
Epoch [185/250], Loss: 0.2606, Val Loss: 0.4885
Epoch [186/250], Loss: 0.2121, Val Loss: 0.4725
Epoch [187/250], Loss: 0.2253, Val Loss: 0.4790
Epoch [188/250], Loss: 0.2277, Val Loss: 0.5228
Epoch [189/250], Loss: 0.2266, Val Loss: 0.4928
Epoch [190/250], Loss: 0.2633, Val Loss: 0.5010
Epoch [191/250], Loss: 0.3071, Val Loss: 0.5731
Epoch [192/250], Loss: 0.2842, Val Loss: 0.5034
Epoch [193/250], Loss: 0.2376, Val Loss: 0.5221
Epoch [194/250], Loss: 0.2896, Val Loss: 0.5396
Epoch [195/250], Loss: 0.3933, Val Loss: 0.5631
Epoch [196/250], Loss: 0.2827, Val Loss: 0.4901
Epoch [197/250], Loss: 0.4842, Val Loss: 0.6700
Epoch [198/250], Loss: 0.2628, Val Loss: 0.5041
Epoch [199/250], Loss: 0.2455, Val Loss: 0.5339
Epoch [200/250], Loss: 0.1963, Val Loss: 0.4749
Epoch [201/250], Loss: 0.8002, Val Loss: 0.5310
Epoch [202/250], Loss: 0.1990, Val Loss: 0.6527
Epoch [203/250], Loss: 0.1658, Val Loss: 0.5049
Epoch [204/250], Loss: 0.2486, Val Loss: 0.4631
Epoch [205/250], Loss: 0.2553, Val Loss: 0.4918
Epoch [206/250], Loss: 0.1692, Val Loss: 0.4939
Epoch [207/250], Loss: 0.2434, Val Loss: 0.4972
Epoch [208/250], Loss: 0.2847, Val Loss: 0.5299
Epoch [209/250], Loss: 0.1827, Val Loss: 0.5365
Epoch [210/250], Loss: 0.2398, Val Loss: 0.5029
Epoch [211/250], Loss: 0.1939, Val Loss: 0.4979
Epoch [212/250], Loss: 0.2169, Val Loss: 0.4958
Epoch [213/250], Loss: 0.3158, Val Loss: 0.4923
Epoch [214/250], Loss: 0.1958, Val Loss: 0.7698
Epoch [215/250], Loss: 0.2526, Val Loss: 0.5303
Epoch [216/250], Loss: 0.2688, Val Loss: 0.5162
Epoch [217/250], Loss: 1.0191, Val Loss: 0.5439
Epoch [218/250], Loss: 0.2777, Val Loss: 0.5444
Epoch [219/250], Loss: 0.6188, Val Loss: 0.5255
Epoch [220/250], Loss: 0.4197, Val Loss: 0.6368
Epoch [221/250], Loss: 0.3239, Val Loss: 0.5033
Epoch [222/250], Loss: 0.2839, Val Loss: 0.5273
Epoch [223/250], Loss: 0.2679, Val Loss: 0.5104
Epoch [224/250], Loss: 0.3720, Val Loss: 0.5012
Epoch [225/250], Loss: 0.2594, Val Loss: 0.5409
Epoch [226/250], Loss: 0.2184, Val Loss: 0.5315
Epoch [227/250], Loss: 0.2730, Val Loss: 0.5449
Epoch [228/250], Loss: 0.2392, Val Loss: 0.5289
Epoch [229/250], Loss: 0.1546, Val Loss: 0.5095
Epoch [230/250], Loss: 0.1754, Val Loss: 0.4996
Epoch [231/250], Loss: 0.2035, Val Loss: 0.5097
Epoch [232/250], Loss: 0.1957, Val Loss: 0.4971
Epoch [233/250], Loss: 0.2261, Val Loss: 0.5485
Epoch [234/250], Loss: 0.1862, Val Loss: 0.4740
Epoch [235/250], Loss: 0.1732, Val Loss: 0.4910
Epoch [236/250], Loss: 0.4935, Val Loss: 0.5147
Epoch [237/250], Loss: 0.2864, Val Loss: 0.4867
Epoch [238/250], Loss: 0.3007, Val Loss: 0.4922
Epoch [239/250], Loss: 0.3181, Val Loss: 0.5091
Epoch [240/250], Loss: 0.2235, Val Loss: 0.5316
Epoch [241/250], Loss: 0.3371, Val Loss: 0.4922
Epoch [242/250], Loss: 0.4634, Val Loss: 0.8788
Epoch [243/250], Loss: 0.4513, Val Loss: 0.5001
Epoch [244/250], Loss: 0.3094, Val Loss: 0.5466
Epoch [245/250], Loss: 0.2701, Val Loss: 0.5996
Epoch [246/250], Loss: 0.2813, Val Loss: 0.5187
Epoch [247/250], Loss: 0.2264, Val Loss: 0.5042
Epoch [248/250], Loss: 0.2181, Val Loss: 0.4852
Epoch [249/250], Loss: 0.1839, Val Loss: 0.5026
Epoch [250/250], Loss: 0.2034, Val Loss: 0.4774
Runtime: 0:01:31.143226
R^2 Score: 0.9107
RMSE: 0.6765
MAE: 0.1850
MAPE: 14.47%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 0.6833, Val Loss: 0.9144
Epoch [2/250], Loss: 0.6502, Val Loss: 0.8552
Epoch [3/250], Loss: 1.0600, Val Loss: 0.8751
Epoch [4/250], Loss: 0.5743, Val Loss: 0.9726
Epoch [5/250], Loss: 0.2871, Val Loss: 0.7696
Epoch [6/250], Loss: 0.7811, Val Loss: 1.2585
Epoch [7/250], Loss: 0.8473, Val Loss: 0.7527
Epoch [8/250], Loss: 0.8313, Val Loss: 0.7261
Epoch [9/250], Loss: 0.6828, Val Loss: 0.7637
Epoch [10/250], Loss: 0.3704, Val Loss: 0.6792
Epoch [11/250], Loss: 0.7905, Val Loss: 0.7518
Epoch [12/250], Loss: 0.4954, Val Loss: 0.7369
Epoch [13/250], Loss: 0.9084, Val Loss: 0.9384
Epoch [14/250], Loss: 1.2650, Val Loss: 0.8313
Epoch [15/250], Loss: 1.2542, Val Loss: 0.6938
Epoch [16/250], Loss: 0.6009, Val Loss: 0.6393
Epoch [17/250], Loss: 0.5263, Val Loss: 0.7578
Epoch [18/250], Loss: 0.6625, Val Loss: 0.6303
Epoch [19/250], Loss: 0.8802, Val Loss: 0.7139
Epoch [20/250], Loss: 0.7003, Val Loss: 0.6443
Epoch [21/250], Loss: 0.6620, Val Loss: 0.6237
Epoch [22/250], Loss: 0.5776, Val Loss: 0.5538
Epoch [23/250], Loss: 0.4792, Val Loss: 0.6470
Epoch [24/250], Loss: 0.3739, Val Loss: 0.6114
Epoch [25/250], Loss: 0.6127, Val Loss: 0.6987
Epoch [26/250], Loss: 0.4545, Val Loss: 0.7043
Epoch [27/250], Loss: 0.2985, Val Loss: 0.5916
Epoch [28/250], Loss: 0.4658, Val Loss: 0.5907
Epoch [29/250], Loss: 1.6463, Val Loss: 0.7716
Epoch [30/250], Loss: 0.4415, Val Loss: 0.6382
Epoch [31/250], Loss: 0.2348, Val Loss: 0.5707
Epoch [32/250], Loss: 0.3931, Val Loss: 0.6183
Epoch [33/250], Loss: 0.5420, Val Loss: 0.5538
Epoch [34/250], Loss: 0.3186, Val Loss: 0.6558
Epoch [35/250], Loss: 0.5490, Val Loss: 0.5739
Epoch [36/250], Loss: 0.7213, Val Loss: 0.6260
Epoch [37/250], Loss: 0.5510, Val Loss: 0.6167
Epoch [38/250], Loss: 0.3100, Val Loss: 0.6352
Epoch [39/250], Loss: 0.9752, Val Loss: 0.8099
Epoch [40/250], Loss: 0.2996, Val Loss: 0.5794
Epoch [41/250], Loss: 0.3252, Val Loss: 0.5769
Epoch [42/250], Loss: 0.5202, Val Loss: 0.5838
Epoch [43/250], Loss: 0.3247, Val Loss: 0.5683
Epoch [44/250], Loss: 0.5417, Val Loss: 0.5584
Epoch [45/250], Loss: 0.3915, Val Loss: 0.5558
Epoch [46/250], Loss: 0.2188, Val Loss: 0.5898
Epoch [47/250], Loss: 0.4741, Val Loss: 0.5453
Epoch [48/250], Loss: 0.4418, Val Loss: 0.6045
Epoch [49/250], Loss: 1.5561, Val Loss: 0.7464
Epoch [50/250], Loss: 0.4929, Val Loss: 0.5907
Epoch [51/250], Loss: 0.1688, Val Loss: 0.5761
Epoch [52/250], Loss: 0.3758, Val Loss: 0.5481
Epoch [53/250], Loss: 0.2471, Val Loss: 0.5572
Epoch [54/250], Loss: 0.3190, Val Loss: 0.6508
Epoch [55/250], Loss: 0.3656, Val Loss: 0.6263
Epoch [56/250], Loss: 0.6689, Val Loss: 0.6127
Epoch [57/250], Loss: 0.2354, Val Loss: 0.6701
Epoch [58/250], Loss: 0.7083, Val Loss: 0.6071
Epoch [59/250], Loss: 0.3998, Val Loss: 0.5498
Epoch [60/250], Loss: 0.5490, Val Loss: 0.5706
Epoch [61/250], Loss: 0.3299, Val Loss: 0.5475
Epoch [62/250], Loss: 0.2592, Val Loss: 0.5995
Epoch [63/250], Loss: 0.5520, Val Loss: 0.6597
Epoch [64/250], Loss: 0.4106, Val Loss: 0.5639
Epoch [65/250], Loss: 0.2310, Val Loss: 0.5856
Epoch [66/250], Loss: 0.4814, Val Loss: 0.6696
Epoch [67/250], Loss: 0.4939, Val Loss: 0.5483
Epoch [68/250], Loss: 0.4199, Val Loss: 0.5451
Epoch [69/250], Loss: 0.4537, Val Loss: 0.5952
Epoch [70/250], Loss: 0.6354, Val Loss: 0.6204
Epoch [71/250], Loss: 0.3439, Val Loss: 0.5842
Epoch [72/250], Loss: 0.2249, Val Loss: 0.5426
Epoch [73/250], Loss: 0.2587, Val Loss: 0.5647
Epoch [74/250], Loss: 0.3530, Val Loss: 0.6040
Epoch [75/250], Loss: 0.3021, Val Loss: 0.5643
Epoch [76/250], Loss: 0.3386, Val Loss: 0.6595
Epoch [77/250], Loss: 0.5280, Val Loss: 0.6064
Epoch [78/250], Loss: 0.6037, Val Loss: 0.6616
Epoch [79/250], Loss: 0.4246, Val Loss: 0.6137
Epoch [80/250], Loss: 0.4791, Val Loss: 0.5652
Epoch [81/250], Loss: 0.2575, Val Loss: 0.5526
Epoch [82/250], Loss: 0.5613, Val Loss: 0.6060
Epoch [83/250], Loss: 0.3552, Val Loss: 0.5897
Epoch [84/250], Loss: 0.4526, Val Loss: 0.5349
Epoch [85/250], Loss: 0.4789, Val Loss: 0.6065
Epoch [86/250], Loss: 0.7785, Val Loss: 0.5668
Epoch [87/250], Loss: 0.2780, Val Loss: 0.5499
Epoch [88/250], Loss: 0.2997, Val Loss: 0.6023
Epoch [89/250], Loss: 0.3634, Val Loss: 0.6667
Epoch [90/250], Loss: 0.8361, Val Loss: 0.5715
Epoch [91/250], Loss: 0.2407, Val Loss: 0.6001
Epoch [92/250], Loss: 0.2951, Val Loss: 0.6457
Epoch [93/250], Loss: 0.2340, Val Loss: 0.5387
Epoch [94/250], Loss: 0.1980, Val Loss: 0.5870
Epoch [95/250], Loss: 0.2698, Val Loss: 0.5887
Epoch [96/250], Loss: 0.3613, Val Loss: 0.6075
Epoch [97/250], Loss: 0.3014, Val Loss: 0.6600
Epoch [98/250], Loss: 0.3563, Val Loss: 0.5738
Epoch [99/250], Loss: 0.2817, Val Loss: 0.5863
Epoch [100/250], Loss: 0.2813, Val Loss: 0.5612
Epoch [101/250], Loss: 0.2978, Val Loss: 0.6263
Epoch [102/250], Loss: 0.3233, Val Loss: 0.5939
Epoch [103/250], Loss: 0.3703, Val Loss: 0.5956
Epoch [104/250], Loss: 0.3637, Val Loss: 0.6983
Epoch [105/250], Loss: 0.3294, Val Loss: 0.6339
Epoch [106/250], Loss: 0.4393, Val Loss: 0.6464
Epoch [107/250], Loss: 0.4368, Val Loss: 0.6087
Epoch [108/250], Loss: 0.3254, Val Loss: 0.5597
Epoch [109/250], Loss: 0.2866, Val Loss: 0.5743
Epoch [110/250], Loss: 0.1985, Val Loss: 0.5908
Epoch [111/250], Loss: 0.4756, Val Loss: 0.6441
Epoch [112/250], Loss: 0.3609, Val Loss: 0.5723
Epoch [113/250], Loss: 0.4240, Val Loss: 0.7860
Epoch [114/250], Loss: 0.2809, Val Loss: 0.6308
Epoch [115/250], Loss: 0.5955, Val Loss: 0.6441
Epoch [116/250], Loss: 0.2790, Val Loss: 0.5732
Epoch [117/250], Loss: 0.6551, Val Loss: 0.5700
Epoch [118/250], Loss: 0.3648, Val Loss: 0.5682
Epoch [119/250], Loss: 0.4353, Val Loss: 0.5642
Epoch [120/250], Loss: 0.2660, Val Loss: 0.5943
Epoch [121/250], Loss: 0.2943, Val Loss: 0.5459
Epoch [122/250], Loss: 0.4527, Val Loss: 0.5809
Epoch [123/250], Loss: 0.2775, Val Loss: 0.5783
Epoch [124/250], Loss: 0.3952, Val Loss: 0.5832
Epoch [125/250], Loss: 0.2897, Val Loss: 0.5766
Epoch [126/250], Loss: 0.3888, Val Loss: 0.5969
Epoch [127/250], Loss: 0.2768, Val Loss: 0.5247
Epoch [128/250], Loss: 0.2311, Val Loss: 0.6311
Epoch [129/250], Loss: 0.4244, Val Loss: 0.5998
Epoch [130/250], Loss: 0.2932, Val Loss: 0.5579
Epoch [131/250], Loss: 0.2387, Val Loss: 0.5700
Epoch [132/250], Loss: 0.3077, Val Loss: 0.5690
Epoch [133/250], Loss: 1.3128, Val Loss: 0.6372
Epoch [134/250], Loss: 0.3566, Val Loss: 0.5624
Epoch [135/250], Loss: 0.3543, Val Loss: 0.5580
Epoch [136/250], Loss: 0.4889, Val Loss: 0.5475
Epoch [137/250], Loss: 0.1992, Val Loss: 0.5673
Epoch [138/250], Loss: 0.3114, Val Loss: 0.5844
Epoch [139/250], Loss: 0.3453, Val Loss: 0.5416
Epoch [140/250], Loss: 0.2360, Val Loss: 0.5676
Epoch [141/250], Loss: 1.1949, Val Loss: 0.5886
Epoch [142/250], Loss: 0.3654, Val Loss: 0.5435
Epoch [143/250], Loss: 0.2972, Val Loss: 0.5672
Epoch [144/250], Loss: 0.2982, Val Loss: 0.6250
Epoch [145/250], Loss: 0.4074, Val Loss: 0.6532
Epoch [146/250], Loss: 0.3904, Val Loss: 0.5238
Epoch [147/250], Loss: 0.2540, Val Loss: 0.5414
Epoch [148/250], Loss: 0.2909, Val Loss: 0.5479
Epoch [149/250], Loss: 0.2886, Val Loss: 0.5533
Epoch [150/250], Loss: 1.1136, Val Loss: 0.5443
Epoch [151/250], Loss: 0.3010, Val Loss: 0.5978
Epoch [152/250], Loss: 0.3892, Val Loss: 0.6514
Epoch [153/250], Loss: 0.2075, Val Loss: 0.5657
Epoch [154/250], Loss: 0.2952, Val Loss: 0.5902
Epoch [155/250], Loss: 0.4399, Val Loss: 0.5881
Epoch [156/250], Loss: 0.1806, Val Loss: 0.6146
Epoch [157/250], Loss: 0.3056, Val Loss: 0.5545
Epoch [158/250], Loss: 0.2218, Val Loss: 0.6195
Epoch [159/250], Loss: 0.2614, Val Loss: 0.5578
Epoch [160/250], Loss: 0.3718, Val Loss: 0.5408
Epoch [161/250], Loss: 0.5214, Val Loss: 0.5616
Epoch [162/250], Loss: 0.5778, Val Loss: 0.5082
Epoch [163/250], Loss: 0.3138, Val Loss: 0.6159
Epoch [164/250], Loss: 0.2225, Val Loss: 0.5463
Epoch [165/250], Loss: 0.4611, Val Loss: 0.5312
Epoch [166/250], Loss: 0.4328, Val Loss: 0.5444
Epoch [167/250], Loss: 1.5032, Val Loss: 0.6323
Epoch [168/250], Loss: 0.2453, Val Loss: 0.5796
Epoch [169/250], Loss: 0.3154, Val Loss: 0.5532
Epoch [170/250], Loss: 0.1778, Val Loss: 0.5786
Epoch [171/250], Loss: 0.3758, Val Loss: 0.5577
Epoch [172/250], Loss: 0.3786, Val Loss: 0.5561
Epoch [173/250], Loss: 0.3031, Val Loss: 0.5715
Epoch [174/250], Loss: 0.3240, Val Loss: 0.5265
Epoch [175/250], Loss: 0.1814, Val Loss: 0.5461
Epoch [176/250], Loss: 0.4012, Val Loss: 0.7331
Epoch [177/250], Loss: 0.4035, Val Loss: 0.5656
Epoch [178/250], Loss: 1.2734, Val Loss: 0.5141
Epoch [179/250], Loss: 0.3142, Val Loss: 0.5729
Epoch [180/250], Loss: 0.3539, Val Loss: 0.5742
Epoch [181/250], Loss: 0.3048, Val Loss: 0.5342
Epoch [182/250], Loss: 0.3181, Val Loss: 0.5457
Epoch [183/250], Loss: 0.1756, Val Loss: 0.5592
Epoch [184/250], Loss: 0.2904, Val Loss: 0.5468
Epoch [185/250], Loss: 0.3421, Val Loss: 0.5280
Epoch [186/250], Loss: 0.1832, Val Loss: 0.5286
Epoch [187/250], Loss: 0.2644, Val Loss: 0.5585
Epoch [188/250], Loss: 0.3233, Val Loss: 0.5652
Epoch [189/250], Loss: 0.2161, Val Loss: 0.5544
Epoch [190/250], Loss: 0.2074, Val Loss: 0.5822
Epoch [191/250], Loss: 0.2594, Val Loss: 0.5105
Epoch [192/250], Loss: 0.3426, Val Loss: 0.5877
Epoch [193/250], Loss: 0.3976, Val Loss: 0.5827
Epoch [194/250], Loss: 0.3023, Val Loss: 0.5610
Epoch [195/250], Loss: 0.3601, Val Loss: 0.5896
Epoch [196/250], Loss: 0.3299, Val Loss: 0.5646
Epoch [197/250], Loss: 0.2634, Val Loss: 0.5632
Epoch [198/250], Loss: 0.1970, Val Loss: 0.5450
Epoch [199/250], Loss: 0.3457, Val Loss: 0.5364
Epoch [200/250], Loss: 0.2347, Val Loss: 0.5283
Epoch [201/250], Loss: 0.2763, Val Loss: 0.5425
Epoch [202/250], Loss: 0.2750, Val Loss: 0.5229
Epoch [203/250], Loss: 0.3061, Val Loss: 0.5396
Epoch [204/250], Loss: 0.2361, Val Loss: 0.5914
Epoch [205/250], Loss: 0.1892, Val Loss: 0.5465
Epoch [206/250], Loss: 0.2619, Val Loss: 0.5897
Epoch [207/250], Loss: 0.1669, Val Loss: 0.5182
Epoch [208/250], Loss: 0.3210, Val Loss: 0.5914
Epoch [209/250], Loss: 0.3260, Val Loss: 0.5502
Epoch [210/250], Loss: 0.2564, Val Loss: 0.5564
Epoch [211/250], Loss: 0.2789, Val Loss: 0.5762
Epoch [212/250], Loss: 0.2883, Val Loss: 0.6371
Epoch [213/250], Loss: 0.2071, Val Loss: 0.5525
Epoch [214/250], Loss: 0.3156, Val Loss: 0.5575
Epoch [215/250], Loss: 0.2496, Val Loss: 0.7430
Epoch [216/250], Loss: 0.2995, Val Loss: 0.5472
Epoch [217/250], Loss: 0.2722, Val Loss: 0.5266
Epoch [218/250], Loss: 0.2176, Val Loss: 0.5602
Epoch [219/250], Loss: 0.3680, Val Loss: 0.5516
Epoch [220/250], Loss: 0.1882, Val Loss: 0.5155
Epoch [221/250], Loss: 0.3457, Val Loss: 0.5646
Epoch [222/250], Loss: 0.2758, Val Loss: 0.5532
Epoch [223/250], Loss: 0.2989, Val Loss: 0.5378
Epoch [224/250], Loss: 0.3614, Val Loss: 0.5442
Epoch [225/250], Loss: 0.2649, Val Loss: 0.6944
Epoch [226/250], Loss: 0.3783, Val Loss: 0.5638
Epoch [227/250], Loss: 0.1847, Val Loss: 0.5174
Epoch [228/250], Loss: 0.4595, Val Loss: 0.5742
Epoch [229/250], Loss: 0.3721, Val Loss: 0.5272
Epoch [230/250], Loss: 0.3038, Val Loss: 0.5496
Epoch [231/250], Loss: 0.3326, Val Loss: 0.5296
Epoch [232/250], Loss: 0.6114, Val Loss: 0.5183
Epoch [233/250], Loss: 0.2980, Val Loss: 0.5293
Epoch [234/250], Loss: 0.2190, Val Loss: 0.5363
Epoch [235/250], Loss: 0.2479, Val Loss: 0.5602
Epoch [236/250], Loss: 0.2807, Val Loss: 0.5485
Epoch [237/250], Loss: 0.7672, Val Loss: 0.5376
Epoch [238/250], Loss: 0.2242, Val Loss: 0.5861
Epoch [239/250], Loss: 0.2782, Val Loss: 0.5502
Epoch [240/250], Loss: 0.2571, Val Loss: 0.5175
Epoch [241/250], Loss: 0.3060, Val Loss: 0.5813
Epoch [242/250], Loss: 0.3279, Val Loss: 0.5076
Epoch [243/250], Loss: 0.3633, Val Loss: 0.5211
Epoch [244/250], Loss: 0.1970, Val Loss: 0.5184
Epoch [245/250], Loss: 0.3477, Val Loss: 0.5146
Epoch [246/250], Loss: 0.2119, Val Loss: 0.5381
Epoch [247/250], Loss: 0.1998, Val Loss: 0.5305
Epoch [248/250], Loss: 0.1930, Val Loss: 0.5788
Epoch [249/250], Loss: 0.2131, Val Loss: 0.6065
Epoch [250/250], Loss: 0.4783, Val Loss: 0.5532
Runtime: 0:01:27.628898
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [128, 512, 1024, 512, 128] - Result:
Epoch [1/250], Loss: 0.5644, Val Loss: 0.8500
Epoch [2/250], Loss: 0.7707, Val Loss: 1.1094
Epoch [3/250], Loss: 0.6280, Val Loss: 0.9002
Epoch [4/250], Loss: 0.5569, Val Loss: 0.8747
Epoch [5/250], Loss: 0.5998, Val Loss: 0.9661
Epoch [6/250], Loss: 0.7447, Val Loss: 0.7587
Epoch [7/250], Loss: 0.6742, Val Loss: 0.6584
Epoch [8/250], Loss: 0.6317, Val Loss: 0.6820
Epoch [9/250], Loss: 0.4789, Val Loss: 0.7233
Epoch [10/250], Loss: 0.5720, Val Loss: 0.6850
Epoch [11/250], Loss: 0.5820, Val Loss: 0.6899
Epoch [12/250], Loss: 1.0709, Val Loss: 0.8105
Epoch [13/250], Loss: 0.5125, Val Loss: 0.9668
Epoch [14/250], Loss: 0.4934, Val Loss: 0.6816
Epoch [15/250], Loss: 0.5367, Val Loss: 0.7622
Epoch [16/250], Loss: 0.6653, Val Loss: 0.8931
Epoch [17/250], Loss: 0.2917, Val Loss: 0.6274
Epoch [18/250], Loss: 0.5463, Val Loss: 0.6991
Epoch [19/250], Loss: 0.4196, Val Loss: 0.6141
Epoch [20/250], Loss: 0.9013, Val Loss: 0.6777
Epoch [21/250], Loss: 0.9757, Val Loss: 0.9705
Epoch [22/250], Loss: 0.3917, Val Loss: 0.6557
Epoch [23/250], Loss: 0.7224, Val Loss: 0.9318
Epoch [24/250], Loss: 0.5548, Val Loss: 0.6867
Epoch [25/250], Loss: 0.3959, Val Loss: 0.5952
Epoch [26/250], Loss: 0.2774, Val Loss: 0.6530
Epoch [27/250], Loss: 0.4062, Val Loss: 0.5911
Epoch [28/250], Loss: 0.4036, Val Loss: 0.5979
Epoch [29/250], Loss: 0.4277, Val Loss: 0.6491
Epoch [30/250], Loss: 0.5240, Val Loss: 0.6397
Epoch [31/250], Loss: 0.5909, Val Loss: 0.6986
Epoch [32/250], Loss: 0.7786, Val Loss: 0.6478
Epoch [33/250], Loss: 0.6035, Val Loss: 0.6080
Epoch [34/250], Loss: 0.6585, Val Loss: 0.6725
Epoch [35/250], Loss: 1.2940, Val Loss: 0.6511
Epoch [36/250], Loss: 0.5130, Val Loss: 0.6360
Epoch [37/250], Loss: 0.7462, Val Loss: 0.6499
Epoch [38/250], Loss: 0.3064, Val Loss: 0.5584
Epoch [39/250], Loss: 1.0408, Val Loss: 0.6814
Epoch [40/250], Loss: 0.5273, Val Loss: 0.5837
Epoch [41/250], Loss: 0.4216, Val Loss: 0.5828
Epoch [42/250], Loss: 0.4734, Val Loss: 0.5770
Epoch [43/250], Loss: 0.3494, Val Loss: 0.5731
Epoch [44/250], Loss: 0.2847, Val Loss: 0.5650
Epoch [45/250], Loss: 0.2453, Val Loss: 0.5191
Epoch [46/250], Loss: 0.5346, Val Loss: 0.7195
Epoch [47/250], Loss: 0.4903, Val Loss: 0.5865
Epoch [48/250], Loss: 0.4972, Val Loss: 0.6939
Epoch [49/250], Loss: 0.4900, Val Loss: 0.5869
Epoch [50/250], Loss: 0.6020, Val Loss: 0.7524
Epoch [51/250], Loss: 0.3679, Val Loss: 0.6710
Epoch [52/250], Loss: 0.3048, Val Loss: 0.7623
Epoch [53/250], Loss: 0.2604, Val Loss: 0.6489
Epoch [54/250], Loss: 0.4268, Val Loss: 0.7784
Epoch [55/250], Loss: 0.5516, Val Loss: 0.5613
Epoch [56/250], Loss: 0.2709, Val Loss: 0.5606
Epoch [57/250], Loss: 0.9632, Val Loss: 0.5341
Epoch [58/250], Loss: 0.2963, Val Loss: 0.5559
Epoch [59/250], Loss: 0.2717, Val Loss: 0.7736
Epoch [60/250], Loss: 0.4769, Val Loss: 0.5372
Epoch [61/250], Loss: 0.2759, Val Loss: 0.5688
Epoch [62/250], Loss: 0.3122, Val Loss: 0.5680
Epoch [63/250], Loss: 0.2985, Val Loss: 0.5512
Epoch [64/250], Loss: 0.1721, Val Loss: 0.5515
Epoch [65/250], Loss: 0.3445, Val Loss: 0.6035
Epoch [66/250], Loss: 0.4026, Val Loss: 0.5587
Epoch [67/250], Loss: 0.3836, Val Loss: 0.5597
Epoch [68/250], Loss: 0.2674, Val Loss: 0.8658
Epoch [69/250], Loss: 0.2866, Val Loss: 0.5614
Epoch [70/250], Loss: 0.5122, Val Loss: 0.5539
Epoch [71/250], Loss: 0.4503, Val Loss: 0.5433
Epoch [72/250], Loss: 0.2616, Val Loss: 0.5831
Epoch [73/250], Loss: 0.3310, Val Loss: 0.5621
Epoch [74/250], Loss: 0.7202, Val Loss: 0.5695
Epoch [75/250], Loss: 0.4001, Val Loss: 0.5503
Epoch [76/250], Loss: 0.4333, Val Loss: 0.5593
Epoch [77/250], Loss: 0.3400, Val Loss: 0.5351
Epoch [78/250], Loss: 0.3036, Val Loss: 0.5336
Epoch [79/250], Loss: 0.3352, Val Loss: 0.5740
Epoch [80/250], Loss: 0.3158, Val Loss: 0.6629
Epoch [81/250], Loss: 0.2320, Val Loss: 0.5726
Epoch [82/250], Loss: 0.4038, Val Loss: 0.5729
Epoch [83/250], Loss: 0.3989, Val Loss: 0.5334
Epoch [84/250], Loss: 0.2836, Val Loss: 0.5805
Epoch [85/250], Loss: 0.3747, Val Loss: 0.5374
Epoch [86/250], Loss: 0.2892, Val Loss: 0.5443
Epoch [87/250], Loss: 0.3990, Val Loss: 0.5745
Epoch [88/250], Loss: 0.2292, Val Loss: 0.6238
Epoch [89/250], Loss: 0.4476, Val Loss: 0.5284
Epoch [90/250], Loss: 0.3254, Val Loss: 0.5912
Epoch [91/250], Loss: 0.5063, Val Loss: 0.6416
Epoch [92/250], Loss: 0.4099, Val Loss: 0.5654
Epoch [93/250], Loss: 0.2647, Val Loss: 0.5251
Epoch [94/250], Loss: 0.3145, Val Loss: 0.5564
Epoch [95/250], Loss: 0.5005, Val Loss: 0.5707
Epoch [96/250], Loss: 0.2050, Val Loss: 0.6126
Epoch [97/250], Loss: 0.4737, Val Loss: 0.5283
Epoch [98/250], Loss: 0.3402, Val Loss: 0.5840
Epoch [99/250], Loss: 0.4516, Val Loss: 0.5384
Epoch [100/250], Loss: 0.3193, Val Loss: 0.5611
Epoch [101/250], Loss: 0.3529, Val Loss: 0.5600
Epoch [102/250], Loss: 0.4312, Val Loss: 0.5350
Epoch [103/250], Loss: 0.2530, Val Loss: 0.5342
Epoch [104/250], Loss: 0.6815, Val Loss: 0.5330
Epoch [105/250], Loss: 0.2346, Val Loss: 0.5427
Epoch [106/250], Loss: 0.1630, Val Loss: 0.5289
Epoch [107/250], Loss: 0.3192, Val Loss: 0.5701
Epoch [108/250], Loss: 0.4048, Val Loss: 0.5302
Epoch [109/250], Loss: 0.3917, Val Loss: 0.5595
Epoch [110/250], Loss: 0.5013, Val Loss: 0.6673
Epoch [111/250], Loss: 0.3820, Val Loss: 0.6027
Epoch [112/250], Loss: 0.2790, Val Loss: 0.5433
Epoch [113/250], Loss: 0.2569, Val Loss: 0.5404
Epoch [114/250], Loss: 0.4193, Val Loss: 0.5497
Epoch [115/250], Loss: 0.3391, Val Loss: 0.5327
Epoch [116/250], Loss: 0.2995, Val Loss: 0.5382
Epoch [117/250], Loss: 0.4579, Val Loss: 0.5594
Epoch [118/250], Loss: 0.3230, Val Loss: 0.6455
Epoch [119/250], Loss: 0.2253, Val Loss: 0.5506
Epoch [120/250], Loss: 0.3035, Val Loss: 0.5695
Epoch [121/250], Loss: 0.3398, Val Loss: 0.6743
Epoch [122/250], Loss: 0.2207, Val Loss: 0.5441
Epoch [123/250], Loss: 0.1604, Val Loss: 0.5295
Epoch [124/250], Loss: 0.2534, Val Loss: 0.6124
Epoch [125/250], Loss: 0.2883, Val Loss: 0.5149
Epoch [126/250], Loss: 0.7200, Val Loss: 0.6212
Epoch [127/250], Loss: 0.1626, Val Loss: 0.5393
Epoch [128/250], Loss: 0.6206, Val Loss: 0.5566
Epoch [129/250], Loss: 0.2174, Val Loss: 0.5610
Epoch [130/250], Loss: 0.2522, Val Loss: 0.5735
Epoch [131/250], Loss: 0.3181, Val Loss: 0.5586
Epoch [132/250], Loss: 0.4381, Val Loss: 0.5451
Epoch [133/250], Loss: 0.2461, Val Loss: 0.7198
Epoch [134/250], Loss: 0.2039, Val Loss: 0.5341
Epoch [135/250], Loss: 0.3142, Val Loss: 0.7537
Epoch [136/250], Loss: 0.2730, Val Loss: 0.5427
Epoch [137/250], Loss: 0.3527, Val Loss: 0.6490
Epoch [138/250], Loss: 0.4173, Val Loss: 0.5507
Epoch [139/250], Loss: 0.3118, Val Loss: 0.5410
Epoch [140/250], Loss: 0.2705, Val Loss: 0.5435
Epoch [141/250], Loss: 0.3267, Val Loss: 0.5433
Epoch [142/250], Loss: 0.3368, Val Loss: 0.5844
Epoch [143/250], Loss: 0.2493, Val Loss: 0.5383
Epoch [144/250], Loss: 0.2863, Val Loss: 0.5990
Epoch [145/250], Loss: 0.2148, Val Loss: 0.6042
Epoch [146/250], Loss: 0.4909, Val Loss: 0.5455
Epoch [147/250], Loss: 0.2834, Val Loss: 0.5592
Epoch [148/250], Loss: 0.2159, Val Loss: 0.5645
Epoch [149/250], Loss: 0.2192, Val Loss: 0.5569
Epoch [150/250], Loss: 0.3011, Val Loss: 0.5327
Epoch [151/250], Loss: 0.2221, Val Loss: 0.5392
Epoch [152/250], Loss: 0.7717, Val Loss: 0.6008
Epoch [153/250], Loss: 0.2891, Val Loss: 0.5334
Epoch [154/250], Loss: 0.2431, Val Loss: 0.5529
Epoch [155/250], Loss: 0.4137, Val Loss: 0.5805
Epoch [156/250], Loss: 0.2585, Val Loss: 0.6212
Epoch [157/250], Loss: 0.6876, Val Loss: 0.5452
Epoch [158/250], Loss: 0.2639, Val Loss: 0.5423
Epoch [159/250], Loss: 0.2672, Val Loss: 0.5515
Epoch [160/250], Loss: 0.2621, Val Loss: 0.5437
Epoch [161/250], Loss: 0.2514, Val Loss: 0.5188
Epoch [162/250], Loss: 0.3155, Val Loss: 0.5413
Epoch [163/250], Loss: 0.2681, Val Loss: 0.6038
Epoch [164/250], Loss: 0.3371, Val Loss: 0.5454
Epoch [165/250], Loss: 0.2634, Val Loss: 0.6026
Epoch [166/250], Loss: 0.2322, Val Loss: 0.5018
Epoch [167/250], Loss: 0.3349, Val Loss: 0.5286
Epoch [168/250], Loss: 0.1935, Val Loss: 0.5189
Epoch [169/250], Loss: 0.4981, Val Loss: 0.5655
Epoch [170/250], Loss: 0.3300, Val Loss: 0.5342
Epoch [171/250], Loss: 0.2709, Val Loss: 0.5800
Epoch [172/250], Loss: 0.1329, Val Loss: 0.6299
Epoch [173/250], Loss: 0.2940, Val Loss: 0.6734
Epoch [174/250], Loss: 0.2743, Val Loss: 0.5534
Epoch [175/250], Loss: 0.2248, Val Loss: 0.5339
Epoch [176/250], Loss: 0.2175, Val Loss: 0.5571
Epoch [177/250], Loss: 0.2654, Val Loss: 0.5246
Epoch [178/250], Loss: 0.1781, Val Loss: 0.5381
Epoch [179/250], Loss: 0.2868, Val Loss: 0.5210
Epoch [180/250], Loss: 0.3578, Val Loss: 0.5589
Epoch [181/250], Loss: 0.2137, Val Loss: 0.5331
Epoch [182/250], Loss: 0.3508, Val Loss: 0.5286
Epoch [183/250], Loss: 0.2670, Val Loss: 0.5328
Epoch [184/250], Loss: 0.1820, Val Loss: 0.5097
Epoch [185/250], Loss: 0.4225, Val Loss: 0.5559
Epoch [186/250], Loss: 0.4906, Val Loss: 0.5290
Epoch [187/250], Loss: 0.2282, Val Loss: 0.5534
Epoch [188/250], Loss: 0.2027, Val Loss: 0.6064
Epoch [189/250], Loss: 0.3038, Val Loss: 0.6526
Epoch [190/250], Loss: 0.5140, Val Loss: 0.6146
Epoch [191/250], Loss: 0.2500, Val Loss: 0.5476
Epoch [192/250], Loss: 0.3198, Val Loss: 0.5406
Epoch [193/250], Loss: 0.2763, Val Loss: 0.7113
Epoch [194/250], Loss: 0.2662, Val Loss: 0.5823
Epoch [195/250], Loss: 0.3107, Val Loss: 0.6474
Epoch [196/250], Loss: 0.2625, Val Loss: 0.6045
Epoch [197/250], Loss: 0.3270, Val Loss: 0.5447
Epoch [198/250], Loss: 0.4217, Val Loss: 0.5279
Epoch [199/250], Loss: 0.2773, Val Loss: 0.5400
Epoch [200/250], Loss: 0.6437, Val Loss: 0.6223
Epoch [201/250], Loss: 0.3601, Val Loss: 0.5636
Epoch [202/250], Loss: 0.4687, Val Loss: 0.5551
Epoch [203/250], Loss: 0.3549, Val Loss: 0.5599
Epoch [204/250], Loss: 0.2501, Val Loss: 0.5218
Epoch [205/250], Loss: 0.2573, Val Loss: 0.5223
Epoch [206/250], Loss: 0.2166, Val Loss: 0.5271
Epoch [207/250], Loss: 0.3496, Val Loss: 0.5524
Epoch [208/250], Loss: 0.2728, Val Loss: 0.5307
Epoch [209/250], Loss: 0.3852, Val Loss: 0.6440
Epoch [210/250], Loss: 0.1804, Val Loss: 0.5297
Epoch [211/250], Loss: 0.6836, Val Loss: 0.6146
Epoch [212/250], Loss: 0.5665, Val Loss: 0.5767
Epoch [213/250], Loss: 0.3939, Val Loss: 0.5651
Epoch [214/250], Loss: 0.2627, Val Loss: 0.5505
Epoch [215/250], Loss: 0.3041, Val Loss: 0.5354
Epoch [216/250], Loss: 0.3029, Val Loss: 0.5151
Epoch [217/250], Loss: 0.2829, Val Loss: 0.5087
Epoch [218/250], Loss: 0.2067, Val Loss: 0.5266
Epoch [219/250], Loss: 0.2430, Val Loss: 0.5340
Epoch [220/250], Loss: 0.3394, Val Loss: 0.5125
Epoch [221/250], Loss: 0.4414, Val Loss: 0.5042
Epoch [222/250], Loss: 0.3893, Val Loss: 0.7252
Epoch [223/250], Loss: 0.3581, Val Loss: 0.5420
Epoch [224/250], Loss: 0.7030, Val Loss: 0.5364
Epoch [225/250], Loss: 0.2655, Val Loss: 0.6258
Epoch [226/250], Loss: 0.3727, Val Loss: 0.5691
Epoch [227/250], Loss: 0.8396, Val Loss: 0.5414
Epoch [228/250], Loss: 0.3032, Val Loss: 0.6913
Epoch [229/250], Loss: 0.3902, Val Loss: 0.5792
Epoch [230/250], Loss: 0.2138, Val Loss: 0.5144
Epoch [231/250], Loss: 0.3019, Val Loss: 0.5938
Epoch [232/250], Loss: 0.3382, Val Loss: 0.6712
Epoch [233/250], Loss: 0.3506, Val Loss: 0.5109
Epoch [234/250], Loss: 0.2365, Val Loss: 0.5192
Epoch [235/250], Loss: 0.3608, Val Loss: 0.5741
Epoch [236/250], Loss: 0.3988, Val Loss: 0.4952
Epoch [237/250], Loss: 0.2287, Val Loss: 0.6553
Epoch [238/250], Loss: 0.1914, Val Loss: 0.5304
Epoch [239/250], Loss: 0.2779, Val Loss: 0.5861
Epoch [240/250], Loss: 0.2708, Val Loss: 0.5380
Epoch [241/250], Loss: 0.2384, Val Loss: 0.5187
Epoch [242/250], Loss: 0.2519, Val Loss: 0.5138
Epoch [243/250], Loss: 0.2550, Val Loss: 0.5443
Epoch [244/250], Loss: 0.2650, Val Loss: 0.5402
Epoch [245/250], Loss: 0.4524, Val Loss: 0.5222
Epoch [246/250], Loss: 0.2530, Val Loss: 0.5551
Epoch [247/250], Loss: 0.2314, Val Loss: 0.4972
Epoch [248/250], Loss: 0.2059, Val Loss: 0.5278
Epoch [249/250], Loss: 0.2342, Val Loss: 0.5102
Epoch [250/250], Loss: 0.2867, Val Loss: 0.6853
Runtime: 0:01:31.778212
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [128, 512, 1024, 512, 128] - Result:
Epoch [1/250], Loss: 0.9523, Val Loss: 1.1338
Epoch [2/250], Loss: 0.8017, Val Loss: 0.8554
Epoch [3/250], Loss: 0.6683, Val Loss: 0.8059
Epoch [4/250], Loss: 0.5620, Val Loss: 0.8788
Epoch [5/250], Loss: 0.7007, Val Loss: 0.8287
Epoch [6/250], Loss: 1.5859, Val Loss: 0.8081
Epoch [7/250], Loss: 0.9922, Val Loss: 0.8575
Epoch [8/250], Loss: 0.9020, Val Loss: 0.8405
Epoch [9/250], Loss: 0.5075, Val Loss: 0.7037
Epoch [10/250], Loss: 0.5192, Val Loss: 0.8045
Epoch [11/250], Loss: 0.6661, Val Loss: 0.7128
Epoch [12/250], Loss: 1.0233, Val Loss: 0.7219
Epoch [13/250], Loss: 0.4995, Val Loss: 0.6711
Epoch [14/250], Loss: 0.8926, Val Loss: 0.6520
Epoch [15/250], Loss: 0.5703, Val Loss: 0.6677
Epoch [16/250], Loss: 0.5125, Val Loss: 0.6696
Epoch [17/250], Loss: 0.5455, Val Loss: 0.7972
Epoch [18/250], Loss: 0.7129, Val Loss: 0.7952
Epoch [19/250], Loss: 0.2152, Val Loss: 0.7096
Epoch [20/250], Loss: 0.6594, Val Loss: 0.8095
Epoch [21/250], Loss: 0.6233, Val Loss: 0.5967
Epoch [22/250], Loss: 0.4277, Val Loss: 0.6403
Epoch [23/250], Loss: 0.8455, Val Loss: 0.7138
Epoch [24/250], Loss: 0.4937, Val Loss: 0.6077
Epoch [25/250], Loss: 0.2783, Val Loss: 0.6024
Epoch [26/250], Loss: 0.5438, Val Loss: 0.7195
Epoch [27/250], Loss: 0.9759, Val Loss: 0.5990
Epoch [28/250], Loss: 0.7475, Val Loss: 0.6404
Epoch [29/250], Loss: 0.3302, Val Loss: 0.6140
Epoch [30/250], Loss: 0.6799, Val Loss: 0.6561
Epoch [31/250], Loss: 0.4588, Val Loss: 0.7364
Epoch [32/250], Loss: 0.5695, Val Loss: 0.6774
Epoch [33/250], Loss: 0.4901, Val Loss: 0.6007
Epoch [34/250], Loss: 0.3830, Val Loss: 0.6599
Epoch [35/250], Loss: 0.3564, Val Loss: 0.5950
Epoch [36/250], Loss: 0.7277, Val Loss: 0.7590
Epoch [37/250], Loss: 0.3721, Val Loss: 0.6368
Epoch [38/250], Loss: 0.5296, Val Loss: 0.6492
Epoch [39/250], Loss: 0.4101, Val Loss: 0.6547
Epoch [40/250], Loss: 0.4142, Val Loss: 0.6192
Epoch [41/250], Loss: 0.5780, Val Loss: 0.7251
Epoch [42/250], Loss: 0.3433, Val Loss: 0.6820
Epoch [43/250], Loss: 0.5409, Val Loss: 0.6333
Epoch [44/250], Loss: 0.4638, Val Loss: 0.6412
Epoch [45/250], Loss: 0.6283, Val Loss: 0.6546
Epoch [46/250], Loss: 0.4086, Val Loss: 0.5567
Epoch [47/250], Loss: 0.6408, Val Loss: 0.5793
Epoch [48/250], Loss: 0.3123, Val Loss: 0.6730
Epoch [49/250], Loss: 0.3691, Val Loss: 0.6043
Epoch [50/250], Loss: 0.3745, Val Loss: 0.6853
Epoch [51/250], Loss: 0.3877, Val Loss: 0.6029
Epoch [52/250], Loss: 0.4743, Val Loss: 0.8803
Epoch [53/250], Loss: 0.4446, Val Loss: 0.6348
Epoch [54/250], Loss: 0.3275, Val Loss: 0.5647
Epoch [55/250], Loss: 0.3822, Val Loss: 0.6006
Epoch [56/250], Loss: 0.2611, Val Loss: 0.6089
Epoch [57/250], Loss: 0.3003, Val Loss: 0.6345
Epoch [58/250], Loss: 0.2717, Val Loss: 0.5773
Epoch [59/250], Loss: 0.3548, Val Loss: 0.5679
Epoch [60/250], Loss: 0.3506, Val Loss: 0.7687
Epoch [61/250], Loss: 0.3454, Val Loss: 0.6134
Epoch [62/250], Loss: 0.3931, Val Loss: 0.6393
Epoch [63/250], Loss: 0.5709, Val Loss: 0.6752
Epoch [64/250], Loss: 0.2629, Val Loss: 0.6176
Epoch [65/250], Loss: 0.4231, Val Loss: 0.6481
Epoch [66/250], Loss: 0.6452, Val Loss: 0.5836
Epoch [67/250], Loss: 0.5460, Val Loss: 0.6089
Epoch [68/250], Loss: 0.3806, Val Loss: 0.5908
Epoch [69/250], Loss: 0.3595, Val Loss: 0.6862
Epoch [70/250], Loss: 0.4930, Val Loss: 0.6031
Epoch [71/250], Loss: 0.3103, Val Loss: 0.6319
Epoch [72/250], Loss: 0.3214, Val Loss: 0.5968
Epoch [73/250], Loss: 0.4673, Val Loss: 0.5958
Epoch [74/250], Loss: 0.5047, Val Loss: 0.5728
Epoch [75/250], Loss: 0.3116, Val Loss: 0.5474
Epoch [76/250], Loss: 0.2897, Val Loss: 0.5776
Epoch [77/250], Loss: 0.9406, Val Loss: 0.6095
Epoch [78/250], Loss: 0.4015, Val Loss: 0.5939
Epoch [79/250], Loss: 0.8335, Val Loss: 0.6303
Epoch [80/250], Loss: 1.1288, Val Loss: 0.5688
Epoch [81/250], Loss: 0.3027, Val Loss: 0.5885
Epoch [82/250], Loss: 0.5575, Val Loss: 0.5898
Epoch [83/250], Loss: 0.4111, Val Loss: 0.5738
Epoch [84/250], Loss: 0.4879, Val Loss: 0.5806
Epoch [85/250], Loss: 0.2890, Val Loss: 0.5663
Epoch [86/250], Loss: 0.3592, Val Loss: 0.6346
Epoch [87/250], Loss: 0.5142, Val Loss: 0.5983
Epoch [88/250], Loss: 0.3735, Val Loss: 0.7083
Epoch [89/250], Loss: 0.4029, Val Loss: 0.5830
Epoch [90/250], Loss: 0.4122, Val Loss: 0.5606
Epoch [91/250], Loss: 0.5968, Val Loss: 0.6470
Epoch [92/250], Loss: 0.2851, Val Loss: 0.5782
Epoch [93/250], Loss: 0.4389, Val Loss: 0.5818
Epoch [94/250], Loss: 0.5513, Val Loss: 0.5510
Epoch [95/250], Loss: 0.2869, Val Loss: 0.5905
Epoch [96/250], Loss: 0.3513, Val Loss: 0.5796
Epoch [97/250], Loss: 0.4171, Val Loss: 0.5815
Epoch [98/250], Loss: 0.4019, Val Loss: 0.6282
Epoch [99/250], Loss: 0.5122, Val Loss: 0.5978
Epoch [100/250], Loss: 0.4124, Val Loss: 0.5845
Epoch [101/250], Loss: 0.2868, Val Loss: 0.5666
Epoch [102/250], Loss: 0.1891, Val Loss: 0.5658
Epoch [103/250], Loss: 0.3552, Val Loss: 0.6422
Epoch [104/250], Loss: 0.2613, Val Loss: 0.5963
Epoch [105/250], Loss: 0.2763, Val Loss: 0.5731
Epoch [106/250], Loss: 0.4899, Val Loss: 0.5557
Epoch [107/250], Loss: 0.2203, Val Loss: 0.5542
Epoch [108/250], Loss: 0.3874, Val Loss: 0.6205
Epoch [109/250], Loss: 0.4178, Val Loss: 0.6474
Epoch [110/250], Loss: 0.3213, Val Loss: 0.6841
Epoch [111/250], Loss: 0.4673, Val Loss: 0.5427
Epoch [112/250], Loss: 0.3901, Val Loss: 0.5652
Epoch [113/250], Loss: 0.2324, Val Loss: 0.5866
Epoch [114/250], Loss: 0.3622, Val Loss: 0.5719
Epoch [115/250], Loss: 0.2771, Val Loss: 0.5494
Epoch [116/250], Loss: 0.4262, Val Loss: 0.5478
Epoch [117/250], Loss: 0.4625, Val Loss: 0.5709
Epoch [118/250], Loss: 0.4096, Val Loss: 0.5865
Epoch [119/250], Loss: 0.2996, Val Loss: 0.6380
Epoch [120/250], Loss: 0.4121, Val Loss: 0.5949
Epoch [121/250], Loss: 1.1726, Val Loss: 0.5623
Epoch [122/250], Loss: 0.4442, Val Loss: 0.5761
Epoch [123/250], Loss: 0.5189, Val Loss: 0.5807
Epoch [124/250], Loss: 0.3713, Val Loss: 0.6014
Epoch [125/250], Loss: 0.5381, Val Loss: 0.5487
Epoch [126/250], Loss: 0.3233, Val Loss: 0.5770
Epoch [127/250], Loss: 0.6038, Val Loss: 0.5563
Epoch [128/250], Loss: 0.7407, Val Loss: 0.6045
Epoch [129/250], Loss: 0.4747, Val Loss: 0.5918
Epoch [130/250], Loss: 0.3743, Val Loss: 0.5690
Epoch [131/250], Loss: 0.6461, Val Loss: 0.5670
Epoch [132/250], Loss: 0.4342, Val Loss: 0.5751
Epoch [133/250], Loss: 0.4133, Val Loss: 0.6128
Epoch [134/250], Loss: 0.3597, Val Loss: 0.5966
Epoch [135/250], Loss: 0.5454, Val Loss: 0.6140
Epoch [136/250], Loss: 0.7638, Val Loss: 0.5822
Epoch [137/250], Loss: 0.3396, Val Loss: 0.5778
Epoch [138/250], Loss: 0.4370, Val Loss: 0.5776
Epoch [139/250], Loss: 1.1046, Val Loss: 0.5499
Epoch [140/250], Loss: 0.3802, Val Loss: 0.5808
Epoch [141/250], Loss: 0.3206, Val Loss: 0.5687
Epoch [142/250], Loss: 0.9663, Val Loss: 0.5714
Epoch [143/250], Loss: 0.3921, Val Loss: 0.6105
Epoch [144/250], Loss: 0.3415, Val Loss: 0.5281
Epoch [145/250], Loss: 0.2988, Val Loss: 0.5358
Epoch [146/250], Loss: 0.3662, Val Loss: 0.5694
Epoch [147/250], Loss: 0.2745, Val Loss: 0.5680
Epoch [148/250], Loss: 0.2675, Val Loss: 0.5588
Epoch [149/250], Loss: 0.4181, Val Loss: 0.5685
Epoch [150/250], Loss: 0.5946, Val Loss: 0.5563
Epoch [151/250], Loss: 0.3556, Val Loss: 0.5964
Epoch [152/250], Loss: 0.3266, Val Loss: 0.6301
Epoch [153/250], Loss: 0.3580, Val Loss: 0.5540
Epoch [154/250], Loss: 0.4661, Val Loss: 0.6105
Epoch [155/250], Loss: 0.5699, Val Loss: 0.5734
Epoch [156/250], Loss: 0.1912, Val Loss: 0.5345
Epoch [157/250], Loss: 0.3958, Val Loss: 0.5283
Epoch [158/250], Loss: 0.4481, Val Loss: 0.5498
Epoch [159/250], Loss: 0.3407, Val Loss: 0.5758
Epoch [160/250], Loss: 0.5261, Val Loss: 0.6043
Epoch [161/250], Loss: 0.3940, Val Loss: 0.5862
Epoch [162/250], Loss: 0.2577, Val Loss: 0.6358
Epoch [163/250], Loss: 0.3350, Val Loss: 0.5998
Epoch [164/250], Loss: 0.4102, Val Loss: 0.5738
Epoch [165/250], Loss: 0.4741, Val Loss: 0.5225
Epoch [166/250], Loss: 0.2501, Val Loss: 0.5306
Epoch [167/250], Loss: 0.2203, Val Loss: 0.6049
Epoch [168/250], Loss: 0.3247, Val Loss: 0.5530
Epoch [169/250], Loss: 0.3960, Val Loss: 0.5425
Epoch [170/250], Loss: 0.2377, Val Loss: 0.5701
Epoch [171/250], Loss: 0.3179, Val Loss: 0.5568
Epoch [172/250], Loss: 0.5244, Val Loss: 0.6492
Epoch [173/250], Loss: 0.3678, Val Loss: 0.5847
Epoch [174/250], Loss: 0.5526, Val Loss: 0.5531
Epoch [175/250], Loss: 0.8511, Val Loss: 0.6420
Epoch [176/250], Loss: 0.2470, Val Loss: 0.5483
Epoch [177/250], Loss: 0.6565, Val Loss: 0.5611
Epoch [178/250], Loss: 0.2231, Val Loss: 0.5505
Epoch [179/250], Loss: 0.3135, Val Loss: 0.5964
Epoch [180/250], Loss: 0.3990, Val Loss: 0.5442
Epoch [181/250], Loss: 0.3697, Val Loss: 0.5835
Epoch [182/250], Loss: 0.4824, Val Loss: 0.5607
Epoch [183/250], Loss: 0.3290, Val Loss: 0.5828
Epoch [184/250], Loss: 0.5640, Val Loss: 0.5265
Epoch [185/250], Loss: 0.3231, Val Loss: 0.5525
Epoch [186/250], Loss: 0.3060, Val Loss: 0.5723
Epoch [187/250], Loss: 0.5514, Val Loss: 0.5427
Epoch [188/250], Loss: 0.4431, Val Loss: 0.5464
Epoch [189/250], Loss: 0.5651, Val Loss: 0.5577
Epoch [190/250], Loss: 0.5930, Val Loss: 0.5975
Epoch [191/250], Loss: 0.4689, Val Loss: 0.6654
Epoch [192/250], Loss: 0.2599, Val Loss: 0.5485
Epoch [193/250], Loss: 0.3359, Val Loss: 0.6055
Epoch [194/250], Loss: 0.5640, Val Loss: 0.5944
Epoch [195/250], Loss: 0.3909, Val Loss: 0.6070
Epoch [196/250], Loss: 0.2629, Val Loss: 0.5946
Epoch [197/250], Loss: 0.3092, Val Loss: 0.5767
Epoch [198/250], Loss: 0.3637, Val Loss: 0.5620
Epoch [199/250], Loss: 0.3108, Val Loss: 0.5402
Epoch [200/250], Loss: 0.2082, Val Loss: 0.5671
Epoch [201/250], Loss: 0.2861, Val Loss: 0.6413
Epoch [202/250], Loss: 0.4845, Val Loss: 0.6213
Epoch [203/250], Loss: 0.5286, Val Loss: 0.5891
Epoch [204/250], Loss: 0.3318, Val Loss: 0.5874
Epoch [205/250], Loss: 0.3745, Val Loss: 0.7141
Epoch [206/250], Loss: 0.4487, Val Loss: 0.6119
Epoch [207/250], Loss: 0.2445, Val Loss: 0.5631
Epoch [208/250], Loss: 0.7419, Val Loss: 0.5620
Epoch [209/250], Loss: 0.4870, Val Loss: 0.5960
Epoch [210/250], Loss: 0.2957, Val Loss: 0.5794
Epoch [211/250], Loss: 0.4098, Val Loss: 0.5808
Epoch [212/250], Loss: 0.3796, Val Loss: 0.5705
Epoch [213/250], Loss: 0.2915, Val Loss: 0.5202
Epoch [214/250], Loss: 0.9148, Val Loss: 0.5393
Epoch [215/250], Loss: 0.2894, Val Loss: 0.6259
Epoch [216/250], Loss: 0.4588, Val Loss: 0.6257
Epoch [217/250], Loss: 0.4939, Val Loss: 0.8694
Epoch [218/250], Loss: 0.2763, Val Loss: 0.5295
Epoch [219/250], Loss: 0.3316, Val Loss: 0.5520
Epoch [220/250], Loss: 0.2774, Val Loss: 0.5659
Epoch [221/250], Loss: 0.4010, Val Loss: 0.5847
Epoch [222/250], Loss: 0.8252, Val Loss: 0.5786
Epoch [223/250], Loss: 0.4898, Val Loss: 0.5724
Epoch [224/250], Loss: 0.2705, Val Loss: 0.6114
Epoch [225/250], Loss: 0.2726, Val Loss: 0.6515
Epoch [226/250], Loss: 0.3398, Val Loss: 0.5418
Epoch [227/250], Loss: 0.1660, Val Loss: 0.5617
Epoch [228/250], Loss: 0.2821, Val Loss: 0.5742
Epoch [229/250], Loss: 0.4687, Val Loss: 0.5984
Epoch [230/250], Loss: 0.3959, Val Loss: 0.5855
Epoch [231/250], Loss: 0.2784, Val Loss: 0.6299
Epoch [232/250], Loss: 0.6060, Val Loss: 0.5954
Epoch [233/250], Loss: 0.4453, Val Loss: 0.5996
Epoch [234/250], Loss: 0.3347, Val Loss: 0.5697
Epoch [235/250], Loss: 0.2970, Val Loss: 0.5566
Epoch [236/250], Loss: 0.4328, Val Loss: 0.5518
Epoch [237/250], Loss: 0.3942, Val Loss: 0.5120
Epoch [238/250], Loss: 0.3347, Val Loss: 0.5814
Epoch [239/250], Loss: 0.4592, Val Loss: 0.6011
Epoch [240/250], Loss: 0.1915, Val Loss: 0.5463
Epoch [241/250], Loss: 0.4254, Val Loss: 0.5738
Epoch [242/250], Loss: 0.4862, Val Loss: 0.5167
Epoch [243/250], Loss: 0.4528, Val Loss: 0.6067
Epoch [244/250], Loss: 0.3062, Val Loss: 0.6359
Epoch [245/250], Loss: 0.5441, Val Loss: 0.5203
Epoch [246/250], Loss: 0.3938, Val Loss: 0.5730
Epoch [247/250], Loss: 0.5048, Val Loss: 0.6732
Epoch [248/250], Loss: 0.4165, Val Loss: 0.5472
Epoch [249/250], Loss: 0.3551, Val Loss: 0.5412
Epoch [250/250], Loss: 0.3274, Val Loss: 0.5364
Runtime: 0:01:31.285703
R^2 Score: 0.8907
RMSE: 0.7486
MAE: 0.2190
MAPE: 19.62%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 0.9500, Val Loss: 0.8790
Epoch [2/250], Loss: 1.0557, Val Loss: 0.8592
Epoch [3/250], Loss: 0.4454, Val Loss: 0.8375
Epoch [4/250], Loss: 0.3879, Val Loss: 0.7726
Epoch [5/250], Loss: 0.7616, Val Loss: 1.2590
Epoch [6/250], Loss: 0.9734, Val Loss: 0.7310
Epoch [7/250], Loss: 0.5470, Val Loss: 0.7144
Epoch [8/250], Loss: 0.4605, Val Loss: 0.7328
Epoch [9/250], Loss: 0.7657, Val Loss: 0.8400
Epoch [10/250], Loss: 0.4539, Val Loss: 0.9280
Epoch [11/250], Loss: 0.8503, Val Loss: 0.6844
Epoch [12/250], Loss: 0.5495, Val Loss: 0.6820
Epoch [13/250], Loss: 0.6401, Val Loss: 1.7683
Epoch [14/250], Loss: 0.4728, Val Loss: 0.6885
Epoch [15/250], Loss: 0.4004, Val Loss: 0.6325
Epoch [16/250], Loss: 1.2983, Val Loss: 0.6673
Epoch [17/250], Loss: 0.3542, Val Loss: 0.6536
Epoch [18/250], Loss: 0.3690, Val Loss: 0.6128
Epoch [19/250], Loss: 0.3021, Val Loss: 0.6276
Epoch [20/250], Loss: 0.4609, Val Loss: 0.6192
Epoch [21/250], Loss: 0.3929, Val Loss: 0.6516
Epoch [22/250], Loss: 0.5069, Val Loss: 0.5800
Epoch [23/250], Loss: 0.6474, Val Loss: 0.6104
Epoch [24/250], Loss: 0.3181, Val Loss: 0.6538
Epoch [25/250], Loss: 0.4058, Val Loss: 0.7067
Epoch [26/250], Loss: 0.3303, Val Loss: 0.5793
Epoch [27/250], Loss: 0.4848, Val Loss: 0.5925
Epoch [28/250], Loss: 0.3269, Val Loss: 0.5720
Epoch [29/250], Loss: 0.2499, Val Loss: 0.5482
Epoch [30/250], Loss: 1.6883, Val Loss: 0.6207
Epoch [31/250], Loss: 0.3966, Val Loss: 0.5663
Epoch [32/250], Loss: 0.5378, Val Loss: 0.5995
Epoch [33/250], Loss: 0.5066, Val Loss: 0.6085
Epoch [34/250], Loss: 1.0940, Val Loss: 0.6362
Epoch [35/250], Loss: 0.1991, Val Loss: 0.6028
Epoch [36/250], Loss: 0.4493, Val Loss: 0.6724
Epoch [37/250], Loss: 0.2796, Val Loss: 0.6293
Epoch [38/250], Loss: 0.5707, Val Loss: 0.6393
Epoch [39/250], Loss: 0.4189, Val Loss: 0.6280
Epoch [40/250], Loss: 0.4338, Val Loss: 0.5472
Epoch [41/250], Loss: 0.4027, Val Loss: 0.6660
Epoch [42/250], Loss: 0.3903, Val Loss: 0.5266
Epoch [43/250], Loss: 0.2963, Val Loss: 0.5558
Epoch [44/250], Loss: 0.2339, Val Loss: 0.5530
Epoch [45/250], Loss: 0.3896, Val Loss: 0.5784
Epoch [46/250], Loss: 0.2629, Val Loss: 0.5587
Epoch [47/250], Loss: 0.3449, Val Loss: 0.6095
Epoch [48/250], Loss: 0.2770, Val Loss: 0.5783
Epoch [49/250], Loss: 0.4427, Val Loss: 0.5752
Epoch [50/250], Loss: 0.2441, Val Loss: 0.5947
Epoch [51/250], Loss: 0.2717, Val Loss: 0.5217
Epoch [52/250], Loss: 0.4350, Val Loss: 0.5664
Epoch [53/250], Loss: 0.1548, Val Loss: 0.5419
Epoch [54/250], Loss: 0.3149, Val Loss: 0.5950
Epoch [55/250], Loss: 0.2525, Val Loss: 0.5997
Epoch [56/250], Loss: 0.3148, Val Loss: 0.5843
Epoch [57/250], Loss: 0.2729, Val Loss: 0.5504
Epoch [58/250], Loss: 0.5919, Val Loss: 0.6676
Epoch [59/250], Loss: 0.2564, Val Loss: 0.5839
Epoch [60/250], Loss: 0.4290, Val Loss: 0.5916
Epoch [61/250], Loss: 0.3372, Val Loss: 0.6358
Epoch [62/250], Loss: 0.2796, Val Loss: 0.5424
Epoch [63/250], Loss: 0.3003, Val Loss: 0.5838
Epoch [64/250], Loss: 0.4665, Val Loss: 0.5721
Epoch [65/250], Loss: 0.3128, Val Loss: 0.5423
Epoch [66/250], Loss: 0.3560, Val Loss: 0.5612
Epoch [67/250], Loss: 0.2073, Val Loss: 0.5146
Epoch [68/250], Loss: 0.2654, Val Loss: 0.5599
Epoch [69/250], Loss: 0.1733, Val Loss: 0.5696
Epoch [70/250], Loss: 0.1650, Val Loss: 0.5558
Epoch [71/250], Loss: 0.2918, Val Loss: 0.5416
Epoch [72/250], Loss: 0.2722, Val Loss: 0.5597
Epoch [73/250], Loss: 0.9410, Val Loss: 0.6607
Epoch [74/250], Loss: 0.1897, Val Loss: 0.7045
Epoch [75/250], Loss: 0.3218, Val Loss: 0.5626
Epoch [76/250], Loss: 0.1895, Val Loss: 0.5361
Epoch [77/250], Loss: 0.2010, Val Loss: 0.5335
Epoch [78/250], Loss: 0.3319, Val Loss: 0.5511
Epoch [79/250], Loss: 0.4860, Val Loss: 0.5862
Epoch [80/250], Loss: 0.3501, Val Loss: 0.5183
Epoch [81/250], Loss: 0.2263, Val Loss: 0.5197
Epoch [82/250], Loss: 0.2908, Val Loss: 0.5175
Epoch [83/250], Loss: 0.2158, Val Loss: 0.6652
Epoch [84/250], Loss: 0.2337, Val Loss: 0.5380
Epoch [85/250], Loss: 0.2059, Val Loss: 0.5622
Epoch [86/250], Loss: 0.2394, Val Loss: 0.5244
Epoch [87/250], Loss: 0.3545, Val Loss: 0.5847
Epoch [88/250], Loss: 0.2138, Val Loss: 0.5201
Epoch [89/250], Loss: 0.7669, Val Loss: 0.6051
Epoch [90/250], Loss: 0.3496, Val Loss: 0.5979
Epoch [91/250], Loss: 0.2454, Val Loss: 0.5780
Epoch [92/250], Loss: 0.4613, Val Loss: 0.6831
Epoch [93/250], Loss: 0.2443, Val Loss: 0.5156
Epoch [94/250], Loss: 0.3893, Val Loss: 0.5992
Epoch [95/250], Loss: 0.1802, Val Loss: 0.4955
Epoch [96/250], Loss: 0.2668, Val Loss: 0.5505
Epoch [97/250], Loss: 0.4984, Val Loss: 0.5876
Epoch [98/250], Loss: 0.7561, Val Loss: 0.5328
Epoch [99/250], Loss: 0.2212, Val Loss: 0.5004
Epoch [100/250], Loss: 0.3151, Val Loss: 0.4924
Epoch [101/250], Loss: 0.2226, Val Loss: 0.4877
Epoch [102/250], Loss: 0.3513, Val Loss: 0.5222
Epoch [103/250], Loss: 0.1872, Val Loss: 0.5197
Epoch [104/250], Loss: 0.2933, Val Loss: 0.5381
Epoch [105/250], Loss: 0.2363, Val Loss: 0.5025
Epoch [106/250], Loss: 0.3099, Val Loss: 0.5126
Epoch [107/250], Loss: 0.2477, Val Loss: 0.5623
Epoch [108/250], Loss: 0.2106, Val Loss: 0.4920
Epoch [109/250], Loss: 0.2603, Val Loss: 0.6257
Epoch [110/250], Loss: 0.1693, Val Loss: 0.5930
Epoch [111/250], Loss: 0.1869, Val Loss: 0.4768
Epoch [112/250], Loss: 0.4999, Val Loss: 0.4986
Epoch [113/250], Loss: 0.2969, Val Loss: 0.5060
Epoch [114/250], Loss: 0.2216, Val Loss: 0.5475
Epoch [115/250], Loss: 0.2980, Val Loss: 0.5242
Epoch [116/250], Loss: 0.3101, Val Loss: 0.4928
Epoch [117/250], Loss: 0.2549, Val Loss: 0.5302
Epoch [118/250], Loss: 0.4466, Val Loss: 0.6365
Epoch [119/250], Loss: 0.8181, Val Loss: 0.4983
Epoch [120/250], Loss: 0.1870, Val Loss: 0.5720
Epoch [121/250], Loss: 0.1570, Val Loss: 0.4956
Epoch [122/250], Loss: 0.2343, Val Loss: 0.5323
Epoch [123/250], Loss: 0.2289, Val Loss: 0.5379
Epoch [124/250], Loss: 0.2217, Val Loss: 0.5032
Epoch [125/250], Loss: 0.1759, Val Loss: 0.5154
Epoch [126/250], Loss: 0.2411, Val Loss: 0.5151
Epoch [127/250], Loss: 0.1901, Val Loss: 0.5535
Epoch [128/250], Loss: 0.2108, Val Loss: 0.6304
Epoch [129/250], Loss: 0.3228, Val Loss: 0.5677
Epoch [130/250], Loss: 0.3395, Val Loss: 0.5282
Epoch [131/250], Loss: 0.2692, Val Loss: 0.5232
Epoch [132/250], Loss: 0.2504, Val Loss: 0.5729
Epoch [133/250], Loss: 0.1981, Val Loss: 0.5330
Epoch [134/250], Loss: 0.3124, Val Loss: 0.5046
Epoch [135/250], Loss: 0.3237, Val Loss: 0.5134
Epoch [136/250], Loss: 0.3389, Val Loss: 0.4891
Epoch [137/250], Loss: 0.5204, Val Loss: 0.5039
Epoch [138/250], Loss: 0.1533, Val Loss: 0.4799
Epoch [139/250], Loss: 0.3589, Val Loss: 0.5528
Epoch [140/250], Loss: 1.4645, Val Loss: 0.5240
Epoch [141/250], Loss: 0.2852, Val Loss: 0.4955
Epoch [142/250], Loss: 0.1958, Val Loss: 0.5026
Epoch [143/250], Loss: 0.2293, Val Loss: 0.4947
Epoch [144/250], Loss: 0.2882, Val Loss: 0.5091
Epoch [145/250], Loss: 0.3751, Val Loss: 0.5174
Epoch [146/250], Loss: 0.2808, Val Loss: 0.5966
Epoch [147/250], Loss: 0.1978, Val Loss: 0.5097
Epoch [148/250], Loss: 0.2921, Val Loss: 0.5544
Epoch [149/250], Loss: 0.3485, Val Loss: 0.6428
Epoch [150/250], Loss: 0.2130, Val Loss: 0.5167
Epoch [151/250], Loss: 0.2453, Val Loss: 0.5108
Epoch [152/250], Loss: 0.1028, Val Loss: 0.4931
Epoch [153/250], Loss: 0.2599, Val Loss: 0.5588
Epoch [154/250], Loss: 0.2975, Val Loss: 0.5054
Epoch [155/250], Loss: 0.2754, Val Loss: 0.5217
Epoch [156/250], Loss: 0.2564, Val Loss: 0.5411
Epoch [157/250], Loss: 0.3177, Val Loss: 0.5166
Epoch [158/250], Loss: 0.2002, Val Loss: 0.6208
Epoch [159/250], Loss: 0.1688, Val Loss: 0.5291
Epoch [160/250], Loss: 0.1970, Val Loss: 0.5009
Epoch [161/250], Loss: 0.1959, Val Loss: 0.5014
Epoch [162/250], Loss: 0.2078, Val Loss: 0.5125
Epoch [163/250], Loss: 0.2405, Val Loss: 0.5380
Epoch [164/250], Loss: 0.4170, Val Loss: 0.5148
Epoch [165/250], Loss: 0.1600, Val Loss: 0.5326
Epoch [166/250], Loss: 0.2649, Val Loss: 0.5390
Epoch [167/250], Loss: 0.3297, Val Loss: 0.5834
Epoch [168/250], Loss: 0.3841, Val Loss: 0.4887
Epoch [169/250], Loss: 0.3207, Val Loss: 0.5007
Epoch [170/250], Loss: 0.2916, Val Loss: 0.5294
Epoch [171/250], Loss: 0.2250, Val Loss: 0.5787
Epoch [172/250], Loss: 0.4765, Val Loss: 0.4987
Epoch [173/250], Loss: 0.2283, Val Loss: 0.6004
Epoch [174/250], Loss: 0.3167, Val Loss: 0.6673
Epoch [175/250], Loss: 0.2369, Val Loss: 0.5099
Epoch [176/250], Loss: 0.1418, Val Loss: 0.5132
Epoch [177/250], Loss: 0.2072, Val Loss: 0.6107
Epoch [178/250], Loss: 0.2292, Val Loss: 0.5167
Epoch [179/250], Loss: 0.2104, Val Loss: 0.5362
Epoch [180/250], Loss: 0.3851, Val Loss: 0.5621
Epoch [181/250], Loss: 0.3053, Val Loss: 0.5175
Epoch [182/250], Loss: 0.1830, Val Loss: 0.5222
Epoch [183/250], Loss: 0.1686, Val Loss: 0.5841
Epoch [184/250], Loss: 0.3103, Val Loss: 0.5168
Epoch [185/250], Loss: 0.3876, Val Loss: 0.5464
Epoch [186/250], Loss: 0.1761, Val Loss: 0.5261
Epoch [187/250], Loss: 0.4865, Val Loss: 0.6451
Epoch [188/250], Loss: 0.4186, Val Loss: 0.6390
Epoch [189/250], Loss: 0.2129, Val Loss: 0.5793
Epoch [190/250], Loss: 0.1804, Val Loss: 0.5619
Epoch [191/250], Loss: 0.2150, Val Loss: 0.5325
Epoch [192/250], Loss: 0.2200, Val Loss: 0.5246
Epoch [193/250], Loss: 0.1546, Val Loss: 0.5169
Epoch [194/250], Loss: 0.3196, Val Loss: 0.5527
Epoch [195/250], Loss: 0.1604, Val Loss: 0.5100
Epoch [196/250], Loss: 0.1793, Val Loss: 0.4969
Epoch [197/250], Loss: 0.2448, Val Loss: 0.5029
Epoch [198/250], Loss: 0.1453, Val Loss: 0.6042
Epoch [199/250], Loss: 0.2194, Val Loss: 0.5180
Epoch [200/250], Loss: 0.2003, Val Loss: 0.5195
Epoch [201/250], Loss: 0.2972, Val Loss: 0.4991
Epoch [202/250], Loss: 0.3216, Val Loss: 0.5283
Epoch [203/250], Loss: 0.2653, Val Loss: 0.5361
Epoch [204/250], Loss: 0.1647, Val Loss: 0.5145
Epoch [205/250], Loss: 0.2164, Val Loss: 0.5797
Epoch [206/250], Loss: 0.2736, Val Loss: 0.5203
Epoch [207/250], Loss: 0.2810, Val Loss: 0.5112
Epoch [208/250], Loss: 0.2679, Val Loss: 0.5402
Epoch [209/250], Loss: 0.1516, Val Loss: 0.5514
Epoch [210/250], Loss: 0.4706, Val Loss: 0.4950
Epoch [211/250], Loss: 0.2254, Val Loss: 0.5203
Epoch [212/250], Loss: 0.2367, Val Loss: 0.5196
Epoch [213/250], Loss: 0.1537, Val Loss: 0.5522
Epoch [214/250], Loss: 0.2048, Val Loss: 0.5065
Epoch [215/250], Loss: 0.2531, Val Loss: 0.5004
Epoch [216/250], Loss: 0.2177, Val Loss: 0.5247
Epoch [217/250], Loss: 0.2250, Val Loss: 0.5095
Epoch [218/250], Loss: 0.2749, Val Loss: 0.5676
Epoch [219/250], Loss: 0.1720, Val Loss: 0.6354
Epoch [220/250], Loss: 0.3369, Val Loss: 0.5282
Epoch [221/250], Loss: 0.2630, Val Loss: 0.5358
Epoch [222/250], Loss: 0.4385, Val Loss: 0.5618
Epoch [223/250], Loss: 0.2908, Val Loss: 0.5671
Epoch [224/250], Loss: 0.5396, Val Loss: 0.5703
Epoch [225/250], Loss: 0.2224, Val Loss: 0.5336
Epoch [226/250], Loss: 0.1447, Val Loss: 0.5115
Epoch [227/250], Loss: 0.2383, Val Loss: 0.5764
Epoch [228/250], Loss: 0.2114, Val Loss: 0.5422
Epoch [229/250], Loss: 0.1391, Val Loss: 0.4912
Epoch [230/250], Loss: 0.1823, Val Loss: 0.5091
Epoch [231/250], Loss: 0.2688, Val Loss: 0.5136
Epoch [232/250], Loss: 0.3031, Val Loss: 0.5210
Epoch [233/250], Loss: 0.2485, Val Loss: 0.5372
Epoch [234/250], Loss: 0.2946, Val Loss: 0.5110
Epoch [235/250], Loss: 0.1853, Val Loss: 0.5303
Epoch [236/250], Loss: 0.1975, Val Loss: 0.5435
Epoch [237/250], Loss: 0.2951, Val Loss: 0.5074
Early stopping at epoch 237
Runtime: 0:01:31.411828
R^2 Score: 0.9112
RMSE: 0.6747
MAE: 0.1733
MAPE: 13.56%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [128, 512, 1024, 512, 128] - Result:
Epoch [1/250], Loss: 0.8144, Val Loss: 0.9464
Epoch [2/250], Loss: 0.9262, Val Loss: 1.0649
Epoch [3/250], Loss: 0.6504, Val Loss: 1.0647
Epoch [4/250], Loss: 0.4401, Val Loss: 0.6894
Epoch [5/250], Loss: 0.5016, Val Loss: 0.7607
Epoch [6/250], Loss: 0.3929, Val Loss: 0.7396
Epoch [7/250], Loss: 0.5666, Val Loss: 0.7538
Epoch [8/250], Loss: 0.5459, Val Loss: 0.6920
Epoch [9/250], Loss: 0.4992, Val Loss: 0.6985
Epoch [10/250], Loss: 0.7143, Val Loss: 0.8020
Epoch [11/250], Loss: 1.1427, Val Loss: 0.6573
Epoch [12/250], Loss: 0.6812, Val Loss: 0.6822
Epoch [13/250], Loss: 0.4668, Val Loss: 0.6290
Epoch [14/250], Loss: 0.6031, Val Loss: 0.7667
Epoch [15/250], Loss: 0.5408, Val Loss: 0.6598
Epoch [16/250], Loss: 0.5470, Val Loss: 0.7296
Epoch [17/250], Loss: 0.5313, Val Loss: 0.5599
Epoch [18/250], Loss: 0.8202, Val Loss: 0.6390
Epoch [19/250], Loss: 0.4529, Val Loss: 0.5913
Epoch [20/250], Loss: 0.3921, Val Loss: 0.8532
Epoch [21/250], Loss: 0.2859, Val Loss: 0.6431
Epoch [22/250], Loss: 0.3911, Val Loss: 0.5944
Epoch [23/250], Loss: 0.3487, Val Loss: 0.6353
Epoch [24/250], Loss: 0.3209, Val Loss: 0.6386
Epoch [25/250], Loss: 0.3551, Val Loss: 0.6152
Epoch [26/250], Loss: 0.2937, Val Loss: 0.5667
Epoch [27/250], Loss: 0.2858, Val Loss: 0.6792
Epoch [28/250], Loss: 0.4299, Val Loss: 0.5711
Epoch [29/250], Loss: 0.2620, Val Loss: 0.5830
Epoch [30/250], Loss: 0.6473, Val Loss: 0.6190
Epoch [31/250], Loss: 0.4227, Val Loss: 0.6769
Epoch [32/250], Loss: 0.5294, Val Loss: 0.5570
Epoch [33/250], Loss: 0.4032, Val Loss: 0.6590
Epoch [34/250], Loss: 0.3560, Val Loss: 0.5385
Epoch [35/250], Loss: 0.5603, Val Loss: 0.5885
Epoch [36/250], Loss: 0.3379, Val Loss: 0.6545
Epoch [37/250], Loss: 0.9647, Val Loss: 0.5476
Epoch [38/250], Loss: 0.6211, Val Loss: 0.6650
Epoch [39/250], Loss: 0.3480, Val Loss: 0.5558
Epoch [40/250], Loss: 0.7700, Val Loss: 0.5873
Epoch [41/250], Loss: 0.2058, Val Loss: 0.5248
Epoch [42/250], Loss: 0.1826, Val Loss: 0.5386
Epoch [43/250], Loss: 0.3233, Val Loss: 0.5391
Epoch [44/250], Loss: 0.4315, Val Loss: 0.5728
Epoch [45/250], Loss: 0.2556, Val Loss: 0.5362
Epoch [46/250], Loss: 0.7029, Val Loss: 0.5623
Epoch [47/250], Loss: 0.4796, Val Loss: 0.6687
Epoch [48/250], Loss: 0.1984, Val Loss: 0.5793
Epoch [49/250], Loss: 0.2307, Val Loss: 0.5941
Epoch [50/250], Loss: 0.2471, Val Loss: 0.6008
Epoch [51/250], Loss: 0.3571, Val Loss: 0.6166
Epoch [52/250], Loss: 0.3753, Val Loss: 0.5682
Epoch [53/250], Loss: 0.1874, Val Loss: 0.5624
Epoch [54/250], Loss: 0.1655, Val Loss: 0.5582
Epoch [55/250], Loss: 0.2368, Val Loss: 0.5971
Epoch [56/250], Loss: 0.4020, Val Loss: 0.5513
Epoch [57/250], Loss: 0.2475, Val Loss: 0.5498
Epoch [58/250], Loss: 0.3569, Val Loss: 0.6426
Epoch [59/250], Loss: 0.3184, Val Loss: 0.6313
Epoch [60/250], Loss: 0.2624, Val Loss: 0.5242
Epoch [61/250], Loss: 0.3240, Val Loss: 0.5687
Epoch [62/250], Loss: 0.4795, Val Loss: 0.6672
Epoch [63/250], Loss: 0.3718, Val Loss: 0.6900
Epoch [64/250], Loss: 0.2414, Val Loss: 0.5879
Epoch [65/250], Loss: 0.2720, Val Loss: 0.5502
Epoch [66/250], Loss: 0.1843, Val Loss: 0.5397
Epoch [67/250], Loss: 0.4117, Val Loss: 0.4931
Epoch [68/250], Loss: 0.7401, Val Loss: 0.5253
Epoch [69/250], Loss: 0.4744, Val Loss: 0.6849
Epoch [70/250], Loss: 0.3022, Val Loss: 0.5385
Epoch [71/250], Loss: 0.4002, Val Loss: 0.5365
Epoch [72/250], Loss: 0.2403, Val Loss: 0.5292
Epoch [73/250], Loss: 0.2514, Val Loss: 0.5740
Epoch [74/250], Loss: 0.3163, Val Loss: 0.5369
Epoch [75/250], Loss: 0.2525, Val Loss: 0.5455
Epoch [76/250], Loss: 0.2965, Val Loss: 0.5035
Epoch [77/250], Loss: 0.3800, Val Loss: 0.5045
Epoch [78/250], Loss: 0.3618, Val Loss: 0.5344
Epoch [79/250], Loss: 0.2431, Val Loss: 0.4973
Epoch [80/250], Loss: 0.2072, Val Loss: 0.5423
Epoch [81/250], Loss: 0.2577, Val Loss: 0.5419
Epoch [82/250], Loss: 0.2676, Val Loss: 0.5198
Epoch [83/250], Loss: 0.1807, Val Loss: 0.5373
Epoch [84/250], Loss: 0.2843, Val Loss: 0.5002
Epoch [85/250], Loss: 0.2590, Val Loss: 0.4986
Epoch [86/250], Loss: 0.3313, Val Loss: 0.5316
Epoch [87/250], Loss: 0.2195, Val Loss: 0.5141
Epoch [88/250], Loss: 0.1840, Val Loss: 0.5100
Epoch [89/250], Loss: 0.2028, Val Loss: 0.5562
Epoch [90/250], Loss: 0.4502, Val Loss: 0.5317
Epoch [91/250], Loss: 0.2226, Val Loss: 0.5722
Epoch [92/250], Loss: 0.2198, Val Loss: 0.5418
Epoch [93/250], Loss: 0.4441, Val Loss: 0.5761
Epoch [94/250], Loss: 0.2362, Val Loss: 0.5122
Epoch [95/250], Loss: 0.1706, Val Loss: 0.5135
Epoch [96/250], Loss: 0.3236, Val Loss: 0.5962
Epoch [97/250], Loss: 0.2328, Val Loss: 0.5522
Epoch [98/250], Loss: 0.2578, Val Loss: 0.5223
Epoch [99/250], Loss: 0.2280, Val Loss: 0.5515
Epoch [100/250], Loss: 0.4034, Val Loss: 0.5383
Epoch [101/250], Loss: 0.2114, Val Loss: 0.4891
Epoch [102/250], Loss: 0.2442, Val Loss: 0.5135
Epoch [103/250], Loss: 0.2733, Val Loss: 0.7816
Epoch [104/250], Loss: 0.4946, Val Loss: 0.5128
Epoch [105/250], Loss: 0.2308, Val Loss: 0.5220
Epoch [106/250], Loss: 0.2921, Val Loss: 0.5104
Epoch [107/250], Loss: 0.2617, Val Loss: 0.6448
Epoch [108/250], Loss: 0.3694, Val Loss: 0.5770
Epoch [109/250], Loss: 0.3812, Val Loss: 0.5253
Epoch [110/250], Loss: 0.2026, Val Loss: 0.5311
Epoch [111/250], Loss: 0.1617, Val Loss: 0.5183
Epoch [112/250], Loss: 0.2083, Val Loss: 0.5483
Epoch [113/250], Loss: 0.2228, Val Loss: 0.6227
Epoch [114/250], Loss: 0.2449, Val Loss: 0.5652
Epoch [115/250], Loss: 0.2401, Val Loss: 0.5463
Epoch [116/250], Loss: 0.2468, Val Loss: 0.5216
Epoch [117/250], Loss: 0.1537, Val Loss: 0.5580
Epoch [118/250], Loss: 0.1373, Val Loss: 0.5425
Epoch [119/250], Loss: 0.2179, Val Loss: 0.5656
Epoch [120/250], Loss: 0.2642, Val Loss: 0.5405
Epoch [121/250], Loss: 0.2572, Val Loss: 0.5866
Epoch [122/250], Loss: 0.2849, Val Loss: 0.5874
Epoch [123/250], Loss: 0.5308, Val Loss: 0.5781
Epoch [124/250], Loss: 0.3137, Val Loss: 0.5919
Epoch [125/250], Loss: 0.2455, Val Loss: 0.5312
Epoch [126/250], Loss: 0.2991, Val Loss: 0.6119
Epoch [127/250], Loss: 0.2185, Val Loss: 0.6696
Epoch [128/250], Loss: 0.1592, Val Loss: 0.5418
Epoch [129/250], Loss: 0.1983, Val Loss: 0.5241
Epoch [130/250], Loss: 0.1979, Val Loss: 0.5031
Epoch [131/250], Loss: 0.2872, Val Loss: 0.4937
Epoch [132/250], Loss: 0.2432, Val Loss: 0.5204
Epoch [133/250], Loss: 0.2664, Val Loss: 0.4938
Epoch [134/250], Loss: 0.2611, Val Loss: 0.5330
Epoch [135/250], Loss: 0.3028, Val Loss: 0.5617
Epoch [136/250], Loss: 0.3508, Val Loss: 0.5823
Epoch [137/250], Loss: 0.3643, Val Loss: 0.6239
Epoch [138/250], Loss: 0.2980, Val Loss: 0.5238
Epoch [139/250], Loss: 0.4295, Val Loss: 0.5922
Epoch [140/250], Loss: 0.1694, Val Loss: 0.5405
Epoch [141/250], Loss: 0.1770, Val Loss: 0.5129
Epoch [142/250], Loss: 0.2181, Val Loss: 0.6286
Epoch [143/250], Loss: 0.2429, Val Loss: 0.5660
Epoch [144/250], Loss: 0.2419, Val Loss: 0.5686
Epoch [145/250], Loss: 0.1455, Val Loss: 0.5223
Epoch [146/250], Loss: 0.1671, Val Loss: 0.5269
Epoch [147/250], Loss: 0.2046, Val Loss: 0.5148
Epoch [148/250], Loss: 0.3849, Val Loss: 0.5707
Epoch [149/250], Loss: 0.2186, Val Loss: 0.5443
Epoch [150/250], Loss: 0.1806, Val Loss: 0.5497
Epoch [151/250], Loss: 0.4439, Val Loss: 0.5336
Epoch [152/250], Loss: 0.2729, Val Loss: 0.5084
Epoch [153/250], Loss: 0.2340, Val Loss: 0.5599
Epoch [154/250], Loss: 0.4887, Val Loss: 0.5977
Epoch [155/250], Loss: 0.1386, Val Loss: 0.5028
Epoch [156/250], Loss: 0.2325, Val Loss: 0.5453
Epoch [157/250], Loss: 0.2106, Val Loss: 0.5020
Epoch [158/250], Loss: 0.3632, Val Loss: 0.5162
Epoch [159/250], Loss: 0.1364, Val Loss: 0.5666
Epoch [160/250], Loss: 0.1610, Val Loss: 0.5391
Epoch [161/250], Loss: 0.2068, Val Loss: 0.5108
Epoch [162/250], Loss: 0.7576, Val Loss: 0.5617
Epoch [163/250], Loss: 0.1614, Val Loss: 0.5367
Epoch [164/250], Loss: 0.2834, Val Loss: 0.5260
Epoch [165/250], Loss: 0.2475, Val Loss: 0.5043
Epoch [166/250], Loss: 0.1716, Val Loss: 0.5332
Epoch [167/250], Loss: 0.4237, Val Loss: 0.4980
Epoch [168/250], Loss: 0.2809, Val Loss: 0.5797
Epoch [169/250], Loss: 0.2228, Val Loss: 0.5387
Epoch [170/250], Loss: 0.1573, Val Loss: 0.5147
Epoch [171/250], Loss: 0.1829, Val Loss: 0.5418
Epoch [172/250], Loss: 0.1599, Val Loss: 0.5155
Epoch [173/250], Loss: 0.1800, Val Loss: 0.5089
Epoch [174/250], Loss: 0.1510, Val Loss: 0.4951
Epoch [175/250], Loss: 0.2006, Val Loss: 0.5862
Epoch [176/250], Loss: 0.2407, Val Loss: 0.5244
Epoch [177/250], Loss: 0.1649, Val Loss: 0.5251
Epoch [178/250], Loss: 0.3292, Val Loss: 0.5631
Epoch [179/250], Loss: 0.1748, Val Loss: 0.7191
Epoch [180/250], Loss: 0.1988, Val Loss: 0.5287
Epoch [181/250], Loss: 0.3659, Val Loss: 0.5931
Epoch [182/250], Loss: 0.2727, Val Loss: 0.5636
Epoch [183/250], Loss: 0.2089, Val Loss: 0.5860
Epoch [184/250], Loss: 0.5667, Val Loss: 0.5437
Epoch [185/250], Loss: 0.3002, Val Loss: 0.5251
Epoch [186/250], Loss: 0.2603, Val Loss: 0.5681
Epoch [187/250], Loss: 0.2661, Val Loss: 0.5396
Epoch [188/250], Loss: 0.2135, Val Loss: 0.5623
Epoch [189/250], Loss: 0.1973, Val Loss: 0.5426
Epoch [190/250], Loss: 0.2483, Val Loss: 0.5393
Epoch [191/250], Loss: 0.2840, Val Loss: 0.5189
Epoch [192/250], Loss: 0.1259, Val Loss: 0.5308
Epoch [193/250], Loss: 0.1863, Val Loss: 0.5291
Epoch [194/250], Loss: 0.1618, Val Loss: 0.5079
Epoch [195/250], Loss: 0.1733, Val Loss: 0.6564
Epoch [196/250], Loss: 0.1931, Val Loss: 0.5276
Epoch [197/250], Loss: 0.1967, Val Loss: 0.5733
Epoch [198/250], Loss: 0.2391, Val Loss: 0.5665
Epoch [199/250], Loss: 0.4572, Val Loss: 0.5324
Epoch [200/250], Loss: 0.1744, Val Loss: 0.5179
Epoch [201/250], Loss: 0.2382, Val Loss: 0.5845
Epoch [202/250], Loss: 0.3102, Val Loss: 0.5581
Epoch [203/250], Loss: 0.2212, Val Loss: 0.5420
Epoch [204/250], Loss: 0.1638, Val Loss: 0.5852
Epoch [205/250], Loss: 0.2310, Val Loss: 0.5275
Epoch [206/250], Loss: 0.1910, Val Loss: 0.5367
Epoch [207/250], Loss: 0.1422, Val Loss: 0.5343
Epoch [208/250], Loss: 0.3924, Val Loss: 0.5079
Epoch [209/250], Loss: 0.2972, Val Loss: 0.5569
Epoch [210/250], Loss: 0.9277, Val Loss: 0.5147
Epoch [211/250], Loss: 0.1656, Val Loss: 0.5151
Epoch [212/250], Loss: 0.1257, Val Loss: 0.5250
Epoch [213/250], Loss: 0.1153, Val Loss: 0.5141
Epoch [214/250], Loss: 0.1735, Val Loss: 0.5123
Epoch [215/250], Loss: 0.2461, Val Loss: 0.5260
Epoch [216/250], Loss: 0.3771, Val Loss: 0.5244
Epoch [217/250], Loss: 0.2504, Val Loss: 0.5085
Epoch [218/250], Loss: 1.4467, Val Loss: 0.5075
Epoch [219/250], Loss: 0.1652, Val Loss: 0.5360
Epoch [220/250], Loss: 0.3381, Val Loss: 0.4861
Epoch [221/250], Loss: 0.2300, Val Loss: 0.5052
Epoch [222/250], Loss: 0.1407, Val Loss: 0.5452
Epoch [223/250], Loss: 1.2737, Val Loss: 0.5947
Epoch [224/250], Loss: 0.1535, Val Loss: 0.5005
Epoch [225/250], Loss: 0.2687, Val Loss: 0.4823
Epoch [226/250], Loss: 0.2285, Val Loss: 0.5358
Epoch [227/250], Loss: 0.1416, Val Loss: 0.5576
Epoch [228/250], Loss: 0.3875, Val Loss: 0.6373
Epoch [229/250], Loss: 0.2115, Val Loss: 0.5008
Epoch [230/250], Loss: 0.2468, Val Loss: 0.5370
Epoch [231/250], Loss: 0.2478, Val Loss: 0.5528
Epoch [232/250], Loss: 0.2067, Val Loss: 0.5144
Epoch [233/250], Loss: 0.2553, Val Loss: 0.5267
Epoch [234/250], Loss: 0.2704, Val Loss: 0.5649
Epoch [235/250], Loss: 0.2427, Val Loss: 0.4969
Epoch [236/250], Loss: 0.4219, Val Loss: 0.4948
Epoch [237/250], Loss: 0.2079, Val Loss: 0.5225
Epoch [238/250], Loss: 0.2177, Val Loss: 0.6290
Epoch [239/250], Loss: 0.3557, Val Loss: 0.6663
Epoch [240/250], Loss: 0.2595, Val Loss: 0.5446
Epoch [241/250], Loss: 0.4298, Val Loss: 0.5365
Epoch [242/250], Loss: 0.1261, Val Loss: 0.5168
Epoch [243/250], Loss: 0.1421, Val Loss: 0.5034
Epoch [244/250], Loss: 0.2405, Val Loss: 0.5157
Epoch [245/250], Loss: 0.2420, Val Loss: 0.5228
Epoch [246/250], Loss: 0.4044, Val Loss: 0.5674
Epoch [247/250], Loss: 0.3243, Val Loss: 0.5165
Epoch [248/250], Loss: 0.2150, Val Loss: 0.5336
Epoch [249/250], Loss: 0.1410, Val Loss: 0.5095
Epoch [250/250], Loss: 0.2116, Val Loss: 0.5335
Runtime: 0:01:41.897559
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 0.4623, Val Loss: 0.8727
Epoch [2/250], Loss: 0.6634, Val Loss: 0.8154
Epoch [3/250], Loss: 0.8088, Val Loss: 0.9788
Epoch [4/250], Loss: 0.7488, Val Loss: 0.7562
Epoch [5/250], Loss: 0.7290, Val Loss: 0.8290
Epoch [6/250], Loss: 0.5545, Val Loss: 0.7659
Epoch [7/250], Loss: 0.5840, Val Loss: 0.7260
Epoch [8/250], Loss: 0.5538, Val Loss: 0.7906
Epoch [9/250], Loss: 1.1232, Val Loss: 0.7343
Epoch [10/250], Loss: 1.0385, Val Loss: 0.7181
Epoch [11/250], Loss: 0.3566, Val Loss: 0.7866
Epoch [12/250], Loss: 0.5833, Val Loss: 0.7502
Epoch [13/250], Loss: 0.5241, Val Loss: 0.6458
Epoch [14/250], Loss: 0.4969, Val Loss: 0.5800
Epoch [15/250], Loss: 0.2655, Val Loss: 0.5556
Epoch [16/250], Loss: 1.2818, Val Loss: 0.6438
Epoch [17/250], Loss: 0.6121, Val Loss: 0.7421
Epoch [18/250], Loss: 0.3658, Val Loss: 0.5845
Epoch [19/250], Loss: 0.4714, Val Loss: 0.5887
Epoch [20/250], Loss: 0.4495, Val Loss: 0.6431
Epoch [21/250], Loss: 0.5721, Val Loss: 0.6279
Epoch [22/250], Loss: 0.2958, Val Loss: 0.6041
Epoch [23/250], Loss: 0.5171, Val Loss: 0.6218
Epoch [24/250], Loss: 0.6690, Val Loss: 0.5868
Epoch [25/250], Loss: 0.5143, Val Loss: 0.5681
Epoch [26/250], Loss: 0.4097, Val Loss: 0.5702
Epoch [27/250], Loss: 0.4820, Val Loss: 0.5618
Epoch [28/250], Loss: 0.3282, Val Loss: 0.5637
Epoch [29/250], Loss: 0.4534, Val Loss: 0.5514
Epoch [30/250], Loss: 0.5964, Val Loss: 0.5873
Epoch [31/250], Loss: 0.4268, Val Loss: 0.7255
Epoch [32/250], Loss: 0.4158, Val Loss: 0.5594
Epoch [33/250], Loss: 0.3626, Val Loss: 0.5471
Epoch [34/250], Loss: 0.6156, Val Loss: 0.6036
Epoch [35/250], Loss: 0.4571, Val Loss: 0.5466
Epoch [36/250], Loss: 0.4619, Val Loss: 0.5586
Epoch [37/250], Loss: 0.2905, Val Loss: 0.6070
Epoch [38/250], Loss: 0.4174, Val Loss: 0.5201
Epoch [39/250], Loss: 0.4014, Val Loss: 0.5998
Epoch [40/250], Loss: 0.3119, Val Loss: 0.6533
Epoch [41/250], Loss: 0.2740, Val Loss: 0.5756
Epoch [42/250], Loss: 0.4244, Val Loss: 0.6984
Epoch [43/250], Loss: 0.5206, Val Loss: 0.5752
Epoch [44/250], Loss: 0.4890, Val Loss: 0.6353
Epoch [45/250], Loss: 0.2422, Val Loss: 0.6195
Epoch [46/250], Loss: 0.1900, Val Loss: 0.5627
Epoch [47/250], Loss: 0.3282, Val Loss: 0.5872
Epoch [48/250], Loss: 0.3486, Val Loss: 0.7176
Epoch [49/250], Loss: 0.2838, Val Loss: 0.5269
Epoch [50/250], Loss: 0.3485, Val Loss: 0.5445
Epoch [51/250], Loss: 0.1609, Val Loss: 0.5406
Epoch [52/250], Loss: 0.2765, Val Loss: 0.5550
Epoch [53/250], Loss: 0.4440, Val Loss: 0.5255
Epoch [54/250], Loss: 0.6914, Val Loss: 0.5613
Epoch [55/250], Loss: 0.2527, Val Loss: 0.5632
Epoch [56/250], Loss: 0.2601, Val Loss: 0.5542
Epoch [57/250], Loss: 0.3657, Val Loss: 0.6302
Epoch [58/250], Loss: 0.3907, Val Loss: 0.5393
Epoch [59/250], Loss: 0.2013, Val Loss: 0.5425
Epoch [60/250], Loss: 0.5391, Val Loss: 0.6292
Epoch [61/250], Loss: 0.3857, Val Loss: 0.5235
Epoch [62/250], Loss: 0.3207, Val Loss: 0.5084
Epoch [63/250], Loss: 0.4618, Val Loss: 0.5640
Epoch [64/250], Loss: 0.2084, Val Loss: 0.4938
Epoch [65/250], Loss: 0.2669, Val Loss: 0.5809
Epoch [66/250], Loss: 0.4976, Val Loss: 0.5309
Epoch [67/250], Loss: 0.5430, Val Loss: 0.5102
Epoch [68/250], Loss: 0.3561, Val Loss: 0.5235
Epoch [69/250], Loss: 0.4407, Val Loss: 0.5475
Epoch [70/250], Loss: 0.3218, Val Loss: 0.6406
Epoch [71/250], Loss: 0.6109, Val Loss: 0.5276
Epoch [72/250], Loss: 0.3677, Val Loss: 0.5512
Epoch [73/250], Loss: 0.3098, Val Loss: 0.6199
Epoch [74/250], Loss: 0.2498, Val Loss: 0.5697
Epoch [75/250], Loss: 0.1935, Val Loss: 0.5320
Epoch [76/250], Loss: 0.1824, Val Loss: 0.5397
Epoch [77/250], Loss: 0.4616, Val Loss: 0.5336
Epoch [78/250], Loss: 0.2057, Val Loss: 0.5231
Epoch [79/250], Loss: 0.2923, Val Loss: 0.5292
Epoch [80/250], Loss: 0.2793, Val Loss: 0.5382
Epoch [81/250], Loss: 0.4101, Val Loss: 0.5721
Epoch [82/250], Loss: 0.1719, Val Loss: 0.5617
Epoch [83/250], Loss: 0.3836, Val Loss: 0.5170
Epoch [84/250], Loss: 0.3125, Val Loss: 0.6198
Epoch [85/250], Loss: 0.3324, Val Loss: 0.6175
Epoch [86/250], Loss: 0.2513, Val Loss: 0.5428
Epoch [87/250], Loss: 0.4332, Val Loss: 0.5821
Epoch [88/250], Loss: 0.3158, Val Loss: 0.6741
Epoch [89/250], Loss: 0.1852, Val Loss: 0.5703
Epoch [90/250], Loss: 0.2023, Val Loss: 0.5204
Epoch [91/250], Loss: 0.2509, Val Loss: 0.5129
Epoch [92/250], Loss: 0.2115, Val Loss: 0.5491
Epoch [93/250], Loss: 0.5486, Val Loss: 0.5971
Epoch [94/250], Loss: 0.4147, Val Loss: 0.5400
Epoch [95/250], Loss: 0.3512, Val Loss: 0.5195
Epoch [96/250], Loss: 0.2488, Val Loss: 0.5492
Epoch [97/250], Loss: 0.2021, Val Loss: 0.5098
Epoch [98/250], Loss: 0.1808, Val Loss: 0.6249
Epoch [99/250], Loss: 0.2972, Val Loss: 0.5066
Epoch [100/250], Loss: 0.2228, Val Loss: 0.5342
Epoch [101/250], Loss: 0.7629, Val Loss: 0.5519
Epoch [102/250], Loss: 0.7553, Val Loss: 0.5387
Epoch [103/250], Loss: 0.2611, Val Loss: 0.5008
Epoch [104/250], Loss: 0.3566, Val Loss: 0.5035
Epoch [105/250], Loss: 0.3280, Val Loss: 0.7213
Epoch [106/250], Loss: 0.3878, Val Loss: 0.5082
Epoch [107/250], Loss: 0.1829, Val Loss: 0.5726
Epoch [108/250], Loss: 0.1602, Val Loss: 0.5379
Epoch [109/250], Loss: 0.2308, Val Loss: 0.5586
Epoch [110/250], Loss: 0.1918, Val Loss: 0.5186
Epoch [111/250], Loss: 0.2946, Val Loss: 0.4944
Epoch [112/250], Loss: 0.2401, Val Loss: 0.6156
Epoch [113/250], Loss: 0.1785, Val Loss: 0.5181
Epoch [114/250], Loss: 0.3100, Val Loss: 0.5242
Epoch [115/250], Loss: 0.2288, Val Loss: 0.6270
Epoch [116/250], Loss: 0.2506, Val Loss: 0.5503
Epoch [117/250], Loss: 0.2318, Val Loss: 0.6613
Epoch [118/250], Loss: 0.3895, Val Loss: 0.5235
Epoch [119/250], Loss: 0.3049, Val Loss: 0.5914
Epoch [120/250], Loss: 0.2510, Val Loss: 0.5674
Epoch [121/250], Loss: 0.4265, Val Loss: 0.5108
Epoch [122/250], Loss: 0.2398, Val Loss: 0.5078
Epoch [123/250], Loss: 0.2372, Val Loss: 0.5322
Epoch [124/250], Loss: 0.2901, Val Loss: 0.5907
Epoch [125/250], Loss: 0.4274, Val Loss: 0.5327
Epoch [126/250], Loss: 1.5688, Val Loss: 0.5386
Epoch [127/250], Loss: 0.3788, Val Loss: 0.5664
Epoch [128/250], Loss: 0.4649, Val Loss: 0.5426
Epoch [129/250], Loss: 0.4909, Val Loss: 0.5328
Epoch [130/250], Loss: 0.3597, Val Loss: 0.5116
Epoch [131/250], Loss: 0.5374, Val Loss: 0.5221
Epoch [132/250], Loss: 0.3762, Val Loss: 0.5341
Epoch [133/250], Loss: 0.2172, Val Loss: 0.6452
Epoch [134/250], Loss: 0.2619, Val Loss: 0.5142
Epoch [135/250], Loss: 0.2068, Val Loss: 0.4968
Epoch [136/250], Loss: 0.1341, Val Loss: 0.5087
Epoch [137/250], Loss: 0.4027, Val Loss: 0.5391
Epoch [138/250], Loss: 0.3587, Val Loss: 0.5033
Epoch [139/250], Loss: 0.1416, Val Loss: 0.4976
Epoch [140/250], Loss: 0.2048, Val Loss: 0.4973
Epoch [141/250], Loss: 0.1560, Val Loss: 0.5024
Epoch [142/250], Loss: 0.6183, Val Loss: 0.5256
Epoch [143/250], Loss: 0.4092, Val Loss: 0.5070
Epoch [144/250], Loss: 0.2222, Val Loss: 0.5459
Epoch [145/250], Loss: 0.1664, Val Loss: 0.5305
Epoch [146/250], Loss: 0.2423, Val Loss: 0.4978
Epoch [147/250], Loss: 0.3009, Val Loss: 0.5546
Epoch [148/250], Loss: 0.3000, Val Loss: 0.5770
Epoch [149/250], Loss: 0.1784, Val Loss: 0.5212
Epoch [150/250], Loss: 0.1712, Val Loss: 0.5230
Epoch [151/250], Loss: 0.1906, Val Loss: 0.4979
Epoch [152/250], Loss: 0.1539, Val Loss: 0.5412
Epoch [153/250], Loss: 0.2733, Val Loss: 0.5508
Epoch [154/250], Loss: 0.1762, Val Loss: 0.5396
Epoch [155/250], Loss: 0.3475, Val Loss: 0.5303
Epoch [156/250], Loss: 0.2652, Val Loss: 0.7237
Epoch [157/250], Loss: 0.2325, Val Loss: 0.6416
Epoch [158/250], Loss: 0.2845, Val Loss: 0.5112
Epoch [159/250], Loss: 0.1050, Val Loss: 0.5166
Epoch [160/250], Loss: 0.1860, Val Loss: 0.5262
Epoch [161/250], Loss: 0.2817, Val Loss: 0.5867
Epoch [162/250], Loss: 0.2480, Val Loss: 0.5225
Epoch [163/250], Loss: 0.1859, Val Loss: 0.5305
Epoch [164/250], Loss: 0.3273, Val Loss: 0.5931
Epoch [165/250], Loss: 0.3077, Val Loss: 0.5006
Epoch [166/250], Loss: 0.2727, Val Loss: 0.5395
Epoch [167/250], Loss: 0.2780, Val Loss: 0.5354
Epoch [168/250], Loss: 0.2730, Val Loss: 0.5331
Epoch [169/250], Loss: 0.1791, Val Loss: 0.5083
Epoch [170/250], Loss: 0.5235, Val Loss: 0.6012
Epoch [171/250], Loss: 0.2153, Val Loss: 0.5855
Epoch [172/250], Loss: 0.1550, Val Loss: 0.5161
Epoch [173/250], Loss: 0.2085, Val Loss: 0.5295
Epoch [174/250], Loss: 0.1654, Val Loss: 0.5062
Epoch [175/250], Loss: 0.2758, Val Loss: 0.7276
Epoch [176/250], Loss: 0.2844, Val Loss: 0.5693
Epoch [177/250], Loss: 0.2268, Val Loss: 0.6522
Epoch [178/250], Loss: 0.4264, Val Loss: 0.5931
Epoch [179/250], Loss: 0.1317, Val Loss: 0.5387
Epoch [180/250], Loss: 0.9561, Val Loss: 0.5475
Epoch [181/250], Loss: 0.1381, Val Loss: 0.5040
Epoch [182/250], Loss: 0.2264, Val Loss: 0.5593
Epoch [183/250], Loss: 0.7799, Val Loss: 0.5533
Epoch [184/250], Loss: 0.2625, Val Loss: 0.5191
Epoch [185/250], Loss: 0.1554, Val Loss: 0.5197
Epoch [186/250], Loss: 0.3525, Val Loss: 0.4888
Epoch [187/250], Loss: 1.4971, Val Loss: 0.5337
Epoch [188/250], Loss: 0.1540, Val Loss: 0.5364
Epoch [189/250], Loss: 0.2065, Val Loss: 0.5160
Epoch [190/250], Loss: 0.8926, Val Loss: 0.5127
Epoch [191/250], Loss: 0.1348, Val Loss: 0.5155
Epoch [192/250], Loss: 0.2654, Val Loss: 0.5374
Epoch [193/250], Loss: 0.2617, Val Loss: 0.5090
Epoch [194/250], Loss: 0.2793, Val Loss: 0.5447
Epoch [195/250], Loss: 0.3728, Val Loss: 0.5238
Epoch [196/250], Loss: 0.1633, Val Loss: 0.5062
Epoch [197/250], Loss: 0.2321, Val Loss: 0.5312
Epoch [198/250], Loss: 0.1991, Val Loss: 0.5002
Epoch [199/250], Loss: 0.1849, Val Loss: 0.6279
Epoch [200/250], Loss: 0.4635, Val Loss: 0.5156
Epoch [201/250], Loss: 0.2897, Val Loss: 0.5238
Epoch [202/250], Loss: 0.2525, Val Loss: 0.5303
Epoch [203/250], Loss: 0.2001, Val Loss: 0.5370
Epoch [204/250], Loss: 0.1289, Val Loss: 0.5062
Epoch [205/250], Loss: 0.1396, Val Loss: 0.6494
Epoch [206/250], Loss: 0.1702, Val Loss: 0.4913
Epoch [207/250], Loss: 0.2467, Val Loss: 0.5730
Epoch [208/250], Loss: 0.2667, Val Loss: 0.5486
Epoch [209/250], Loss: 0.3150, Val Loss: 0.4922
Epoch [210/250], Loss: 0.2998, Val Loss: 0.5299
Epoch [211/250], Loss: 0.9730, Val Loss: 0.5604
Epoch [212/250], Loss: 0.2239, Val Loss: 0.5220
Epoch [213/250], Loss: 0.2636, Val Loss: 0.5504
Epoch [214/250], Loss: 0.1751, Val Loss: 0.4914
Epoch [215/250], Loss: 0.4874, Val Loss: 0.5149
Epoch [216/250], Loss: 0.2158, Val Loss: 0.4893
Epoch [217/250], Loss: 0.2564, Val Loss: 0.5089
Epoch [218/250], Loss: 0.4769, Val Loss: 0.5014
Epoch [219/250], Loss: 0.7520, Val Loss: 0.5059
Epoch [220/250], Loss: 0.2240, Val Loss: 0.5669
Epoch [221/250], Loss: 0.2408, Val Loss: 0.5487
Epoch [222/250], Loss: 0.1857, Val Loss: 0.5255
Epoch [223/250], Loss: 0.2674, Val Loss: 0.4988
Epoch [224/250], Loss: 0.2228, Val Loss: 0.5241
Epoch [225/250], Loss: 0.1796, Val Loss: 0.4991
Epoch [226/250], Loss: 0.1718, Val Loss: 0.5045
Epoch [227/250], Loss: 0.1564, Val Loss: 0.5086
Epoch [228/250], Loss: 0.1839, Val Loss: 0.4896
Epoch [229/250], Loss: 0.2858, Val Loss: 0.5236
Epoch [230/250], Loss: 0.2025, Val Loss: 0.5023
Epoch [231/250], Loss: 0.2347, Val Loss: 0.6345
Epoch [232/250], Loss: 0.2092, Val Loss: 0.4970
Epoch [233/250], Loss: 0.1868, Val Loss: 0.5283
Epoch [234/250], Loss: 0.2475, Val Loss: 0.6284
Epoch [235/250], Loss: 0.4401, Val Loss: 0.5734
Epoch [236/250], Loss: 0.2280, Val Loss: 0.5492
Epoch [237/250], Loss: 0.2690, Val Loss: 0.5153
Epoch [238/250], Loss: 0.2036, Val Loss: 0.4859
Epoch [239/250], Loss: 0.2911, Val Loss: 0.4975
Epoch [240/250], Loss: 0.1943, Val Loss: 0.7156
Epoch [241/250], Loss: 0.2118, Val Loss: 0.5513
Epoch [242/250], Loss: 0.2249, Val Loss: 0.5170
Epoch [243/250], Loss: 0.1972, Val Loss: 0.5554
Epoch [244/250], Loss: 0.2082, Val Loss: 0.5062
Epoch [245/250], Loss: 0.1629, Val Loss: 0.5028
Epoch [246/250], Loss: 0.2013, Val Loss: 0.4865
Epoch [247/250], Loss: 0.2484, Val Loss: 0.5129
Epoch [248/250], Loss: 0.9147, Val Loss: 0.5272
Epoch [249/250], Loss: 0.1767, Val Loss: 0.5298
Epoch [250/250], Loss: 0.1756, Val Loss: 0.5183
Runtime: 0:01:37.555202
R^2 Score: 0.9037
RMSE: 0.7027
MAE: 0.1795
MAPE: 14.16%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 0.6896, Val Loss: 0.9974
Epoch [2/250], Loss: 0.6617, Val Loss: 1.2510
Epoch [3/250], Loss: 1.5226, Val Loss: 0.9301
Epoch [4/250], Loss: 0.7610, Val Loss: 1.0049
Epoch [5/250], Loss: 0.4127, Val Loss: 0.7331
Epoch [6/250], Loss: 0.4374, Val Loss: 0.6934
Epoch [7/250], Loss: 0.5810, Val Loss: 0.7514
Epoch [8/250], Loss: 0.7447, Val Loss: 0.9867
Epoch [9/250], Loss: 1.2530, Val Loss: 0.9850
Epoch [10/250], Loss: 0.3693, Val Loss: 0.7484
Epoch [11/250], Loss: 0.7719, Val Loss: 0.7551
Epoch [12/250], Loss: 0.4753, Val Loss: 0.7453
Epoch [13/250], Loss: 0.3710, Val Loss: 0.6736
Epoch [14/250], Loss: 0.4351, Val Loss: 0.6634
Epoch [15/250], Loss: 0.4879, Val Loss: 0.7827
Epoch [16/250], Loss: 0.5479, Val Loss: 0.6199
Epoch [17/250], Loss: 0.2572, Val Loss: 0.7828
Epoch [18/250], Loss: 0.3486, Val Loss: 0.6758
Epoch [19/250], Loss: 0.3503, Val Loss: 0.5828
Epoch [20/250], Loss: 0.8653, Val Loss: 0.6463
Epoch [21/250], Loss: 0.3964, Val Loss: 0.6794
Epoch [22/250], Loss: 0.4055, Val Loss: 0.6268
Epoch [23/250], Loss: 0.2882, Val Loss: 0.6426
Epoch [24/250], Loss: 0.2448, Val Loss: 0.6932
Epoch [25/250], Loss: 1.3415, Val Loss: 0.7192
Epoch [26/250], Loss: 0.2799, Val Loss: 0.6133
Epoch [27/250], Loss: 0.4128, Val Loss: 0.7433
Epoch [28/250], Loss: 0.2987, Val Loss: 0.6658
Epoch [29/250], Loss: 0.6594, Val Loss: 0.6364
Epoch [30/250], Loss: 0.3797, Val Loss: 0.6064
Epoch [31/250], Loss: 0.4691, Val Loss: 0.7857
Epoch [32/250], Loss: 0.6173, Val Loss: 0.5857
Epoch [33/250], Loss: 0.3956, Val Loss: 0.5892
Epoch [34/250], Loss: 0.7055, Val Loss: 0.5940
Epoch [35/250], Loss: 0.2691, Val Loss: 0.5989
Epoch [36/250], Loss: 0.1986, Val Loss: 0.5936
Epoch [37/250], Loss: 0.2620, Val Loss: 0.5865
Epoch [38/250], Loss: 1.4835, Val Loss: 0.8262
Epoch [39/250], Loss: 0.7341, Val Loss: 0.6127
Epoch [40/250], Loss: 0.2608, Val Loss: 0.5666
Epoch [41/250], Loss: 0.4246, Val Loss: 0.6208
Epoch [42/250], Loss: 0.4301, Val Loss: 0.5585
Epoch [43/250], Loss: 0.2675, Val Loss: 0.6215
Epoch [44/250], Loss: 0.3718, Val Loss: 0.5848
Epoch [45/250], Loss: 0.3320, Val Loss: 0.6268
Epoch [46/250], Loss: 0.6934, Val Loss: 0.6613
Epoch [47/250], Loss: 0.2274, Val Loss: 0.5884
Epoch [48/250], Loss: 0.2074, Val Loss: 0.5825
Epoch [49/250], Loss: 0.2750, Val Loss: 0.5772
Epoch [50/250], Loss: 0.2381, Val Loss: 0.5696
Epoch [51/250], Loss: 0.6993, Val Loss: 0.6519
Epoch [52/250], Loss: 0.2622, Val Loss: 0.6314
Epoch [53/250], Loss: 0.5201, Val Loss: 0.6066
Epoch [54/250], Loss: 0.2427, Val Loss: 0.5814
Epoch [55/250], Loss: 0.2972, Val Loss: 0.5491
Epoch [56/250], Loss: 0.3544, Val Loss: 0.6100
Epoch [57/250], Loss: 0.3080, Val Loss: 0.5762
Epoch [58/250], Loss: 0.2139, Val Loss: 0.5340
Epoch [59/250], Loss: 0.2364, Val Loss: 0.5691
Epoch [60/250], Loss: 0.3165, Val Loss: 0.5740
Epoch [61/250], Loss: 0.4803, Val Loss: 0.7145
Epoch [62/250], Loss: 0.6339, Val Loss: 0.5979
Epoch [63/250], Loss: 0.4161, Val Loss: 0.5834
Epoch [64/250], Loss: 0.3800, Val Loss: 0.6418
Epoch [65/250], Loss: 0.7187, Val Loss: 0.5740
Epoch [66/250], Loss: 0.2524, Val Loss: 0.5777
Epoch [67/250], Loss: 0.4334, Val Loss: 0.7199
Epoch [68/250], Loss: 0.3927, Val Loss: 0.6042
Epoch [69/250], Loss: 0.1820, Val Loss: 0.5890
Epoch [70/250], Loss: 0.4184, Val Loss: 0.6471
Epoch [71/250], Loss: 0.3678, Val Loss: 0.6058
Epoch [72/250], Loss: 0.2556, Val Loss: 0.5852
Epoch [73/250], Loss: 0.2191, Val Loss: 0.6109
Epoch [74/250], Loss: 0.2083, Val Loss: 0.5753
Epoch [75/250], Loss: 0.3091, Val Loss: 0.6154
Epoch [76/250], Loss: 0.1652, Val Loss: 0.5562
Epoch [77/250], Loss: 0.2984, Val Loss: 0.5504
Epoch [78/250], Loss: 0.3442, Val Loss: 0.5779
Epoch [79/250], Loss: 0.1861, Val Loss: 0.5838
Epoch [80/250], Loss: 0.1380, Val Loss: 0.5729
Epoch [81/250], Loss: 0.2861, Val Loss: 0.5999
Epoch [82/250], Loss: 0.1486, Val Loss: 0.5965
Epoch [83/250], Loss: 0.1721, Val Loss: 0.5608
Epoch [84/250], Loss: 0.3162, Val Loss: 0.6180
Epoch [85/250], Loss: 0.2491, Val Loss: 0.5695
Epoch [86/250], Loss: 0.2994, Val Loss: 0.5636
Epoch [87/250], Loss: 0.4409, Val Loss: 0.6079
Epoch [88/250], Loss: 0.3609, Val Loss: 0.7781
Epoch [89/250], Loss: 0.1385, Val Loss: 0.5937
Epoch [90/250], Loss: 0.1736, Val Loss: 0.5550
Epoch [91/250], Loss: 0.2207, Val Loss: 0.6079
Epoch [92/250], Loss: 0.1855, Val Loss: 0.6472
Epoch [93/250], Loss: 0.4388, Val Loss: 0.6353
Epoch [94/250], Loss: 0.2883, Val Loss: 0.6294
Epoch [95/250], Loss: 0.1476, Val Loss: 0.5622
Epoch [96/250], Loss: 0.1759, Val Loss: 0.5648
Epoch [97/250], Loss: 0.1542, Val Loss: 0.6753
Epoch [98/250], Loss: 0.3071, Val Loss: 0.5656
Epoch [99/250], Loss: 0.2026, Val Loss: 0.5731
Epoch [100/250], Loss: 0.1649, Val Loss: 0.5837
Epoch [101/250], Loss: 0.2726, Val Loss: 0.7333
Epoch [102/250], Loss: 0.3288, Val Loss: 0.5790
Epoch [103/250], Loss: 0.1823, Val Loss: 0.5881
Epoch [104/250], Loss: 0.3468, Val Loss: 0.8328
Epoch [105/250], Loss: 0.3099, Val Loss: 0.5563
Epoch [106/250], Loss: 0.2731, Val Loss: 0.6619
Epoch [107/250], Loss: 0.3384, Val Loss: 0.6780
Epoch [108/250], Loss: 0.2647, Val Loss: 0.5933
Epoch [109/250], Loss: 0.4729, Val Loss: 0.6592
Epoch [110/250], Loss: 1.3537, Val Loss: 0.6031
Epoch [111/250], Loss: 0.2549, Val Loss: 0.6291
Epoch [112/250], Loss: 0.2093, Val Loss: 0.5898
Epoch [113/250], Loss: 0.4338, Val Loss: 0.5941
Epoch [114/250], Loss: 0.1668, Val Loss: 0.6025
Epoch [115/250], Loss: 1.1020, Val Loss: 0.5345
Epoch [116/250], Loss: 0.1575, Val Loss: 0.6164
Epoch [117/250], Loss: 0.1631, Val Loss: 0.5606
Epoch [118/250], Loss: 0.2657, Val Loss: 0.5515
Epoch [119/250], Loss: 0.2915, Val Loss: 0.5186
Epoch [120/250], Loss: 1.1593, Val Loss: 0.5301
Epoch [121/250], Loss: 0.3456, Val Loss: 0.5890
Epoch [122/250], Loss: 0.1921, Val Loss: 0.7257
Epoch [123/250], Loss: 0.1587, Val Loss: 0.5642
Epoch [124/250], Loss: 1.0078, Val Loss: 0.7980
Epoch [125/250], Loss: 0.3670, Val Loss: 0.5358
Epoch [126/250], Loss: 0.2427, Val Loss: 0.5609
Epoch [127/250], Loss: 0.2957, Val Loss: 0.5203
Epoch [128/250], Loss: 0.2781, Val Loss: 0.5654
Epoch [129/250], Loss: 0.2579, Val Loss: 0.5412
Epoch [130/250], Loss: 0.1768, Val Loss: 0.5509
Epoch [131/250], Loss: 0.3817, Val Loss: 0.6065
Epoch [132/250], Loss: 0.3437, Val Loss: 0.6148
Epoch [133/250], Loss: 0.3670, Val Loss: 0.5968
Epoch [134/250], Loss: 0.2038, Val Loss: 0.5723
Epoch [135/250], Loss: 0.2888, Val Loss: 0.6038
Epoch [136/250], Loss: 0.3025, Val Loss: 0.7525
Epoch [137/250], Loss: 0.2910, Val Loss: 0.5587
Epoch [138/250], Loss: 0.2169, Val Loss: 0.6209
Epoch [139/250], Loss: 0.1639, Val Loss: 0.5849
Epoch [140/250], Loss: 0.2130, Val Loss: 0.6377
Epoch [141/250], Loss: 0.1548, Val Loss: 0.5510
Epoch [142/250], Loss: 0.4064, Val Loss: 0.5579
Epoch [143/250], Loss: 0.2009, Val Loss: 0.5754
Epoch [144/250], Loss: 0.1513, Val Loss: 0.5592
Epoch [145/250], Loss: 0.2223, Val Loss: 0.5630
Epoch [146/250], Loss: 0.2552, Val Loss: 0.5468
Epoch [147/250], Loss: 0.2500, Val Loss: 0.5477
Epoch [148/250], Loss: 0.2708, Val Loss: 0.5663
Epoch [149/250], Loss: 0.3133, Val Loss: 0.5447
Epoch [150/250], Loss: 0.4018, Val Loss: 0.6106
Epoch [151/250], Loss: 0.4322, Val Loss: 0.7730
Epoch [152/250], Loss: 0.3588, Val Loss: 0.5813
Epoch [153/250], Loss: 0.1827, Val Loss: 0.5356
Epoch [154/250], Loss: 0.1616, Val Loss: 0.6266
Epoch [155/250], Loss: 0.3588, Val Loss: 0.6693
Epoch [156/250], Loss: 0.1848, Val Loss: 0.5246
Epoch [157/250], Loss: 0.1596, Val Loss: 0.5985
Epoch [158/250], Loss: 0.1330, Val Loss: 0.5503
Epoch [159/250], Loss: 0.1749, Val Loss: 0.7802
Epoch [160/250], Loss: 1.1012, Val Loss: 0.6175
Epoch [161/250], Loss: 0.1382, Val Loss: 0.6171
Epoch [162/250], Loss: 0.9276, Val Loss: 0.6241
Epoch [163/250], Loss: 0.3995, Val Loss: 0.5491
Epoch [164/250], Loss: 0.2205, Val Loss: 0.7415
Epoch [165/250], Loss: 0.1988, Val Loss: 0.5606
Epoch [166/250], Loss: 0.2914, Val Loss: 0.5318
Epoch [167/250], Loss: 0.3440, Val Loss: 0.5465
Epoch [168/250], Loss: 0.1788, Val Loss: 0.5536
Epoch [169/250], Loss: 0.4710, Val Loss: 0.5850
Epoch [170/250], Loss: 0.2056, Val Loss: 0.5887
Epoch [171/250], Loss: 0.3364, Val Loss: 0.5585
Epoch [172/250], Loss: 0.1951, Val Loss: 0.5650
Epoch [173/250], Loss: 0.2395, Val Loss: 0.6094
Epoch [174/250], Loss: 0.2314, Val Loss: 0.5532
Epoch [175/250], Loss: 0.3073, Val Loss: 0.5804
Epoch [176/250], Loss: 0.5859, Val Loss: 0.5633
Epoch [177/250], Loss: 0.1737, Val Loss: 0.6407
Epoch [178/250], Loss: 0.3692, Val Loss: 0.7571
Epoch [179/250], Loss: 0.1554, Val Loss: 0.5442
Epoch [180/250], Loss: 0.1598, Val Loss: 0.5509
Epoch [181/250], Loss: 0.1274, Val Loss: 0.5629
Epoch [182/250], Loss: 0.1728, Val Loss: 0.5752
Epoch [183/250], Loss: 0.3084, Val Loss: 0.7128
Epoch [184/250], Loss: 0.2349, Val Loss: 0.5595
Epoch [185/250], Loss: 0.4312, Val Loss: 0.7059
Epoch [186/250], Loss: 0.2869, Val Loss: 0.5146
Epoch [187/250], Loss: 0.2881, Val Loss: 0.6660
Epoch [188/250], Loss: 0.2600, Val Loss: 0.5367
Epoch [189/250], Loss: 0.2386, Val Loss: 0.5548
Epoch [190/250], Loss: 0.2557, Val Loss: 0.5576
Epoch [191/250], Loss: 0.5001, Val Loss: 0.5478
Epoch [192/250], Loss: 0.1547, Val Loss: 0.6820
Epoch [193/250], Loss: 0.3194, Val Loss: 0.5588
Epoch [194/250], Loss: 0.3400, Val Loss: 0.5832
Epoch [195/250], Loss: 0.1987, Val Loss: 0.5665
Epoch [196/250], Loss: 0.4124, Val Loss: 0.5705
Epoch [197/250], Loss: 0.1904, Val Loss: 0.5161
Epoch [198/250], Loss: 0.1914, Val Loss: 0.6717
Epoch [199/250], Loss: 0.1430, Val Loss: 0.5696
Epoch [200/250], Loss: 0.1722, Val Loss: 0.7133
Epoch [201/250], Loss: 0.3010, Val Loss: 0.6007
Epoch [202/250], Loss: 0.3374, Val Loss: 0.5595
Epoch [203/250], Loss: 0.1338, Val Loss: 0.5889
Epoch [204/250], Loss: 0.2519, Val Loss: 0.5663
Epoch [205/250], Loss: 0.1635, Val Loss: 0.7801
Epoch [206/250], Loss: 0.1121, Val Loss: 0.5603
Epoch [207/250], Loss: 0.2131, Val Loss: 0.5651
Epoch [208/250], Loss: 0.1511, Val Loss: 0.5443
Epoch [209/250], Loss: 0.2249, Val Loss: 0.5335
Epoch [210/250], Loss: 0.1800, Val Loss: 0.5651
Epoch [211/250], Loss: 0.1330, Val Loss: 0.5719
Epoch [212/250], Loss: 0.1375, Val Loss: 0.5350
Epoch [213/250], Loss: 0.2855, Val Loss: 0.5657
Epoch [214/250], Loss: 0.2192, Val Loss: 0.5743
Epoch [215/250], Loss: 0.2958, Val Loss: 0.5089
Epoch [216/250], Loss: 0.2800, Val Loss: 0.5466
Epoch [217/250], Loss: 0.1913, Val Loss: 0.5053
Epoch [218/250], Loss: 0.4175, Val Loss: 0.7148
Epoch [219/250], Loss: 0.1860, Val Loss: 0.5384
Epoch [220/250], Loss: 0.2315, Val Loss: 0.5617
Epoch [221/250], Loss: 0.1587, Val Loss: 0.5500
Epoch [222/250], Loss: 0.2134, Val Loss: 0.5752
Epoch [223/250], Loss: 0.1213, Val Loss: 0.5472
Epoch [224/250], Loss: 0.1552, Val Loss: 0.5293
Epoch [225/250], Loss: 0.3791, Val Loss: 0.6409
Epoch [226/250], Loss: 0.1842, Val Loss: 0.5304
Epoch [227/250], Loss: 0.1743, Val Loss: 0.5813
Epoch [228/250], Loss: 0.1797, Val Loss: 0.5486
Epoch [229/250], Loss: 0.1423, Val Loss: 0.5282
Epoch [230/250], Loss: 0.1664, Val Loss: 0.7136
Epoch [231/250], Loss: 0.2145, Val Loss: 0.5679
Epoch [232/250], Loss: 0.1680, Val Loss: 0.5313
Epoch [233/250], Loss: 0.2486, Val Loss: 0.5293
Epoch [234/250], Loss: 0.2200, Val Loss: 0.5548
Epoch [235/250], Loss: 0.2511, Val Loss: 0.5324
Epoch [236/250], Loss: 0.3074, Val Loss: 0.7016
Epoch [237/250], Loss: 0.1804, Val Loss: 0.5539
Epoch [238/250], Loss: 0.5078, Val Loss: 0.5635
Epoch [239/250], Loss: 0.1400, Val Loss: 0.5552
Epoch [240/250], Loss: 0.1291, Val Loss: 0.6115
Epoch [241/250], Loss: 0.2823, Val Loss: 0.5624
Epoch [242/250], Loss: 0.1129, Val Loss: 0.5678
Epoch [243/250], Loss: 0.1624, Val Loss: 0.5204
Epoch [244/250], Loss: 0.1727, Val Loss: 0.5744
Epoch [245/250], Loss: 0.2308, Val Loss: 0.5139
Epoch [246/250], Loss: 0.1794, Val Loss: 0.5388
Epoch [247/250], Loss: 0.1587, Val Loss: 0.5409
Epoch [248/250], Loss: 0.1642, Val Loss: 0.5830
Epoch [249/250], Loss: 0.2038, Val Loss: 0.5877
Epoch [250/250], Loss: 0.3639, Val Loss: 0.6100
Runtime: 0:01:38.629245
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 1.0309, Val Loss: 1.1573
Epoch [2/250], Loss: 0.6038, Val Loss: 0.8828
Epoch [3/250], Loss: 0.5007, Val Loss: 0.8517
Epoch [4/250], Loss: 0.3905, Val Loss: 1.1626
Epoch [5/250], Loss: 1.9301, Val Loss: 0.8018
Epoch [6/250], Loss: 0.4511, Val Loss: 0.7823
Epoch [7/250], Loss: 0.8126, Val Loss: 0.6935
Epoch [8/250], Loss: 0.4295, Val Loss: 0.6991
Epoch [9/250], Loss: 0.7595, Val Loss: 0.6841
Epoch [10/250], Loss: 0.3374, Val Loss: 0.7595
Epoch [11/250], Loss: 0.6741, Val Loss: 0.8424
Epoch [12/250], Loss: 0.5927, Val Loss: 0.8000
Epoch [13/250], Loss: 0.5436, Val Loss: 0.8515
Epoch [14/250], Loss: 0.4824, Val Loss: 0.6887
Epoch [15/250], Loss: 0.3719, Val Loss: 0.7045
Epoch [16/250], Loss: 0.6585, Val Loss: 0.6824
Epoch [17/250], Loss: 0.7291, Val Loss: 0.6655
Epoch [18/250], Loss: 0.6230, Val Loss: 0.6184
Epoch [19/250], Loss: 0.4120, Val Loss: 0.6186
Epoch [20/250], Loss: 0.5494, Val Loss: 0.6125
Epoch [21/250], Loss: 0.4049, Val Loss: 0.6583
Epoch [22/250], Loss: 0.5972, Val Loss: 0.6250
Epoch [23/250], Loss: 0.5506, Val Loss: 0.5713
Epoch [24/250], Loss: 0.2425, Val Loss: 0.6436
Epoch [25/250], Loss: 0.4162, Val Loss: 0.6495
Epoch [26/250], Loss: 0.3374, Val Loss: 0.5950
Epoch [27/250], Loss: 0.5085, Val Loss: 0.6039
Epoch [28/250], Loss: 0.3595, Val Loss: 0.8309
Epoch [29/250], Loss: 0.9055, Val Loss: 0.5634
Epoch [30/250], Loss: 0.2116, Val Loss: 0.5616
Epoch [31/250], Loss: 0.3060, Val Loss: 0.5569
Epoch [32/250], Loss: 0.3194, Val Loss: 0.5984
Epoch [33/250], Loss: 0.7579, Val Loss: 0.5802
Epoch [34/250], Loss: 0.5042, Val Loss: 0.5683
Epoch [35/250], Loss: 0.2501, Val Loss: 0.6374
Epoch [36/250], Loss: 0.5116, Val Loss: 0.6030
Epoch [37/250], Loss: 0.2730, Val Loss: 0.5351
Epoch [38/250], Loss: 0.2549, Val Loss: 0.5382
Epoch [39/250], Loss: 0.3417, Val Loss: 0.5791
Epoch [40/250], Loss: 0.3033, Val Loss: 0.5266
Epoch [41/250], Loss: 0.2946, Val Loss: 0.5698
Epoch [42/250], Loss: 0.2929, Val Loss: 0.5352
Epoch [43/250], Loss: 0.4753, Val Loss: 0.5573
Epoch [44/250], Loss: 0.3055, Val Loss: 0.5270
Epoch [45/250], Loss: 0.2767, Val Loss: 0.6383
Epoch [46/250], Loss: 0.4534, Val Loss: 0.5303
Epoch [47/250], Loss: 0.4679, Val Loss: 0.5539
Epoch [48/250], Loss: 0.4688, Val Loss: 0.6829
Epoch [49/250], Loss: 0.3925, Val Loss: 0.5483
Epoch [50/250], Loss: 0.4275, Val Loss: 0.5656
Epoch [51/250], Loss: 0.5016, Val Loss: 0.5706
Epoch [52/250], Loss: 0.3002, Val Loss: 0.5930
Epoch [53/250], Loss: 0.4622, Val Loss: 0.6133
Epoch [54/250], Loss: 0.2008, Val Loss: 0.5401
Epoch [55/250], Loss: 0.2231, Val Loss: 0.5267
Epoch [56/250], Loss: 0.2610, Val Loss: 0.5627
Epoch [57/250], Loss: 0.2614, Val Loss: 0.5592
Epoch [58/250], Loss: 0.3845, Val Loss: 0.6781
Epoch [59/250], Loss: 0.2078, Val Loss: 0.5277
Epoch [60/250], Loss: 0.3063, Val Loss: 0.6389
Epoch [61/250], Loss: 0.3125, Val Loss: 0.5569
Epoch [62/250], Loss: 0.2799, Val Loss: 0.5793
Epoch [63/250], Loss: 0.3933, Val Loss: 0.6075
Epoch [64/250], Loss: 0.2441, Val Loss: 0.5731
Epoch [65/250], Loss: 0.2070, Val Loss: 0.6786
Epoch [66/250], Loss: 0.2882, Val Loss: 0.5973
Epoch [67/250], Loss: 0.3332, Val Loss: 0.5259
Epoch [68/250], Loss: 0.4054, Val Loss: 0.5500
Epoch [69/250], Loss: 0.8300, Val Loss: 0.5777
Epoch [70/250], Loss: 0.4966, Val Loss: 0.5203
Epoch [71/250], Loss: 0.2970, Val Loss: 0.6050
Epoch [72/250], Loss: 0.4034, Val Loss: 0.5533
Epoch [73/250], Loss: 0.2247, Val Loss: 0.5247
Epoch [74/250], Loss: 0.2213, Val Loss: 0.4989
Epoch [75/250], Loss: 0.3775, Val Loss: 0.5380
Epoch [76/250], Loss: 0.4116, Val Loss: 0.5681
Epoch [77/250], Loss: 0.8828, Val Loss: 0.5266
Epoch [78/250], Loss: 0.4670, Val Loss: 0.8374
Epoch [79/250], Loss: 0.5086, Val Loss: 0.5358
Epoch [80/250], Loss: 1.4418, Val Loss: 0.5296
Epoch [81/250], Loss: 0.2938, Val Loss: 0.5682
Epoch [82/250], Loss: 0.3565, Val Loss: 0.5694
Epoch [83/250], Loss: 0.1507, Val Loss: 0.5784
Epoch [84/250], Loss: 0.2731, Val Loss: 0.5373
Epoch [85/250], Loss: 0.3258, Val Loss: 0.5686
Epoch [86/250], Loss: 0.1891, Val Loss: 0.5253
Epoch [87/250], Loss: 0.3112, Val Loss: 0.5084
Epoch [88/250], Loss: 0.1786, Val Loss: 0.5489
Epoch [89/250], Loss: 0.4278, Val Loss: 0.5617
Epoch [90/250], Loss: 0.1936, Val Loss: 0.5239
Epoch [91/250], Loss: 0.1716, Val Loss: 0.5258
Epoch [92/250], Loss: 0.3025, Val Loss: 0.7510
Epoch [93/250], Loss: 0.1844, Val Loss: 0.5459
Epoch [94/250], Loss: 0.2231, Val Loss: 0.5316
Epoch [95/250], Loss: 0.3652, Val Loss: 0.5789
Epoch [96/250], Loss: 0.1625, Val Loss: 0.5629
Epoch [97/250], Loss: 0.4110, Val Loss: 0.5567
Epoch [98/250], Loss: 0.1785, Val Loss: 0.5388
Epoch [99/250], Loss: 0.2449, Val Loss: 0.5259
Epoch [100/250], Loss: 0.1813, Val Loss: 0.5092
Epoch [101/250], Loss: 0.2963, Val Loss: 0.5030
Epoch [102/250], Loss: 0.2065, Val Loss: 0.6085
Epoch [103/250], Loss: 1.0010, Val Loss: 0.6165
Epoch [104/250], Loss: 0.2070, Val Loss: 0.5208
Epoch [105/250], Loss: 0.5085, Val Loss: 0.5096
Epoch [106/250], Loss: 0.1575, Val Loss: 0.5450
Epoch [107/250], Loss: 0.2401, Val Loss: 0.5344
Epoch [108/250], Loss: 1.0945, Val Loss: 0.6262
Epoch [109/250], Loss: 0.2296, Val Loss: 0.6171
Epoch [110/250], Loss: 0.2746, Val Loss: 0.5511
Epoch [111/250], Loss: 0.1452, Val Loss: 0.5410
Epoch [112/250], Loss: 0.3289, Val Loss: 0.5336
Epoch [113/250], Loss: 0.2264, Val Loss: 0.6308
Epoch [114/250], Loss: 0.2389, Val Loss: 0.5648
Epoch [115/250], Loss: 0.2223, Val Loss: 0.6494
Epoch [116/250], Loss: 0.6484, Val Loss: 0.5649
Epoch [117/250], Loss: 0.5183, Val Loss: 0.6811
Epoch [118/250], Loss: 0.4593, Val Loss: 0.5186
Epoch [119/250], Loss: 0.5030, Val Loss: 0.5302
Epoch [120/250], Loss: 0.5432, Val Loss: 0.5547
Epoch [121/250], Loss: 0.3322, Val Loss: 0.5165
Epoch [122/250], Loss: 0.1599, Val Loss: 0.5092
Epoch [123/250], Loss: 0.2197, Val Loss: 0.5150
Epoch [124/250], Loss: 0.1766, Val Loss: 0.5258
Epoch [125/250], Loss: 0.2597, Val Loss: 0.5134
Epoch [126/250], Loss: 0.1621, Val Loss: 0.5318
Epoch [127/250], Loss: 0.2526, Val Loss: 0.5189
Epoch [128/250], Loss: 0.2912, Val Loss: 0.5421
Epoch [129/250], Loss: 0.2243, Val Loss: 0.6211
Epoch [130/250], Loss: 0.4013, Val Loss: 0.6779
Epoch [131/250], Loss: 0.1598, Val Loss: 0.5097
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 1.2231, Val Loss: 1.1415
Epoch [2/250], Loss: 0.7338, Val Loss: 0.9006
Epoch [3/250], Loss: 0.6067, Val Loss: 0.8327
Epoch [4/250], Loss: 0.5912, Val Loss: 0.7500
Epoch [5/250], Loss: 0.6561, Val Loss: 0.7733
Epoch [6/250], Loss: 0.7109, Val Loss: 0.8100
Epoch [7/250], Loss: 1.0680, Val Loss: 0.7004
Epoch [8/250], Loss: 0.9862, Val Loss: 0.7128
Epoch [9/250], Loss: 0.8109, Val Loss: 0.9113
Epoch [10/250], Loss: 0.3971, Val Loss: 0.7379
Epoch [11/250], Loss: 0.6991, Val Loss: 0.6849
Epoch [12/250], Loss: 0.6204, Val Loss: 0.7369
Epoch [13/250], Loss: 0.2592, Val Loss: 0.6766
Epoch [14/250], Loss: 0.3506, Val Loss: 0.6757
Epoch [15/250], Loss: 0.8336, Val Loss: 0.6638
Epoch [16/250], Loss: 0.2545, Val Loss: 0.6520
Epoch [17/250], Loss: 0.8130, Val Loss: 0.5917
Epoch [18/250], Loss: 0.4666, Val Loss: 0.7048
Epoch [19/250], Loss: 0.5379, Val Loss: 0.8041
Epoch [20/250], Loss: 0.3477, Val Loss: 0.5901
Epoch [21/250], Loss: 0.3652, Val Loss: 0.5710
Epoch [22/250], Loss: 0.3560, Val Loss: 0.5904
Epoch [23/250], Loss: 0.3110, Val Loss: 0.5713
Epoch [24/250], Loss: 0.3667, Val Loss: 0.6439
Epoch [25/250], Loss: 1.4201, Val Loss: 0.6932
Epoch [26/250], Loss: 0.5173, Val Loss: 0.6263
Epoch [27/250], Loss: 0.3114, Val Loss: 0.5990
Epoch [28/250], Loss: 0.3616, Val Loss: 0.6238
Epoch [29/250], Loss: 0.1801, Val Loss: 0.5654
Epoch [30/250], Loss: 0.4784, Val Loss: 0.5560
Epoch [31/250], Loss: 0.4300, Val Loss: 0.5843
Epoch [32/250], Loss: 0.2424, Val Loss: 0.5750
Epoch [33/250], Loss: 1.4835, Val Loss: 0.7121
Epoch [34/250], Loss: 0.3930, Val Loss: 0.6312
Epoch [35/250], Loss: 0.4265, Val Loss: 0.5770
Epoch [36/250], Loss: 0.4591, Val Loss: 0.5335
Epoch [37/250], Loss: 0.2356, Val Loss: 0.5451
Epoch [38/250], Loss: 0.5542, Val Loss: 0.6011
Epoch [39/250], Loss: 0.2104, Val Loss: 0.6376
Epoch [40/250], Loss: 0.3409, Val Loss: 0.6611
Epoch [41/250], Loss: 0.3554, Val Loss: 0.5792
Epoch [42/250], Loss: 0.3783, Val Loss: 0.5721
Epoch [43/250], Loss: 0.4625, Val Loss: 0.5618
Epoch [44/250], Loss: 0.3795, Val Loss: 0.5511
Epoch [45/250], Loss: 0.3943, Val Loss: 0.5691
Epoch [46/250], Loss: 0.5497, Val Loss: 0.6562
Epoch [47/250], Loss: 0.2051, Val Loss: 0.5891
Epoch [48/250], Loss: 0.3066, Val Loss: 0.6459
Epoch [49/250], Loss: 0.2733, Val Loss: 0.5834
Epoch [50/250], Loss: 0.3036, Val Loss: 0.5708
Epoch [51/250], Loss: 0.2791, Val Loss: 0.5768
Epoch [52/250], Loss: 0.4662, Val Loss: 0.5523
Epoch [53/250], Loss: 0.2095, Val Loss: 0.6954
Epoch [54/250], Loss: 0.3133, Val Loss: 0.5961
Epoch [55/250], Loss: 0.3014, Val Loss: 0.5971
Epoch [56/250], Loss: 0.2445, Val Loss: 0.6161
Epoch [57/250], Loss: 0.5470, Val Loss: 0.5814
Epoch [58/250], Loss: 0.1981, Val Loss: 0.5363
Epoch [59/250], Loss: 0.2544, Val Loss: 0.6121
Epoch [60/250], Loss: 0.3938, Val Loss: 0.6163
Epoch [61/250], Loss: 0.3908, Val Loss: 0.6637
Epoch [62/250], Loss: 0.3196, Val Loss: 0.5717
Epoch [63/250], Loss: 0.3498, Val Loss: 0.5571
Epoch [64/250], Loss: 0.2515, Val Loss: 0.6065
Epoch [65/250], Loss: 0.3323, Val Loss: 0.6017
Epoch [66/250], Loss: 0.3567, Val Loss: 0.5769
Epoch [67/250], Loss: 0.1961, Val Loss: 0.5369
Epoch [68/250], Loss: 0.4136, Val Loss: 0.5986
Epoch [69/250], Loss: 0.2183, Val Loss: 0.5481
Epoch [70/250], Loss: 0.2904, Val Loss: 0.5523
Epoch [71/250], Loss: 0.3910, Val Loss: 0.7144
Epoch [72/250], Loss: 0.2061, Val Loss: 0.5538
Epoch [73/250], Loss: 0.2032, Val Loss: 0.5280
Epoch [74/250], Loss: 0.3599, Val Loss: 0.6083
Epoch [75/250], Loss: 0.3049, Val Loss: 0.5203
Epoch [76/250], Loss: 0.2101, Val Loss: 0.5339
Epoch [77/250], Loss: 0.2362, Val Loss: 0.5260
Epoch [78/250], Loss: 0.3390, Val Loss: 0.5975
Epoch [79/250], Loss: 0.3793, Val Loss: 0.6090
Epoch [80/250], Loss: 0.6986, Val Loss: 0.5729
Epoch [81/250], Loss: 0.2172, Val Loss: 0.5708
Epoch [82/250], Loss: 0.2735, Val Loss: 0.5672
Epoch [83/250], Loss: 0.2728, Val Loss: 0.5755
Epoch [84/250], Loss: 0.3434, Val Loss: 0.6461
Epoch [85/250], Loss: 0.3494, Val Loss: 0.5593
Epoch [86/250], Loss: 0.3235, Val Loss: 0.5487
Epoch [87/250], Loss: 0.3081, Val Loss: 0.5678
Epoch [88/250], Loss: 0.3538, Val Loss: 0.5586
Epoch [89/250], Loss: 0.2499, Val Loss: 0.5562
Epoch [90/250], Loss: 0.2550, Val Loss: 0.5498
Epoch [91/250], Loss: 0.2221, Val Loss: 0.5289
Epoch [92/250], Loss: 0.1874, Val Loss: 0.5400
Epoch [93/250], Loss: 0.2501, Val Loss: 0.5485
Epoch [94/250], Loss: 0.2748, Val Loss: 0.5309
Epoch [95/250], Loss: 0.3366, Val Loss: 0.5315
Epoch [96/250], Loss: 0.2646, Val Loss: 0.5064
Epoch [97/250], Loss: 0.2976, Val Loss: 0.5340
Epoch [98/250], Loss: 0.2618, Val Loss: 0.5465
Epoch [99/250], Loss: 0.3993, Val Loss: 0.5644
Epoch [100/250], Loss: 0.9785, Val Loss: 0.5420
Epoch [101/250], Loss: 0.2993, Val Loss: 0.5655
Epoch [102/250], Loss: 0.2772, Val Loss: 0.5962
Epoch [103/250], Loss: 0.3395, Val Loss: 0.5781
Epoch [104/250], Loss: 0.2759, Val Loss: 0.5682
Epoch [105/250], Loss: 0.4064, Val Loss: 0.5200
Epoch [106/250], Loss: 0.4545, Val Loss: 0.5739
Epoch [107/250], Loss: 0.2961, Val Loss: 0.5271
Epoch [108/250], Loss: 0.3325, Val Loss: 0.5608
Epoch [109/250], Loss: 0.4285, Val Loss: 0.5347
Epoch [110/250], Loss: 0.2618, Val Loss: 0.5000
Epoch [111/250], Loss: 0.4046, Val Loss: 0.5442
Epoch [112/250], Loss: 0.2187, Val Loss: 0.5350
Epoch [113/250], Loss: 0.1771, Val Loss: 0.5067
Epoch [114/250], Loss: 0.2075, Val Loss: 0.5044
Epoch [115/250], Loss: 0.1987, Val Loss: 0.5311
Epoch [116/250], Loss: 0.3488, Val Loss: 0.5564
Epoch [117/250], Loss: 0.1991, Val Loss: 0.5215
Epoch [118/250], Loss: 0.2422, Val Loss: 0.5304
Epoch [119/250], Loss: 0.2450, Val Loss: 0.6403
Epoch [120/250], Loss: 0.2240, Val Loss: 0.4856
Epoch [121/250], Loss: 0.2681, Val Loss: 0.5089
Epoch [122/250], Loss: 0.2249, Val Loss: 0.5351
Epoch [123/250], Loss: 0.2464, Val Loss: 0.5023
Epoch [124/250], Loss: 0.3191, Val Loss: 0.5848
Epoch [125/250], Loss: 0.5666, Val Loss: 0.5256
Epoch [126/250], Loss: 0.2362, Val Loss: 0.5303
Epoch [127/250], Loss: 0.2608, Val Loss: 0.5191
Epoch [128/250], Loss: 0.2319, Val Loss: 0.5211
Epoch [129/250], Loss: 0.3822, Val Loss: 0.5356
Epoch [130/250], Loss: 0.2189, Val Loss: 0.6152
Epoch [131/250], Loss: 0.4990, Val Loss: 0.5574
Epoch [132/250], Loss: 0.1509, Val Loss: 0.5707
Epoch [133/250], Loss: 0.3327, Val Loss: 0.5327
Epoch [134/250], Loss: 0.4798, Val Loss: 0.5297
Epoch [135/250], Loss: 0.2566, Val Loss: 0.5040
Epoch [136/250], Loss: 0.2722, Val Loss: 0.5063
Epoch [137/250], Loss: 0.3821, Val Loss: 0.5512
Epoch [138/250], Loss: 0.3189, Val Loss: 0.5106
Epoch [139/250], Loss: 0.4299, Val Loss: 0.5871
Epoch [140/250], Loss: 0.1771, Val Loss: 0.4816
Epoch [141/250], Loss: 0.2343, Val Loss: 0.5012
Epoch [142/250], Loss: 0.2347, Val Loss: 0.5015
Epoch [143/250], Loss: 0.1409, Val Loss: 0.5172
Epoch [144/250], Loss: 0.2441, Val Loss: 0.5470
Epoch [145/250], Loss: 0.2568, Val Loss: 0.5049
Epoch [146/250], Loss: 0.2158, Val Loss: 0.5083
Epoch [147/250], Loss: 0.4568, Val Loss: 0.5582
Epoch [148/250], Loss: 0.3912, Val Loss: 0.5167
Epoch [149/250], Loss: 0.2901, Val Loss: 0.5431
Epoch [150/250], Loss: 0.6297, Val Loss: 0.5316
Epoch [151/250], Loss: 0.4093, Val Loss: 0.5149
Epoch [152/250], Loss: 0.2810, Val Loss: 0.5083
Epoch [153/250], Loss: 1.1058, Val Loss: 0.5009
Epoch [154/250], Loss: 0.2628, Val Loss: 0.5075
Epoch [155/250], Loss: 0.2890, Val Loss: 0.5227
Epoch [156/250], Loss: 0.2226, Val Loss: 0.5623
Epoch [157/250], Loss: 0.2128, Val Loss: 0.5675
Epoch [158/250], Loss: 0.3239, Val Loss: 0.5090
Epoch [159/250], Loss: 0.3411, Val Loss: 0.5529
Epoch [160/250], Loss: 0.1517, Val Loss: 0.5025
Epoch [161/250], Loss: 0.3476, Val Loss: 0.5701
Epoch [162/250], Loss: 0.1732, Val Loss: 0.4905
Epoch [163/250], Loss: 0.2485, Val Loss: 0.4786
Epoch [164/250], Loss: 0.1900, Val Loss: 0.4945
Epoch [165/250], Loss: 0.3845, Val Loss: 0.4865
Epoch [166/250], Loss: 0.1966, Val Loss: 0.4976
Epoch [167/250], Loss: 0.2083, Val Loss: 0.5050
Epoch [168/250], Loss: 0.3431, Val Loss: 0.5994
Epoch [169/250], Loss: 0.2372, Val Loss: 0.6234
Epoch [170/250], Loss: 0.2128, Val Loss: 0.5041
Epoch [171/250], Loss: 0.2637, Val Loss: 0.4839
Epoch [172/250], Loss: 0.3500, Val Loss: 0.5728
Epoch [173/250], Loss: 0.2658, Val Loss: 0.5382
Epoch [174/250], Loss: 0.1697, Val Loss: 0.4896
Epoch [175/250], Loss: 0.3485, Val Loss: 0.5415
Epoch [176/250], Loss: 0.1565, Val Loss: 0.4926
Epoch [177/250], Loss: 0.2203, Val Loss: 0.4871
Epoch [178/250], Loss: 0.1505, Val Loss: 0.4911
Epoch [179/250], Loss: 0.2161, Val Loss: 0.5670
Epoch [180/250], Loss: 0.2591, Val Loss: 0.5209
Epoch [181/250], Loss: 0.2639, Val Loss: 0.5349
Epoch [182/250], Loss: 0.2613, Val Loss: 0.5781
Epoch [183/250], Loss: 0.3802, Val Loss: 0.5084
Epoch [184/250], Loss: 0.1361, Val Loss: 0.5154
Epoch [185/250], Loss: 0.1375, Val Loss: 0.5074
Epoch [186/250], Loss: 0.1838, Val Loss: 0.5010
Epoch [187/250], Loss: 0.3559, Val Loss: 0.5000
Epoch [188/250], Loss: 0.1778, Val Loss: 0.4971
Epoch [189/250], Loss: 0.3570, Val Loss: 0.5454
Epoch [190/250], Loss: 0.1766, Val Loss: 0.4936
Epoch [191/250], Loss: 0.2258, Val Loss: 0.5038
Epoch [192/250], Loss: 0.2926, Val Loss: 0.5040
Epoch [193/250], Loss: 0.2826, Val Loss: 0.5023
Epoch [194/250], Loss: 0.2395, Val Loss: 0.5323
Epoch [195/250], Loss: 0.3177, Val Loss: 0.5375
Epoch [196/250], Loss: 0.1845, Val Loss: 0.5356
Epoch [197/250], Loss: 0.3457, Val Loss: 0.5150
Epoch [198/250], Loss: 0.2189, Val Loss: 0.5572
Epoch [199/250], Loss: 0.3223, Val Loss: 0.4935
Epoch [200/250], Loss: 0.3106, Val Loss: 0.5619
Epoch [201/250], Loss: 0.2780, Val Loss: 0.5317
Epoch [202/250], Loss: 0.2402, Val Loss: 0.5767
Epoch [203/250], Loss: 0.2772, Val Loss: 0.4977
Epoch [204/250], Loss: 0.2648, Val Loss: 0.5129
Epoch [205/250], Loss: 0.4001, Val Loss: 0.5192
Epoch [206/250], Loss: 0.2108, Val Loss: 0.5169
Epoch [207/250], Loss: 0.2608, Val Loss: 0.5254
Epoch [208/250], Loss: 0.2390, Val Loss: 0.5209
Epoch [209/250], Loss: 0.2775, Val Loss: 0.5313
Epoch [210/250], Loss: 0.3940, Val Loss: 0.5127
Epoch [211/250], Loss: 0.2747, Val Loss: 0.5134
Epoch [212/250], Loss: 0.2084, Val Loss: 0.6520
Epoch [213/250], Loss: 1.4055, Val Loss: 0.5417
Epoch [214/250], Loss: 0.1898, Val Loss: 0.5063
Epoch [215/250], Loss: 0.2758, Val Loss: 0.5506
Epoch [216/250], Loss: 0.5885, Val Loss: 0.5302
Epoch [217/250], Loss: 0.3305, Val Loss: 0.5370
Epoch [218/250], Loss: 0.2401, Val Loss: 0.4959
Epoch [219/250], Loss: 0.2115, Val Loss: 0.5017
Epoch [220/250], Loss: 0.5064, Val Loss: 0.5248
Epoch [221/250], Loss: 0.5382, Val Loss: 0.5190
Epoch [222/250], Loss: 0.4023, Val Loss: 0.5664
Epoch [223/250], Loss: 0.1985, Val Loss: 0.5018
Epoch [224/250], Loss: 0.1593, Val Loss: 0.5166
Epoch [225/250], Loss: 0.2293, Val Loss: 0.4728
Epoch [226/250], Loss: 0.2155, Val Loss: 0.4744
Epoch [227/250], Loss: 0.2295, Val Loss: 0.5274
Epoch [228/250], Loss: 0.3062, Val Loss: 0.5060
Epoch [229/250], Loss: 0.3638, Val Loss: 0.5504
Epoch [230/250], Loss: 0.3682, Val Loss: 0.5411
Epoch [231/250], Loss: 0.1509, Val Loss: 0.5171
Epoch [232/250], Loss: 0.2238, Val Loss: 0.5184
Epoch [233/250], Loss: 0.2284, Val Loss: 0.4867
Epoch [234/250], Loss: 0.1687, Val Loss: 0.5463
Epoch [235/250], Loss: 0.6066, Val Loss: 0.4895
Epoch [236/250], Loss: 0.2422, Val Loss: 0.5224
Epoch [237/250], Loss: 0.2308, Val Loss: 0.4845
Epoch [238/250], Loss: 0.3379, Val Loss: 0.5272
Epoch [239/250], Loss: 0.2477, Val Loss: 0.4858
Epoch [240/250], Loss: 0.2850, Val Loss: 0.5030
Epoch [241/250], Loss: 0.3221, Val Loss: 0.4943
Epoch [242/250], Loss: 0.5754, Val Loss: 0.5987
Epoch [243/250], Loss: 0.2676, Val Loss: 0.5209
Epoch [244/250], Loss: 0.2568, Val Loss: 0.4749
Epoch [245/250], Loss: 0.1471, Val Loss: 0.5468
Epoch [246/250], Loss: 0.1713, Val Loss: 0.5225
Epoch [247/250], Loss: 0.1672, Val Loss: 0.5030
Epoch [248/250], Loss: 0.2583, Val Loss: 0.5043
Epoch [249/250], Loss: 0.2384, Val Loss: 0.5683
Epoch [250/250], Loss: 0.2909, Val Loss: 0.6031
Runtime: 0:01:33.145890
R^2 Score: 0.8917
RMSE: 0.7451
MAE: 0.1963
MAPE: 17.14%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 0.9040, Val Loss: 0.9004
Epoch [2/250], Loss: 0.6034, Val Loss: 0.8465
Epoch [3/250], Loss: 0.4978, Val Loss: 0.8406
Epoch [4/250], Loss: 0.5989, Val Loss: 0.8757
Epoch [5/250], Loss: 0.7730, Val Loss: 0.7150
Epoch [6/250], Loss: 1.2464, Val Loss: 0.7620
Epoch [7/250], Loss: 0.5679, Val Loss: 0.8046
Epoch [8/250], Loss: 0.6390, Val Loss: 1.1377
Epoch [9/250], Loss: 0.6871, Val Loss: 0.7008
Epoch [10/250], Loss: 0.5561, Val Loss: 0.6880
Epoch [11/250], Loss: 0.3877, Val Loss: 0.6911
Epoch [12/250], Loss: 0.5699, Val Loss: 0.7533
Epoch [13/250], Loss: 0.5322, Val Loss: 0.6914
Epoch [14/250], Loss: 0.6957, Val Loss: 0.7107
Epoch [15/250], Loss: 0.4636, Val Loss: 0.6041
Epoch [16/250], Loss: 0.8403, Val Loss: 0.7009
Epoch [17/250], Loss: 0.5059, Val Loss: 0.7052
Epoch [18/250], Loss: 0.6486, Val Loss: 0.6760
Epoch [19/250], Loss: 0.5141, Val Loss: 0.7048
Epoch [20/250], Loss: 0.7090, Val Loss: 0.7239
Epoch [21/250], Loss: 0.7500, Val Loss: 0.6849
Epoch [22/250], Loss: 0.4331, Val Loss: 0.6362
Epoch [23/250], Loss: 0.2646, Val Loss: 0.6637
Epoch [24/250], Loss: 0.8634, Val Loss: 0.6064
Epoch [25/250], Loss: 0.3285, Val Loss: 0.7634
Epoch [26/250], Loss: 0.2902, Val Loss: 0.6584
Epoch [27/250], Loss: 0.5366, Val Loss: 0.5892
Epoch [28/250], Loss: 0.3761, Val Loss: 0.6313
Epoch [29/250], Loss: 0.4127, Val Loss: 0.6132
Epoch [30/250], Loss: 0.5033, Val Loss: 0.5777
Epoch [31/250], Loss: 0.4434, Val Loss: 0.6659
Epoch [32/250], Loss: 0.9624, Val Loss: 0.6914
Epoch [33/250], Loss: 0.5203, Val Loss: 0.6847
Epoch [34/250], Loss: 0.8384, Val Loss: 0.6108
Epoch [35/250], Loss: 0.2789, Val Loss: 0.5856
Epoch [36/250], Loss: 0.3775, Val Loss: 0.5855
Epoch [37/250], Loss: 0.3739, Val Loss: 0.5622
Epoch [38/250], Loss: 0.2704, Val Loss: 0.6081
Epoch [39/250], Loss: 0.5511, Val Loss: 0.6875
Epoch [40/250], Loss: 0.5764, Val Loss: 0.6413
Epoch [41/250], Loss: 0.4359, Val Loss: 0.5648
Epoch [42/250], Loss: 0.3505, Val Loss: 0.6094
Epoch [43/250], Loss: 0.4029, Val Loss: 0.6459
Epoch [44/250], Loss: 0.4242, Val Loss: 0.5861
Epoch [45/250], Loss: 0.3974, Val Loss: 0.6217
Epoch [46/250], Loss: 0.3787, Val Loss: 0.6409
Epoch [47/250], Loss: 0.3066, Val Loss: 0.5567
Epoch [48/250], Loss: 0.2803, Val Loss: 0.7774
Epoch [49/250], Loss: 0.3512, Val Loss: 0.5701
Epoch [50/250], Loss: 0.3026, Val Loss: 0.5815
Epoch [51/250], Loss: 0.7018, Val Loss: 0.5710
Epoch [52/250], Loss: 0.6912, Val Loss: 0.5662
Epoch [53/250], Loss: 0.2627, Val Loss: 0.5473
Epoch [54/250], Loss: 0.4545, Val Loss: 0.5819
Epoch [55/250], Loss: 0.3437, Val Loss: 0.5449
Epoch [56/250], Loss: 0.2561, Val Loss: 0.5905
Epoch [57/250], Loss: 0.2429, Val Loss: 0.5322
Epoch [58/250], Loss: 0.5961, Val Loss: 0.5553
Epoch [59/250], Loss: 0.3476, Val Loss: 0.5451
Epoch [60/250], Loss: 0.4795, Val Loss: 0.5985
Epoch [61/250], Loss: 0.5003, Val Loss: 0.5740
Epoch [62/250], Loss: 0.2888, Val Loss: 0.6265
Epoch [63/250], Loss: 0.3908, Val Loss: 0.5548
Epoch [64/250], Loss: 0.2153, Val Loss: 0.5641
Epoch [65/250], Loss: 0.3139, Val Loss: 0.5912
Epoch [66/250], Loss: 0.3133, Val Loss: 0.6716
Epoch [67/250], Loss: 0.2548, Val Loss: 0.5360
Epoch [68/250], Loss: 0.4258, Val Loss: 0.5551
Epoch [69/250], Loss: 0.2273, Val Loss: 0.5160
Epoch [70/250], Loss: 0.3344, Val Loss: 0.5484
Epoch [71/250], Loss: 0.3156, Val Loss: 0.6135
Epoch [72/250], Loss: 0.3516, Val Loss: 0.5474
Epoch [73/250], Loss: 1.1526, Val Loss: 0.5637
Epoch [74/250], Loss: 0.1931, Val Loss: 0.5794
Epoch [75/250], Loss: 0.2697, Val Loss: 0.5308
Epoch [76/250], Loss: 0.2333, Val Loss: 0.5447
Epoch [77/250], Loss: 0.2780, Val Loss: 0.5859
Epoch [78/250], Loss: 0.2665, Val Loss: 0.5324
Epoch [79/250], Loss: 0.3010, Val Loss: 0.5230
Epoch [80/250], Loss: 0.2497, Val Loss: 0.6873
Epoch [81/250], Loss: 0.2959, Val Loss: 0.5632
Epoch [82/250], Loss: 1.0156, Val Loss: 0.5572
Epoch [83/250], Loss: 0.2591, Val Loss: 0.5544
Epoch [84/250], Loss: 0.5218, Val Loss: 0.6843
Epoch [85/250], Loss: 0.4760, Val Loss: 0.6252
Epoch [86/250], Loss: 0.7363, Val Loss: 0.5326
Epoch [87/250], Loss: 0.3230, Val Loss: 0.5641
Epoch [88/250], Loss: 0.4311, Val Loss: 0.5307
Epoch [89/250], Loss: 0.2535, Val Loss: 0.5415
Epoch [90/250], Loss: 0.2402, Val Loss: 0.5278
Epoch [91/250], Loss: 0.2081, Val Loss: 0.5171
Epoch [92/250], Loss: 0.2636, Val Loss: 0.5300
Epoch [93/250], Loss: 0.2370, Val Loss: 0.5324
Epoch [94/250], Loss: 0.4865, Val Loss: 0.6148
Epoch [95/250], Loss: 0.3218, Val Loss: 0.5932
Epoch [96/250], Loss: 0.2912, Val Loss: 0.5316
Epoch [97/250], Loss: 0.3814, Val Loss: 0.4898
Epoch [98/250], Loss: 0.3240, Val Loss: 0.5610
Epoch [99/250], Loss: 0.2994, Val Loss: 0.5604
Epoch [100/250], Loss: 0.4177, Val Loss: 0.6460
Epoch [101/250], Loss: 0.2547, Val Loss: 0.5138
Epoch [102/250], Loss: 0.6443, Val Loss: 0.6141
Epoch [103/250], Loss: 0.3259, Val Loss: 0.5468
Epoch [104/250], Loss: 0.2547, Val Loss: 0.5067
Epoch [105/250], Loss: 0.2558, Val Loss: 0.5322
Epoch [106/250], Loss: 0.2393, Val Loss: 0.5209
Epoch [107/250], Loss: 0.3570, Val Loss: 0.4993
Epoch [108/250], Loss: 0.3144, Val Loss: 0.6033
Epoch [109/250], Loss: 0.2300, Val Loss: 0.4884
Epoch [110/250], Loss: 0.2088, Val Loss: 0.4927
Epoch [111/250], Loss: 0.6349, Val Loss: 0.7139
Epoch [112/250], Loss: 0.3647, Val Loss: 0.5848
Epoch [113/250], Loss: 0.3205, Val Loss: 0.5177
Epoch [114/250], Loss: 0.3344, Val Loss: 0.5200
Epoch [115/250], Loss: 0.3284, Val Loss: 0.5198
Epoch [116/250], Loss: 0.3245, Val Loss: 0.5389
Epoch [117/250], Loss: 0.4221, Val Loss: 0.5122
Epoch [118/250], Loss: 0.3126, Val Loss: 0.5250
Epoch [119/250], Loss: 0.3901, Val Loss: 0.5068
Epoch [120/250], Loss: 0.3842, Val Loss: 0.5046
Epoch [121/250], Loss: 0.3384, Val Loss: 0.5956
Epoch [122/250], Loss: 0.2924, Val Loss: 0.5465
Epoch [123/250], Loss: 0.2755, Val Loss: 0.6550
Epoch [124/250], Loss: 0.2278, Val Loss: 0.5002
Epoch [125/250], Loss: 0.3702, Val Loss: 0.5059
Epoch [126/250], Loss: 0.2418, Val Loss: 0.5085
Epoch [127/250], Loss: 0.2741, Val Loss: 0.5271
Epoch [128/250], Loss: 0.3926, Val Loss: 0.5444
Epoch [129/250], Loss: 0.2075, Val Loss: 0.5392
Epoch [130/250], Loss: 0.3321, Val Loss: 0.4961
Epoch [131/250], Loss: 0.3609, Val Loss: 0.5365
Epoch [132/250], Loss: 0.2607, Val Loss: 0.5068
Epoch [133/250], Loss: 0.2930, Val Loss: 0.5403
Epoch [134/250], Loss: 0.3316, Val Loss: 0.5272
Epoch [135/250], Loss: 0.2333, Val Loss: 0.5076
Epoch [136/250], Loss: 0.2715, Val Loss: 0.5187
Epoch [137/250], Loss: 0.2744, Val Loss: 0.5070
Epoch [138/250], Loss: 0.2414, Val Loss: 0.5732
Epoch [139/250], Loss: 0.3898, Val Loss: 0.6783
Epoch [140/250], Loss: 0.4405, Val Loss: 0.5198
Epoch [141/250], Loss: 0.2811, Val Loss: 0.5966
Epoch [142/250], Loss: 0.3696, Val Loss: 0.5663
Epoch [143/250], Loss: 0.2251, Val Loss: 0.5383
Epoch [144/250], Loss: 0.3687, Val Loss: 0.5726
Epoch [145/250], Loss: 0.2641, Val Loss: 0.4949
Epoch [146/250], Loss: 0.2603, Val Loss: 0.5073
Epoch [147/250], Loss: 0.3595, Val Loss: 0.5221
Epoch [148/250], Loss: 0.1760, Val Loss: 0.4903
Epoch [149/250], Loss: 0.3704, Val Loss: 0.5275
Epoch [150/250], Loss: 0.2345, Val Loss: 0.5088
Epoch [151/250], Loss: 0.2939, Val Loss: 0.5243
Epoch [152/250], Loss: 0.3208, Val Loss: 0.5290
Epoch [153/250], Loss: 0.2777, Val Loss: 0.5180
Epoch [154/250], Loss: 0.3195, Val Loss: 0.5185
Epoch [155/250], Loss: 0.1806, Val Loss: 0.5183
Epoch [156/250], Loss: 0.3439, Val Loss: 0.5050
Epoch [157/250], Loss: 0.2582, Val Loss: 0.5072
Epoch [158/250], Loss: 0.4481, Val Loss: 0.5235
Epoch [159/250], Loss: 0.1988, Val Loss: 0.5407
Epoch [160/250], Loss: 0.2059, Val Loss: 0.4881
Epoch [161/250], Loss: 0.3507, Val Loss: 0.5460
Epoch [162/250], Loss: 0.1876, Val Loss: 0.5145
Epoch [163/250], Loss: 0.4506, Val Loss: 0.5121
Epoch [164/250], Loss: 0.1833, Val Loss: 0.5265
Epoch [165/250], Loss: 0.2116, Val Loss: 0.4869
Epoch [166/250], Loss: 0.2939, Val Loss: 0.5163
Epoch [167/250], Loss: 0.1336, Val Loss: 0.5386
Epoch [168/250], Loss: 0.4134, Val Loss: 0.6052
Epoch [169/250], Loss: 0.4253, Val Loss: 0.5306
Epoch [170/250], Loss: 0.2869, Val Loss: 0.5330
Epoch [171/250], Loss: 0.9039, Val Loss: 0.5365
Epoch [172/250], Loss: 0.3108, Val Loss: 0.5350
Epoch [173/250], Loss: 0.1701, Val Loss: 0.4985
Epoch [174/250], Loss: 0.2414, Val Loss: 0.5071
Epoch [175/250], Loss: 0.2657, Val Loss: 0.5055
Epoch [176/250], Loss: 0.2831, Val Loss: 0.5532
Epoch [177/250], Loss: 0.2058, Val Loss: 0.5108
Epoch [178/250], Loss: 0.1603, Val Loss: 0.4875
Epoch [179/250], Loss: 0.2114, Val Loss: 0.5099
Epoch [180/250], Loss: 0.2319, Val Loss: 0.5146
Epoch [181/250], Loss: 0.5505, Val Loss: 0.6215
Epoch [182/250], Loss: 0.3227, Val Loss: 0.5288
Epoch [183/250], Loss: 0.3223, Val Loss: 0.5021
Epoch [184/250], Loss: 0.3042, Val Loss: 0.5461
Epoch [185/250], Loss: 0.2592, Val Loss: 0.5421
Epoch [186/250], Loss: 0.4471, Val Loss: 0.4885
Epoch [187/250], Loss: 0.2188, Val Loss: 0.5015
Epoch [188/250], Loss: 0.3250, Val Loss: 0.5052
Epoch [189/250], Loss: 0.3681, Val Loss: 0.5321
Epoch [190/250], Loss: 0.4093, Val Loss: 0.5498
Epoch [191/250], Loss: 0.2386, Val Loss: 0.5269
Epoch [192/250], Loss: 0.3998, Val Loss: 0.5380
Epoch [193/250], Loss: 0.2979, Val Loss: 0.5074
Epoch [194/250], Loss: 0.1793, Val Loss: 0.5019
Epoch [195/250], Loss: 0.2292, Val Loss: 0.6242
Epoch [196/250], Loss: 0.2720, Val Loss: 0.5228
Epoch [197/250], Loss: 0.4904, Val Loss: 0.4834
Epoch [198/250], Loss: 0.2211, Val Loss: 0.5228
Epoch [199/250], Loss: 0.2183, Val Loss: 0.5090
Epoch [200/250], Loss: 0.3894, Val Loss: 0.4969
Epoch [201/250], Loss: 0.4135, Val Loss: 0.5481
Epoch [202/250], Loss: 0.3271, Val Loss: 0.5181
Epoch [203/250], Loss: 0.2523, Val Loss: 0.5281
Epoch [204/250], Loss: 0.2771, Val Loss: 0.5651
Epoch [205/250], Loss: 0.2614, Val Loss: 0.5306
Epoch [206/250], Loss: 0.2259, Val Loss: 0.5039
Epoch [207/250], Loss: 0.2179, Val Loss: 0.4881
Epoch [208/250], Loss: 0.2693, Val Loss: 0.5335
Epoch [209/250], Loss: 0.1969, Val Loss: 0.5873
Epoch [210/250], Loss: 0.2489, Val Loss: 0.5156
Epoch [211/250], Loss: 0.2157, Val Loss: 0.5292
Epoch [212/250], Loss: 0.2905, Val Loss: 0.5636
Epoch [213/250], Loss: 0.3203, Val Loss: 0.5007
Epoch [214/250], Loss: 0.2715, Val Loss: 0.6332
Epoch [215/250], Loss: 0.3430, Val Loss: 0.5608
Epoch [216/250], Loss: 0.3132, Val Loss: 0.5199
Epoch [217/250], Loss: 0.1518, Val Loss: 0.5189
Epoch [218/250], Loss: 0.2284, Val Loss: 0.4963
Epoch [219/250], Loss: 0.2944, Val Loss: 0.4968
Epoch [220/250], Loss: 0.1814, Val Loss: 0.5113
Epoch [221/250], Loss: 0.2329, Val Loss: 0.4995
Epoch [222/250], Loss: 0.2171, Val Loss: 0.5152
Epoch [223/250], Loss: 0.1839, Val Loss: 0.5612
Epoch [224/250], Loss: 0.3192, Val Loss: 0.4774
Epoch [225/250], Loss: 0.1967, Val Loss: 0.5089
Epoch [226/250], Loss: 0.4909, Val Loss: 0.6204
Epoch [227/250], Loss: 0.3123, Val Loss: 0.6207
Epoch [228/250], Loss: 0.5210, Val Loss: 0.5241
Epoch [229/250], Loss: 0.2664, Val Loss: 0.5657
Epoch [230/250], Loss: 0.2877, Val Loss: 0.5270
Epoch [231/250], Loss: 0.2496, Val Loss: 0.5279
Epoch [232/250], Loss: 0.2391, Val Loss: 0.5709
Epoch [233/250], Loss: 0.2654, Val Loss: 0.4941
Epoch [234/250], Loss: 0.3128, Val Loss: 0.5462
Epoch [235/250], Loss: 0.2130, Val Loss: 0.5366
Epoch [236/250], Loss: 0.2193, Val Loss: 0.5310
Epoch [237/250], Loss: 0.1651, Val Loss: 0.4999
Epoch [238/250], Loss: 0.1625, Val Loss: 0.4942
Epoch [239/250], Loss: 0.2223, Val Loss: 0.5184
Epoch [240/250], Loss: 0.2640, Val Loss: 0.4877
Epoch [241/250], Loss: 0.2137, Val Loss: 0.4854
Epoch [242/250], Loss: 0.2079, Val Loss: 0.4919
Epoch [243/250], Loss: 0.4015, Val Loss: 0.5111
Epoch [244/250], Loss: 0.2192, Val Loss: 0.5015
Epoch [245/250], Loss: 0.2310, Val Loss: 0.5208
Epoch [246/250], Loss: 0.3305, Val Loss: 0.5120
Epoch [247/250], Loss: 0.2824, Val Loss: 0.5650
Epoch [248/250], Loss: 0.3269, Val Loss: 0.5672
Epoch [249/250], Loss: 0.3982, Val Loss: 0.5228
Epoch [250/250], Loss: 0.2916, Val Loss: 0.5163
Runtime: 0:01:36.425768
R^2 Score: 0.9082
RMSE: 0.6859
MAE: 0.1867
MAPE: 16.42%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [111, 451, 692, 512, 80] - Result:
Epoch [1/250], Loss: 0.3548, Val Loss: 0.5176
Epoch [2/250], Loss: 0.2066, Val Loss: 0.5477
Epoch [3/250], Loss: 0.3388, Val Loss: 0.5249
Epoch [4/250], Loss: 0.2256, Val Loss: 0.4992
Epoch [5/250], Loss: 0.2767, Val Loss: 0.5689
Epoch [6/250], Loss: 0.1720, Val Loss: 0.5415
Epoch [7/250], Loss: 0.1785, Val Loss: 0.4991
Epoch [8/250], Loss: 0.2048, Val Loss: 0.5122
Epoch [9/250], Loss: 0.2325, Val Loss: 0.5278
Epoch [10/250], Loss: 0.3032, Val Loss: 0.5080
Epoch [11/250], Loss: 0.3281, Val Loss: 0.5505
Epoch [12/250], Loss: 0.3093, Val Loss: 0.5321
Epoch [13/250], Loss: 0.4957, Val Loss: 0.5418
Epoch [14/250], Loss: 0.2681, Val Loss: 0.5971
Epoch [15/250], Loss: 0.2824, Val Loss: 0.5255
Epoch [16/250], Loss: 0.3308, Val Loss: 0.5021
Epoch [17/250], Loss: 0.3154, Val Loss: 0.5477
Epoch [18/250], Loss: 0.1505, Val Loss: 0.5142
Epoch [19/250], Loss: 0.3371, Val Loss: 0.5010
Epoch [20/250], Loss: 0.2469, Val Loss: 0.5276
Epoch [21/250], Loss: 0.2458, Val Loss: 0.5251
Epoch [22/250], Loss: 0.2278, Val Loss: 0.5471
Epoch [23/250], Loss: 0.1875, Val Loss: 0.5245
Epoch [24/250], Loss: 0.1887, Val Loss: 0.4999
Epoch [25/250], Loss: 0.1976, Val Loss: 0.6192
Epoch [26/250], Loss: 0.2438, Val Loss: 0.5074
Epoch [27/250], Loss: 0.1947, Val Loss: 0.5106
Epoch [28/250], Loss: 0.2372, Val Loss: 0.5141
Epoch [29/250], Loss: 0.2104, Val Loss: 0.5241
Epoch [30/250], Loss: 0.2978, Val Loss: 0.5561
Epoch [31/250], Loss: 0.3501, Val Loss: 0.5197
Epoch [32/250], Loss: 0.3655, Val Loss: 0.5132
Epoch [33/250], Loss: 0.2605, Val Loss: 0.4907
Epoch [34/250], Loss: 0.2528, Val Loss: 0.4988
Epoch [35/250], Loss: 0.1822, Val Loss: 0.5201
Epoch [36/250], Loss: 0.2229, Val Loss: 0.5034
Epoch [37/250], Loss: 0.2050, Val Loss: 0.4908
Epoch [38/250], Loss: 0.2483, Val Loss: 0.5100
Epoch [39/250], Loss: 0.1651, Val Loss: 0.5132
Epoch [40/250], Loss: 0.3764, Val Loss: 0.5069
Epoch [41/250], Loss: 0.3347, Val Loss: 0.4953
Epoch [42/250], Loss: 0.2023, Val Loss: 0.5159
Epoch [43/250], Loss: 0.4320, Val Loss: 0.5595
Epoch [44/250], Loss: 0.2398, Val Loss: 0.5192
Epoch [45/250], Loss: 0.4826, Val Loss: 0.5053
Epoch [46/250], Loss: 0.1846, Val Loss: 0.5206
Epoch [47/250], Loss: 0.2555, Val Loss: 0.5073
Epoch [48/250], Loss: 0.1545, Val Loss: 0.5620
Epoch [49/250], Loss: 0.2198, Val Loss: 0.5006
Epoch [50/250], Loss: 0.2687, Val Loss: 0.5100
Epoch [51/250], Loss: 0.2515, Val Loss: 0.5093
Epoch [52/250], Loss: 0.2491, Val Loss: 0.5732
Epoch [53/250], Loss: 0.2684, Val Loss: 0.5103
Epoch [54/250], Loss: 0.2800, Val Loss: 0.5218
Epoch [55/250], Loss: 0.1458, Val Loss: 0.5262
Epoch [56/250], Loss: 0.2388, Val Loss: 0.5198
Epoch [57/250], Loss: 0.2545, Val Loss: 0.5240
Epoch [58/250], Loss: 0.2174, Val Loss: 0.6120
Epoch [59/250], Loss: 0.2944, Val Loss: 0.5269
Epoch [60/250], Loss: 0.2882, Val Loss: 0.5023
Epoch [61/250], Loss: 0.1518, Val Loss: 0.5382
Epoch [62/250], Loss: 0.2809, Val Loss: 0.5023
Epoch [63/250], Loss: 0.2228, Val Loss: 0.5389
Epoch [64/250], Loss: 0.1976, Val Loss: 0.5086
Epoch [65/250], Loss: 0.1988, Val Loss: 0.5321
Epoch [66/250], Loss: 0.1227, Val Loss: 0.5230
Epoch [67/250], Loss: 0.2316, Val Loss: 0.5362
Epoch [68/250], Loss: 0.2007, Val Loss: 0.5390
Epoch [69/250], Loss: 0.2196, Val Loss: 0.5371
Epoch [70/250], Loss: 0.2501, Val Loss: 0.5280
Epoch [71/250], Loss: 0.1653, Val Loss: 0.5356
Epoch [72/250], Loss: 0.3147, Val Loss: 0.5126
Epoch [73/250], Loss: 0.4686, Val Loss: 0.6352
Epoch [74/250], Loss: 0.2151, Val Loss: 0.6401
Epoch [75/250], Loss: 0.4747, Val Loss: 0.5644
Epoch [76/250], Loss: 0.2476, Val Loss: 0.5529
Epoch [77/250], Loss: 0.1908, Val Loss: 0.4975
Epoch [78/250], Loss: 0.2149, Val Loss: 0.5321
Epoch [79/250], Loss: 0.2661, Val Loss: 0.5995
Epoch [80/250], Loss: 0.3051, Val Loss: 0.4977
Epoch [81/250], Loss: 0.3109, Val Loss: 0.5011
Epoch [82/250], Loss: 0.2206, Val Loss: 0.5030
Epoch [83/250], Loss: 0.2990, Val Loss: 0.6456
Epoch [84/250], Loss: 0.2647, Val Loss: 0.5306
Epoch [85/250], Loss: 0.2620, Val Loss: 0.5603
Epoch [86/250], Loss: 0.2699, Val Loss: 0.5196
Epoch [87/250], Loss: 0.1845, Val Loss: 0.4969
Epoch [88/250], Loss: 0.2601, Val Loss: 0.5324
Epoch [89/250], Loss: 0.1823, Val Loss: 0.5312
Epoch [90/250], Loss: 0.2131, Val Loss: 0.5269
Epoch [91/250], Loss: 0.2913, Val Loss: 0.4907
Epoch [92/250], Loss: 0.5320, Val Loss: 0.5307
Epoch [93/250], Loss: 0.4482, Val Loss: 0.5788
Epoch [94/250], Loss: 0.2088, Val Loss: 0.5816
Epoch [95/250], Loss: 0.4229, Val Loss: 0.5142
Epoch [96/250], Loss: 0.2341, Val Loss: 0.5292
Epoch [97/250], Loss: 0.1777, Val Loss: 0.4929
Epoch [98/250], Loss: 0.2402, Val Loss: 0.5039
Epoch [99/250], Loss: 0.1514, Val Loss: 0.5152
Epoch [100/250], Loss: 0.1587, Val Loss: 0.4841
Epoch [101/250], Loss: 0.2523, Val Loss: 0.4804
Epoch [102/250], Loss: 0.3769, Val Loss: 0.5115
Epoch [103/250], Loss: 0.3256, Val Loss: 0.5225
Epoch [104/250], Loss: 0.1876, Val Loss: 0.5187
Epoch [105/250], Loss: 0.2999, Val Loss: 0.5211
Epoch [106/250], Loss: 0.1897, Val Loss: 0.5551
Epoch [107/250], Loss: 0.3295, Val Loss: 0.5174
Epoch [108/250], Loss: 0.2739, Val Loss: 0.5092
Epoch [109/250], Loss: 0.2482, Val Loss: 0.5228
Epoch [110/250], Loss: 0.2141, Val Loss: 0.4972
Epoch [111/250], Loss: 0.2638, Val Loss: 0.5584
Epoch [112/250], Loss: 0.2758, Val Loss: 0.5493
Epoch [113/250], Loss: 0.2761, Val Loss: 0.5558
Epoch [114/250], Loss: 0.2229, Val Loss: 0.5430
Epoch [115/250], Loss: 0.3755, Val Loss: 0.5190
Epoch [116/250], Loss: 0.1876, Val Loss: 0.5135
Epoch [117/250], Loss: 0.3055, Val Loss: 0.4910
Epoch [118/250], Loss: 0.2321, Val Loss: 0.5127
Epoch [119/250], Loss: 0.2300, Val Loss: 0.4863
Epoch [120/250], Loss: 0.2185, Val Loss: 0.5127
Epoch [121/250], Loss: 0.1944, Val Loss: 0.5080
Epoch [122/250], Loss: 0.3108, Val Loss: 0.5260
Epoch [123/250], Loss: 0.1410, Val Loss: 0.5183
Epoch [124/250], Loss: 0.3023, Val Loss: 0.4891
Epoch [125/250], Loss: 0.4267, Val Loss: 0.5180
Epoch [126/250], Loss: 0.3046, Val Loss: 0.5462
Epoch [127/250], Loss: 0.4561, Val Loss: 0.5271
Epoch [128/250], Loss: 0.1793, Val Loss: 0.5189
Epoch [129/250], Loss: 0.2862, Val Loss: 0.5113
Epoch [130/250], Loss: 0.2334, Val Loss: 0.5372
Epoch [131/250], Loss: 0.2310, Val Loss: 0.4839
Epoch [132/250], Loss: 0.2574, Val Loss: 0.5463
Epoch [133/250], Loss: 0.2036, Val Loss: 0.5128
Epoch [134/250], Loss: 0.4024, Val Loss: 0.5265
Epoch [135/250], Loss: 0.2457, Val Loss: 0.5424
Epoch [136/250], Loss: 0.2545, Val Loss: 0.5362
Epoch [137/250], Loss: 0.3014, Val Loss: 0.5241
Epoch [138/250], Loss: 0.2170, Val Loss: 0.5174
Epoch [139/250], Loss: 0.2324, Val Loss: 0.5101
Epoch [140/250], Loss: 0.2384, Val Loss: 0.5176
Epoch [141/250], Loss: 0.2745, Val Loss: 0.5066
Epoch [142/250], Loss: 0.2196, Val Loss: 0.5288
Epoch [143/250], Loss: 0.2353, Val Loss: 0.4849
Epoch [144/250], Loss: 0.2400, Val Loss: 0.5218
Epoch [145/250], Loss: 0.2873, Val Loss: 0.5148
Epoch [146/250], Loss: 0.2342, Val Loss: 0.5396
Epoch [147/250], Loss: 0.2107, Val Loss: 0.5219
Epoch [148/250], Loss: 0.1986, Val Loss: 0.5166
Epoch [149/250], Loss: 0.3083, Val Loss: 0.5037
Epoch [150/250], Loss: 0.3099, Val Loss: 0.5171
Epoch [151/250], Loss: 0.1529, Val Loss: 0.5042
Epoch [152/250], Loss: 0.1841, Val Loss: 0.5817
Epoch [153/250], Loss: 0.2499, Val Loss: 0.5568
Epoch [154/250], Loss: 0.2051, Val Loss: 0.4854
Epoch [155/250], Loss: 0.1559, Val Loss: 0.5020
Epoch [156/250], Loss: 0.2710, Val Loss: 0.5271
Epoch [157/250], Loss: 0.4624, Val Loss: 0.5318
Epoch [158/250], Loss: 0.2222, Val Loss: 0.5048
Epoch [159/250], Loss: 0.1805, Val Loss: 0.5173
Epoch [160/250], Loss: 0.3500, Val Loss: 0.5147
Epoch [161/250], Loss: 0.1916, Val Loss: 0.5424
Epoch [162/250], Loss: 0.2101, Val Loss: 0.5303
Epoch [163/250], Loss: 0.5114, Val Loss: 0.5491
Epoch [164/250], Loss: 0.3624, Val Loss: 0.5449
Epoch [165/250], Loss: 0.2478, Val Loss: 0.5136
Epoch [166/250], Loss: 0.2884, Val Loss: 0.5115
Epoch [167/250], Loss: 0.3691, Val Loss: 0.5249
Epoch [168/250], Loss: 0.2039, Val Loss: 0.5325
Epoch [169/250], Loss: 0.1384, Val Loss: 0.5384
Epoch [170/250], Loss: 0.2872, Val Loss: 0.5570
Epoch [171/250], Loss: 0.3048, Val Loss: 0.5278
Epoch [172/250], Loss: 0.3300, Val Loss: 0.5228
Epoch [173/250], Loss: 0.2491, Val Loss: 0.5656
Epoch [174/250], Loss: 0.2824, Val Loss: 0.5519
Epoch [175/250], Loss: 0.2523, Val Loss: 0.5399
Epoch [176/250], Loss: 0.4037, Val Loss: 0.5518
Epoch [177/250], Loss: 0.3786, Val Loss: 0.5161
Epoch [178/250], Loss: 0.2305, Val Loss: 0.5530
Epoch [179/250], Loss: 0.1938, Val Loss: 0.5164
Epoch [180/250], Loss: 0.1876, Val Loss: 0.4961
Epoch [181/250], Loss: 0.2516, Val Loss: 0.4868
Epoch [182/250], Loss: 0.1894, Val Loss: 0.5702
Epoch [183/250], Loss: 0.2135, Val Loss: 0.4932
Epoch [184/250], Loss: 0.3395, Val Loss: 0.5077
Epoch [185/250], Loss: 0.3595, Val Loss: 0.5435
Epoch [186/250], Loss: 0.2891, Val Loss: 0.5065
Epoch [187/250], Loss: 0.5643, Val Loss: 0.5093
Epoch [188/250], Loss: 0.4998, Val Loss: 0.5665
Epoch [189/250], Loss: 0.2229, Val Loss: 0.5472
Epoch [190/250], Loss: 0.1788, Val Loss: 0.5097
Epoch [191/250], Loss: 0.2234, Val Loss: 0.4888
Epoch [192/250], Loss: 0.2336, Val Loss: 0.5315
Epoch [193/250], Loss: 0.2735, Val Loss: 0.5248
Epoch [194/250], Loss: 0.1584, Val Loss: 0.5095
Epoch [195/250], Loss: 0.1987, Val Loss: 0.5010
Epoch [196/250], Loss: 0.2247, Val Loss: 0.4961
Epoch [197/250], Loss: 0.1664, Val Loss: 0.6282
Epoch [198/250], Loss: 0.3960, Val Loss: 0.5142
Epoch [199/250], Loss: 0.3805, Val Loss: 0.5124
Epoch [200/250], Loss: 0.3858, Val Loss: 0.5265
Epoch [201/250], Loss: 0.1865, Val Loss: 0.4899
Epoch [202/250], Loss: 0.2330, Val Loss: 0.5187
Epoch [203/250], Loss: 0.2267, Val Loss: 0.4970
Epoch [204/250], Loss: 0.3409, Val Loss: 0.5123
Epoch [205/250], Loss: 0.1869, Val Loss: 0.5324
Epoch [206/250], Loss: 0.2305, Val Loss: 0.5108
Epoch [207/250], Loss: 0.1833, Val Loss: 0.5356
Epoch [208/250], Loss: 0.2293, Val Loss: 0.5046
Epoch [209/250], Loss: 0.2186, Val Loss: 0.5077
Epoch [210/250], Loss: 0.2176, Val Loss: 0.4946
Epoch [211/250], Loss: 0.2090, Val Loss: 0.5044
Epoch [212/250], Loss: 0.2649, Val Loss: 0.5470
Epoch [213/250], Loss: 0.3719, Val Loss: 0.5591
Epoch [214/250], Loss: 1.1990, Val Loss: 0.5407
Epoch [215/250], Loss: 0.2967, Val Loss: 0.6545
Epoch [216/250], Loss: 1.1533, Val Loss: 0.5134
Epoch [217/250], Loss: 0.4149, Val Loss: 0.5081
Epoch [218/250], Loss: 0.2235, Val Loss: 0.5168
Epoch [219/250], Loss: 0.1991, Val Loss: 0.5633
Epoch [220/250], Loss: 0.2483, Val Loss: 0.5118
Epoch [221/250], Loss: 0.2490, Val Loss: 0.5566
Epoch [222/250], Loss: 0.1860, Val Loss: 0.5018
Epoch [223/250], Loss: 0.2121, Val Loss: 0.5372
Epoch [224/250], Loss: 0.3206, Val Loss: 0.5449
Epoch [225/250], Loss: 0.3126, Val Loss: 0.5046
Epoch [226/250], Loss: 0.3048, Val Loss: 0.5212
Epoch [227/250], Loss: 0.2032, Val Loss: 0.4906
Epoch [228/250], Loss: 0.2060, Val Loss: 0.5197
Epoch [229/250], Loss: 0.2554, Val Loss: 0.4978
Epoch [230/250], Loss: 0.1942, Val Loss: 0.5239
Epoch [231/250], Loss: 0.2068, Val Loss: 0.5330
Epoch [232/250], Loss: 0.2022, Val Loss: 0.5416
Epoch [233/250], Loss: 0.3007, Val Loss: 0.5334
Epoch [234/250], Loss: 0.2246, Val Loss: 0.6210
Epoch [235/250], Loss: 0.1799, Val Loss: 0.5045
Epoch [236/250], Loss: 0.2095, Val Loss: 0.5311
Epoch [237/250], Loss: 0.2806, Val Loss: 0.5265
Epoch [238/250], Loss: 0.1462, Val Loss: 0.5749
Epoch [239/250], Loss: 0.2535, Val Loss: 0.5129
Epoch [240/250], Loss: 0.3122, Val Loss: 0.5123
Epoch [241/250], Loss: 0.7362, Val Loss: 0.5426
Epoch [242/250], Loss: 0.7828, Val Loss: 0.5415
Epoch [243/250], Loss: 0.3372, Val Loss: 0.5682
Epoch [244/250], Loss: 0.1783, Val Loss: 0.5010
Epoch [245/250], Loss: 0.2990, Val Loss: 0.5022
Epoch [246/250], Loss: 0.3247, Val Loss: 0.6662
Epoch [247/250], Loss: 0.2192, Val Loss: 0.5503
Epoch [248/250], Loss: 0.3142, Val Loss: 0.5094
Epoch [249/250], Loss: 0.2840, Val Loss: 0.5196
Epoch [250/250], Loss: 0.3170, Val Loss: 0.5153
Runtime: 0:01:36.456559
R^2 Score: 0.9204
RMSE: 0.6389
MAE: 0.1741
MAPE: 15.13%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 0.2702, Val Loss: 0.9243
Epoch [2/100], Loss: 0.2736, Val Loss: 0.8234
Epoch [3/100], Loss: 0.2579, Val Loss: 0.7305
Early stopping at epoch 3
Runtime: 0:00:06.245625
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/100], Loss: 2.0365, Val Loss: 0.7088
Epoch [2/100], Loss: 0.8215, Val Loss: 0.7534
Epoch [3/100], Loss: 0.2186, Val Loss: 0.7669
Epoch [4/100], Loss: 0.6600, Val Loss: 0.6853
Epoch [5/100], Loss: 0.2747, Val Loss: 0.9729
Epoch [6/100], Loss: 0.6446, Val Loss: 0.6926
Epoch [7/100], Loss: 0.4096, Val Loss: 0.6979
Epoch [8/100], Loss: 0.3550, Val Loss: 0.6681
Epoch [9/100], Loss: 0.6860, Val Loss: 0.7866
Epoch [10/100], Loss: 0.5259, Val Loss: 0.6923
Epoch [11/100], Loss: 0.0881, Val Loss: 0.6240
Epoch [12/100], Loss: 0.0760, Val Loss: 0.6497
Epoch [13/100], Loss: 0.1404, Val Loss: 0.6414
Epoch [14/100], Loss: 0.3961, Val Loss: 0.6686
Epoch [15/100], Loss: 0.3015, Val Loss: 0.6404
Epoch [16/100], Loss: 0.3434, Val Loss: 0.6392
Epoch [17/100], Loss: 0.3360, Val Loss: 0.7564
Epoch [18/100], Loss: 0.2744, Val Loss: 0.7105
Epoch [19/100], Loss: 0.4791, Val Loss: 0.6459
Epoch [20/100], Loss: 0.0919, Val Loss: 0.6308
Epoch [21/100], Loss: 0.2987, Val Loss: 0.7283
Epoch [22/100], Loss: 0.1123, Val Loss: 0.7370
Epoch [23/100], Loss: 0.1180, Val Loss: 0.7651
Epoch [24/100], Loss: 0.1518, Val Loss: 0.6437
Epoch [25/100], Loss: 0.1806, Val Loss: 0.7992
Epoch [26/100], Loss: 0.2674, Val Loss: 0.6987
Epoch [27/100], Loss: 0.3245, Val Loss: 0.7214
Epoch [28/100], Loss: 0.4898, Val Loss: 0.6737
Epoch [29/100], Loss: 0.8428, Val Loss: 0.6527
Epoch [30/100], Loss: 0.2941, Val Loss: 0.6378
Epoch [31/100], Loss: 0.1832, Val Loss: 0.7644
Epoch [32/100], Loss: 0.8151, Val Loss: 0.6546
Epoch [33/100], Loss: 0.2747, Val Loss: 0.6568
Epoch [34/100], Loss: 2.6274, Val Loss: 0.6454
Epoch [35/100], Loss: 0.6819, Val Loss: 0.6824
Epoch [36/100], Loss: 0.5859, Val Loss: 0.6694
Epoch [37/100], Loss: 0.1894, Val Loss: 0.7081
Epoch [38/100], Loss: 1.8564, Val Loss: 0.7984
Epoch [39/100], Loss: 0.2446, Val Loss: 0.6598
Epoch [40/100], Loss: 0.2204, Val Loss: 0.6256
Epoch [41/100], Loss: 0.0759, Val Loss: 0.6355
Epoch [42/100], Loss: 0.3164, Val Loss: 0.7245
Epoch [43/100], Loss: 0.2010, Val Loss: 0.6647
Epoch [44/100], Loss: 1.6814, Val Loss: 0.8472
Epoch [45/100], Loss: 0.3211, Val Loss: 0.6458
Epoch [46/100], Loss: 0.2872, Val Loss: 0.7109
Epoch [47/100], Loss: 0.8674, Val Loss: 0.7037
Epoch [48/100], Loss: 0.9996, Val Loss: 0.6705
Epoch [49/100], Loss: 0.4638, Val Loss: 0.6981
Epoch [50/100], Loss: 0.1572, Val Loss: 0.7597
Epoch [51/100], Loss: 0.1868, Val Loss: 0.6876
Epoch [52/100], Loss: 0.2324, Val Loss: 0.7890
Epoch [53/100], Loss: 0.1974, Val Loss: 0.8794
Epoch [54/100], Loss: 0.2141, Val Loss: 0.7569
Epoch [55/100], Loss: 0.4695, Val Loss: 0.6833
Epoch [56/100], Loss: 0.2118, Val Loss: 0.8378
Epoch [57/100], Loss: 0.4250, Val Loss: 0.6592
Epoch [58/100], Loss: 0.1702, Val Loss: 0.6647
Epoch [59/100], Loss: 0.1460, Val Loss: 0.7738
Epoch [60/100], Loss: 0.0532, Val Loss: 1.0169
Early stopping at epoch 60
Runtime: 0:01:35.027130
R^2 Score: 0.8849
RMSE: 0.7796
MAE: 0.2458
MAPE: 19.69%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/30], Loss: 0.2942, Val Loss: 0.6258
Epoch [2/30], Loss: 0.1884, Val Loss: 0.6976
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/30], Loss: 0.5539, Val Loss: 0.8068
Epoch [2/30], Loss: 0.2426, Val Loss: 0.6956
Epoch [3/30], Loss: 0.1175, Val Loss: 0.8129
Epoch [4/30], Loss: 0.3196, Val Loss: 0.7591
Epoch [5/30], Loss: 0.1856, Val Loss: 0.6845
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/30], Loss: 0.3642, Val Loss: 0.8761
Epoch [2/30], Loss: 0.1017, Val Loss: 0.8543
Epoch [3/30], Loss: 1.0651, Val Loss: 0.7157
Epoch [4/30], Loss: 0.7100, Val Loss: 0.7080
Epoch [5/30], Loss: 0.2157, Val Loss: 0.6920
Epoch [6/30], Loss: 2.0721, Val Loss: 0.7177
Epoch [7/30], Loss: 0.2311, Val Loss: 0.7592
Epoch [8/30], Loss: 0.3269, Val Loss: 0.6765
Epoch [9/30], Loss: 0.2536, Val Loss: 0.6873
Epoch [10/30], Loss: 1.6866, Val Loss: 0.6731
Epoch [11/30], Loss: 0.1766, Val Loss: 0.6536
Epoch [12/30], Loss: 0.1335, Val Loss: 0.7743
Epoch [13/30], Loss: 0.0815, Val Loss: 0.6908
Epoch [14/30], Loss: 0.7786, Val Loss: 0.6472
Epoch [15/30], Loss: 0.6708, Val Loss: 0.6455
Epoch [16/30], Loss: 0.1843, Val Loss: 0.6368
Epoch [17/30], Loss: 0.5429, Val Loss: 0.6643
Epoch [18/30], Loss: 0.2954, Val Loss: 0.6665
Epoch [19/30], Loss: 0.3321, Val Loss: 0.6659
Epoch [20/30], Loss: 0.2062, Val Loss: 0.6485
Epoch [21/30], Loss: 0.4041, Val Loss: 0.6411
Epoch [22/30], Loss: 0.2617, Val Loss: 0.6380
Epoch [23/30], Loss: 0.4038, Val Loss: 0.6931
Epoch [24/30], Loss: 0.2238, Val Loss: 0.6852
Epoch [25/30], Loss: 1.3120, Val Loss: 0.6524
Epoch [26/30], Loss: 0.2169, Val Loss: 0.6270
Epoch [27/30], Loss: 0.0608, Val Loss: 0.7132
Epoch [28/30], Loss: 0.5404, Val Loss: 0.6456
Epoch [29/30], Loss: 0.2946, Val Loss: 0.6572
Epoch [30/30], Loss: 0.1803, Val Loss: 0.7068
Runtime: 0:00:47.200411
R^2 Score: 0.8485
RMSE: 0.8947
MAE: 0.2928
MAPE: 27.92%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/120], Loss: 0.2141, Val Loss: 0.8001
Epoch [2/120], Loss: 0.1750, Val Loss: 0.7543
Epoch [3/120], Loss: 0.8348, Val Loss: 0.7007
Epoch [4/120], Loss: 0.5756, Val Loss: 0.8133
Epoch [5/120], Loss: 0.9117, Val Loss: 0.7418
Epoch [6/120], Loss: 0.1519, Val Loss: 0.6900
Epoch [7/120], Loss: 0.1898, Val Loss: 0.6758
Epoch [8/120], Loss: 0.9566, Val Loss: 0.8605
Epoch [9/120], Loss: 0.9292, Val Loss: 0.6543
Epoch [10/120], Loss: 0.1175, Val Loss: 0.7893
Epoch [11/120], Loss: 0.1971, Val Loss: 0.6805
Epoch [12/120], Loss: 0.1140, Val Loss: 0.7167
Epoch [13/120], Loss: 0.9709, Val Loss: 0.7270
Epoch [14/120], Loss: 0.5924, Val Loss: 0.7852
Epoch [15/120], Loss: 0.1283, Val Loss: 0.6302
Epoch [16/120], Loss: 0.0888, Val Loss: 0.7534
Epoch [17/120], Loss: 0.3535, Val Loss: 0.6713
Epoch [18/120], Loss: 0.1641, Val Loss: 0.7052
Epoch [19/120], Loss: 0.2913, Val Loss: 0.7448
Epoch [20/120], Loss: 0.2057, Val Loss: 0.7271
Epoch [21/120], Loss: 1.1660, Val Loss: 0.6618
Epoch [22/120], Loss: 0.7446, Val Loss: 0.7084
Epoch [23/120], Loss: 0.0882, Val Loss: 0.6764
Epoch [24/120], Loss: 0.1189, Val Loss: 0.6408
Epoch [25/120], Loss: 0.2714, Val Loss: 0.6626
Epoch [26/120], Loss: 0.2924, Val Loss: 0.6397
Epoch [27/120], Loss: 0.1067, Val Loss: 0.6950
Epoch [28/120], Loss: 0.2340, Val Loss: 0.7013
Epoch [29/120], Loss: 0.1719, Val Loss: 0.6946
Epoch [30/120], Loss: 0.1316, Val Loss: 0.6242
Epoch [31/120], Loss: 0.1320, Val Loss: 0.6152
Epoch [32/120], Loss: 0.3133, Val Loss: 0.7085
Epoch [33/120], Loss: 0.4259, Val Loss: 0.8031
Epoch [34/120], Loss: 0.1668, Val Loss: 0.6439
Epoch [35/120], Loss: 0.3010, Val Loss: 0.6477
Epoch [36/120], Loss: 0.1564, Val Loss: 0.6818
Epoch [37/120], Loss: 0.0779, Val Loss: 0.6462
Epoch [38/120], Loss: 0.0957, Val Loss: 0.6522
Epoch [39/120], Loss: 0.3448, Val Loss: 0.6040
Epoch [40/120], Loss: 0.4483, Val Loss: 0.6311
Epoch [41/120], Loss: 0.1557, Val Loss: 0.6190
Epoch [42/120], Loss: 0.1720, Val Loss: 0.6156
Epoch [43/120], Loss: 0.2324, Val Loss: 0.6213
Epoch [44/120], Loss: 0.1799, Val Loss: 0.6780
Epoch [45/120], Loss: 0.1482, Val Loss: 0.6122
Epoch [46/120], Loss: 0.1525, Val Loss: 0.6145
Epoch [47/120], Loss: 0.1372, Val Loss: 0.6373
Epoch [48/120], Loss: 0.0948, Val Loss: 0.6264
Epoch [49/120], Loss: 0.1587, Val Loss: 0.6468
Epoch [50/120], Loss: 0.1896, Val Loss: 0.6614
Epoch [51/120], Loss: 0.1050, Val Loss: 0.6890
Epoch [52/120], Loss: 0.5583, Val Loss: 0.6227
Epoch [53/120], Loss: 0.0986, Val Loss: 0.6268
Epoch [54/120], Loss: 0.3357, Val Loss: 0.6358
Epoch [55/120], Loss: 0.3158, Val Loss: 0.6040
Epoch [56/120], Loss: 0.1902, Val Loss: 0.5926
Epoch [57/120], Loss: 0.0998, Val Loss: 0.6175
Epoch [58/120], Loss: 0.1622, Val Loss: 0.6864
Epoch [59/120], Loss: 0.1726, Val Loss: 0.6711
Epoch [60/120], Loss: 1.3720, Val Loss: 0.6470
Epoch [61/120], Loss: 0.1860, Val Loss: 0.6338
Epoch [62/120], Loss: 0.2837, Val Loss: 0.6284
Epoch [63/120], Loss: 0.3879, Val Loss: 0.6019
Epoch [64/120], Loss: 0.1108, Val Loss: 0.6553
Epoch [65/120], Loss: 0.0558, Val Loss: 0.6130
Epoch [66/120], Loss: 0.0545, Val Loss: 0.6501
Epoch [67/120], Loss: 0.1282, Val Loss: 0.6362
Epoch [68/120], Loss: 0.3600, Val Loss: 0.6022
Epoch [69/120], Loss: 0.3309, Val Loss: 0.6039
Epoch [70/120], Loss: 0.0999, Val Loss: 0.6736
Epoch [71/120], Loss: 0.1603, Val Loss: 0.6174
Epoch [72/120], Loss: 0.2071, Val Loss: 0.6412
Epoch [73/120], Loss: 0.2818, Val Loss: 0.6411
Epoch [74/120], Loss: 0.1160, Val Loss: 0.6706
Epoch [75/120], Loss: 0.1790, Val Loss: 0.6820
Epoch [76/120], Loss: 0.1321, Val Loss: 0.6367
Epoch [77/120], Loss: 0.1693, Val Loss: 0.6890
Epoch [78/120], Loss: 0.0755, Val Loss: 0.6206
Epoch [79/120], Loss: 0.1039, Val Loss: 0.7907
Epoch [80/120], Loss: 0.1168, Val Loss: 0.6004
Epoch [81/120], Loss: 0.0817, Val Loss: 0.6291
Epoch [82/120], Loss: 0.1360, Val Loss: 0.6181
Epoch [83/120], Loss: 0.1031, Val Loss: 0.6390
Epoch [84/120], Loss: 0.2009, Val Loss: 0.6268
Epoch [85/120], Loss: 0.0841, Val Loss: 0.6819
Epoch [86/120], Loss: 0.1711, Val Loss: 0.5912
Epoch [87/120], Loss: 0.2797, Val Loss: 0.6240
Epoch [88/120], Loss: 0.1979, Val Loss: 0.6702
Epoch [89/120], Loss: 3.4485, Val Loss: 0.6090
Epoch [90/120], Loss: 0.1629, Val Loss: 0.6130
Epoch [91/120], Loss: 0.1716, Val Loss: 0.6076
Epoch [92/120], Loss: 0.0939, Val Loss: 0.6505
Epoch [93/120], Loss: 0.1695, Val Loss: 0.6139
Epoch [94/120], Loss: 0.1221, Val Loss: 0.6411
Epoch [95/120], Loss: 0.3048, Val Loss: 0.6470
Epoch [96/120], Loss: 0.0695, Val Loss: 0.6197
Epoch [97/120], Loss: 0.1098, Val Loss: 0.6195
Epoch [98/120], Loss: 0.1243, Val Loss: 0.6653
Epoch [99/120], Loss: 0.0510, Val Loss: 0.6142
Epoch [100/120], Loss: 0.0857, Val Loss: 0.6240
Epoch [101/120], Loss: 0.0972, Val Loss: 0.6606
Epoch [102/120], Loss: 0.0899, Val Loss: 0.6040
Epoch [103/120], Loss: 0.1312, Val Loss: 0.6732
Epoch [104/120], Loss: 0.4225, Val Loss: 0.6419
Epoch [105/120], Loss: 0.2022, Val Loss: 0.6141
Epoch [106/120], Loss: 0.1231, Val Loss: 0.6302
Epoch [107/120], Loss: 0.1617, Val Loss: 0.7266
Epoch [108/120], Loss: 0.1235, Val Loss: 0.6664
Epoch [109/120], Loss: 0.1174, Val Loss: 0.6335
Epoch [110/120], Loss: 0.2277, Val Loss: 0.6880
Epoch [111/120], Loss: 0.1976, Val Loss: 0.6760
Epoch [112/120], Loss: 0.1593, Val Loss: 0.6601
Epoch [113/120], Loss: 0.1149, Val Loss: 0.7225
Epoch [114/120], Loss: 0.1160, Val Loss: 0.6361
Epoch [115/120], Loss: 0.2151, Val Loss: 0.6408
Early stopping at epoch 115
Runtime: 0:03:01.342452
R^2 Score: 0.8883
RMSE: 0.7683
MAE: 0.2390
MAPE: 19.27%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/150], Loss: 2.7000, Val Loss: 0.7677
Epoch [2/150], Loss: 0.2869, Val Loss: 0.7906
Epoch [3/150], Loss: 0.7838, Val Loss: 0.6938
Epoch [4/150], Loss: 0.3666, Val Loss: 0.7573
Epoch [5/150], Loss: 0.2607, Val Loss: 0.7630
Epoch [6/150], Loss: 0.1186, Val Loss: 0.7250
Epoch [7/150], Loss: 0.6267, Val Loss: 0.6855
Epoch [8/150], Loss: 0.3451, Val Loss: 0.8252
Epoch [9/150], Loss: 0.2021, Val Loss: 0.6610
Epoch [10/150], Loss: 0.7089, Val Loss: 0.7318
Epoch [11/150], Loss: 0.2112, Val Loss: 0.6852
Epoch [12/150], Loss: 0.6191, Val Loss: 0.6847
Epoch [13/150], Loss: 0.7911, Val Loss: 0.6774
Epoch [14/150], Loss: 0.1679, Val Loss: 0.6879
Epoch [15/150], Loss: 0.7746, Val Loss: 0.6567
Epoch [16/150], Loss: 0.1108, Val Loss: 0.7589
Epoch [17/150], Loss: 0.4098, Val Loss: 0.6896
Epoch [18/150], Loss: 0.3752, Val Loss: 0.7008
Epoch [19/150], Loss: 0.1444, Val Loss: 0.6481
Epoch [20/150], Loss: 0.7709, Val Loss: 0.6582
Epoch [21/150], Loss: 0.0952, Val Loss: 0.6769
Epoch [22/150], Loss: 0.1527, Val Loss: 0.6694
Epoch [23/150], Loss: 0.0936, Val Loss: 0.7657
Epoch [24/150], Loss: 0.1961, Val Loss: 0.6809
Epoch [25/150], Loss: 0.7458, Val Loss: 0.6663
Epoch [26/150], Loss: 0.2200, Val Loss: 0.6671
Epoch [27/150], Loss: 0.0605, Val Loss: 0.7402
Epoch [28/150], Loss: 0.1376, Val Loss: 0.6693
Epoch [29/150], Loss: 0.6791, Val Loss: 0.6385
Epoch [30/150], Loss: 0.2877, Val Loss: 0.6366
Epoch [31/150], Loss: 0.1888, Val Loss: 0.7023
Epoch [32/150], Loss: 0.0901, Val Loss: 0.6465
Epoch [33/150], Loss: 0.2054, Val Loss: 0.6653
Epoch [34/150], Loss: 0.4310, Val Loss: 0.6343
Epoch [35/150], Loss: 0.5694, Val Loss: 0.6137
Epoch [36/150], Loss: 0.1757, Val Loss: 0.6687
Epoch [37/150], Loss: 0.3048, Val Loss: 0.5965
Epoch [38/150], Loss: 0.1622, Val Loss: 0.6283
Epoch [39/150], Loss: 0.1093, Val Loss: 0.5978
Epoch [40/150], Loss: 0.5899, Val Loss: 0.6189
Epoch [41/150], Loss: 0.0770, Val Loss: 0.6267
Epoch [42/150], Loss: 0.3710, Val Loss: 0.6635
Epoch [43/150], Loss: 0.1747, Val Loss: 0.6373
Epoch [44/150], Loss: 0.1299, Val Loss: 0.6291
Epoch [45/150], Loss: 0.2053, Val Loss: 0.6316
Epoch [46/150], Loss: 0.2281, Val Loss: 0.6220
Epoch [47/150], Loss: 0.4061, Val Loss: 0.6214
Epoch [48/150], Loss: 0.2401, Val Loss: 0.6424
Epoch [49/150], Loss: 0.1570, Val Loss: 0.6654
Epoch [50/150], Loss: 0.2286, Val Loss: 0.6244
Epoch [51/150], Loss: 0.8489, Val Loss: 0.6459
Epoch [52/150], Loss: 0.1838, Val Loss: 0.6368
Epoch [53/150], Loss: 0.1216, Val Loss: 0.6260
Epoch [54/150], Loss: 0.2033, Val Loss: 0.6027
Epoch [55/150], Loss: 0.2242, Val Loss: 0.6252
Epoch [56/150], Loss: 0.0657, Val Loss: 0.6466
Epoch [57/150], Loss: 0.3226, Val Loss: 0.6012
Epoch [58/150], Loss: 0.1067, Val Loss: 0.6777
Epoch [59/150], Loss: 0.1469, Val Loss: 0.6293
Epoch [60/150], Loss: 0.1450, Val Loss: 0.6140
Epoch [61/150], Loss: 0.1221, Val Loss: 0.7632
Epoch [62/150], Loss: 0.1695, Val Loss: 0.6206
Epoch [63/150], Loss: 0.4285, Val Loss: 0.6322
Epoch [64/150], Loss: 0.0684, Val Loss: 0.6441
Epoch [65/150], Loss: 0.1231, Val Loss: 0.7220
Epoch [66/150], Loss: 0.1333, Val Loss: 0.6635
Epoch [67/150], Loss: 0.0485, Val Loss: 0.6081
Epoch [68/150], Loss: 0.1912, Val Loss: 0.6458
Epoch [69/150], Loss: 0.3570, Val Loss: 0.6160
Epoch [70/150], Loss: 0.1818, Val Loss: 0.6487
Epoch [71/150], Loss: 0.9546, Val Loss: 0.6496
Epoch [72/150], Loss: 0.1215, Val Loss: 0.6228
Epoch [73/150], Loss: 0.0977, Val Loss: 0.6537
Epoch [74/150], Loss: 0.2134, Val Loss: 0.6287
Epoch [75/150], Loss: 0.1861, Val Loss: 0.6359
Epoch [76/150], Loss: 0.2096, Val Loss: 0.6155
Epoch [77/150], Loss: 0.4706, Val Loss: 0.6436
Epoch [78/150], Loss: 0.0590, Val Loss: 0.6395
Epoch [79/150], Loss: 0.1146, Val Loss: 0.6316
Epoch [80/150], Loss: 0.1015, Val Loss: 0.6678
Epoch [81/150], Loss: 0.9209, Val Loss: 0.6152
Epoch [82/150], Loss: 0.1065, Val Loss: 0.6431
Epoch [83/150], Loss: 0.3488, Val Loss: 0.6401
Epoch [84/150], Loss: 0.0826, Val Loss: 0.6229
Epoch [85/150], Loss: 0.2518, Val Loss: 0.5943
Epoch [86/150], Loss: 0.1525, Val Loss: 0.6423
Epoch [87/150], Loss: 0.2031, Val Loss: 0.6431
Epoch [88/150], Loss: 0.2072, Val Loss: 0.6441
Epoch [89/150], Loss: 0.6429, Val Loss: 0.6107
Epoch [90/150], Loss: 0.1641, Val Loss: 0.5984
Epoch [91/150], Loss: 0.1890, Val Loss: 0.6151
Epoch [92/150], Loss: 0.1498, Val Loss: 0.6013
Epoch [93/150], Loss: 0.1411, Val Loss: 0.6056
Epoch [94/150], Loss: 0.1726, Val Loss: 0.6267
Epoch [95/150], Loss: 0.4646, Val Loss: 0.6027
Epoch [96/150], Loss: 0.1931, Val Loss: 0.6147
Epoch [97/150], Loss: 0.1095, Val Loss: 0.6422
Epoch [98/150], Loss: 0.0428, Val Loss: 0.6252
Epoch [99/150], Loss: 0.1938, Val Loss: 0.6081
Epoch [100/150], Loss: 0.1365, Val Loss: 0.6480
Epoch [101/150], Loss: 0.3001, Val Loss: 0.6063
Epoch [102/150], Loss: 0.1264, Val Loss: 0.6443
Epoch [103/150], Loss: 0.5423, Val Loss: 0.6265
Epoch [104/150], Loss: 0.1648, Val Loss: 0.6753
Epoch [105/150], Loss: 0.0790, Val Loss: 0.6058
Epoch [106/150], Loss: 0.2289, Val Loss: 0.6251
Epoch [107/150], Loss: 0.0563, Val Loss: 0.6589
Epoch [108/150], Loss: 0.1196, Val Loss: 0.6362
Epoch [109/150], Loss: 0.0902, Val Loss: 0.6406
Epoch [110/150], Loss: 0.0795, Val Loss: 0.6311
Epoch [111/150], Loss: 0.3114, Val Loss: 0.5959
Epoch [112/150], Loss: 0.0760, Val Loss: 0.6111
Epoch [113/150], Loss: 0.1796, Val Loss: 0.6213
Epoch [114/150], Loss: 0.1633, Val Loss: 0.6015
Epoch [115/150], Loss: 0.1543, Val Loss: 0.6324
Epoch [116/150], Loss: 0.0778, Val Loss: 0.6556
Epoch [117/150], Loss: 0.1785, Val Loss: 0.6323
Epoch [118/150], Loss: 0.1504, Val Loss: 0.6322
Epoch [119/150], Loss: 0.1109, Val Loss: 0.6182
Epoch [120/150], Loss: 0.0625, Val Loss: 0.6185
Epoch [121/150], Loss: 0.1712, Val Loss: 0.6608
Epoch [122/150], Loss: 0.2311, Val Loss: 0.6200
Epoch [123/150], Loss: 0.1986, Val Loss: 0.6166
Epoch [124/150], Loss: 0.4786, Val Loss: 0.6511
Epoch [125/150], Loss: 0.1919, Val Loss: 0.6560
Epoch [126/150], Loss: 0.1509, Val Loss: 0.6182
Epoch [127/150], Loss: 0.3480, Val Loss: 0.6156
Epoch [128/150], Loss: 0.1266, Val Loss: 0.6309
Epoch [129/150], Loss: 0.2976, Val Loss: 0.6238
Epoch [130/150], Loss: 0.2338, Val Loss: 0.6390
Epoch [131/150], Loss: 0.3680, Val Loss: 0.6529
Epoch [132/150], Loss: 0.0785, Val Loss: 0.6091
Epoch [133/150], Loss: 0.0876, Val Loss: 0.6258
Epoch [134/150], Loss: 0.0707, Val Loss: 0.6353
Epoch [135/150], Loss: 0.1633, Val Loss: 0.6336
Epoch [136/150], Loss: 0.1417, Val Loss: 0.6111
Epoch [137/150], Loss: 0.1156, Val Loss: 0.6477
Epoch [138/150], Loss: 0.2348, Val Loss: 0.6186
Epoch [139/150], Loss: 0.1750, Val Loss: 0.6054
Epoch [140/150], Loss: 0.3429, Val Loss: 0.6180
Epoch [141/150], Loss: 0.1061, Val Loss: 0.6318
Epoch [142/150], Loss: 0.2010, Val Loss: 0.6231
Epoch [143/150], Loss: 0.1045, Val Loss: 0.6696
Epoch [144/150], Loss: 0.3533, Val Loss: 0.5983
Epoch [145/150], Loss: 0.0885, Val Loss: 0.6085
Epoch [146/150], Loss: 0.1994, Val Loss: 0.6373
Epoch [147/150], Loss: 0.1395, Val Loss: 0.6109
Epoch [148/150], Loss: 0.1236, Val Loss: 0.6108
Epoch [149/150], Loss: 0.2185, Val Loss: 0.6679
Epoch [150/150], Loss: 0.1237, Val Loss: 0.6166
Runtime: 0:03:43.987799
R^2 Score: 0.8660
RMSE: 0.8415
MAE: 0.2455
MAPE: 21.63%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/150], Loss: 1.2937, Val Loss: 0.7720
Epoch [2/150], Loss: 0.2078, Val Loss: 0.7438
Epoch [3/150], Loss: 0.5561, Val Loss: 0.7328
Epoch [4/150], Loss: 0.2340, Val Loss: 0.8167
Epoch [5/150], Loss: 0.1607, Val Loss: 0.7412
Epoch [6/150], Loss: 0.2944, Val Loss: 0.6643
Epoch [7/150], Loss: 0.3394, Val Loss: 0.7658
Epoch [8/150], Loss: 0.2862, Val Loss: 0.8241
Epoch [9/150], Loss: 1.3105, Val Loss: 0.6783
Epoch [10/150], Loss: 1.1278, Val Loss: 0.6884
Epoch [11/150], Loss: 0.2010, Val Loss: 0.7070
Epoch [12/150], Loss: 0.1265, Val Loss: 0.7849
Epoch [13/150], Loss: 0.0880, Val Loss: 0.7146
Epoch [14/150], Loss: 0.5647, Val Loss: 0.6410
Epoch [15/150], Loss: 0.5301, Val Loss: 0.7091
Epoch [16/150], Loss: 0.7478, Val Loss: 0.8297
Epoch [17/150], Loss: 0.2547, Val Loss: 0.7260
Epoch [18/150], Loss: 0.2425, Val Loss: 0.6721
Epoch [19/150], Loss: 0.4399, Val Loss: 0.6680
Epoch [20/150], Loss: 0.2006, Val Loss: 0.6391
Epoch [21/150], Loss: 0.2157, Val Loss: 0.6958
Epoch [22/150], Loss: 0.3841, Val Loss: 0.6506
Epoch [23/150], Loss: 0.3419, Val Loss: 0.6818
Epoch [24/150], Loss: 0.4275, Val Loss: 0.6363
Epoch [25/150], Loss: 0.1661, Val Loss: 0.7179
Epoch [26/150], Loss: 0.6757, Val Loss: 0.6661
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/150], Loss: 0.2880, Val Loss: 0.8236
Epoch [2/150], Loss: 0.2079, Val Loss: 0.7683
Epoch [3/150], Loss: 0.2913, Val Loss: 0.7533
Epoch [4/150], Loss: 0.6712, Val Loss: 0.7339
Epoch [5/150], Loss: 0.8231, Val Loss: 0.7484
Epoch [6/150], Loss: 0.3933, Val Loss: 0.7419
Epoch [7/150], Loss: 0.4937, Val Loss: 0.6916
Epoch [8/150], Loss: 0.2058, Val Loss: 0.7786
Epoch [9/150], Loss: 0.1127, Val Loss: 0.6923
Epoch [10/150], Loss: 0.2183, Val Loss: 0.7059
Epoch [11/150], Loss: 0.2389, Val Loss: 0.8414
Epoch [12/150], Loss: 0.5365, Val Loss: 0.6676
Epoch [13/150], Loss: 0.1736, Val Loss: 0.7447
Epoch [14/150], Loss: 0.3752, Val Loss: 0.7030
Epoch [15/150], Loss: 1.0042, Val Loss: 0.6965
Epoch [16/150], Loss: 0.9851, Val Loss: 0.6629
Epoch [17/150], Loss: 0.2456, Val Loss: 0.7031
Epoch [18/150], Loss: 0.1065, Val Loss: 0.6527
Epoch [19/150], Loss: 1.1783, Val Loss: 0.6466
Epoch [20/150], Loss: 0.2825, Val Loss: 0.6536
Epoch [21/150], Loss: 0.4711, Val Loss: 0.6511
Epoch [22/150], Loss: 0.1189, Val Loss: 0.7614
Epoch [23/150], Loss: 0.1977, Val Loss: 0.6523
Epoch [24/150], Loss: 0.2560, Val Loss: 0.6828
Epoch [25/150], Loss: 0.1881, Val Loss: 0.6332
Epoch [26/150], Loss: 0.1070, Val Loss: 0.6299
Epoch [27/150], Loss: 0.6222, Val Loss: 0.6214
Epoch [28/150], Loss: 1.0388, Val Loss: 0.6981
Epoch [29/150], Loss: 0.1945, Val Loss: 0.6499
Epoch [30/150], Loss: 0.1116, Val Loss: 0.6342
Epoch [31/150], Loss: 0.2949, Val Loss: 0.6560
Epoch [32/150], Loss: 0.1432, Val Loss: 0.6446
Epoch [33/150], Loss: 0.5583, Val Loss: 0.6494
Epoch [34/150], Loss: 0.0868, Val Loss: 0.6462
Epoch [35/150], Loss: 1.3524, Val Loss: 0.6364
Epoch [36/150], Loss: 0.7523, Val Loss: 0.6563
Epoch [37/150], Loss: 0.1366, Val Loss: 0.6768
Epoch [38/150], Loss: 0.1077, Val Loss: 0.6906
Epoch [39/150], Loss: 0.1764, Val Loss: 0.6177
Epoch [40/150], Loss: 0.3581, Val Loss: 0.6079
Epoch [41/150], Loss: 0.2408, Val Loss: 0.6437
Epoch [42/150], Loss: 2.9020, Val Loss: 0.6304
Epoch [43/150], Loss: 0.2459, Val Loss: 0.5976
Epoch [44/150], Loss: 0.5229, Val Loss: 0.5916
Epoch [45/150], Loss: 0.7744, Val Loss: 0.5798
Epoch [46/150], Loss: 0.4817, Val Loss: 0.6111
Epoch [47/150], Loss: 0.1443, Val Loss: 0.5998
Epoch [48/150], Loss: 0.1387, Val Loss: 0.6470
Epoch [49/150], Loss: 0.2070, Val Loss: 0.5939
Epoch [50/150], Loss: 0.2739, Val Loss: 0.6448
Epoch [51/150], Loss: 0.1784, Val Loss: 0.6055
Epoch [52/150], Loss: 0.2022, Val Loss: 0.6231
Epoch [53/150], Loss: 0.5867, Val Loss: 0.5741
Epoch [54/150], Loss: 0.0585, Val Loss: 0.5918
Epoch [55/150], Loss: 0.1174, Val Loss: 0.6079
Epoch [56/150], Loss: 0.4071, Val Loss: 0.6059
Epoch [57/150], Loss: 0.4339, Val Loss: 0.5844
Epoch [58/150], Loss: 0.1848, Val Loss: 0.6128
Epoch [59/150], Loss: 0.4326, Val Loss: 0.6359
Epoch [60/150], Loss: 0.4968, Val Loss: 0.5948
Epoch [61/150], Loss: 0.1912, Val Loss: 0.6189
Epoch [62/150], Loss: 0.1415, Val Loss: 0.6307
Epoch [63/150], Loss: 0.1234, Val Loss: 0.6113
Epoch [64/150], Loss: 0.0658, Val Loss: 0.6013
Epoch [65/150], Loss: 0.1445, Val Loss: 0.6158
Epoch [66/150], Loss: 0.0838, Val Loss: 0.6959
Epoch [67/150], Loss: 0.2590, Val Loss: 0.5816
Epoch [68/150], Loss: 0.1621, Val Loss: 0.5945
Epoch [69/150], Loss: 0.0662, Val Loss: 0.5871
Epoch [70/150], Loss: 0.6628, Val Loss: 0.5979
Epoch [71/150], Loss: 0.4317, Val Loss: 0.6139
Epoch [72/150], Loss: 0.4024, Val Loss: 0.5857
Epoch [73/150], Loss: 0.5511, Val Loss: 0.6198
Epoch [74/150], Loss: 0.4882, Val Loss: 0.5727
Epoch [75/150], Loss: 0.1661, Val Loss: 0.5980
Epoch [76/150], Loss: 0.1244, Val Loss: 0.5781
Epoch [77/150], Loss: 0.9624, Val Loss: 0.5862
Epoch [78/150], Loss: 0.6704, Val Loss: 0.5857
Epoch [79/150], Loss: 0.0953, Val Loss: 0.5787
Epoch [80/150], Loss: 0.1636, Val Loss: 0.5928
Epoch [81/150], Loss: 0.0944, Val Loss: 0.6190
Epoch [82/150], Loss: 0.1201, Val Loss: 0.5762
Epoch [83/150], Loss: 0.0852, Val Loss: 0.5894
Epoch [84/150], Loss: 0.2126, Val Loss: 0.5981
Epoch [85/150], Loss: 0.1211, Val Loss: 0.6089
Epoch [86/150], Loss: 0.1453, Val Loss: 0.5661
Epoch [87/150], Loss: 0.2772, Val Loss: 0.5865
Epoch [88/150], Loss: 0.4137, Val Loss: 0.6328
Epoch [89/150], Loss: 0.1138, Val Loss: 0.5875
Epoch [90/150], Loss: 0.3587, Val Loss: 0.5769
Epoch [91/150], Loss: 0.1960, Val Loss: 0.5978
Epoch [92/150], Loss: 0.1655, Val Loss: 0.5900
Epoch [93/150], Loss: 0.1080, Val Loss: 0.5902
Epoch [94/150], Loss: 0.1408, Val Loss: 0.5978
Epoch [95/150], Loss: 0.2420, Val Loss: 0.6197
Epoch [96/150], Loss: 0.4437, Val Loss: 0.5701
Epoch [97/150], Loss: 0.4337, Val Loss: 0.5968
Epoch [98/150], Loss: 0.3584, Val Loss: 0.5599
Epoch [99/150], Loss: 0.0978, Val Loss: 0.5878
Epoch [100/150], Loss: 0.1730, Val Loss: 0.5834
Epoch [101/150], Loss: 0.5161, Val Loss: 0.5727
Epoch [102/150], Loss: 0.3343, Val Loss: 0.5962
Epoch [103/150], Loss: 0.2092, Val Loss: 0.5891
Epoch [104/150], Loss: 0.0926, Val Loss: 0.5798
Epoch [105/150], Loss: 0.0278, Val Loss: 0.5946
Epoch [106/150], Loss: 0.1223, Val Loss: 0.5960
Epoch [107/150], Loss: 0.1500, Val Loss: 0.5768
Epoch [108/150], Loss: 0.1327, Val Loss: 0.5945
Epoch [109/150], Loss: 0.1484, Val Loss: 0.5973
Epoch [110/150], Loss: 0.1204, Val Loss: 0.5774
Epoch [111/150], Loss: 0.1249, Val Loss: 0.5750
Epoch [112/150], Loss: 0.1128, Val Loss: 0.5969
Epoch [113/150], Loss: 0.9200, Val Loss: 0.5914
Epoch [114/150], Loss: 0.0956, Val Loss: 0.6019
Epoch [115/150], Loss: 0.2623, Val Loss: 0.6391
Epoch [116/150], Loss: 0.2119, Val Loss: 0.5877
Epoch [117/150], Loss: 0.2384, Val Loss: 0.5965
Epoch [118/150], Loss: 0.7956, Val Loss: 0.6036
Epoch [119/150], Loss: 0.2092, Val Loss: 0.6014
Epoch [120/150], Loss: 0.0496, Val Loss: 0.5839
Epoch [121/150], Loss: 0.2132, Val Loss: 0.6206
Epoch [122/150], Loss: 0.1458, Val Loss: 0.6082
Epoch [123/150], Loss: 0.1172, Val Loss: 0.5943
Epoch [124/150], Loss: 0.0811, Val Loss: 0.6430
Epoch [125/150], Loss: 0.1385, Val Loss: 0.5854
Epoch [126/150], Loss: 0.1202, Val Loss: 0.6057
Epoch [127/150], Loss: 0.1772, Val Loss: 0.5896
Epoch [128/150], Loss: 0.1107, Val Loss: 0.5741
Epoch [129/150], Loss: 0.1189, Val Loss: 0.5896
Epoch [130/150], Loss: 0.3099, Val Loss: 0.5955
Epoch [131/150], Loss: 0.3411, Val Loss: 0.7233
Epoch [132/150], Loss: 0.0618, Val Loss: 0.5623
Epoch [133/150], Loss: 0.1815, Val Loss: 0.6156
Epoch [134/150], Loss: 0.1668, Val Loss: 0.5723
Epoch [135/150], Loss: 0.7608, Val Loss: 0.6533
Epoch [136/150], Loss: 0.1233, Val Loss: 0.5995
Epoch [137/150], Loss: 0.2859, Val Loss: 0.5689
Epoch [138/150], Loss: 0.3341, Val Loss: 0.6138
Epoch [139/150], Loss: 0.1448, Val Loss: 0.5798
Epoch [140/150], Loss: 0.3000, Val Loss: 0.5875
Epoch [141/150], Loss: 0.1519, Val Loss: 0.5854
Epoch [142/150], Loss: 0.1562, Val Loss: 0.5922
Epoch [143/150], Loss: 0.1488, Val Loss: 0.6277
Epoch [144/150], Loss: 0.2826, Val Loss: 0.5933
Epoch [145/150], Loss: 0.5106, Val Loss: 0.5865
Epoch [146/150], Loss: 0.2608, Val Loss: 0.5891
Epoch [147/150], Loss: 0.1016, Val Loss: 0.6090
Epoch [148/150], Loss: 0.0680, Val Loss: 0.5935
Epoch [149/150], Loss: 0.3198, Val Loss: 0.6008
Epoch [150/150], Loss: 0.1000, Val Loss: 0.5910
Runtime: 0:01:23.564203
R^2 Score: 0.8785
RMSE: 0.8011
MAE: 0.2576
MAPE: 24.32%
Using optimizer: Adam
With PSO (1470 iter) initializationStandard data
Optimized hyperparameter at Trial 927 finished with value: 0.17793542919064725 and parameters: {'weight_decay': 4.0533892993599144e-05}.            Suggested LR = 0.00038980599492788315
TruncatedSVD_50
MLP with layer size: [49, 61, 61] - Result:
Epoch [1/150], Loss: 1.0273, Val Loss: 0.8059
Epoch [2/150], Loss: 0.7466, Val Loss: 0.7761
Epoch [3/150], Loss: 0.6056, Val Loss: 0.7754
Epoch [4/150], Loss: 0.4176, Val Loss: 0.7533
Epoch [5/150], Loss: 0.5432, Val Loss: 0.9163
Epoch [6/150], Loss: 0.6954, Val Loss: 0.7687
Epoch [7/150], Loss: 0.3644, Val Loss: 1.0079
Epoch [8/150], Loss: 0.6269, Val Loss: 0.7510
Epoch [9/150], Loss: 0.6404, Val Loss: 0.7118
Epoch [10/150], Loss: 0.9842, Val Loss: 0.7002
Epoch [11/150], Loss: 0.8705, Val Loss: 0.7106
Epoch [12/150], Loss: 0.7001, Val Loss: 0.7217
Epoch [13/150], Loss: 0.8184, Val Loss: 0.7160
Epoch [14/150], Loss: 0.4718, Val Loss: 0.7887
Epoch [15/150], Loss: 0.5613, Val Loss: 0.7311
Epoch [16/150], Loss: 0.5306, Val Loss: 0.7326
Epoch [17/150], Loss: 0.9356, Val Loss: 0.6911
Epoch [18/150], Loss: 0.5728, Val Loss: 0.6979
Epoch [19/150], Loss: 0.5359, Val Loss: 0.7205
Epoch [20/150], Loss: 1.5826, Val Loss: 0.6946
Epoch [21/150], Loss: 0.3545, Val Loss: 0.7173
Epoch [22/150], Loss: 0.7605, Val Loss: 0.7639
Epoch [23/150], Loss: 0.5069, Val Loss: 0.7021
Epoch [24/150], Loss: 0.3805, Val Loss: 0.7169
Epoch [25/150], Loss: 0.3526, Val Loss: 0.6949
Epoch [26/150], Loss: 0.5103, Val Loss: 0.6873
Epoch [27/150], Loss: 0.3379, Val Loss: 0.6858
Epoch [28/150], Loss: 0.6605, Val Loss: 0.6650
Epoch [29/150], Loss: 0.6152, Val Loss: 0.7069
Epoch [30/150], Loss: 0.4339, Val Loss: 0.7192
Epoch [31/150], Loss: 0.2753, Val Loss: 0.6726
Epoch [32/150], Loss: 0.4753, Val Loss: 0.6388
Epoch [33/150], Loss: 0.4325, Val Loss: 0.6720
Epoch [34/150], Loss: 0.5802, Val Loss: 0.6932
Epoch [35/150], Loss: 0.5692, Val Loss: 0.6489
Epoch [36/150], Loss: 0.5194, Val Loss: 0.6485
Epoch [37/150], Loss: 0.4836, Val Loss: 0.7086
Epoch [38/150], Loss: 0.2702, Val Loss: 0.6657
Epoch [39/150], Loss: 1.0918, Val Loss: 0.6667
Epoch [40/150], Loss: 0.3260, Val Loss: 0.6327
Epoch [41/150], Loss: 0.3959, Val Loss: 0.6635
Epoch [42/150], Loss: 0.3691, Val Loss: 0.6535
Epoch [43/150], Loss: 0.4682, Val Loss: 0.6349
Epoch [44/150], Loss: 0.6319, Val Loss: 0.6382
Epoch [45/150], Loss: 0.4296, Val Loss: 0.6639
Epoch [46/150], Loss: 0.4083, Val Loss: 0.6629
Epoch [47/150], Loss: 0.3890, Val Loss: 0.6315
Epoch [48/150], Loss: 0.3741, Val Loss: 0.7212
Epoch [49/150], Loss: 0.3337, Val Loss: 0.6267
Epoch [50/150], Loss: 0.3280, Val Loss: 0.6639
Epoch [51/150], Loss: 0.3941, Val Loss: 0.6684
Epoch [52/150], Loss: 0.9944, Val Loss: 0.7210
Epoch [53/150], Loss: 0.4935, Val Loss: 0.6714
Epoch [54/150], Loss: 0.2404, Val Loss: 0.6396
Epoch [55/150], Loss: 1.1509, Val Loss: 0.6465
Epoch [56/150], Loss: 0.5331, Val Loss: 0.6308
Epoch [57/150], Loss: 0.4502, Val Loss: 0.6279
Epoch [58/150], Loss: 0.4746, Val Loss: 0.6236
Epoch [59/150], Loss: 0.5288, Val Loss: 0.7010
Epoch [60/150], Loss: 0.3768, Val Loss: 0.6250
Epoch [61/150], Loss: 0.4639, Val Loss: 0.6478
Epoch [62/150], Loss: 0.2650, Val Loss: 0.6353
Epoch [63/150], Loss: 0.3878, Val Loss: 0.6276
Epoch [64/150], Loss: 0.6824, Val Loss: 0.6593
Epoch [65/150], Loss: 0.4334, Val Loss: 0.6335
Epoch [66/150], Loss: 0.2180, Val Loss: 0.6240
Epoch [67/150], Loss: 0.3680, Val Loss: 0.6454
Epoch [68/150], Loss: 0.3710, Val Loss: 0.5990
Epoch [69/150], Loss: 0.4450, Val Loss: 0.6140
Epoch [70/150], Loss: 0.4345, Val Loss: 0.6250
Epoch [71/150], Loss: 0.2240, Val Loss: 0.5956
Epoch [72/150], Loss: 0.4586, Val Loss: 0.5996
Epoch [73/150], Loss: 0.4103, Val Loss: 0.5958
Epoch [74/150], Loss: 0.4002, Val Loss: 0.6272
Epoch [75/150], Loss: 0.3304, Val Loss: 0.6601
Epoch [76/150], Loss: 0.3027, Val Loss: 0.6137
Epoch [77/150], Loss: 0.4691, Val Loss: 0.6785
Epoch [78/150], Loss: 0.4315, Val Loss: 0.6080
Epoch [79/150], Loss: 0.2553, Val Loss: 0.6070
Epoch [80/150], Loss: 0.3978, Val Loss: 0.6481
Epoch [81/150], Loss: 0.3982, Val Loss: 0.6610
Epoch [82/150], Loss: 0.2184, Val Loss: 0.6441
Epoch [83/150], Loss: 0.3715, Val Loss: 0.6572
Epoch [84/150], Loss: 0.3063, Val Loss: 0.6205
Epoch [85/150], Loss: 0.3418, Val Loss: 0.6228
Epoch [86/150], Loss: 0.3272, Val Loss: 0.5923
Epoch [87/150], Loss: 0.2710, Val Loss: 0.6165
Epoch [88/150], Loss: 0.3382, Val Loss: 0.6189
Epoch [89/150], Loss: 0.2481, Val Loss: 0.6305
Epoch [90/150], Loss: 0.5084, Val Loss: 0.6569
Epoch [91/150], Loss: 0.3035, Val Loss: 0.6105
Epoch [92/150], Loss: 0.3714, Val Loss: 0.5913
Epoch [93/150], Loss: 1.0826, Val Loss: 0.6528
Epoch [94/150], Loss: 0.8299, Val Loss: 0.6076
Epoch [95/150], Loss: 0.3780, Val Loss: 0.6095
Epoch [96/150], Loss: 0.2599, Val Loss: 0.6229
Epoch [97/150], Loss: 0.2191, Val Loss: 0.6301
Epoch [98/150], Loss: 0.4518, Val Loss: 0.5989
Epoch [99/150], Loss: 0.3701, Val Loss: 0.5996
Epoch [100/150], Loss: 0.4233, Val Loss: 0.5911
Epoch [101/150], Loss: 0.4022, Val Loss: 0.6277
Epoch [102/150], Loss: 0.3768, Val Loss: 0.5990
Epoch [103/150], Loss: 0.2882, Val Loss: 0.6027
Epoch [104/150], Loss: 0.2675, Val Loss: 0.5965
Epoch [105/150], Loss: 0.3746, Val Loss: 0.6455
Epoch [106/150], Loss: 0.2896, Val Loss: 0.5822
Epoch [107/150], Loss: 0.2701, Val Loss: 0.6100
Epoch [108/150], Loss: 0.2869, Val Loss: 0.5679
Epoch [109/150], Loss: 0.2409, Val Loss: 0.6166
Epoch [110/150], Loss: 0.2882, Val Loss: 0.6079
Epoch [111/150], Loss: 0.3748, Val Loss: 0.7447
Epoch [112/150], Loss: 0.7422, Val Loss: 0.5813
Epoch [113/150], Loss: 0.5384, Val Loss: 0.6561
Epoch [114/150], Loss: 0.4137, Val Loss: 0.5813
Epoch [115/150], Loss: 0.2786, Val Loss: 0.5881
Epoch [116/150], Loss: 0.4342, Val Loss: 0.5796
Epoch [117/150], Loss: 0.2742, Val Loss: 0.5827
Epoch [118/150], Loss: 0.3001, Val Loss: 0.6478
Epoch [119/150], Loss: 0.2175, Val Loss: 0.6046
Epoch [120/150], Loss: 0.3119, Val Loss: 0.6389
Epoch [121/150], Loss: 0.2934, Val Loss: 0.5957
Epoch [122/150], Loss: 0.9955, Val Loss: 0.5996
Epoch [123/150], Loss: 0.2570, Val Loss: 0.5836
Epoch [124/150], Loss: 0.2831, Val Loss: 0.6122
Epoch [125/150], Loss: 0.4010, Val Loss: 0.5645
Epoch [126/150], Loss: 0.3124, Val Loss: 0.6073
Epoch [127/150], Loss: 0.3471, Val Loss: 0.6988
Epoch [128/150], Loss: 0.2712, Val Loss: 0.5929
Epoch [129/150], Loss: 0.4557, Val Loss: 0.5626
Epoch [130/150], Loss: 0.3253, Val Loss: 0.5693
Epoch [131/150], Loss: 0.4000, Val Loss: 0.6128
Epoch [132/150], Loss: 0.3728, Val Loss: 0.5706
Epoch [133/150], Loss: 0.2887, Val Loss: 0.6196
Epoch [134/150], Loss: 0.2459, Val Loss: 0.5773
Epoch [135/150], Loss: 0.2078, Val Loss: 0.6089
Epoch [136/150], Loss: 0.2765, Val Loss: 0.5847
Epoch [137/150], Loss: 0.2161, Val Loss: 0.5995
Epoch [138/150], Loss: 0.2703, Val Loss: 0.5787
Epoch [139/150], Loss: 0.2530, Val Loss: 0.5867
Epoch [140/150], Loss: 0.3039, Val Loss: 0.5688
Epoch [141/150], Loss: 0.2660, Val Loss: 0.5538
Epoch [142/150], Loss: 0.2975, Val Loss: 0.5793
Epoch [143/150], Loss: 0.2508, Val Loss: 0.6036
Epoch [144/150], Loss: 0.3968, Val Loss: 0.5688
Epoch [145/150], Loss: 0.2519, Val Loss: 0.5923
Epoch [146/150], Loss: 0.2062, Val Loss: 0.5872
Epoch [147/150], Loss: 0.4419, Val Loss: 0.6159
Epoch [148/150], Loss: 0.2226, Val Loss: 0.7290
Epoch [149/150], Loss: 0.2026, Val Loss: 0.5924
Epoch [150/150], Loss: 0.3379, Val Loss: 0.5873
Runtime: 0:00:47.309321
R^2 Score: 0.8923
RMSE: 0.7544
MAE: 0.2420
MAPE: 20.93%
R^2 Score: 0.8923
RMSE: 0.7544
MAE: 0.2420
MAPE: 20.93%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [222, 900, 1384, 1024, 160] - Result:
Epoch [1/500], Loss: 0.9291, Val Loss: 1.1449
Epoch [2/500], Loss: 1.1464, Val Loss: 1.1298
Epoch [3/500], Loss: 0.5285, Val Loss: 0.9226
Epoch [4/500], Loss: 0.7171, Val Loss: 0.7618
Epoch [5/500], Loss: 0.6014, Val Loss: 0.8847
Epoch [6/500], Loss: 1.0429, Val Loss: 0.8285
Epoch [7/500], Loss: 0.4820, Val Loss: 0.7398
Epoch [8/500], Loss: 0.9190, Val Loss: 0.7804
Epoch [9/500], Loss: 0.5715, Val Loss: 0.9568
Epoch [10/500], Loss: 0.6191, Val Loss: 0.7101
Epoch [11/500], Loss: 0.7302, Val Loss: 0.6425
Epoch [12/500], Loss: 0.5139, Val Loss: 0.7515
Epoch [13/500], Loss: 0.3592, Val Loss: 0.7149
Epoch [14/500], Loss: 0.5237, Val Loss: 0.6980
Epoch [15/500], Loss: 0.5009, Val Loss: 0.6623
Epoch [16/500], Loss: 0.5415, Val Loss: 0.6976
Epoch [17/500], Loss: 0.6068, Val Loss: 0.6710
Epoch [18/500], Loss: 0.4590, Val Loss: 0.6089
Epoch [19/500], Loss: 0.5464, Val Loss: 0.5630
Epoch [20/500], Loss: 0.8920, Val Loss: 0.8572
Epoch [21/500], Loss: 0.4536, Val Loss: 0.6577
Epoch [22/500], Loss: 0.3496, Val Loss: 0.5995
Epoch [23/500], Loss: 0.4678, Val Loss: 0.5668
Epoch [24/500], Loss: 0.3054, Val Loss: 0.6490
Epoch [25/500], Loss: 0.7365, Val Loss: 0.6326
Epoch [26/500], Loss: 0.5810, Val Loss: 0.5845
Epoch [27/500], Loss: 0.4462, Val Loss: 0.6824
Epoch [28/500], Loss: 0.7096, Val Loss: 0.6215
Epoch [29/500], Loss: 0.4749, Val Loss: 0.6835
Epoch [30/500], Loss: 0.8959, Val Loss: 0.7555
Epoch [31/500], Loss: 0.6751, Val Loss: 0.5774
Epoch [32/500], Loss: 0.2899, Val Loss: 0.6178
Epoch [33/500], Loss: 0.3911, Val Loss: 0.5503
Epoch [34/500], Loss: 0.4784, Val Loss: 0.5337
Epoch [35/500], Loss: 0.7955, Val Loss: 0.6420
Epoch [36/500], Loss: 0.3600, Val Loss: 0.5826
Epoch [37/500], Loss: 0.4031, Val Loss: 0.5823
Epoch [38/500], Loss: 0.7917, Val Loss: 0.6026
Epoch [39/500], Loss: 0.3138, Val Loss: 0.5678
Epoch [40/500], Loss: 0.3405, Val Loss: 0.5488
Epoch [41/500], Loss: 0.2224, Val Loss: 0.5363
Epoch [42/500], Loss: 0.2025, Val Loss: 0.5254
Epoch [43/500], Loss: 0.3536, Val Loss: 0.5671
Epoch [44/500], Loss: 0.2876, Val Loss: 0.5425
Epoch [45/500], Loss: 0.4171, Val Loss: 0.7657
Epoch [46/500], Loss: 0.5218, Val Loss: 0.5635
Epoch [47/500], Loss: 0.2592, Val Loss: 0.5301
Epoch [48/500], Loss: 0.2440, Val Loss: 0.5512
Epoch [49/500], Loss: 0.2891, Val Loss: 0.5924
Epoch [50/500], Loss: 0.3082, Val Loss: 0.5209
Epoch [51/500], Loss: 0.8708, Val Loss: 0.5719
Epoch [52/500], Loss: 0.3389, Val Loss: 0.5028
Epoch [53/500], Loss: 0.3780, Val Loss: 0.5398
Epoch [54/500], Loss: 0.5791, Val Loss: 0.5561
Epoch [55/500], Loss: 0.2365, Val Loss: 0.5434
Epoch [56/500], Loss: 0.2518, Val Loss: 0.5450
Epoch [57/500], Loss: 0.4629, Val Loss: 0.5906
Epoch [58/500], Loss: 0.2908, Val Loss: 0.6412
Epoch [59/500], Loss: 0.2613, Val Loss: 0.5386
Epoch [60/500], Loss: 0.5637, Val Loss: 0.5624
Epoch [61/500], Loss: 0.4288, Val Loss: 0.6185
Epoch [62/500], Loss: 0.3100, Val Loss: 0.5158
Epoch [63/500], Loss: 0.2238, Val Loss: 0.5299
Epoch [64/500], Loss: 0.6718, Val Loss: 0.5696
Epoch [65/500], Loss: 0.3168, Val Loss: 0.6268
Epoch [66/500], Loss: 0.8587, Val Loss: 0.5588
Epoch [67/500], Loss: 0.3648, Val Loss: 0.5691
Epoch [68/500], Loss: 0.5706, Val Loss: 0.5619
Epoch [69/500], Loss: 0.4777, Val Loss: 0.6019
Epoch [70/500], Loss: 0.2664, Val Loss: 0.5144
Epoch [71/500], Loss: 0.3254, Val Loss: 0.5337
Epoch [72/500], Loss: 0.4033, Val Loss: 0.6361
Epoch [73/500], Loss: 0.4177, Val Loss: 0.5244
Epoch [74/500], Loss: 0.3824, Val Loss: 0.5386
Epoch [75/500], Loss: 0.5814, Val Loss: 0.5347
Epoch [76/500], Loss: 0.2091, Val Loss: 0.5492
Epoch [77/500], Loss: 0.5422, Val Loss: 0.6139
Epoch [78/500], Loss: 0.2827, Val Loss: 0.6135
Epoch [79/500], Loss: 0.3900, Val Loss: 0.5767
Epoch [80/500], Loss: 0.3824, Val Loss: 0.5811
Epoch [81/500], Loss: 0.4550, Val Loss: 0.8390
Epoch [82/500], Loss: 0.6030, Val Loss: 0.6445
Epoch [83/500], Loss: 0.2988, Val Loss: 0.5508
Epoch [84/500], Loss: 0.2639, Val Loss: 0.5730
Epoch [85/500], Loss: 0.2614, Val Loss: 0.5066
Epoch [86/500], Loss: 0.4096, Val Loss: 0.5849
Epoch [87/500], Loss: 0.5246, Val Loss: 0.5819
Epoch [88/500], Loss: 0.2622, Val Loss: 0.5166
Epoch [89/500], Loss: 0.2933, Val Loss: 0.5500
Epoch [90/500], Loss: 0.2870, Val Loss: 0.5086
Epoch [91/500], Loss: 0.2777, Val Loss: 0.5245
Epoch [92/500], Loss: 0.2683, Val Loss: 0.4994
Epoch [93/500], Loss: 0.4763, Val Loss: 0.5986
Epoch [94/500], Loss: 0.4245, Val Loss: 0.5231
Epoch [95/500], Loss: 0.2552, Val Loss: 0.6438
Epoch [96/500], Loss: 0.3076, Val Loss: 0.5328
Epoch [97/500], Loss: 0.4489, Val Loss: 0.5613
Epoch [98/500], Loss: 0.8218, Val Loss: 0.6222
Epoch [99/500], Loss: 0.2730, Val Loss: 0.5279
Epoch [100/500], Loss: 0.7840, Val Loss: 0.5163
Epoch [101/500], Loss: 0.3939, Val Loss: 0.5730
Epoch [102/500], Loss: 0.3420, Val Loss: 0.6089
Epoch [103/500], Loss: 0.4251, Val Loss: 0.5507
Epoch [104/500], Loss: 0.2707, Val Loss: 0.6584
Epoch [105/500], Loss: 0.2169, Val Loss: 0.5401
Epoch [106/500], Loss: 0.3240, Val Loss: 0.5559
Epoch [107/500], Loss: 0.3571, Val Loss: 0.5553
Epoch [108/500], Loss: 0.2652, Val Loss: 0.6526
Epoch [109/500], Loss: 0.2072, Val Loss: 0.5434
Epoch [110/500], Loss: 0.5260, Val Loss: 0.5305
Epoch [111/500], Loss: 0.2492, Val Loss: 0.5266
Epoch [112/500], Loss: 0.1702, Val Loss: 0.5581
Epoch [113/500], Loss: 0.3311, Val Loss: 0.5632
Epoch [114/500], Loss: 0.2126, Val Loss: 0.5059
Epoch [115/500], Loss: 0.2156, Val Loss: 0.5483
Epoch [116/500], Loss: 0.2253, Val Loss: 0.5225
Epoch [117/500], Loss: 0.2366, Val Loss: 0.5199
Epoch [118/500], Loss: 0.2231, Val Loss: 0.5177
Epoch [119/500], Loss: 0.4407, Val Loss: 0.5412
Epoch [120/500], Loss: 0.6031, Val Loss: 0.5427
Epoch [121/500], Loss: 0.4133, Val Loss: 0.5574
Epoch [122/500], Loss: 0.2433, Val Loss: 0.7347
Epoch [123/500], Loss: 0.3156, Val Loss: 0.5447
Epoch [124/500], Loss: 0.3726, Val Loss: 0.5298
Epoch [125/500], Loss: 0.7269, Val Loss: 0.5811
Epoch [126/500], Loss: 0.2051, Val Loss: 0.5701
Epoch [127/500], Loss: 0.3777, Val Loss: 0.5993
Epoch [128/500], Loss: 0.3438, Val Loss: 0.5409
Epoch [129/500], Loss: 0.6521, Val Loss: 0.5330
Epoch [130/500], Loss: 1.5489, Val Loss: 0.5512
Epoch [131/500], Loss: 0.2698, Val Loss: 0.5802
Epoch [132/500], Loss: 0.2783, Val Loss: 0.5568
Epoch [133/500], Loss: 0.3206, Val Loss: 0.5237
Epoch [134/500], Loss: 0.3016, Val Loss: 0.5909
Epoch [135/500], Loss: 0.3036, Val Loss: 0.5581
Epoch [136/500], Loss: 0.2522, Val Loss: 0.5545
Epoch [137/500], Loss: 0.3526, Val Loss: 0.5444
Epoch [138/500], Loss: 0.2978, Val Loss: 0.5433
Epoch [139/500], Loss: 0.2267, Val Loss: 0.5294
Epoch [140/500], Loss: 0.1548, Val Loss: 0.5304
Epoch [141/500], Loss: 0.1770, Val Loss: 0.5479
Epoch [142/500], Loss: 0.1624, Val Loss: 0.5143
Epoch [143/500], Loss: 0.2785, Val Loss: 0.5403
Epoch [144/500], Loss: 0.3508, Val Loss: 0.6263
Epoch [145/500], Loss: 0.3473, Val Loss: 0.5339
Epoch [146/500], Loss: 0.2651, Val Loss: 0.5342
Epoch [147/500], Loss: 0.2451, Val Loss: 0.5950
Epoch [148/500], Loss: 0.3262, Val Loss: 0.5487
Epoch [149/500], Loss: 0.1756, Val Loss: 0.6451
Epoch [150/500], Loss: 0.3124, Val Loss: 0.5238
Epoch [151/500], Loss: 0.2129, Val Loss: 0.4997
Epoch [152/500], Loss: 0.3884, Val Loss: 0.5338
Epoch [153/500], Loss: 0.3089, Val Loss: 0.5875
Epoch [154/500], Loss: 0.2576, Val Loss: 0.5210
Epoch [155/500], Loss: 0.3617, Val Loss: 0.5144
Epoch [156/500], Loss: 0.3872, Val Loss: 0.5550
Epoch [157/500], Loss: 0.2794, Val Loss: 0.5988
Epoch [158/500], Loss: 0.2984, Val Loss: 0.4991
Epoch [159/500], Loss: 0.2393, Val Loss: 0.5850
Epoch [160/500], Loss: 0.4333, Val Loss: 0.6183
Epoch [161/500], Loss: 0.5323, Val Loss: 0.5825
Epoch [162/500], Loss: 0.2692, Val Loss: 0.5163
Epoch [163/500], Loss: 0.2050, Val Loss: 0.7505
Epoch [164/500], Loss: 0.3269, Val Loss: 0.5360
Epoch [165/500], Loss: 0.5067, Val Loss: 0.6257
Epoch [166/500], Loss: 0.3530, Val Loss: 0.5323
Epoch [167/500], Loss: 1.6620, Val Loss: 0.6827
Epoch [168/500], Loss: 0.3955, Val Loss: 0.5481
Epoch [169/500], Loss: 0.7234, Val Loss: 0.5239
Epoch [170/500], Loss: 0.3780, Val Loss: 0.5071
Epoch [171/500], Loss: 0.2478, Val Loss: 0.5824
Epoch [172/500], Loss: 0.3267, Val Loss: 0.5579
Epoch [173/500], Loss: 0.3166, Val Loss: 0.5080
Epoch [174/500], Loss: 0.3336, Val Loss: 0.5501
Epoch [175/500], Loss: 0.4310, Val Loss: 0.5037
Epoch [176/500], Loss: 0.1651, Val Loss: 0.6962
Epoch [177/500], Loss: 0.2491, Val Loss: 0.6080
Epoch [178/500], Loss: 0.4041, Val Loss: 0.5516
Epoch [179/500], Loss: 0.2294, Val Loss: 0.6232
Epoch [180/500], Loss: 0.2748, Val Loss: 0.5482
Epoch [181/500], Loss: 0.3952, Val Loss: 0.6195
Epoch [182/500], Loss: 0.5490, Val Loss: 0.5295
Epoch [183/500], Loss: 0.2690, Val Loss: 0.5714
Epoch [184/500], Loss: 0.2693, Val Loss: 0.5574
Epoch [185/500], Loss: 0.1552, Val Loss: 0.4994
Epoch [186/500], Loss: 0.2236, Val Loss: 0.5071
Epoch [187/500], Loss: 0.2131, Val Loss: 0.5332
Epoch [188/500], Loss: 0.2419, Val Loss: 0.5226
Epoch [189/500], Loss: 0.1915, Val Loss: 0.5323
Epoch [190/500], Loss: 0.4362, Val Loss: 0.5956
Epoch [191/500], Loss: 0.2302, Val Loss: 0.5013
Epoch [192/500], Loss: 0.2536, Val Loss: 0.5380
Epoch [193/500], Loss: 0.2667, Val Loss: 0.6621
Epoch [194/500], Loss: 0.2595, Val Loss: 0.6117
Epoch [195/500], Loss: 0.2768, Val Loss: 0.5534
Epoch [196/500], Loss: 0.4114, Val Loss: 0.5788
Epoch [197/500], Loss: 0.5747, Val Loss: 0.6095
Epoch [198/500], Loss: 0.3905, Val Loss: 0.5786
Epoch [199/500], Loss: 0.5708, Val Loss: 0.5228
Epoch [200/500], Loss: 0.2819, Val Loss: 0.8289
Epoch [201/500], Loss: 0.2175, Val Loss: 0.4917
Epoch [202/500], Loss: 0.2755, Val Loss: 0.5434
Epoch [203/500], Loss: 0.2558, Val Loss: 0.4888
Epoch [204/500], Loss: 0.2795, Val Loss: 0.5263
Epoch [205/500], Loss: 0.1681, Val Loss: 0.5264
Epoch [206/500], Loss: 0.2301, Val Loss: 0.5015
Epoch [207/500], Loss: 0.5641, Val Loss: 0.5201
Epoch [208/500], Loss: 0.3001, Val Loss: 0.5924
Epoch [209/500], Loss: 0.3732, Val Loss: 0.4860
Epoch [210/500], Loss: 0.2595, Val Loss: 0.5091
Epoch [211/500], Loss: 0.2896, Val Loss: 0.5007
Epoch [212/500], Loss: 0.2974, Val Loss: 0.5347
Epoch [213/500], Loss: 0.2000, Val Loss: 0.5366
Epoch [214/500], Loss: 0.3018, Val Loss: 0.5727
Epoch [215/500], Loss: 0.2713, Val Loss: 0.5502
Epoch [216/500], Loss: 0.1968, Val Loss: 0.5157
Epoch [217/500], Loss: 0.3501, Val Loss: 0.4892
Epoch [218/500], Loss: 0.2476, Val Loss: 0.5206
Epoch [219/500], Loss: 0.3550, Val Loss: 0.4937
Epoch [220/500], Loss: 0.2012, Val Loss: 0.5074
Epoch [221/500], Loss: 0.2963, Val Loss: 0.5018
Epoch [222/500], Loss: 0.2257, Val Loss: 0.5174
Epoch [223/500], Loss: 0.2533, Val Loss: 0.4964
Epoch [224/500], Loss: 0.2511, Val Loss: 0.4999
Epoch [225/500], Loss: 0.1957, Val Loss: 0.5269
Epoch [226/500], Loss: 0.3384, Val Loss: 0.5649
Epoch [227/500], Loss: 0.5236, Val Loss: 0.5287
Epoch [228/500], Loss: 0.2868, Val Loss: 0.5249
Epoch [229/500], Loss: 0.1999, Val Loss: 0.5065
Epoch [230/500], Loss: 0.2699, Val Loss: 0.5046
Epoch [231/500], Loss: 0.2574, Val Loss: 0.5225
Epoch [232/500], Loss: 0.2382, Val Loss: 0.5020
Epoch [233/500], Loss: 0.2660, Val Loss: 0.5513
Epoch [234/500], Loss: 0.3520, Val Loss: 0.4966
Epoch [235/500], Loss: 0.4566, Val Loss: 0.5256
Epoch [236/500], Loss: 0.2300, Val Loss: 0.4898
Epoch [237/500], Loss: 0.2002, Val Loss: 0.5321
Epoch [238/500], Loss: 0.2078, Val Loss: 0.4991
Epoch [239/500], Loss: 0.2743, Val Loss: 0.5081
Epoch [240/500], Loss: 0.4947, Val Loss: 0.7017
Epoch [241/500], Loss: 0.2661, Val Loss: 0.5348
Epoch [242/500], Loss: 0.2557, Val Loss: 0.5242
Epoch [243/500], Loss: 0.2888, Val Loss: 0.5087
Epoch [244/500], Loss: 0.1792, Val Loss: 0.4802
Epoch [245/500], Loss: 0.2123, Val Loss: 0.5263
Epoch [246/500], Loss: 0.1763, Val Loss: 0.4984
Epoch [247/500], Loss: 0.3092, Val Loss: 0.4979
Epoch [248/500], Loss: 0.2102, Val Loss: 0.6523
Epoch [249/500], Loss: 0.4111, Val Loss: 0.5713
Epoch [250/500], Loss: 0.2123, Val Loss: 0.4732
Epoch [251/500], Loss: 0.2433, Val Loss: 0.5151
Epoch [252/500], Loss: 0.2290, Val Loss: 0.5095
Epoch [253/500], Loss: 0.2756, Val Loss: 0.4902
Epoch [254/500], Loss: 0.2112, Val Loss: 0.5285
Epoch [255/500], Loss: 0.2869, Val Loss: 0.5733
Epoch [256/500], Loss: 0.4885, Val Loss: 0.5407
Epoch [257/500], Loss: 0.7868, Val Loss: 0.4965
Epoch [258/500], Loss: 0.4114, Val Loss: 0.5088
Epoch [259/500], Loss: 0.9223, Val Loss: 0.5395
Epoch [260/500], Loss: 0.2732, Val Loss: 0.5410
Epoch [261/500], Loss: 0.3034, Val Loss: 0.5271
Epoch [262/500], Loss: 0.5179, Val Loss: 0.6398
Epoch [263/500], Loss: 0.2965, Val Loss: 0.4982
Epoch [264/500], Loss: 0.2705, Val Loss: 0.5215
Epoch [265/500], Loss: 0.1541, Val Loss: 0.5022
Epoch [266/500], Loss: 0.2437, Val Loss: 0.4805
Epoch [267/500], Loss: 0.2330, Val Loss: 0.5085
Epoch [268/500], Loss: 0.3912, Val Loss: 0.4953
Epoch [269/500], Loss: 1.2263, Val Loss: 0.5805
Epoch [270/500], Loss: 1.0234, Val Loss: 0.5952
Epoch [271/500], Loss: 0.2570, Val Loss: 0.5407
Epoch [272/500], Loss: 0.2098, Val Loss: 0.5439
Epoch [273/500], Loss: 0.4893, Val Loss: 0.4902
Epoch [274/500], Loss: 0.2101, Val Loss: 0.4764
Epoch [275/500], Loss: 0.1698, Val Loss: 0.4948
Epoch [276/500], Loss: 0.2255, Val Loss: 0.5062
Epoch [277/500], Loss: 0.2800, Val Loss: 0.4964
Epoch [278/500], Loss: 0.1997, Val Loss: 0.4944
Epoch [279/500], Loss: 0.1781, Val Loss: 0.5191
Epoch [280/500], Loss: 0.3292, Val Loss: 0.4975
Epoch [281/500], Loss: 0.4042, Val Loss: 0.5358
Epoch [282/500], Loss: 0.3637, Val Loss: 0.4806
Epoch [283/500], Loss: 0.2486, Val Loss: 0.5009
Epoch [284/500], Loss: 0.2120, Val Loss: 0.5184
Epoch [285/500], Loss: 0.1952, Val Loss: 0.5193
Epoch [286/500], Loss: 0.2979, Val Loss: 0.6004
Epoch [287/500], Loss: 0.3187, Val Loss: 0.5353
Epoch [288/500], Loss: 0.2643, Val Loss: 0.5683
Epoch [289/500], Loss: 0.2422, Val Loss: 0.5281
Epoch [290/500], Loss: 0.2526, Val Loss: 0.4997
Epoch [291/500], Loss: 0.2767, Val Loss: 0.5173
Epoch [292/500], Loss: 0.3284, Val Loss: 0.4840
Epoch [293/500], Loss: 0.2548, Val Loss: 0.4793
Epoch [294/500], Loss: 0.1870, Val Loss: 0.4853
Epoch [295/500], Loss: 0.2067, Val Loss: 0.4891
Epoch [296/500], Loss: 0.2211, Val Loss: 0.5342
Epoch [297/500], Loss: 0.1959, Val Loss: 0.5482
Epoch [298/500], Loss: 0.2572, Val Loss: 0.5922
Epoch [299/500], Loss: 0.3096, Val Loss: 0.5304
Epoch [300/500], Loss: 0.1440, Val Loss: 0.5272
Epoch [301/500], Loss: 0.3450, Val Loss: 0.4809
Epoch [302/500], Loss: 0.2275, Val Loss: 0.5230
Epoch [303/500], Loss: 0.1658, Val Loss: 0.5254
Epoch [304/500], Loss: 0.2304, Val Loss: 0.6245
Epoch [305/500], Loss: 0.3530, Val Loss: 0.4981
Epoch [306/500], Loss: 0.2484, Val Loss: 0.5114
Epoch [307/500], Loss: 0.1974, Val Loss: 0.5120
Epoch [308/500], Loss: 0.2916, Val Loss: 0.5335
Epoch [309/500], Loss: 0.3826, Val Loss: 0.4994
Epoch [310/500], Loss: 0.3958, Val Loss: 0.5106
Epoch [311/500], Loss: 0.2466, Val Loss: 0.5088
Epoch [312/500], Loss: 0.2637, Val Loss: 0.4821
Epoch [313/500], Loss: 0.3026, Val Loss: 0.5010
Epoch [314/500], Loss: 0.2067, Val Loss: 0.5028
Epoch [315/500], Loss: 0.2197, Val Loss: 0.5296
Epoch [316/500], Loss: 0.2294, Val Loss: 0.5236
Epoch [317/500], Loss: 0.2871, Val Loss: 0.5145
Epoch [318/500], Loss: 0.2765, Val Loss: 0.4995
Epoch [319/500], Loss: 0.2630, Val Loss: 0.5879
Epoch [320/500], Loss: 0.1841, Val Loss: 0.5273
Epoch [321/500], Loss: 0.3284, Val Loss: 0.5922
Epoch [322/500], Loss: 0.2175, Val Loss: 0.5426
Epoch [323/500], Loss: 0.2109, Val Loss: 0.5041
Epoch [324/500], Loss: 1.4227, Val Loss: 0.5333
Epoch [325/500], Loss: 0.3682, Val Loss: 0.5039
Epoch [326/500], Loss: 0.2453, Val Loss: 0.5007
Epoch [327/500], Loss: 0.1669, Val Loss: 0.4769
Epoch [328/500], Loss: 0.1951, Val Loss: 0.4717
Epoch [329/500], Loss: 0.2003, Val Loss: 0.4974
Epoch [330/500], Loss: 0.3557, Val Loss: 0.5103
Epoch [331/500], Loss: 0.2539, Val Loss: 0.5113
Epoch [332/500], Loss: 0.2442, Val Loss: 0.5182
Epoch [333/500], Loss: 0.2536, Val Loss: 0.5964
Epoch [334/500], Loss: 0.2569, Val Loss: 0.5253
Epoch [335/500], Loss: 0.2170, Val Loss: 0.5414
Epoch [336/500], Loss: 1.5315, Val Loss: 0.5074
Epoch [337/500], Loss: 0.3112, Val Loss: 0.6028
Epoch [338/500], Loss: 0.1434, Val Loss: 0.5420
Epoch [339/500], Loss: 0.2689, Val Loss: 0.4936
Epoch [340/500], Loss: 0.2198, Val Loss: 0.4945
Epoch [341/500], Loss: 0.2488, Val Loss: 0.5335
Epoch [342/500], Loss: 0.2220, Val Loss: 0.5231
Epoch [343/500], Loss: 0.1789, Val Loss: 0.6362
Epoch [344/500], Loss: 0.1614, Val Loss: 0.4936
Epoch [345/500], Loss: 0.2264, Val Loss: 0.6494
Epoch [346/500], Loss: 0.2510, Val Loss: 0.5451
Epoch [347/500], Loss: 0.3913, Val Loss: 0.5046
Epoch [348/500], Loss: 0.1966, Val Loss: 0.5133
Epoch [349/500], Loss: 0.3156, Val Loss: 0.5012
Epoch [350/500], Loss: 0.2930, Val Loss: 0.6692
Epoch [351/500], Loss: 0.1652, Val Loss: 0.4904
Epoch [352/500], Loss: 0.1658, Val Loss: 0.4980
Epoch [353/500], Loss: 0.2108, Val Loss: 0.4822
Epoch [354/500], Loss: 0.2206, Val Loss: 0.5019
Epoch [355/500], Loss: 0.3788, Val Loss: 0.5149
Epoch [356/500], Loss: 0.1826, Val Loss: 0.5061
Epoch [357/500], Loss: 0.2495, Val Loss: 0.5127
Epoch [358/500], Loss: 0.3314, Val Loss: 0.4830
Epoch [359/500], Loss: 0.2907, Val Loss: 0.6062
Epoch [360/500], Loss: 0.2981, Val Loss: 0.5069
Epoch [361/500], Loss: 0.4206, Val Loss: 0.5182
Epoch [362/500], Loss: 0.2004, Val Loss: 0.5042
Epoch [363/500], Loss: 0.1563, Val Loss: 0.5059
Epoch [364/500], Loss: 0.2153, Val Loss: 0.5282
Epoch [365/500], Loss: 0.4260, Val Loss: 0.5306
Epoch [366/500], Loss: 0.2852, Val Loss: 0.5078
Epoch [367/500], Loss: 0.6356, Val Loss: 0.5036
Epoch [368/500], Loss: 0.2360, Val Loss: 0.6375
Epoch [369/500], Loss: 0.3798, Val Loss: 0.5625
Epoch [370/500], Loss: 0.2720, Val Loss: 0.5633
Epoch [371/500], Loss: 0.2343, Val Loss: 0.5083
Epoch [372/500], Loss: 1.1079, Val Loss: 0.5503
Epoch [373/500], Loss: 0.3219, Val Loss: 0.5104
Epoch [374/500], Loss: 0.2230, Val Loss: 0.5100
Epoch [375/500], Loss: 0.2208, Val Loss: 0.4952
Epoch [376/500], Loss: 0.9436, Val Loss: 0.5071
Epoch [377/500], Loss: 0.1944, Val Loss: 0.5010
Epoch [378/500], Loss: 0.8698, Val Loss: 0.5064
Epoch [379/500], Loss: 0.2021, Val Loss: 0.5383
Epoch [380/500], Loss: 0.3009, Val Loss: 0.5878
Epoch [381/500], Loss: 0.2064, Val Loss: 0.5827
Epoch [382/500], Loss: 0.1801, Val Loss: 0.5448
Epoch [383/500], Loss: 0.2641, Val Loss: 0.5257
Epoch [384/500], Loss: 0.2662, Val Loss: 0.5106
Epoch [385/500], Loss: 0.3114, Val Loss: 0.5432
Epoch [386/500], Loss: 0.2463, Val Loss: 0.4918
Epoch [387/500], Loss: 0.3814, Val Loss: 0.5274
Epoch [388/500], Loss: 0.2806, Val Loss: 0.5320
Epoch [389/500], Loss: 0.1964, Val Loss: 0.5095
Epoch [390/500], Loss: 0.2539, Val Loss: 0.4809
Epoch [391/500], Loss: 0.2794, Val Loss: 0.5214
Epoch [392/500], Loss: 0.3106, Val Loss: 0.5474
Epoch [393/500], Loss: 0.4092, Val Loss: 0.4662
Epoch [394/500], Loss: 0.2791, Val Loss: 0.5442
Epoch [395/500], Loss: 0.1702, Val Loss: 0.4826
Epoch [396/500], Loss: 0.3028, Val Loss: 0.5165
Epoch [397/500], Loss: 0.2034, Val Loss: 0.5091
Epoch [398/500], Loss: 0.2256, Val Loss: 0.5330
Epoch [399/500], Loss: 0.5639, Val Loss: 0.5547
Epoch [400/500], Loss: 0.1718, Val Loss: 0.5017
Epoch [401/500], Loss: 0.2380, Val Loss: 0.5047
Epoch [402/500], Loss: 0.2326, Val Loss: 0.4921
Epoch [403/500], Loss: 0.2340, Val Loss: 0.5240
Epoch [404/500], Loss: 0.4558, Val Loss: 0.5178
Epoch [405/500], Loss: 0.7921, Val Loss: 0.5299
Epoch [406/500], Loss: 0.7788, Val Loss: 0.5308
Epoch [407/500], Loss: 0.3244, Val Loss: 0.5106
Epoch [408/500], Loss: 0.2682, Val Loss: 0.4808
Epoch [409/500], Loss: 1.1516, Val Loss: 0.5147
Epoch [410/500], Loss: 0.3671, Val Loss: 0.5113
Epoch [411/500], Loss: 0.3253, Val Loss: 0.4962
Epoch [412/500], Loss: 0.2556, Val Loss: 0.5149
Epoch [413/500], Loss: 0.3134, Val Loss: 0.4961
Epoch [414/500], Loss: 0.3429, Val Loss: 0.5101
Epoch [415/500], Loss: 0.2918, Val Loss: 0.5062
Epoch [416/500], Loss: 0.2603, Val Loss: 0.6177
Epoch [417/500], Loss: 0.1818, Val Loss: 0.4911
Epoch [418/500], Loss: 0.1829, Val Loss: 0.5475
Epoch [419/500], Loss: 0.2054, Val Loss: 0.5156
Epoch [420/500], Loss: 0.2476, Val Loss: 0.5356
Epoch [421/500], Loss: 0.2436, Val Loss: 0.5153
Epoch [422/500], Loss: 0.2868, Val Loss: 0.5481
Epoch [423/500], Loss: 0.1989, Val Loss: 0.5223
Epoch [424/500], Loss: 0.2059, Val Loss: 0.5087
Epoch [425/500], Loss: 0.2283, Val Loss: 0.6161
Epoch [426/500], Loss: 0.2960, Val Loss: 0.5258
Epoch [427/500], Loss: 0.2856, Val Loss: 0.5383
Epoch [428/500], Loss: 0.4128, Val Loss: 0.5405
Epoch [429/500], Loss: 0.1668, Val Loss: 0.5063
Epoch [430/500], Loss: 0.1656, Val Loss: 0.5119
Epoch [431/500], Loss: 0.3261, Val Loss: 0.5354
Epoch [432/500], Loss: 0.4803, Val Loss: 0.5022
Epoch [433/500], Loss: 0.1902, Val Loss: 0.5237
Epoch [434/500], Loss: 0.1980, Val Loss: 0.5579
Epoch [435/500], Loss: 0.2501, Val Loss: 0.5315
Epoch [436/500], Loss: 0.3723, Val Loss: 0.5517
Epoch [437/500], Loss: 0.2321, Val Loss: 0.5352
Epoch [438/500], Loss: 0.2481, Val Loss: 0.5110
Epoch [439/500], Loss: 0.3130, Val Loss: 0.6350
Epoch [440/500], Loss: 0.2515, Val Loss: 0.4977
Epoch [441/500], Loss: 0.3065, Val Loss: 0.5769
Epoch [442/500], Loss: 1.7380, Val Loss: 0.5149
Epoch [443/500], Loss: 0.3447, Val Loss: 0.5321
Epoch [444/500], Loss: 0.2701, Val Loss: 0.5456
Epoch [445/500], Loss: 0.2135, Val Loss: 0.5002
Epoch [446/500], Loss: 0.1595, Val Loss: 0.5073
Epoch [447/500], Loss: 0.2105, Val Loss: 0.5068
Epoch [448/500], Loss: 0.2997, Val Loss: 0.4980
Epoch [449/500], Loss: 0.2703, Val Loss: 0.5122
Epoch [450/500], Loss: 0.2026, Val Loss: 0.5043
Epoch [451/500], Loss: 0.1567, Val Loss: 0.4746
Epoch [452/500], Loss: 0.1717, Val Loss: 0.5039
Epoch [453/500], Loss: 0.5440, Val Loss: 0.5912
Epoch [454/500], Loss: 0.2874, Val Loss: 0.4879
Epoch [455/500], Loss: 0.1902, Val Loss: 0.5606
Epoch [456/500], Loss: 0.1742, Val Loss: 0.5001
Epoch [457/500], Loss: 0.1750, Val Loss: 0.4984
Epoch [458/500], Loss: 0.2695, Val Loss: 0.5235
Epoch [459/500], Loss: 0.2366, Val Loss: 0.5078
Epoch [460/500], Loss: 0.2128, Val Loss: 0.5323
Epoch [461/500], Loss: 0.1942, Val Loss: 0.5320
Epoch [462/500], Loss: 0.2203, Val Loss: 0.5587
Epoch [463/500], Loss: 0.3984, Val Loss: 0.5130
Epoch [464/500], Loss: 0.1766, Val Loss: 0.5200
Epoch [465/500], Loss: 0.3749, Val Loss: 0.4894
Epoch [466/500], Loss: 0.2591, Val Loss: 0.5431
Epoch [467/500], Loss: 0.1850, Val Loss: 0.4817
Epoch [468/500], Loss: 0.2239, Val Loss: 0.4963
Epoch [469/500], Loss: 0.2092, Val Loss: 0.5050
Epoch [470/500], Loss: 0.2028, Val Loss: 0.4891
Epoch [471/500], Loss: 0.1822, Val Loss: 0.5093
Epoch [472/500], Loss: 0.2617, Val Loss: 0.5298
Epoch [473/500], Loss: 0.3329, Val Loss: 0.5185
Epoch [474/500], Loss: 0.2460, Val Loss: 0.4910
Epoch [475/500], Loss: 0.2529, Val Loss: 0.5311
Epoch [476/500], Loss: 0.2680, Val Loss: 0.4890
Epoch [477/500], Loss: 0.1489, Val Loss: 0.5389
Epoch [478/500], Loss: 0.2907, Val Loss: 0.4900
Epoch [479/500], Loss: 0.3608, Val Loss: 0.6629
Epoch [480/500], Loss: 0.2853, Val Loss: 0.5808
Epoch [481/500], Loss: 0.2294, Val Loss: 0.4948
Epoch [482/500], Loss: 0.2429, Val Loss: 0.5160
Epoch [483/500], Loss: 0.9811, Val Loss: 0.4889
Epoch [484/500], Loss: 0.2984, Val Loss: 0.4984
Epoch [485/500], Loss: 0.2787, Val Loss: 0.5336
Epoch [486/500], Loss: 0.2387, Val Loss: 0.5107
Epoch [487/500], Loss: 0.2323, Val Loss: 0.4899
Epoch [488/500], Loss: 0.1969, Val Loss: 0.4864
Epoch [489/500], Loss: 0.4861, Val Loss: 0.5268
Epoch [490/500], Loss: 0.3029, Val Loss: 0.5193
Epoch [491/500], Loss: 0.2171, Val Loss: 0.4850
Epoch [492/500], Loss: 0.2473, Val Loss: 0.5155
Early stopping at epoch 492
Runtime: 0:03:04.204598
R^2 Score: 0.9169
RMSE: 0.6528
MAE: 0.1854
MAPE: 15.77%
Using optimizer: Adam
TruncatedSVD_50
MLP with layer size: [222, 900, 1384, 1024, 160] - Result:
Epoch [1/1000], Loss: 0.9296, Val Loss: 0.9279
Epoch [2/1000], Loss: 0.6447, Val Loss: 0.8081
Epoch [3/1000], Loss: 0.9035, Val Loss: 0.8304
Epoch [4/1000], Loss: 0.6826, Val Loss: 0.9356
Epoch [5/1000], Loss: 0.6236, Val Loss: 0.7351
Epoch [6/1000], Loss: 0.6168, Val Loss: 0.7843
Epoch [7/1000], Loss: 1.0265, Val Loss: 0.7002
Epoch [8/1000], Loss: 0.9246, Val Loss: 0.8649
Epoch [9/1000], Loss: 0.6706, Val Loss: 0.6899
Epoch [10/1000], Loss: 0.3610, Val Loss: 0.7101
Epoch [11/1000], Loss: 0.3835, Val Loss: 0.6244
Epoch [12/1000], Loss: 0.5238, Val Loss: 0.7298
Epoch [13/1000], Loss: 0.5475, Val Loss: 0.6418
Epoch [14/1000], Loss: 0.4720, Val Loss: 0.6819
Epoch [15/1000], Loss: 0.4393, Val Loss: 0.6437
Epoch [16/1000], Loss: 0.6660, Val Loss: 0.6821
Epoch [17/1000], Loss: 0.4465, Val Loss: 0.6772
Epoch [18/1000], Loss: 0.5599, Val Loss: 0.5533
Epoch [19/1000], Loss: 0.7710, Val Loss: 0.6158
Epoch [20/1000], Loss: 0.3707, Val Loss: 0.5881
Epoch [21/1000], Loss: 0.4529, Val Loss: 0.7308
Epoch [22/1000], Loss: 0.2730, Val Loss: 0.6922
Epoch [23/1000], Loss: 0.4066, Val Loss: 0.6220
Epoch [24/1000], Loss: 0.6618, Val Loss: 0.6933
Epoch [25/1000], Loss: 0.4513, Val Loss: 0.5939
Epoch [26/1000], Loss: 0.5199, Val Loss: 0.5750
Epoch [27/1000], Loss: 0.4505, Val Loss: 0.6740
Epoch [28/1000], Loss: 0.3453, Val Loss: 0.5530
Epoch [29/1000], Loss: 0.2757, Val Loss: 0.5671
Epoch [30/1000], Loss: 0.2843, Val Loss: 0.5803
Epoch [31/1000], Loss: 0.5303, Val Loss: 0.6312
Epoch [32/1000], Loss: 0.2561, Val Loss: 0.6092
Epoch [33/1000], Loss: 0.3532, Val Loss: 0.5610
Epoch [34/1000], Loss: 0.5179, Val Loss: 0.6858
Epoch [35/1000], Loss: 0.4006, Val Loss: 0.7359
Epoch [36/1000], Loss: 0.5533, Val Loss: 0.5656
Epoch [37/1000], Loss: 0.4660, Val Loss: 0.6465
Epoch [38/1000], Loss: 0.3610, Val Loss: 0.5267
Epoch [39/1000], Loss: 0.3082, Val Loss: 0.6553
Epoch [40/1000], Loss: 0.4134, Val Loss: 0.6098
Epoch [41/1000], Loss: 0.2735, Val Loss: 0.5231
Epoch [42/1000], Loss: 0.3524, Val Loss: 0.6228
Epoch [43/1000], Loss: 0.2233, Val Loss: 0.5628
Epoch [44/1000], Loss: 0.3165, Val Loss: 0.5920
Epoch [45/1000], Loss: 0.2323, Val Loss: 0.6838
Epoch [46/1000], Loss: 0.3669, Val Loss: 0.5905
Epoch [47/1000], Loss: 0.3939, Val Loss: 0.5512
Epoch [48/1000], Loss: 0.2554, Val Loss: 0.5536
Epoch [49/1000], Loss: 1.0971, Val Loss: 0.6730
Epoch [50/1000], Loss: 0.2744, Val Loss: 0.7058
Epoch [51/1000], Loss: 0.9573, Val Loss: 0.5530
Epoch [52/1000], Loss: 0.2600, Val Loss: 0.5842
Epoch [53/1000], Loss: 0.4908, Val Loss: 0.5950
Epoch [54/1000], Loss: 0.6030, Val Loss: 0.5932
Epoch [55/1000], Loss: 0.3374, Val Loss: 0.5572
Epoch [56/1000], Loss: 0.2934, Val Loss: 0.5535
Epoch [57/1000], Loss: 0.3507, Val Loss: 0.6435
Epoch [58/1000], Loss: 0.2996, Val Loss: 0.6260
Epoch [59/1000], Loss: 0.4295, Val Loss: 0.5602
Epoch [60/1000], Loss: 0.3478, Val Loss: 0.6122
Epoch [61/1000], Loss: 0.3414, Val Loss: 0.5757
Epoch [62/1000], Loss: 0.2814, Val Loss: 0.5447
Epoch [63/1000], Loss: 0.3858, Val Loss: 0.5490
Epoch [64/1000], Loss: 0.4481, Val Loss: 0.5601
Epoch [65/1000], Loss: 0.2983, Val Loss: 0.5321
Epoch [66/1000], Loss: 0.2590, Val Loss: 0.5503
Epoch [67/1000], Loss: 0.5168, Val Loss: 0.5317
Epoch [68/1000], Loss: 0.3578, Val Loss: 0.5525
Epoch [69/1000], Loss: 0.2165, Val Loss: 0.5822
Epoch [70/1000], Loss: 0.3609, Val Loss: 0.6765
Epoch [71/1000], Loss: 0.2135, Val Loss: 0.5292
Epoch [72/1000], Loss: 0.3327, Val Loss: 0.5372
Epoch [73/1000], Loss: 0.4034, Val Loss: 0.6341
Epoch [74/1000], Loss: 0.2008, Val Loss: 0.5623
Epoch [75/1000], Loss: 0.3830, Val Loss: 0.6080
Epoch [76/1000], Loss: 0.3996, Val Loss: 0.5979
Epoch [77/1000], Loss: 0.3284, Val Loss: 0.6666
Epoch [78/1000], Loss: 0.2801, Val Loss: 0.5627
Epoch [79/1000], Loss: 0.4083, Val Loss: 0.5447
Epoch [80/1000], Loss: 0.5386, Val Loss: 0.5865
Epoch [81/1000], Loss: 0.1938, Val Loss: 0.5252
Epoch [82/1000], Loss: 0.5460, Val Loss: 0.5564
Epoch [83/1000], Loss: 0.3008, Val Loss: 0.5866
Epoch [84/1000], Loss: 0.2792, Val Loss: 0.5603
Epoch [85/1000], Loss: 0.3863, Val Loss: 0.6286
Epoch [86/1000], Loss: 0.3364, Val Loss: 0.5932
Epoch [87/1000], Loss: 0.2478, Val Loss: 0.5640
Epoch [88/1000], Loss: 0.2634, Val Loss: 0.5818
Epoch [89/1000], Loss: 0.3332, Val Loss: 0.6352
Epoch [90/1000], Loss: 0.2753, Val Loss: 0.6062
Epoch [91/1000], Loss: 0.3913, Val Loss: 0.5795
Epoch [92/1000], Loss: 0.4119, Val Loss: 0.5774
Epoch [93/1000], Loss: 0.4745, Val Loss: 0.5929
Epoch [94/1000], Loss: 0.3236, Val Loss: 0.5657
Epoch [95/1000], Loss: 0.1826, Val Loss: 0.5320
Epoch [96/1000], Loss: 0.6124, Val Loss: 0.5809
Epoch [97/1000], Loss: 0.2554, Val Loss: 0.5407
Epoch [98/1000], Loss: 0.3134, Val Loss: 0.5341
Epoch [99/1000], Loss: 0.3150, Val Loss: 0.5808
Epoch [100/1000], Loss: 0.2385, Val Loss: 0.5466
Epoch [101/1000], Loss: 0.4344, Val Loss: 0.5326
Epoch [102/1000], Loss: 0.3791, Val Loss: 0.5329
Epoch [103/1000], Loss: 0.3310, Val Loss: 0.5162
Epoch [104/1000], Loss: 0.2133, Val Loss: 0.5362
Epoch [105/1000], Loss: 0.2549, Val Loss: 0.5139
Epoch [106/1000], Loss: 0.4330, Val Loss: 0.5392
Epoch [107/1000], Loss: 0.7046, Val Loss: 0.5680
Epoch [108/1000], Loss: 0.2837, Val Loss: 0.5997
Epoch [109/1000], Loss: 0.2384, Val Loss: 0.5515
Epoch [110/1000], Loss: 0.2177, Val Loss: 0.5224
Epoch [111/1000], Loss: 0.1667, Val Loss: 0.5400
Epoch [112/1000], Loss: 0.2086, Val Loss: 0.5347
Epoch [113/1000], Loss: 0.1776, Val Loss: 0.5894
Epoch [114/1000], Loss: 0.2287, Val Loss: 0.5247
Epoch [115/1000], Loss: 0.2126, Val Loss: 0.5493
Epoch [116/1000], Loss: 0.2278, Val Loss: 0.5312
Epoch [117/1000], Loss: 0.1718, Val Loss: 0.5560
Epoch [118/1000], Loss: 0.2618, Val Loss: 0.5310
Epoch [119/1000], Loss: 0.2777, Val Loss: 0.5857
Epoch [120/1000], Loss: 0.4186, Val Loss: 0.6528
Epoch [121/1000], Loss: 0.4127, Val Loss: 0.5884
Epoch [122/1000], Loss: 0.2842, Val Loss: 0.5444
Epoch [123/1000], Loss: 0.3194, Val Loss: 0.5899
Epoch [124/1000], Loss: 0.4586, Val Loss: 0.5914
Epoch [125/1000], Loss: 0.3346, Val Loss: 0.5223
Epoch [126/1000], Loss: 0.2365, Val Loss: 0.5205
Epoch [127/1000], Loss: 0.3589, Val Loss: 0.5613
Epoch [128/1000], Loss: 0.5890, Val Loss: 0.5607
Epoch [129/1000], Loss: 0.3210, Val Loss: 0.5669
Epoch [130/1000], Loss: 1.4579, Val Loss: 0.5997
Epoch [131/1000], Loss: 0.4929, Val Loss: 0.6020
Epoch [132/1000], Loss: 0.3943, Val Loss: 0.5514
Epoch [133/1000], Loss: 0.1604, Val Loss: 0.5176
Epoch [134/1000], Loss: 0.3316, Val Loss: 0.5219
Epoch [135/1000], Loss: 0.2751, Val Loss: 0.5250
Epoch [136/1000], Loss: 0.3761, Val Loss: 0.5895
Epoch [137/1000], Loss: 0.2667, Val Loss: 0.6884
Epoch [138/1000], Loss: 0.3945, Val Loss: 0.5801
Epoch [139/1000], Loss: 0.2570, Val Loss: 0.5844
Epoch [140/1000], Loss: 0.2182, Val Loss: 0.5141
Epoch [141/1000], Loss: 0.3779, Val Loss: 0.5228
Epoch [142/1000], Loss: 0.2057, Val Loss: 0.5217
Epoch [143/1000], Loss: 0.3603, Val Loss: 0.5090
Epoch [144/1000], Loss: 0.4425, Val Loss: 0.5240
Epoch [145/1000], Loss: 0.5951, Val Loss: 0.5372
Epoch [146/1000], Loss: 0.2775, Val Loss: 0.5391
Epoch [147/1000], Loss: 0.5029, Val Loss: 0.5583
Epoch [148/1000], Loss: 0.2221, Val Loss: 0.5077
Epoch [149/1000], Loss: 0.2083, Val Loss: 0.5212
Epoch [150/1000], Loss: 0.5145, Val Loss: 0.5250
Epoch [151/1000], Loss: 0.3402, Val Loss: 0.5793
Epoch [152/1000], Loss: 0.4058, Val Loss: 0.5148
Epoch [153/1000], Loss: 0.3585, Val Loss: 0.5204
Epoch [154/1000], Loss: 0.2348, Val Loss: 0.5485
Epoch [155/1000], Loss: 0.3236, Val Loss: 0.5452
Epoch [156/1000], Loss: 0.2279, Val Loss: 0.5700
Epoch [157/1000], Loss: 0.3199, Val Loss: 0.5432
Epoch [158/1000], Loss: 0.2506, Val Loss: 0.5157
Epoch [159/1000], Loss: 0.2828, Val Loss: 0.5505
Epoch [160/1000], Loss: 0.2527, Val Loss: 0.5340
Epoch [161/1000], Loss: 0.2808, Val Loss: 0.5560
Epoch [162/1000], Loss: 0.2588, Val Loss: 0.5419
Epoch [163/1000], Loss: 0.2177, Val Loss: 0.5477
Epoch [164/1000], Loss: 0.3946, Val Loss: 0.5349
Epoch [165/1000], Loss: 0.2775, Val Loss: 0.5324
Epoch [166/1000], Loss: 0.2569, Val Loss: 0.5587
Epoch [167/1000], Loss: 0.5270, Val Loss: 0.5449
Epoch [168/1000], Loss: 0.7887, Val Loss: 0.5636
Epoch [169/1000], Loss: 0.1854, Val Loss: 0.5234
Epoch [170/1000], Loss: 0.2373, Val Loss: 0.5528
Epoch [171/1000], Loss: 0.3450, Val Loss: 0.5169
Epoch [172/1000], Loss: 0.2376, Val Loss: 0.5520
Epoch [173/1000], Loss: 0.3206, Val Loss: 0.5338
Epoch [174/1000], Loss: 0.4041, Val Loss: 0.5579
Epoch [175/1000], Loss: 0.4110, Val Loss: 0.5171
Epoch [176/1000], Loss: 0.2087, Val Loss: 0.5553
Epoch [177/1000], Loss: 0.3010, Val Loss: 0.5642
Epoch [178/1000], Loss: 0.2166, Val Loss: 0.5220
Epoch [179/1000], Loss: 0.1904, Val Loss: 0.5207
Epoch [180/1000], Loss: 0.2952, Val Loss: 0.5611
Epoch [181/1000], Loss: 0.2011, Val Loss: 0.5809
Epoch [182/1000], Loss: 0.2996, Val Loss: 0.5064
Epoch [183/1000], Loss: 0.2206, Val Loss: 0.5176
Epoch [184/1000], Loss: 0.2415, Val Loss: 0.4996
Epoch [185/1000], Loss: 0.3006, Val Loss: 0.5199
Epoch [186/1000], Loss: 0.2162, Val Loss: 0.5212
Epoch [187/1000], Loss: 0.1970, Val Loss: 0.5210
Epoch [188/1000], Loss: 0.1163, Val Loss: 0.5047
Epoch [189/1000], Loss: 0.2049, Val Loss: 0.5266
Epoch [190/1000], Loss: 0.4380, Val Loss: 0.5068
Epoch [191/1000], Loss: 0.2051, Val Loss: 0.5627
Epoch [192/1000], Loss: 0.2305, Val Loss: 0.5669
Epoch [193/1000], Loss: 0.3636, Val Loss: 0.5721
Epoch [194/1000], Loss: 0.3685, Val Loss: 0.5496
Epoch [195/1000], Loss: 0.7040, Val Loss: 0.5923
Epoch [196/1000], Loss: 0.2634, Val Loss: 0.5321
Epoch [197/1000], Loss: 0.2748, Val Loss: 0.5565
Epoch [198/1000], Loss: 0.2868, Val Loss: 0.5269
Epoch [199/1000], Loss: 0.2368, Val Loss: 0.4992
Epoch [200/1000], Loss: 0.2033, Val Loss: 0.5264
Epoch [201/1000], Loss: 0.2360, Val Loss: 0.5504
Epoch [202/1000], Loss: 0.1867, Val Loss: 0.5853
Epoch [203/1000], Loss: 0.7867, Val Loss: 0.5124
Epoch [204/1000], Loss: 0.3001, Val Loss: 0.5789
Epoch [205/1000], Loss: 0.2170, Val Loss: 0.5189
Epoch [206/1000], Loss: 0.2273, Val Loss: 0.5046
Epoch [207/1000], Loss: 0.2194, Val Loss: 0.5151
Epoch [208/1000], Loss: 0.2684, Val Loss: 0.5273
Epoch [209/1000], Loss: 0.2548, Val Loss: 0.5845
Epoch [210/1000], Loss: 0.2036, Val Loss: 0.5444
Epoch [211/1000], Loss: 0.1993, Val Loss: 0.5030
Epoch [212/1000], Loss: 0.2258, Val Loss: 0.5195
Epoch [213/1000], Loss: 0.3022, Val Loss: 0.5319
Epoch [214/1000], Loss: 0.2300, Val Loss: 0.5203
Epoch [215/1000], Loss: 0.2178, Val Loss: 0.5261
Epoch [216/1000], Loss: 0.4229, Val Loss: 0.6112
Epoch [217/1000], Loss: 0.2550, Val Loss: 0.5312
Epoch [218/1000], Loss: 0.2900, Val Loss: 0.5276
Epoch [219/1000], Loss: 0.2451, Val Loss: 0.5208
Epoch [220/1000], Loss: 0.2248, Val Loss: 0.5620
Epoch [221/1000], Loss: 0.4551, Val Loss: 0.6307
Epoch [222/1000], Loss: 0.2294, Val Loss: 0.5139
Epoch [223/1000], Loss: 0.2079, Val Loss: 0.5289
Epoch [224/1000], Loss: 0.2000, Val Loss: 0.4904
Epoch [225/1000], Loss: 0.7359, Val Loss: 0.5294
Epoch [226/1000], Loss: 0.4009, Val Loss: 0.5395
Epoch [227/1000], Loss: 0.3430, Val Loss: 0.5585
Epoch [228/1000], Loss: 0.2261, Val Loss: 0.5419
Epoch [229/1000], Loss: 0.2373, Val Loss: 0.5001
Epoch [230/1000], Loss: 0.3549, Val Loss: 0.5091
Epoch [231/1000], Loss: 0.2731, Val Loss: 0.5134
Epoch [232/1000], Loss: 0.2984, Val Loss: 0.5342
Epoch [233/1000], Loss: 0.5072, Val Loss: 0.5221
Epoch [234/1000], Loss: 0.3980, Val Loss: 0.5179
Epoch [235/1000], Loss: 0.2286, Val Loss: 0.5470
Epoch [236/1000], Loss: 0.2382, Val Loss: 0.5208
Epoch [237/1000], Loss: 0.5952, Val Loss: 0.5185
Epoch [238/1000], Loss: 0.1847, Val Loss: 0.5273
Epoch [239/1000], Loss: 0.2393, Val Loss: 0.4986
Epoch [240/1000], Loss: 0.2615, Val Loss: 0.4845
Epoch [241/1000], Loss: 0.2104, Val Loss: 0.5086
Epoch [242/1000], Loss: 0.2058, Val Loss: 0.5015
Epoch [243/1000], Loss: 0.2052, Val Loss: 0.5250
Epoch [244/1000], Loss: 0.1701, Val Loss: 0.5266
Epoch [245/1000], Loss: 0.1745, Val Loss: 0.5095
Epoch [246/1000], Loss: 0.4101, Val Loss: 0.4864
Epoch [247/1000], Loss: 0.2231, Val Loss: 0.5078
Epoch [248/1000], Loss: 0.3407, Val Loss: 0.5692
Epoch [249/1000], Loss: 0.4965, Val Loss: 0.5374
Epoch [250/1000], Loss: 0.2390, Val Loss: 0.5580
Epoch [251/1000], Loss: 0.3251, Val Loss: 0.4819
Epoch [252/1000], Loss: 0.2364, Val Loss: 0.5283
Epoch [253/1000], Loss: 0.3102, Val Loss: 0.5152
Epoch [254/1000], Loss: 0.3049, Val Loss: 0.4992
Epoch [255/1000], Loss: 0.4195, Val Loss: 0.5200
Epoch [256/1000], Loss: 0.3606, Val Loss: 0.5448
Epoch [257/1000], Loss: 0.5191, Val Loss: 0.5203
Epoch [258/1000], Loss: 0.1865, Val Loss: 0.5019
Epoch [259/1000], Loss: 0.2887, Val Loss: 0.5489
Epoch [260/1000], Loss: 0.2722, Val Loss: 0.4977
Epoch [261/1000], Loss: 0.1651, Val Loss: 0.5000
Epoch [262/1000], Loss: 0.3403, Val Loss: 0.5215
Epoch [263/1000], Loss: 0.2933, Val Loss: 0.5477
Epoch [264/1000], Loss: 0.2719, Val Loss: 0.5225
Epoch [265/1000], Loss: 0.3184, Val Loss: 0.5149
Epoch [266/1000], Loss: 0.2707, Val Loss: 0.4870
Epoch [267/1000], Loss: 0.3247, Val Loss: 0.5678
Epoch [268/1000], Loss: 0.4542, Val Loss: 0.5266
Epoch [269/1000], Loss: 0.2259, Val Loss: 0.5120
Epoch [270/1000], Loss: 0.2951, Val Loss: 0.5052
Epoch [271/1000], Loss: 0.3114, Val Loss: 0.5118
Epoch [272/1000], Loss: 0.2383, Val Loss: 0.5335
Epoch [273/1000], Loss: 0.2548, Val Loss: 0.5021
Epoch [274/1000], Loss: 0.2211, Val Loss: 0.5020
Epoch [275/1000], Loss: 0.2817, Val Loss: 0.4981
Epoch [276/1000], Loss: 0.2023, Val Loss: 0.5262
Epoch [277/1000], Loss: 0.2437, Val Loss: 0.4995
Epoch [278/1000], Loss: 0.5885, Val Loss: 0.5624
Epoch [279/1000], Loss: 0.4319, Val Loss: 0.5565
Epoch [280/1000], Loss: 0.3196, Val Loss: 0.5526
Epoch [281/1000], Loss: 0.4451, Val Loss: 0.5100
Epoch [282/1000], Loss: 0.1780, Val Loss: 0.5239
Epoch [283/1000], Loss: 0.4571, Val Loss: 0.5407
Epoch [284/1000], Loss: 0.3672, Val Loss: 0.5025
Epoch [285/1000], Loss: 0.2693, Val Loss: 0.4942
Epoch [286/1000], Loss: 0.1116, Val Loss: 0.5072
Epoch [287/1000], Loss: 0.2819, Val Loss: 0.4985
Epoch [288/1000], Loss: 0.2011, Val Loss: 0.4815
Epoch [289/1000], Loss: 0.2110, Val Loss: 0.5013
Epoch [290/1000], Loss: 0.4117, Val Loss: 0.5471
Epoch [291/1000], Loss: 0.2205, Val Loss: 0.5733
Epoch [292/1000], Loss: 0.4847, Val Loss: 0.5683
Epoch [293/1000], Loss: 0.3030, Val Loss: 0.5100
Epoch [294/1000], Loss: 0.2880, Val Loss: 0.4991
Epoch [295/1000], Loss: 0.2667, Val Loss: 0.5614
Epoch [296/1000], Loss: 0.1517, Val Loss: 0.4827
Epoch [297/1000], Loss: 0.2162, Val Loss: 0.5153
Epoch [298/1000], Loss: 0.2760, Val Loss: 0.5163
Epoch [299/1000], Loss: 0.3342, Val Loss: 0.5280
Epoch [300/1000], Loss: 0.4294, Val Loss: 0.5619
Epoch [301/1000], Loss: 0.3177, Val Loss: 0.5393
Epoch [302/1000], Loss: 0.2032, Val Loss: 0.5342
Epoch [303/1000], Loss: 0.2958, Val Loss: 0.5097
Epoch [304/1000], Loss: 0.1469, Val Loss: 0.5069
Epoch [305/1000], Loss: 0.3210, Val Loss: 0.5202
Epoch [306/1000], Loss: 0.2197, Val Loss: 0.4916
Epoch [307/1000], Loss: 0.1304, Val Loss: 0.5003
Epoch [308/1000], Loss: 0.2402, Val Loss: 0.5289
Epoch [309/1000], Loss: 0.1454, Val Loss: 0.5233
Epoch [310/1000], Loss: 0.2609, Val Loss: 0.4849
Epoch [311/1000], Loss: 0.1125, Val Loss: 0.4886
Epoch [312/1000], Loss: 0.2021, Val Loss: 0.5105
Epoch [313/1000], Loss: 0.2898, Val Loss: 0.4824
Epoch [314/1000], Loss: 0.1681, Val Loss: 0.5429
Epoch [315/1000], Loss: 0.2697, Val Loss: 0.5036
Epoch [316/1000], Loss: 0.2381, Val Loss: 0.5401
Epoch [317/1000], Loss: 0.4823, Val Loss: 0.5312
Epoch [318/1000], Loss: 0.3844, Val Loss: 0.5278
Epoch [319/1000], Loss: 0.1893, Val Loss: 0.5682
Epoch [320/1000], Loss: 0.3896, Val Loss: 0.5091
Epoch [321/1000], Loss: 0.3252, Val Loss: 0.5225
Epoch [322/1000], Loss: 0.3861, Val Loss: 0.5236
Epoch [323/1000], Loss: 0.2814, Val Loss: 0.5373
Epoch [324/1000], Loss: 0.2530, Val Loss: 0.4936
Epoch [325/1000], Loss: 0.2609, Val Loss: 0.5007
Epoch [326/1000], Loss: 0.2760, Val Loss: 0.5465
Epoch [327/1000], Loss: 0.1842, Val Loss: 0.4847
Epoch [328/1000], Loss: 0.2277, Val Loss: 0.5263
Epoch [329/1000], Loss: 0.2103, Val Loss: 0.4969
Epoch [330/1000], Loss: 0.1633, Val Loss: 0.5046
Epoch [331/1000], Loss: 0.3478, Val Loss: 0.5278
Epoch [332/1000], Loss: 0.1549, Val Loss: 0.4976
Epoch [333/1000], Loss: 0.2449, Val Loss: 0.5450
Epoch [334/1000], Loss: 0.3034, Val Loss: 0.5282
Epoch [335/1000], Loss: 0.2803, Val Loss: 0.5033
Epoch [336/1000], Loss: 0.2462, Val Loss: 0.5095
Epoch [337/1000], Loss: 0.2237, Val Loss: 0.5667
Epoch [338/1000], Loss: 0.2743, Val Loss: 0.5132
Epoch [339/1000], Loss: 0.2264, Val Loss: 0.5498
Epoch [340/1000], Loss: 0.2985, Val Loss: 0.5275
Epoch [341/1000], Loss: 0.2169, Val Loss: 0.5066
Epoch [342/1000], Loss: 0.1852, Val Loss: 0.4985
Epoch [343/1000], Loss: 0.2164, Val Loss: 0.5401
Epoch [344/1000], Loss: 0.2214, Val Loss: 0.5184
Epoch [345/1000], Loss: 0.5115, Val Loss: 0.5239
Epoch [346/1000], Loss: 0.1793, Val Loss: 0.5156
Epoch [347/1000], Loss: 0.1937, Val Loss: 0.5364
Epoch [348/1000], Loss: 0.1441, Val Loss: 0.5229
Epoch [349/1000], Loss: 0.2448, Val Loss: 0.4953
Epoch [350/1000], Loss: 0.1631, Val Loss: 0.5020
Epoch [351/1000], Loss: 0.1626, Val Loss: 0.4985
Epoch [352/1000], Loss: 0.3032, Val Loss: 0.5205
Epoch [353/1000], Loss: 1.0201, Val Loss: 0.5287
Epoch [354/1000], Loss: 0.3268, Val Loss: 0.5222
Epoch [355/1000], Loss: 0.4711, Val Loss: 0.5250
Epoch [356/1000], Loss: 0.2339, Val Loss: 0.4839
Epoch [357/1000], Loss: 0.1689, Val Loss: 0.5079
Epoch [358/1000], Loss: 0.4277, Val Loss: 0.4914
Epoch [359/1000], Loss: 0.2140, Val Loss: 0.4904
Epoch [360/1000], Loss: 0.1502, Val Loss: 0.5059
Epoch [361/1000], Loss: 0.1986, Val Loss: 0.5091
Epoch [362/1000], Loss: 0.2040, Val Loss: 0.4992
Epoch [363/1000], Loss: 0.2159, Val Loss: 0.4918
Epoch [364/1000], Loss: 0.1586, Val Loss: 0.5162
Epoch [365/1000], Loss: 0.3564, Val Loss: 0.5111
Epoch [366/1000], Loss: 0.1676, Val Loss: 0.5243
Epoch [367/1000], Loss: 0.2900, Val Loss: 0.5333
Epoch [368/1000], Loss: 0.1855, Val Loss: 0.5129
Epoch [369/1000], Loss: 0.4704, Val Loss: 0.5121
Epoch [370/1000], Loss: 0.4146, Val Loss: 0.5066
Epoch [371/1000], Loss: 0.3233, Val Loss: 0.5297
Epoch [372/1000], Loss: 0.2290, Val Loss: 0.5623
Epoch [373/1000], Loss: 0.5083, Val Loss: 0.5286
Epoch [374/1000], Loss: 0.2182, Val Loss: 0.5644
Epoch [375/1000], Loss: 0.2048, Val Loss: 0.5267
Epoch [376/1000], Loss: 0.1381, Val Loss: 0.5107
Epoch [377/1000], Loss: 0.1820, Val Loss: 0.4857
Epoch [378/1000], Loss: 0.1855, Val Loss: 0.4948
Epoch [379/1000], Loss: 0.2032, Val Loss: 0.5223
Epoch [380/1000], Loss: 0.2337, Val Loss: 0.5324
Epoch [381/1000], Loss: 0.2253, Val Loss: 0.4741
Epoch [382/1000], Loss: 1.0804, Val Loss: 0.5228
Epoch [383/1000], Loss: 0.4078, Val Loss: 0.5150
Epoch [384/1000], Loss: 0.3675, Val Loss: 0.5090
Epoch [385/1000], Loss: 0.2874, Val Loss: 0.5241
Epoch [386/1000], Loss: 0.2988, Val Loss: 0.5227
Epoch [387/1000], Loss: 0.2944, Val Loss: 0.5196
Epoch [388/1000], Loss: 0.4657, Val Loss: 0.5299
Epoch [389/1000], Loss: 0.3238, Val Loss: 0.4832
Epoch [390/1000], Loss: 0.1881, Val Loss: 0.4767
Epoch [391/1000], Loss: 0.2276, Val Loss: 0.4831
Epoch [392/1000], Loss: 0.1702, Val Loss: 0.5415
Epoch [393/1000], Loss: 0.2305, Val Loss: 0.5132
Epoch [394/1000], Loss: 0.2545, Val Loss: 0.5276
Epoch [395/1000], Loss: 0.2983, Val Loss: 0.4947
Epoch [396/1000], Loss: 0.1500, Val Loss: 0.5004
Epoch [397/1000], Loss: 0.1862, Val Loss: 0.4919
Epoch [398/1000], Loss: 0.2081, Val Loss: 0.4986
Epoch [399/1000], Loss: 0.1547, Val Loss: 0.5080
Epoch [400/1000], Loss: 0.1745, Val Loss: 0.5004
Epoch [401/1000], Loss: 0.2763, Val Loss: 0.4898
Epoch [402/1000], Loss: 0.3009, Val Loss: 0.4909
Epoch [403/1000], Loss: 0.2025, Val Loss: 0.4989
Epoch [404/1000], Loss: 0.2645, Val Loss: 0.4734
Epoch [405/1000], Loss: 1.1401, Val Loss: 0.5464
Epoch [406/1000], Loss: 0.1588, Val Loss: 0.5191
Epoch [407/1000], Loss: 0.2347, Val Loss: 0.5229
Epoch [408/1000], Loss: 0.1857, Val Loss: 0.4986
Epoch [409/1000], Loss: 0.7122, Val Loss: 0.5630
Epoch [410/1000], Loss: 0.1855, Val Loss: 0.5328
Epoch [411/1000], Loss: 0.1792, Val Loss: 0.5026
Epoch [412/1000], Loss: 0.2302, Val Loss: 0.4987
Epoch [413/1000], Loss: 0.1511, Val Loss: 0.4811
Epoch [414/1000], Loss: 0.1362, Val Loss: 0.4981
Epoch [415/1000], Loss: 0.2619, Val Loss: 0.5004
Epoch [416/1000], Loss: 0.2869, Val Loss: 0.5233
Epoch [417/1000], Loss: 0.1437, Val Loss: 0.4971
Epoch [418/1000], Loss: 0.2391, Val Loss: 0.5125
Epoch [419/1000], Loss: 0.1727, Val Loss: 0.4960
Epoch [420/1000], Loss: 0.1851, Val Loss: 0.5004
Epoch [421/1000], Loss: 0.1689, Val Loss: 0.4905
Epoch [422/1000], Loss: 0.1932, Val Loss: 0.5119
Epoch [423/1000], Loss: 0.2846, Val Loss: 0.5305
Epoch [424/1000], Loss: 0.2329, Val Loss: 0.4800
Epoch [425/1000], Loss: 0.1519, Val Loss: 0.5265
Epoch [426/1000], Loss: 0.1879, Val Loss: 0.5010
Epoch [427/1000], Loss: 0.1661, Val Loss: 0.5087
Epoch [428/1000], Loss: 0.4713, Val Loss: 0.4967
Epoch [429/1000], Loss: 0.3771, Val Loss: 0.5520
Epoch [430/1000], Loss: 0.2720, Val Loss: 0.5125
Epoch [431/1000], Loss: 0.3105, Val Loss: 0.5101
Epoch [432/1000], Loss: 0.1985, Val Loss: 0.5083
Epoch [433/1000], Loss: 0.2054, Val Loss: 0.5167
Epoch [434/1000], Loss: 0.2916, Val Loss: 0.5483
Epoch [435/1000], Loss: 0.2453, Val Loss: 0.5207
Epoch [436/1000], Loss: 0.2220, Val Loss: 0.5062
Epoch [437/1000], Loss: 0.2986, Val Loss: 0.4989
Epoch [438/1000], Loss: 0.1332, Val Loss: 0.4975
Epoch [439/1000], Loss: 0.3444, Val Loss: 0.5134
Epoch [440/1000], Loss: 0.2331, Val Loss: 0.5480
Epoch [441/1000], Loss: 0.1539, Val Loss: 0.4825
Epoch [442/1000], Loss: 0.1910, Val Loss: 0.4953
Epoch [443/1000], Loss: 0.1901, Val Loss: 0.5143
Epoch [444/1000], Loss: 0.1892, Val Loss: 0.5301
Epoch [445/1000], Loss: 0.2818, Val Loss: 0.4976
Epoch [446/1000], Loss: 0.1572, Val Loss: 0.5139
Epoch [447/1000], Loss: 0.2549, Val Loss: 0.5118
Epoch [448/1000], Loss: 0.1874, Val Loss: 0.5052
Epoch [449/1000], Loss: 0.2556, Val Loss: 0.5063
Epoch [450/1000], Loss: 0.2175, Val Loss: 0.5069
Epoch [451/1000], Loss: 0.1677, Val Loss: 0.5010
Epoch [452/1000], Loss: 0.1541, Val Loss: 0.5014
Epoch [453/1000], Loss: 0.2377, Val Loss: 0.4816
Epoch [454/1000], Loss: 0.3465, Val Loss: 0.5068
Epoch [455/1000], Loss: 1.1894, Val Loss: 0.5705
Epoch [456/1000], Loss: 0.1909, Val Loss: 0.5325
Epoch [457/1000], Loss: 0.2406, Val Loss: 0.5156
Epoch [458/1000], Loss: 0.2363, Val Loss: 0.5140
Epoch [459/1000], Loss: 0.1573, Val Loss: 0.5162
Epoch [460/1000], Loss: 0.2048, Val Loss: 0.4772
Epoch [461/1000], Loss: 0.2638, Val Loss: 0.4847
Epoch [462/1000], Loss: 0.1494, Val Loss: 0.5133
Epoch [463/1000], Loss: 0.3804, Val Loss: 0.5203
Epoch [464/1000], Loss: 0.2271, Val Loss: 0.5300
Epoch [465/1000], Loss: 0.1584, Val Loss: 0.4954
Epoch [466/1000], Loss: 0.2420, Val Loss: 0.5258
Epoch [467/1000], Loss: 0.2257, Val Loss: 0.4963
Epoch [468/1000], Loss: 0.3894, Val Loss: 0.4714
Epoch [469/1000], Loss: 0.2130, Val Loss: 0.4896
Epoch [470/1000], Loss: 0.2897, Val Loss: 0.5251
Epoch [471/1000], Loss: 1.4031, Val Loss: 0.5325
Epoch [472/1000], Loss: 0.1315, Val Loss: 0.5142
Epoch [473/1000], Loss: 0.2793, Val Loss: 0.5184
Epoch [474/1000], Loss: 0.2176, Val Loss: 0.4978
Epoch [475/1000], Loss: 0.2004, Val Loss: 0.4913
Epoch [476/1000], Loss: 0.2165, Val Loss: 0.5121
Epoch [477/1000], Loss: 0.2832, Val Loss: 0.5119
Epoch [478/1000], Loss: 0.2317, Val Loss: 0.4964
Epoch [479/1000], Loss: 0.2976, Val Loss: 0.4919
Epoch [480/1000], Loss: 0.3106, Val Loss: 0.5004
Epoch [481/1000], Loss: 1.1464, Val Loss: 0.5522
Epoch [482/1000], Loss: 0.3950, Val Loss: 0.5322
Epoch [483/1000], Loss: 0.2829, Val Loss: 0.5058
Epoch [484/1000], Loss: 0.2264, Val Loss: 0.4915
Epoch [485/1000], Loss: 0.3192, Val Loss: 0.4983
Epoch [486/1000], Loss: 0.3015, Val Loss: 0.5219
Epoch [487/1000], Loss: 0.2309, Val Loss: 0.4894
Epoch [488/1000], Loss: 0.1390, Val Loss: 0.5076
Epoch [489/1000], Loss: 0.1684, Val Loss: 0.5051
Epoch [490/1000], Loss: 0.1872, Val Loss: 0.5011
Epoch [491/1000], Loss: 0.2269, Val Loss: 0.4954
Epoch [492/1000], Loss: 0.2288, Val Loss: 0.5016
Epoch [493/1000], Loss: 0.1821, Val Loss: 0.5070
Epoch [494/1000], Loss: 0.2753, Val Loss: 0.5103
Epoch [495/1000], Loss: 0.1882, Val Loss: 0.5015
Epoch [496/1000], Loss: 0.1256, Val Loss: 0.5300
Epoch [497/1000], Loss: 0.1987, Val Loss: 0.4770
Epoch [498/1000], Loss: 0.6070, Val Loss: 0.5193
Epoch [499/1000], Loss: 0.3493, Val Loss: 0.5229
Epoch [500/1000], Loss: 0.1857, Val Loss: 0.4756
Epoch [501/1000], Loss: 0.2515, Val Loss: 0.5307
Epoch [502/1000], Loss: 0.3314, Val Loss: 0.4997
Epoch [503/1000], Loss: 0.2899, Val Loss: 0.5247
Epoch [504/1000], Loss: 0.2774, Val Loss: 0.5043
Epoch [505/1000], Loss: 0.2899, Val Loss: 0.4952
Epoch [506/1000], Loss: 0.2274, Val Loss: 0.5261
Epoch [507/1000], Loss: 0.2337, Val Loss: 0.5295
Epoch [508/1000], Loss: 0.3777, Val Loss: 0.5101
Epoch [509/1000], Loss: 0.3022, Val Loss: 0.5230
Epoch [510/1000], Loss: 0.4369, Val Loss: 0.5235
Epoch [511/1000], Loss: 0.3197, Val Loss: 0.5338
Epoch [512/1000], Loss: 0.2684, Val Loss: 0.5158
Epoch [513/1000], Loss: 0.2388, Val Loss: 0.5044
Epoch [514/1000], Loss: 0.2256, Val Loss: 0.5005
Epoch [515/1000], Loss: 0.2718, Val Loss: 0.5452
Epoch [516/1000], Loss: 0.2588, Val Loss: 0.5058
Epoch [517/1000], Loss: 0.2249, Val Loss: 0.5035
Epoch [518/1000], Loss: 0.2992, Val Loss: 0.4951
Epoch [519/1000], Loss: 0.3103, Val Loss: 0.5310
Epoch [520/1000], Loss: 0.3444, Val Loss: 0.5205
Epoch [521/1000], Loss: 0.4701, Val Loss: 0.5412
Epoch [522/1000], Loss: 0.2607, Val Loss: 0.5212
Epoch [523/1000], Loss: 0.2264, Val Loss: 0.5017
Epoch [524/1000], Loss: 0.2092, Val Loss: 0.5079
Epoch [525/1000], Loss: 0.2165, Val Loss: 0.4909
Epoch [526/1000], Loss: 0.3994, Val Loss: 0.5253
Epoch [527/1000], Loss: 0.2832, Val Loss: 0.5386
Epoch [528/1000], Loss: 0.2180, Val Loss: 0.4891
Epoch [529/1000], Loss: 0.1689, Val Loss: 0.4920
Epoch [530/1000], Loss: 0.6823, Val Loss: 0.5180
Epoch [531/1000], Loss: 0.2313, Val Loss: 0.5687
Epoch [532/1000], Loss: 0.2564, Val Loss: 0.4982
Epoch [533/1000], Loss: 0.2049, Val Loss: 0.5064
Epoch [534/1000], Loss: 0.3017, Val Loss: 0.4988
Epoch [535/1000], Loss: 0.1505, Val Loss: 0.5017
Epoch [536/1000], Loss: 0.1896, Val Loss: 0.5035
Epoch [537/1000], Loss: 0.3182, Val Loss: 0.4798
Epoch [538/1000], Loss: 0.2436, Val Loss: 0.4992
Epoch [539/1000], Loss: 0.1523, Val Loss: 0.4899
Epoch [540/1000], Loss: 0.1938, Val Loss: 0.4903
Epoch [541/1000], Loss: 0.2506, Val Loss: 0.5123
Epoch [542/1000], Loss: 0.1606, Val Loss: 0.4927
Epoch [543/1000], Loss: 0.1552, Val Loss: 0.5109
Epoch [544/1000], Loss: 0.1891, Val Loss: 0.5097
Epoch [545/1000], Loss: 0.2131, Val Loss: 0.4815
Epoch [546/1000], Loss: 0.3035, Val Loss: 0.4957
Epoch [547/1000], Loss: 0.4852, Val Loss: 0.5010
Epoch [548/1000], Loss: 0.2934, Val Loss: 0.5278
Epoch [549/1000], Loss: 0.1782, Val Loss: 0.4939
Epoch [550/1000], Loss: 0.2336, Val Loss: 0.5514
Epoch [551/1000], Loss: 0.3150, Val Loss: 0.5194
Epoch [552/1000], Loss: 0.2004, Val Loss: 0.5129
Epoch [553/1000], Loss: 0.2018, Val Loss: 0.5285
Epoch [554/1000], Loss: 0.1977, Val Loss: 0.5223
Epoch [555/1000], Loss: 0.2958, Val Loss: 0.5442
Epoch [556/1000], Loss: 0.2146, Val Loss: 0.5492
Epoch [557/1000], Loss: 0.1670, Val Loss: 0.5186
Epoch [558/1000], Loss: 0.2293, Val Loss: 0.5093
Epoch [559/1000], Loss: 0.2457, Val Loss: 0.4742
Epoch [560/1000], Loss: 0.2079, Val Loss: 0.4843
Epoch [561/1000], Loss: 0.3839, Val Loss: 0.5052
Epoch [562/1000], Loss: 0.1808, Val Loss: 0.5344
Epoch [563/1000], Loss: 0.1941, Val Loss: 0.4832
Epoch [564/1000], Loss: 0.1904, Val Loss: 0.4886
Epoch [565/1000], Loss: 0.2179, Val Loss: 0.4847
Epoch [566/1000], Loss: 0.2499, Val Loss: 0.4944
Epoch [567/1000], Loss: 0.2291, Val Loss: 0.5627
Epoch [568/1000], Loss: 0.3008, Val Loss: 0.5056
Epoch [569/1000], Loss: 0.4413, Val Loss: 0.5002
Epoch [570/1000], Loss: 0.3140, Val Loss: 0.5266
Epoch [571/1000], Loss: 0.2523, Val Loss: 0.4870
Epoch [572/1000], Loss: 0.2294, Val Loss: 0.5232
Epoch [573/1000], Loss: 0.1588, Val Loss: 0.4879
Epoch [574/1000], Loss: 0.2293, Val Loss: 0.4895
Epoch [575/1000], Loss: 0.4084, Val Loss: 0.5087
Epoch [576/1000], Loss: 0.1279, Val Loss: 0.4938
Epoch [577/1000], Loss: 0.2715, Val Loss: 0.5088
Epoch [578/1000], Loss: 0.2004, Val Loss: 0.5037
Epoch [579/1000], Loss: 0.2260, Val Loss: 0.4822
Epoch [580/1000], Loss: 0.2822, Val Loss: 0.5098
Epoch [581/1000], Loss: 0.2123, Val Loss: 0.4812
Epoch [582/1000], Loss: 0.2039, Val Loss: 0.4906
Epoch [583/1000], Loss: 0.2479, Val Loss: 0.4961
Epoch [584/1000], Loss: 0.2176, Val Loss: 0.5176
Epoch [585/1000], Loss: 0.2240, Val Loss: 0.4875
Epoch [586/1000], Loss: 0.2664, Val Loss: 0.4906
Epoch [587/1000], Loss: 0.2504, Val Loss: 0.5209
Epoch [588/1000], Loss: 0.1469, Val Loss: 0.5567
Epoch [589/1000], Loss: 0.1577, Val Loss: 0.5330
Epoch [590/1000], Loss: 0.3791, Val Loss: 0.5118
Epoch [591/1000], Loss: 0.3792, Val Loss: 0.4994
Epoch [592/1000], Loss: 0.4033, Val Loss: 0.5068
Epoch [593/1000], Loss: 0.2265, Val Loss: 0.5193
Epoch [594/1000], Loss: 0.2442, Val Loss: 0.5476
Epoch [595/1000], Loss: 0.2601, Val Loss: 0.5583
Epoch [596/1000], Loss: 0.2649, Val Loss: 0.4963
Epoch [597/1000], Loss: 0.2456, Val Loss: 0.5536
Epoch [598/1000], Loss: 0.2679, Val Loss: 0.4946
Epoch [599/1000], Loss: 0.2219, Val Loss: 0.4985
Epoch [600/1000], Loss: 0.2184, Val Loss: 0.4943
Epoch [601/1000], Loss: 0.1836, Val Loss: 0.4975
Epoch [602/1000], Loss: 0.1853, Val Loss: 0.4939
Epoch [603/1000], Loss: 0.2456, Val Loss: 0.5573
Epoch [604/1000], Loss: 0.2512, Val Loss: 0.5052
Epoch [605/1000], Loss: 0.2364, Val Loss: 0.5087
Epoch [606/1000], Loss: 0.1830, Val Loss: 0.5179
Epoch [607/1000], Loss: 0.3752, Val Loss: 0.5104
Epoch [608/1000], Loss: 0.2484, Val Loss: 0.5342
Epoch [609/1000], Loss: 0.1558, Val Loss: 0.5259
Epoch [610/1000], Loss: 0.2416, Val Loss: 0.5006
Epoch [611/1000], Loss: 0.2048, Val Loss: 0.5008
Epoch [612/1000], Loss: 0.1886, Val Loss: 0.4925
Epoch [613/1000], Loss: 0.1426, Val Loss: 0.4734
Epoch [614/1000], Loss: 0.1315, Val Loss: 0.4961
Epoch [615/1000], Loss: 0.1641, Val Loss: 0.5001
Epoch [616/1000], Loss: 0.2484, Val Loss: 0.5241
Epoch [617/1000], Loss: 0.4316, Val Loss: 0.4929
Epoch [618/1000], Loss: 0.3267, Val Loss: 0.4993
Epoch [619/1000], Loss: 0.1992, Val Loss: 0.4882
Epoch [620/1000], Loss: 0.2702, Val Loss: 0.5062
Epoch [621/1000], Loss: 0.2084, Val Loss: 0.5082
Epoch [622/1000], Loss: 0.1571, Val Loss: 0.4904
Epoch [623/1000], Loss: 0.2460, Val Loss: 0.5050
Epoch [624/1000], Loss: 0.2506, Val Loss: 0.5086
Epoch [625/1000], Loss: 0.3106, Val Loss: 0.5070
Epoch [626/1000], Loss: 0.2659, Val Loss: 0.5247
Epoch [627/1000], Loss: 0.2188, Val Loss: 0.4825
Epoch [628/1000], Loss: 0.2252, Val Loss: 0.5813
Epoch [629/1000], Loss: 0.3738, Val Loss: 0.5243
Epoch [630/1000], Loss: 0.3955, Val Loss: 0.6303
Epoch [631/1000], Loss: 0.2089, Val Loss: 0.5050
Epoch [632/1000], Loss: 0.2291, Val Loss: 0.5211
Epoch [633/1000], Loss: 0.5953, Val Loss: 0.5254
Epoch [634/1000], Loss: 0.2538, Val Loss: 0.5139
Epoch [635/1000], Loss: 0.1508, Val Loss: 0.5088
Epoch [636/1000], Loss: 0.1779, Val Loss: 0.4889
Epoch [637/1000], Loss: 0.1325, Val Loss: 0.4934
Epoch [638/1000], Loss: 0.2786, Val Loss: 0.5146
Epoch [639/1000], Loss: 0.2035, Val Loss: 0.4928
Epoch [640/1000], Loss: 0.2084, Val Loss: 0.5122
Epoch [641/1000], Loss: 0.1730, Val Loss: 0.5093
Epoch [642/1000], Loss: 0.2207, Val Loss: 0.4869
Epoch [643/1000], Loss: 0.2575, Val Loss: 0.4851
Epoch [644/1000], Loss: 0.1432, Val Loss: 0.4799
Epoch [645/1000], Loss: 0.2845, Val Loss: 0.5179
Epoch [646/1000], Loss: 0.1940, Val Loss: 0.4848
Epoch [647/1000], Loss: 0.2002, Val Loss: 0.5449
Epoch [648/1000], Loss: 0.3201, Val Loss: 0.4995
Epoch [649/1000], Loss: 0.2436, Val Loss: 0.5353
Epoch [650/1000], Loss: 0.2666, Val Loss: 0.4958
Epoch [651/1000], Loss: 0.3457, Val Loss: 0.4810
Epoch [652/1000], Loss: 0.1970, Val Loss: 0.5161
Epoch [653/1000], Loss: 0.1660, Val Loss: 0.5041
Epoch [654/1000], Loss: 0.2038, Val Loss: 0.5164
Epoch [655/1000], Loss: 0.1547, Val Loss: 0.4841
Epoch [656/1000], Loss: 0.1321, Val Loss: 0.4945
Epoch [657/1000], Loss: 0.1540, Val Loss: 0.5280
Epoch [658/1000], Loss: 0.2190, Val Loss: 0.4819
Epoch [659/1000], Loss: 0.3263, Val Loss: 0.5207
Epoch [660/1000], Loss: 0.2069, Val Loss: 0.4997
Epoch [661/1000], Loss: 0.1702, Val Loss: 0.5026
Epoch [662/1000], Loss: 0.2818, Val Loss: 0.5037
Epoch [663/1000], Loss: 0.1479, Val Loss: 0.4877
Epoch [664/1000], Loss: 0.1955, Val Loss: 0.4897
Epoch [665/1000], Loss: 0.2307, Val Loss: 0.4863
Epoch [666/1000], Loss: 0.3972, Val Loss: 0.4981
Epoch [667/1000], Loss: 0.2880, Val Loss: 0.4887
Epoch [668/1000], Loss: 0.4280, Val Loss: 0.5021
Epoch [669/1000], Loss: 0.6174, Val Loss: 0.5074
Epoch [670/1000], Loss: 0.2636, Val Loss: 0.4904
Epoch [671/1000], Loss: 0.2543, Val Loss: 0.5132
Epoch [672/1000], Loss: 0.2412, Val Loss: 0.5341
Epoch [673/1000], Loss: 0.1934, Val Loss: 0.5109
Epoch [674/1000], Loss: 0.3350, Val Loss: 0.5012
Epoch [675/1000], Loss: 0.2420, Val Loss: 0.4778
Epoch [676/1000], Loss: 0.1788, Val Loss: 0.5196
Epoch [677/1000], Loss: 0.2153, Val Loss: 0.4656
Epoch [678/1000], Loss: 0.2579, Val Loss: 0.4717
Epoch [679/1000], Loss: 0.3428, Val Loss: 0.4824
Epoch [680/1000], Loss: 0.1735, Val Loss: 0.5006
Epoch [681/1000], Loss: 0.1989, Val Loss: 0.4729
Epoch [682/1000], Loss: 0.2837, Val Loss: 0.4673
Epoch [683/1000], Loss: 0.1954, Val Loss: 0.4828
Epoch [684/1000], Loss: 0.2922, Val Loss: 0.4854
Epoch [685/1000], Loss: 0.2125, Val Loss: 0.4822
Epoch [686/1000], Loss: 0.1729, Val Loss: 0.4843
Epoch [687/1000], Loss: 0.1650, Val Loss: 0.4710
Epoch [688/1000], Loss: 0.2006, Val Loss: 0.4780
Epoch [689/1000], Loss: 0.2248, Val Loss: 0.4952
Epoch [690/1000], Loss: 0.2648, Val Loss: 0.5043
Epoch [691/1000], Loss: 0.1810, Val Loss: 0.4955
Epoch [692/1000], Loss: 0.1989, Val Loss: 0.4749
Epoch [693/1000], Loss: 0.1691, Val Loss: 0.5016
Epoch [694/1000], Loss: 0.2417, Val Loss: 0.5089
Epoch [695/1000], Loss: 0.2374, Val Loss: 0.5035
Epoch [696/1000], Loss: 0.2959, Val Loss: 0.4898
Epoch [697/1000], Loss: 0.2367, Val Loss: 0.5279
Epoch [698/1000], Loss: 0.1569, Val Loss: 0.5010
Epoch [699/1000], Loss: 0.1958, Val Loss: 0.4953
Epoch [700/1000], Loss: 0.1770, Val Loss: 0.4988
Epoch [701/1000], Loss: 0.1976, Val Loss: 0.4826
Epoch [702/1000], Loss: 0.2545, Val Loss: 0.5198
Epoch [703/1000], Loss: 0.4167, Val Loss: 0.5090
Epoch [704/1000], Loss: 0.2098, Val Loss: 0.5213
Epoch [705/1000], Loss: 0.1933, Val Loss: 0.4822
Epoch [706/1000], Loss: 0.2742, Val Loss: 0.5004
Epoch [707/1000], Loss: 0.2415, Val Loss: 0.4916
Epoch [708/1000], Loss: 0.1102, Val Loss: 0.5037
Epoch [709/1000], Loss: 0.1450, Val Loss: 0.4917
Epoch [710/1000], Loss: 0.1836, Val Loss: 0.5030
Epoch [711/1000], Loss: 0.1551, Val Loss: 0.4975
Epoch [712/1000], Loss: 0.2378, Val Loss: 0.5223
Epoch [713/1000], Loss: 0.1611, Val Loss: 0.5062
Epoch [714/1000], Loss: 0.1581, Val Loss: 0.4917
Epoch [715/1000], Loss: 0.1716, Val Loss: 0.4811
Epoch [716/1000], Loss: 0.1347, Val Loss: 0.4871
Epoch [717/1000], Loss: 0.2193, Val Loss: 0.4935
Epoch [718/1000], Loss: 0.2386, Val Loss: 0.5049
Epoch [719/1000], Loss: 0.2634, Val Loss: 0.4873
Epoch [720/1000], Loss: 0.2194, Val Loss: 0.4966
Epoch [721/1000], Loss: 0.2776, Val Loss: 0.5151
Epoch [722/1000], Loss: 0.5175, Val Loss: 0.4703
Epoch [723/1000], Loss: 0.1997, Val Loss: 0.8403
Epoch [724/1000], Loss: 0.2661, Val Loss: 0.5223
Epoch [725/1000], Loss: 0.4016, Val Loss: 0.5250
Epoch [726/1000], Loss: 0.4448, Val Loss: 0.5281
Epoch [727/1000], Loss: 0.2026, Val Loss: 0.5087
Epoch [728/1000], Loss: 0.1923, Val Loss: 0.5169
Epoch [729/1000], Loss: 0.2946, Val Loss: 0.4997
Epoch [730/1000], Loss: 0.2723, Val Loss: 0.4740
Epoch [731/1000], Loss: 0.4096, Val Loss: 0.5452
Epoch [732/1000], Loss: 0.2442, Val Loss: 0.5216
Epoch [733/1000], Loss: 1.3724, Val Loss: 0.5749
Epoch [734/1000], Loss: 0.2105, Val Loss: 0.5257
Epoch [735/1000], Loss: 0.3099, Val Loss: 0.5139
Epoch [736/1000], Loss: 0.3240, Val Loss: 0.5146
Epoch [737/1000], Loss: 0.1799, Val Loss: 0.4921
Epoch [738/1000], Loss: 0.2224, Val Loss: 0.5253
Epoch [739/1000], Loss: 0.1943, Val Loss: 0.5053
Epoch [740/1000], Loss: 0.1914, Val Loss: 0.4956
Epoch [741/1000], Loss: 0.2325, Val Loss: 0.4986
Epoch [742/1000], Loss: 0.2426, Val Loss: 0.4776
Epoch [743/1000], Loss: 0.2389, Val Loss: 0.5002
Epoch [744/1000], Loss: 0.2338, Val Loss: 0.5499
Epoch [745/1000], Loss: 0.2070, Val Loss: 0.5318
Epoch [746/1000], Loss: 0.3453, Val Loss: 0.5371
Epoch [747/1000], Loss: 0.2506, Val Loss: 0.4875
Epoch [748/1000], Loss: 0.4864, Val Loss: 0.5352
Epoch [749/1000], Loss: 0.2172, Val Loss: 0.5156
Epoch [750/1000], Loss: 0.1661, Val Loss: 0.4672
Epoch [751/1000], Loss: 0.3164, Val Loss: 0.4931
Epoch [752/1000], Loss: 0.1445, Val Loss: 0.5233
Epoch [753/1000], Loss: 0.2278, Val Loss: 0.4972
Epoch [754/1000], Loss: 0.3033, Val Loss: 0.5031
Epoch [755/1000], Loss: 0.2118, Val Loss: 0.4794
Epoch [756/1000], Loss: 0.3141, Val Loss: 0.4990
Epoch [757/1000], Loss: 0.2472, Val Loss: 0.5034
Epoch [758/1000], Loss: 0.1914, Val Loss: 0.5032
Epoch [759/1000], Loss: 0.1835, Val Loss: 0.5002
Epoch [760/1000], Loss: 0.1541, Val Loss: 0.5157
Epoch [761/1000], Loss: 0.1613, Val Loss: 0.4954
Epoch [762/1000], Loss: 0.1390, Val Loss: 0.4979
Epoch [763/1000], Loss: 0.3274, Val Loss: 0.5101
Epoch [764/1000], Loss: 0.3029, Val Loss: 0.4842
Epoch [765/1000], Loss: 0.2013, Val Loss: 0.5269
Epoch [766/1000], Loss: 0.2605, Val Loss: 0.5058
Epoch [767/1000], Loss: 0.1667, Val Loss: 0.5085
Epoch [768/1000], Loss: 0.2879, Val Loss: 0.5173
Epoch [769/1000], Loss: 0.3104, Val Loss: 0.5028
Epoch [770/1000], Loss: 0.1121, Val Loss: 0.5003
Epoch [771/1000], Loss: 0.1321, Val Loss: 0.5037
Epoch [772/1000], Loss: 0.1399, Val Loss: 0.4824
Epoch [773/1000], Loss: 0.1340, Val Loss: 0.5070
Epoch [774/1000], Loss: 0.1577, Val Loss: 0.4935
Epoch [775/1000], Loss: 0.2183, Val Loss: 0.5016
Epoch [776/1000], Loss: 0.2719, Val Loss: 0.5338
Epoch [777/1000], Loss: 0.2668, Val Loss: 0.5278
Epoch [778/1000], Loss: 0.4366, Val Loss: 0.4901
Epoch [779/1000], Loss: 0.3294, Val Loss: 0.5592
Epoch [780/1000], Loss: 0.2518, Val Loss: 0.5489
Epoch [781/1000], Loss: 0.2058, Val Loss: 0.5227
Epoch [782/1000], Loss: 0.1912, Val Loss: 0.4869
Epoch [783/1000], Loss: 0.1667, Val Loss: 0.5263
Epoch [784/1000], Loss: 1.2458, Val Loss: 0.5495
Epoch [785/1000], Loss: 0.1981, Val Loss: 0.5073
Epoch [786/1000], Loss: 0.3807, Val Loss: 0.5542
Epoch [787/1000], Loss: 0.2368, Val Loss: 0.5060
Epoch [788/1000], Loss: 0.1733, Val Loss: 0.5010
Epoch [789/1000], Loss: 0.1992, Val Loss: 0.4962
Epoch [790/1000], Loss: 0.2305, Val Loss: 0.4948
Epoch [791/1000], Loss: 0.2304, Val Loss: 0.5122
Epoch [792/1000], Loss: 0.1709, Val Loss: 0.5007
Epoch [793/1000], Loss: 0.2283, Val Loss: 0.5063
Epoch [794/1000], Loss: 0.1367, Val Loss: 0.4848
Epoch [795/1000], Loss: 0.2471, Val Loss: 0.5127
Epoch [796/1000], Loss: 0.1759, Val Loss: 0.4964
Epoch [797/1000], Loss: 0.3305, Val Loss: 0.5141
Epoch [798/1000], Loss: 0.1910, Val Loss: 0.5135
Epoch [799/1000], Loss: 0.2884, Val Loss: 0.5082
Epoch [800/1000], Loss: 0.4676, Val Loss: 0.5152
Epoch [801/1000], Loss: 0.2954, Val Loss: 0.5419
Epoch [802/1000], Loss: 0.2970, Val Loss: 0.5238
Epoch [803/1000], Loss: 0.1335, Val Loss: 0.5201
Epoch [804/1000], Loss: 0.1983, Val Loss: 0.5145
Epoch [805/1000], Loss: 0.2684, Val Loss: 0.5069
Epoch [806/1000], Loss: 0.1867, Val Loss: 0.5261
Epoch [807/1000], Loss: 0.3317, Val Loss: 0.5051
Epoch [808/1000], Loss: 0.2467, Val Loss: 0.5512
Epoch [809/1000], Loss: 0.1522, Val Loss: 0.4930
Epoch [810/1000], Loss: 0.1980, Val Loss: 0.4937
Epoch [811/1000], Loss: 0.1940, Val Loss: 0.5201
Epoch [812/1000], Loss: 0.1380, Val Loss: 0.4990
Epoch [813/1000], Loss: 0.2491, Val Loss: 0.4971
Epoch [814/1000], Loss: 0.1754, Val Loss: 0.5274
Epoch [815/1000], Loss: 0.1750, Val Loss: 0.5148
Epoch [816/1000], Loss: 0.2830, Val Loss: 0.4960
Epoch [817/1000], Loss: 0.2183, Val Loss: 0.4846
Epoch [818/1000], Loss: 0.1956, Val Loss: 0.4996
Epoch [819/1000], Loss: 0.1737, Val Loss: 0.4841
Epoch [820/1000], Loss: 0.2421, Val Loss: 0.5061
Epoch [821/1000], Loss: 0.2096, Val Loss: 0.5068
Epoch [822/1000], Loss: 0.3119, Val Loss: 0.5010
Epoch [823/1000], Loss: 0.1971, Val Loss: 0.4891
Epoch [824/1000], Loss: 0.2039, Val Loss: 0.5242
Epoch [825/1000], Loss: 0.2404, Val Loss: 0.4840
Epoch [826/1000], Loss: 0.2275, Val Loss: 0.4875
Epoch [827/1000], Loss: 0.1596, Val Loss: 0.5089
Epoch [828/1000], Loss: 0.1767, Val Loss: 0.4860
Epoch [829/1000], Loss: 0.2622, Val Loss: 0.5379
Epoch [830/1000], Loss: 0.2607, Val Loss: 0.5246
Epoch [831/1000], Loss: 0.1074, Val Loss: 0.5103
Epoch [832/1000], Loss: 0.2103, Val Loss: 0.4841
Epoch [833/1000], Loss: 0.1865, Val Loss: 0.4766
Epoch [834/1000], Loss: 0.3044, Val Loss: 0.5064
Epoch [835/1000], Loss: 0.2959, Val Loss: 0.5324
Epoch [836/1000], Loss: 0.2964, Val Loss: 0.4964
Epoch [837/1000], Loss: 0.1821, Val Loss: 0.5047
Epoch [838/1000], Loss: 0.2640, Val Loss: 0.4683
Epoch [839/1000], Loss: 0.3223, Val Loss: 0.5120
Epoch [840/1000], Loss: 0.3283, Val Loss: 0.4857
Epoch [841/1000], Loss: 0.2269, Val Loss: 0.4900
Epoch [842/1000], Loss: 0.1839, Val Loss: 0.5061
Epoch [843/1000], Loss: 0.1838, Val Loss: 0.5002
Epoch [844/1000], Loss: 0.2755, Val Loss: 0.5011
Epoch [845/1000], Loss: 0.1418, Val Loss: 0.5131
Epoch [846/1000], Loss: 0.1532, Val Loss: 0.4807
Epoch [847/1000], Loss: 0.2018, Val Loss: 0.4937
Epoch [848/1000], Loss: 0.2300, Val Loss: 0.4866
Epoch [849/1000], Loss: 0.1747, Val Loss: 0.4927
Epoch [850/1000], Loss: 0.1780, Val Loss: 0.4788
Epoch [851/1000], Loss: 0.3288, Val Loss: 0.4937
Epoch [852/1000], Loss: 0.2293, Val Loss: 0.5210
Epoch [853/1000], Loss: 0.3835, Val Loss: 0.4908
Epoch [854/1000], Loss: 0.2529, Val Loss: 0.5094
Epoch [855/1000], Loss: 0.2098, Val Loss: 0.4889
Epoch [856/1000], Loss: 0.2031, Val Loss: 0.5008
Epoch [857/1000], Loss: 0.3059, Val Loss: 0.5822
Epoch [858/1000], Loss: 0.1692, Val Loss: 0.5324
Epoch [859/1000], Loss: 0.3276, Val Loss: 0.5080
Epoch [860/1000], Loss: 0.3446, Val Loss: 0.5071
Epoch [861/1000], Loss: 1.0174, Val Loss: 0.5999
Epoch [862/1000], Loss: 0.1668, Val Loss: 0.5005
Epoch [863/1000], Loss: 0.1746, Val Loss: 0.4911
Epoch [864/1000], Loss: 0.2781, Val Loss: 0.5372
Epoch [865/1000], Loss: 0.2729, Val Loss: 0.5284
Epoch [866/1000], Loss: 0.2188, Val Loss: 0.5016
Epoch [867/1000], Loss: 0.2293, Val Loss: 0.4950
Epoch [868/1000], Loss: 0.1705, Val Loss: 0.5038
Epoch [869/1000], Loss: 0.2436, Val Loss: 0.5021
Epoch [870/1000], Loss: 0.2145, Val Loss: 0.5126
Epoch [871/1000], Loss: 0.2140, Val Loss: 0.5168
Epoch [872/1000], Loss: 0.1983, Val Loss: 0.5103
Epoch [873/1000], Loss: 0.2045, Val Loss: 0.5141
Epoch [874/1000], Loss: 0.1461, Val Loss: 0.5175
Epoch [875/1000], Loss: 0.1980, Val Loss: 0.5127
Epoch [876/1000], Loss: 0.2146, Val Loss: 0.5394
Epoch [877/1000], Loss: 0.1764, Val Loss: 0.5243
Epoch [878/1000], Loss: 0.2341, Val Loss: 0.5109
Epoch [879/1000], Loss: 0.2001, Val Loss: 0.4983
Epoch [880/1000], Loss: 0.2555, Val Loss: 0.4999
Epoch [881/1000], Loss: 0.1832, Val Loss: 0.4997
Epoch [882/1000], Loss: 0.3485, Val Loss: 0.4947
Epoch [883/1000], Loss: 0.1467, Val Loss: 0.4992
Epoch [884/1000], Loss: 0.1855, Val Loss: 0.5012
Epoch [885/1000], Loss: 0.2440, Val Loss: 0.4980
Epoch [886/1000], Loss: 0.2624, Val Loss: 0.5022
Epoch [887/1000], Loss: 0.2376, Val Loss: 0.4852
Epoch [888/1000], Loss: 0.3229, Val Loss: 0.4922
Epoch [889/1000], Loss: 0.1441, Val Loss: 0.4946
Epoch [890/1000], Loss: 0.2346, Val Loss: 0.5058
Epoch [891/1000], Loss: 0.3950, Val Loss: 0.5092
Epoch [892/1000], Loss: 0.2836, Val Loss: 0.4875
Epoch [893/1000], Loss: 0.1607, Val Loss: 0.5003
Epoch [894/1000], Loss: 0.2072, Val Loss: 0.5134
Epoch [895/1000], Loss: 0.1974, Val Loss: 0.4891
Epoch [896/1000], Loss: 0.2084, Val Loss: 0.4776
Epoch [897/1000], Loss: 0.3421, Val Loss: 0.4966
Epoch [898/1000], Loss: 0.1990, Val Loss: 0.4956
Epoch [899/1000], Loss: 0.1647, Val Loss: 0.4907
Epoch [900/1000], Loss: 0.1663, Val Loss: 0.4962
Epoch [901/1000], Loss: 0.2093, Val Loss: 0.5194
Epoch [902/1000], Loss: 0.1679, Val Loss: 0.5174
Epoch [903/1000], Loss: 0.1788, Val Loss: 0.4880
Epoch [904/1000], Loss: 0.2415, Val Loss: 0.5001
Epoch [905/1000], Loss: 0.2363, Val Loss: 0.4876
Epoch [906/1000], Loss: 0.1676, Val Loss: 0.5204
Epoch [907/1000], Loss: 0.2947, Val Loss: 0.5017
Epoch [908/1000], Loss: 0.4005, Val Loss: 0.5473
Epoch [909/1000], Loss: 0.4105, Val Loss: 0.5020
Epoch [910/1000], Loss: 0.2016, Val Loss: 0.4966
Epoch [911/1000], Loss: 0.3213, Val Loss: 0.5359
Epoch [912/1000], Loss: 0.3457, Val Loss: 0.5025
Epoch [913/1000], Loss: 0.1552, Val Loss: 0.5478
Epoch [914/1000], Loss: 1.4401, Val Loss: 0.5591
Epoch [915/1000], Loss: 0.3034, Val Loss: 0.6050
Epoch [916/1000], Loss: 0.3325, Val Loss: 0.5333
Epoch [917/1000], Loss: 0.2053, Val Loss: 0.4886
Epoch [918/1000], Loss: 0.2999, Val Loss: 0.5204
Epoch [919/1000], Loss: 0.1727, Val Loss: 0.5123
Epoch [920/1000], Loss: 0.1774, Val Loss: 0.5014
Epoch [921/1000], Loss: 0.2518, Val Loss: 0.5323
Epoch [922/1000], Loss: 0.2046, Val Loss: 0.5009
Epoch [923/1000], Loss: 0.1631, Val Loss: 0.5199
Epoch [924/1000], Loss: 0.2486, Val Loss: 0.4881
Epoch [925/1000], Loss: 0.2112, Val Loss: 0.5420
Epoch [926/1000], Loss: 0.2558, Val Loss: 0.5033
Epoch [927/1000], Loss: 0.1978, Val Loss: 0.4785
Epoch [928/1000], Loss: 0.2073, Val Loss: 0.5026
Epoch [929/1000], Loss: 0.1908, Val Loss: 0.5146
Epoch [930/1000], Loss: 0.1673, Val Loss: 0.5014
Epoch [931/1000], Loss: 0.2547, Val Loss: 0.4947
Epoch [932/1000], Loss: 0.1383, Val Loss: 0.4893
Epoch [933/1000], Loss: 0.2016, Val Loss: 0.4967
Epoch [934/1000], Loss: 0.2134, Val Loss: 0.4842
Epoch [935/1000], Loss: 0.2263, Val Loss: 0.5106
Epoch [936/1000], Loss: 0.1823, Val Loss: 0.4970
Epoch [937/1000], Loss: 0.2290, Val Loss: 0.5066
Early stopping at epoch 937
Runtime: 0:04:08.017560
R^2 Score: 0.9131
RMSE: 0.6675
MAE: 0.1836
MAPE: 16.37%
